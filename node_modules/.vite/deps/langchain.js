import {
  $ZodAny,
  $ZodArray,
  $ZodBase64,
  $ZodBase64URL,
  $ZodBigInt,
  $ZodBigIntFormat,
  $ZodBoolean,
  $ZodCIDRv4,
  $ZodCIDRv6,
  $ZodCUID,
  $ZodCUID2,
  $ZodCatch,
  $ZodCheck,
  $ZodCodec,
  $ZodCustom,
  $ZodCustomStringFormat,
  $ZodDate,
  $ZodDefault,
  $ZodDiscriminatedUnion,
  $ZodE164,
  $ZodEmail,
  $ZodEmoji,
  $ZodEncodeError,
  $ZodEnum,
  $ZodError,
  $ZodExactOptional,
  $ZodFile,
  $ZodFunction,
  $ZodGUID,
  $ZodIPv4,
  $ZodIPv6,
  $ZodISODate,
  $ZodISODateTime,
  $ZodISODuration,
  $ZodISOTime,
  $ZodIntersection,
  $ZodJWT,
  $ZodKSUID,
  $ZodLazy,
  $ZodLiteral,
  $ZodMAC,
  $ZodMap,
  $ZodNaN,
  $ZodNanoID,
  $ZodNever,
  $ZodNonOptional,
  $ZodNull,
  $ZodNullable,
  $ZodNumber,
  $ZodNumberFormat,
  $ZodObjectJIT,
  $ZodOptional,
  $ZodPipe,
  $ZodPrefault,
  $ZodPromise,
  $ZodReadonly,
  $ZodRecord,
  $ZodRegistry,
  $ZodSet,
  $ZodString,
  $ZodStringFormat,
  $ZodSuccess,
  $ZodSymbol,
  $ZodTemplateLiteral,
  $ZodTransform,
  $ZodTuple,
  $ZodType,
  $ZodULID,
  $ZodURL,
  $ZodUUID,
  $ZodUndefined,
  $ZodUnion,
  $ZodUnknown,
  $ZodVoid,
  $ZodXID,
  $ZodXor,
  $brand,
  $constructor,
  $input,
  $output,
  AIMessage,
  AIMessageChunk,
  AsyncCaller,
  AsyncGeneratorWithSetup,
  AsyncLocalStorageProviderSingleton,
  BaseCallbackHandler,
  BaseMessage,
  BaseMessageChunk,
  BaseTracer,
  CallbackManager,
  ChatGenerationChunk,
  ChatMessage,
  ChatMessageChunk,
  Client,
  DEFAULT_MERGE_IGNORE_KEYS,
  Document,
  FunctionMessage,
  FunctionMessageChunk,
  GenerationChunk,
  Graph,
  HumanMessage,
  HumanMessageChunk,
  IterableReadableStream,
  NEVER,
  RUN_KEY,
  RemoveMessage,
  Runnable,
  RunnableAssign,
  RunnableBinding,
  RunnableEach,
  RunnableLambda,
  RunnableMap,
  RunnableParallel,
  RunnablePick,
  RunnableRetry,
  RunnableSequence,
  RunnableToolLike,
  RunnableWithFallbacks,
  Serializable,
  SystemMessage,
  SystemMessageChunk,
  TimePrecision,
  ToolInputParsingException,
  ToolMessage,
  ToolMessageChunk,
  Validator,
  __export as __export2,
  _any,
  _array,
  _base64,
  _base64url,
  _bigint,
  _boolean,
  _cidrv4,
  _cidrv6,
  _coerceToDict,
  _coerceToRunnable,
  _coercedBigint,
  _coercedBoolean,
  _coercedDate,
  _coercedNumber,
  _coercedString,
  _configHasToolCallId,
  _cuid,
  _cuid2,
  _custom,
  _date,
  _decode,
  _decodeAsync,
  _e164,
  _email,
  _emoji,
  _encode,
  _encodeAsync,
  _endsWith,
  _file,
  _float32,
  _float64,
  _gt,
  _gte,
  _guid,
  _includes,
  _int,
  _int32,
  _int64,
  _ipv4,
  _ipv6,
  _isMessageFieldWithRole,
  _isToolCall,
  _isoDate,
  _isoDateTime,
  _isoDuration,
  _isoTime,
  _jwt,
  _ksuid,
  _length,
  _lowercase,
  _lt,
  _lte,
  _mac,
  _maxLength,
  _maxSize,
  _mergeDicts,
  _mergeLists,
  _mergeObj,
  _mergeStatus,
  _mime,
  _minLength,
  _minSize,
  _multipleOf,
  _nan,
  _nanoid,
  _negative,
  _never,
  _nonnegative,
  _nonpositive,
  _normalize,
  _null,
  _number,
  _overwrite,
  _parse,
  _parseAsync,
  _positive,
  _property,
  _refine,
  _regex,
  _safeDecode,
  _safeDecodeAsync,
  _safeEncode,
  _safeEncodeAsync,
  _safeParse,
  _safeParseAsync,
  _size,
  _slugify,
  _startsWith,
  _string,
  _stringFormat,
  _stringbool,
  _superRefine,
  _symbol,
  _toLowerCase,
  _toUpperCase,
  _trim,
  _uint32,
  _uint64,
  _ulid,
  _undefined,
  _unknown,
  _uppercase,
  _url,
  _uuid,
  _uuidv4,
  _uuidv6,
  _uuidv7,
  _void,
  _xid,
  addLangChainErrorFields,
  anyProcessor,
  applyPatch,
  arrayProcessor,
  async_caller_exports,
  base_exports,
  base_exports2,
  bigintProcessor,
  booleanProcessor,
  callbackHandlerPrefersStreaming,
  catchProcessor,
  clone,
  coerceMessageLikeToMessage,
  collapseToolCallChunks,
  compare,
  concat,
  config,
  console_exports,
  convertToChunk,
  convertToOpenAIImageBlock,
  convertToProviderContentBlock,
  core_exports,
  createStandardJSONSchemaMethod,
  createToJSONSchemaMethod,
  customProcessor,
  dateProcessor,
  deepCompareStrict,
  defaultProcessor,
  defaultToolCallParser,
  describe,
  documents_exports,
  en_default,
  encodingForModel,
  ensureConfig,
  enumProcessor,
  env_exports,
  extendInteropZodObject,
  external_exports,
  fileProcessor,
  flattenError,
  formatError,
  functionProcessor,
  getAbortSignalError,
  getBufferString,
  getCallbackManagerForConfig,
  getEnvironmentVariable,
  getInteropZodDefaultGetter,
  getInteropZodObjectShape,
  getSchemaDescription,
  get_lc_unique_name,
  globalRegistry,
  graph_exports,
  iife,
  interopParse,
  interopParseAsync,
  interopSafeParse,
  interopSafeParseAsync,
  interopZodObjectMakeFieldsOptional,
  interopZodObjectPartial,
  interopZodObjectPassthrough,
  interopZodObjectStrict,
  interopZodTransformInputSchema,
  intersectionProcessor,
  isAIMessage,
  isAIMessageChunk,
  isBase64ContentBlock,
  isBaseMessage,
  isBaseMessageChunk,
  isChatMessage,
  isChatMessageChunk,
  isDataContentBlock,
  isDirectToolOutput,
  isEscapedObject,
  isFunctionMessage,
  isFunctionMessageChunk,
  isHumanMessage,
  isHumanMessageChunk,
  isIDContentBlock,
  isInteropZodError,
  isInteropZodLiteral,
  isInteropZodObject,
  isInteropZodSchema,
  isMessage,
  isOpenAIToolCallArray,
  isPlainTextContentBlock,
  isShapelessZodSchema,
  isSimpleStringZodSchema,
  isSystemMessage,
  isSystemMessageChunk,
  isToolMessage,
  isToolMessageChunk,
  isURLContentBlock,
  isZodArrayV4,
  isZodLiteralV3,
  isZodLiteralV4,
  isZodNullableV4,
  isZodObjectV3,
  isZodObjectV4,
  isZodOptionalV4,
  isZodSchema,
  isZodSchemaV3,
  isZodSchemaV4,
  jsonStringifyReplacer,
  json_schema_exports,
  keyFromJson,
  lazyProcessor,
  literalProcessor,
  locales_exports,
  log_stream_exports,
  manager_exports,
  mapChatMessagesToStoredMessages,
  mapKeys,
  mapProcessor,
  mapStoredMessageToChatMessage,
  mapStoredMessagesToChatMessages,
  mergeConfigs,
  mergeContent,
  mergeResponseMetadata,
  mergeUsageMetadata,
  meta,
  nanProcessor,
  neverProcessor,
  nonoptionalProcessor,
  nullProcessor,
  nullableProcessor,
  numberProcessor,
  objectProcessor,
  optionalProcessor,
  outputs_exports,
  parseBase64DataUrl,
  parseCallbackConfigArg,
  parseJsonMarkdown,
  parseMimeType,
  parsePartialJson,
  patchConfig,
  pickRunnableConfigKeys,
  pipeProcessor,
  prefaultProcessor,
  prettifyError,
  promiseProcessor,
  promises_exports,
  raceWithSignal,
  readonlyProcessor,
  recordProcessor,
  regexes_exports,
  registry,
  serializable_exports,
  setProcessor,
  singletons_exports,
  stream_exports,
  stringProcessor,
  successProcessor,
  symbolProcessor,
  templateLiteralProcessor,
  tiktoken_exports,
  toJSONSchema,
  toJsonSchema,
  tool_exports,
  tracer_langchain_exports,
  transformProcessor,
  treeifyError,
  tupleProcessor,
  undefinedProcessor,
  unescapeValue,
  unionProcessor,
  unknownProcessor,
  util_exports,
  v4_default,
  v5_default,
  v6,
  validate,
  validate_default,
  validatesOnlyStrings,
  voidProcessor
} from "./chunk-NAEW72CO.js";
import {
  __commonJS,
  __export,
  __toESM
} from "./chunk-V4OQ3NZ2.js";

// browser-external:node:async_hooks
var require_node_async_hooks = __commonJS({
  "browser-external:node:async_hooks"(exports, module) {
    module.exports = Object.create(new Proxy({}, {
      get(_, key) {
        if (key !== "__esModule" && key !== "__proto__" && key !== "constructor" && key !== "splice") {
          console.warn(`Module "node:async_hooks" has been externalized for browser compatibility. Cannot access "node:async_hooks.${key}" in client code. See https://vite.dev/guide/troubleshooting.html#module-externalized-for-browser-compatibility for more details.`);
        }
      }
    }));
  }
});

// node_modules/langchain/dist/_virtual/rolldown_runtime.js
var __defProp = Object.defineProperty;
var __export3 = (target, all) => {
  for (var name in all) __defProp(target, name, {
    get: all[name],
    enumerable: true
  });
};

// node_modules/@langchain/core/dist/messages/transformers.js
var _isMessageType = (msg, types) => {
  const typesAsStrings = [...new Set(types?.map((t) => {
    if (typeof t === "string") return t;
    const instantiatedMsgClass = new t({});
    if (!("getType" in instantiatedMsgClass) || typeof instantiatedMsgClass.getType !== "function") throw new Error("Invalid type provided.");
    return instantiatedMsgClass.getType();
  }))];
  const msgType = msg.getType();
  return typesAsStrings.some((t) => t === msgType);
};
function filterMessages(messagesOrOptions, options) {
  if (Array.isArray(messagesOrOptions)) return _filterMessages(messagesOrOptions, options);
  return RunnableLambda.from((input) => {
    return _filterMessages(input, messagesOrOptions);
  });
}
function _filterMessages(messages, options = {}) {
  const { includeNames, excludeNames, includeTypes, excludeTypes, includeIds, excludeIds } = options;
  const filtered = [];
  for (const msg of messages) {
    if (excludeNames && msg.name && excludeNames.includes(msg.name)) continue;
    else if (excludeTypes && _isMessageType(msg, excludeTypes)) continue;
    else if (excludeIds && msg.id && excludeIds.includes(msg.id)) continue;
    if (!(includeTypes || includeIds || includeNames)) filtered.push(msg);
    else if (includeNames && msg.name && includeNames.some((iName) => iName === msg.name)) filtered.push(msg);
    else if (includeTypes && _isMessageType(msg, includeTypes)) filtered.push(msg);
    else if (includeIds && msg.id && includeIds.some((id) => id === msg.id)) filtered.push(msg);
  }
  return filtered;
}
function mergeMessageRuns(messages) {
  if (Array.isArray(messages)) return _mergeMessageRuns(messages);
  return RunnableLambda.from(_mergeMessageRuns);
}
function _mergeMessageRuns(messages) {
  if (!messages.length) return [];
  const merged = [];
  for (const msg of messages) {
    const curr = msg;
    const last = merged.pop();
    if (!last) merged.push(curr);
    else if (curr.getType() === "tool" || !(curr.getType() === last.getType())) merged.push(last, curr);
    else {
      const lastChunk = convertToChunk(last);
      const currChunk = convertToChunk(curr);
      const mergedChunks = lastChunk.concat(currChunk);
      if (typeof lastChunk.content === "string" && typeof currChunk.content === "string") mergedChunks.content = `${lastChunk.content}
${currChunk.content}`;
      merged.push(_chunkToMsg(mergedChunks));
    }
  }
  return merged;
}
function trimMessages(messagesOrOptions, options) {
  if (Array.isArray(messagesOrOptions)) {
    const messages = messagesOrOptions;
    if (!options) throw new Error("Options parameter is required when providing messages.");
    return _trimMessagesHelper(messages, options);
  } else {
    const trimmerOptions = messagesOrOptions;
    return RunnableLambda.from((input) => _trimMessagesHelper(input, trimmerOptions)).withConfig({ runName: "trim_messages" });
  }
}
async function _trimMessagesHelper(messages, options) {
  const { maxTokens, tokenCounter, strategy = "last", allowPartial = false, endOn, startOn, includeSystem = false, textSplitter } = options;
  if (startOn && strategy === "first") throw new Error("`startOn` should only be specified if `strategy` is 'last'.");
  if (includeSystem && strategy === "first") throw new Error("`includeSystem` should only be specified if `strategy` is 'last'.");
  let listTokenCounter;
  if ("getNumTokens" in tokenCounter) listTokenCounter = async (msgs) => {
    const tokenCounts = await Promise.all(msgs.map((msg) => tokenCounter.getNumTokens(msg.content)));
    return tokenCounts.reduce((sum, count) => sum + count, 0);
  };
  else listTokenCounter = async (msgs) => tokenCounter(msgs);
  let textSplitterFunc = defaultTextSplitter;
  if (textSplitter) if ("splitText" in textSplitter) textSplitterFunc = textSplitter.splitText;
  else textSplitterFunc = async (text) => textSplitter(text);
  if (strategy === "first") return _firstMaxTokens(messages, {
    maxTokens,
    tokenCounter: listTokenCounter,
    textSplitter: textSplitterFunc,
    partialStrategy: allowPartial ? "first" : void 0,
    endOn
  });
  else if (strategy === "last") return _lastMaxTokens(messages, {
    maxTokens,
    tokenCounter: listTokenCounter,
    textSplitter: textSplitterFunc,
    allowPartial,
    includeSystem,
    startOn,
    endOn
  });
  else throw new Error(`Unrecognized strategy: '${strategy}'. Must be one of 'first' or 'last'.`);
}
async function _firstMaxTokens(messages, options) {
  const { maxTokens, tokenCounter, textSplitter, partialStrategy, endOn } = options;
  let messagesCopy = [...messages];
  let idx = 0;
  for (let i = 0; i < messagesCopy.length; i += 1) {
    const remainingMessages = i > 0 ? messagesCopy.slice(0, -i) : messagesCopy;
    if (await tokenCounter(remainingMessages) <= maxTokens) {
      idx = messagesCopy.length - i;
      break;
    }
  }
  if (idx < messagesCopy.length && partialStrategy) {
    let includedPartial = false;
    if (Array.isArray(messagesCopy[idx].content)) {
      const excluded = messagesCopy[idx];
      if (typeof excluded.content === "string") throw new Error("Expected content to be an array.");
      const numBlock = excluded.content.length;
      const reversedContent = partialStrategy === "last" ? [...excluded.content].reverse() : excluded.content;
      for (let i = 1; i <= numBlock; i += 1) {
        const partialContent = partialStrategy === "first" ? reversedContent.slice(0, i) : reversedContent.slice(-i);
        const fields = Object.fromEntries(Object.entries(excluded).filter(([k]) => k !== "type" && !k.startsWith("lc_")));
        const updatedMessage = _switchTypeToMessage(excluded.getType(), {
          ...fields,
          content: partialContent
        });
        const slicedMessages = [...messagesCopy.slice(0, idx), updatedMessage];
        if (await tokenCounter(slicedMessages) <= maxTokens) {
          messagesCopy = slicedMessages;
          idx += 1;
          includedPartial = true;
        } else break;
      }
      if (includedPartial && partialStrategy === "last") excluded.content = [...reversedContent].reverse();
    }
    if (!includedPartial) {
      const excluded = messagesCopy[idx];
      let text;
      if (Array.isArray(excluded.content) && excluded.content.some((block) => typeof block === "string" || block.type === "text")) {
        const textBlock = excluded.content.find((block) => block.type === "text" && block.text);
        text = textBlock?.text;
      } else if (typeof excluded.content === "string") text = excluded.content;
      if (text) {
        const splitTexts = await textSplitter(text);
        const numSplits = splitTexts.length;
        if (partialStrategy === "last") splitTexts.reverse();
        for (let _ = 0; _ < numSplits - 1; _ += 1) {
          splitTexts.pop();
          excluded.content = splitTexts.join("");
          if (await tokenCounter([...messagesCopy.slice(0, idx), excluded]) <= maxTokens) {
            if (partialStrategy === "last") excluded.content = [...splitTexts].reverse().join("");
            messagesCopy = [...messagesCopy.slice(0, idx), excluded];
            idx += 1;
            break;
          }
        }
      }
    }
  }
  if (endOn) {
    const endOnArr = Array.isArray(endOn) ? endOn : [endOn];
    while (idx > 0 && !_isMessageType(messagesCopy[idx - 1], endOnArr)) idx -= 1;
  }
  return messagesCopy.slice(0, idx);
}
async function _lastMaxTokens(messages, options) {
  const { allowPartial = false, includeSystem = false, endOn, startOn, ...rest } = options;
  let messagesCopy = messages.map((message) => {
    const fields = Object.fromEntries(Object.entries(message).filter(([k]) => k !== "type" && !k.startsWith("lc_")));
    return _switchTypeToMessage(message.getType(), fields, isBaseMessageChunk(message));
  });
  if (endOn) {
    const endOnArr = Array.isArray(endOn) ? endOn : [endOn];
    while (messagesCopy.length > 0 && !_isMessageType(messagesCopy[messagesCopy.length - 1], endOnArr)) messagesCopy = messagesCopy.slice(0, -1);
  }
  const swappedSystem = includeSystem && messagesCopy[0]?.getType() === "system";
  let reversed_ = swappedSystem ? messagesCopy.slice(0, 1).concat(messagesCopy.slice(1).reverse()) : messagesCopy.reverse();
  reversed_ = await _firstMaxTokens(reversed_, {
    ...rest,
    partialStrategy: allowPartial ? "last" : void 0,
    endOn: startOn
  });
  if (swappedSystem) return [reversed_[0], ...reversed_.slice(1).reverse()];
  else return reversed_.reverse();
}
var _MSG_CHUNK_MAP = {
  human: {
    message: HumanMessage,
    messageChunk: HumanMessageChunk
  },
  ai: {
    message: AIMessage,
    messageChunk: AIMessageChunk
  },
  system: {
    message: SystemMessage,
    messageChunk: SystemMessageChunk
  },
  developer: {
    message: SystemMessage,
    messageChunk: SystemMessageChunk
  },
  tool: {
    message: ToolMessage,
    messageChunk: ToolMessageChunk
  },
  function: {
    message: FunctionMessage,
    messageChunk: FunctionMessageChunk
  },
  generic: {
    message: ChatMessage,
    messageChunk: ChatMessageChunk
  },
  remove: {
    message: RemoveMessage,
    messageChunk: RemoveMessage
  }
};
function _switchTypeToMessage(messageType, fields, returnChunk) {
  let chunk;
  let msg;
  switch (messageType) {
    case "human":
      if (returnChunk) chunk = new HumanMessageChunk(fields);
      else msg = new HumanMessage(fields);
      break;
    case "ai":
      if (returnChunk) {
        let aiChunkFields = { ...fields };
        if ("tool_calls" in aiChunkFields) aiChunkFields = {
          ...aiChunkFields,
          tool_call_chunks: aiChunkFields.tool_calls?.map((tc) => ({
            ...tc,
            type: "tool_call_chunk",
            index: void 0,
            args: JSON.stringify(tc.args)
          }))
        };
        chunk = new AIMessageChunk(aiChunkFields);
      } else msg = new AIMessage(fields);
      break;
    case "system":
      if (returnChunk) chunk = new SystemMessageChunk(fields);
      else msg = new SystemMessage(fields);
      break;
    case "developer":
      if (returnChunk) chunk = new SystemMessageChunk({
        ...fields,
        additional_kwargs: {
          ...fields.additional_kwargs,
          __openai_role__: "developer"
        }
      });
      else msg = new SystemMessage({
        ...fields,
        additional_kwargs: {
          ...fields.additional_kwargs,
          __openai_role__: "developer"
        }
      });
      break;
    case "tool":
      if ("tool_call_id" in fields) if (returnChunk) chunk = new ToolMessageChunk(fields);
      else msg = new ToolMessage(fields);
      else throw new Error("Can not convert ToolMessage to ToolMessageChunk if 'tool_call_id' field is not defined.");
      break;
    case "function":
      if (returnChunk) chunk = new FunctionMessageChunk(fields);
      else {
        if (!fields.name) throw new Error("FunctionMessage must have a 'name' field");
        msg = new FunctionMessage(fields);
      }
      break;
    case "generic":
      if ("role" in fields) if (returnChunk) chunk = new ChatMessageChunk(fields);
      else msg = new ChatMessage(fields);
      else throw new Error("Can not convert ChatMessage to ChatMessageChunk if 'role' field is not defined.");
      break;
    default:
      throw new Error(`Unrecognized message type ${messageType}`);
  }
  if (returnChunk && chunk) return chunk;
  if (msg) return msg;
  throw new Error(`Unrecognized message type ${messageType}`);
}
function _chunkToMsg(chunk) {
  const chunkType = chunk.getType();
  let msg;
  const fields = Object.fromEntries(Object.entries(chunk).filter(([k]) => !["type", "tool_call_chunks"].includes(k) && !k.startsWith("lc_")));
  if (chunkType in _MSG_CHUNK_MAP) msg = _switchTypeToMessage(chunkType, fields);
  if (!msg) throw new Error(`Unrecognized message chunk class ${chunkType}. Supported classes are ${Object.keys(_MSG_CHUNK_MAP)}`);
  return msg;
}
function defaultTextSplitter(text) {
  const splits = text.split("\n");
  return Promise.resolve([...splits.slice(0, -1).map((s) => `${s}
`), splits[splits.length - 1]]);
}

// node_modules/@langchain/core/dist/messages/content/tools.js
var KNOWN_BLOCK_TYPES = [
  "tool_call",
  "tool_call_chunk",
  "invalid_tool_call",
  "server_tool_call",
  "server_tool_call_chunk",
  "server_tool_call_result"
];

// node_modules/@langchain/core/dist/messages/content/multimodal.js
var KNOWN_BLOCK_TYPES2 = [
  "image",
  "video",
  "audio",
  "text-plain",
  "file"
];

// node_modules/@langchain/core/dist/messages/content/index.js
var KNOWN_BLOCK_TYPES$2 = [
  "text",
  "reasoning",
  ...KNOWN_BLOCK_TYPES,
  ...KNOWN_BLOCK_TYPES2
];

// node_modules/@langchain/core/dist/messages/index.js
var messages_exports = {};
__export2(messages_exports, {
  AIMessage: () => AIMessage,
  AIMessageChunk: () => AIMessageChunk,
  BaseMessage: () => BaseMessage,
  BaseMessageChunk: () => BaseMessageChunk,
  ChatMessage: () => ChatMessage,
  ChatMessageChunk: () => ChatMessageChunk,
  DEFAULT_MERGE_IGNORE_KEYS: () => DEFAULT_MERGE_IGNORE_KEYS,
  FunctionMessage: () => FunctionMessage,
  FunctionMessageChunk: () => FunctionMessageChunk,
  HumanMessage: () => HumanMessage,
  HumanMessageChunk: () => HumanMessageChunk,
  KNOWN_BLOCK_TYPES: () => KNOWN_BLOCK_TYPES$2,
  RemoveMessage: () => RemoveMessage,
  SystemMessage: () => SystemMessage,
  SystemMessageChunk: () => SystemMessageChunk,
  ToolMessage: () => ToolMessage,
  ToolMessageChunk: () => ToolMessageChunk,
  _isMessageFieldWithRole: () => _isMessageFieldWithRole,
  _mergeDicts: () => _mergeDicts,
  _mergeLists: () => _mergeLists,
  _mergeObj: () => _mergeObj,
  _mergeStatus: () => _mergeStatus,
  coerceMessageLikeToMessage: () => coerceMessageLikeToMessage,
  collapseToolCallChunks: () => collapseToolCallChunks,
  convertToChunk: () => convertToChunk,
  convertToOpenAIImageBlock: () => convertToOpenAIImageBlock,
  convertToProviderContentBlock: () => convertToProviderContentBlock,
  defaultTextSplitter: () => defaultTextSplitter,
  defaultToolCallParser: () => defaultToolCallParser,
  filterMessages: () => filterMessages,
  getBufferString: () => getBufferString,
  iife: () => iife,
  isAIMessage: () => isAIMessage,
  isAIMessageChunk: () => isAIMessageChunk,
  isBase64ContentBlock: () => isBase64ContentBlock,
  isBaseMessage: () => isBaseMessage,
  isBaseMessageChunk: () => isBaseMessageChunk,
  isChatMessage: () => isChatMessage,
  isChatMessageChunk: () => isChatMessageChunk,
  isDataContentBlock: () => isDataContentBlock,
  isDirectToolOutput: () => isDirectToolOutput,
  isFunctionMessage: () => isFunctionMessage,
  isFunctionMessageChunk: () => isFunctionMessageChunk,
  isHumanMessage: () => isHumanMessage,
  isHumanMessageChunk: () => isHumanMessageChunk,
  isIDContentBlock: () => isIDContentBlock,
  isMessage: () => isMessage,
  isOpenAIToolCallArray: () => isOpenAIToolCallArray,
  isPlainTextContentBlock: () => isPlainTextContentBlock,
  isSystemMessage: () => isSystemMessage,
  isSystemMessageChunk: () => isSystemMessageChunk,
  isToolMessage: () => isToolMessage,
  isToolMessageChunk: () => isToolMessageChunk,
  isURLContentBlock: () => isURLContentBlock,
  mapChatMessagesToStoredMessages: () => mapChatMessagesToStoredMessages,
  mapStoredMessageToChatMessage: () => mapStoredMessageToChatMessage,
  mapStoredMessagesToChatMessages: () => mapStoredMessagesToChatMessages,
  mergeContent: () => mergeContent,
  mergeMessageRuns: () => mergeMessageRuns,
  mergeResponseMetadata: () => mergeResponseMetadata,
  mergeUsageMetadata: () => mergeUsageMetadata,
  parseBase64DataUrl: () => parseBase64DataUrl,
  parseMimeType: () => parseMimeType,
  trimMessages: () => trimMessages
});

// node_modules/@langchain/core/dist/prompt_values.js
var prompt_values_exports = {};
__export2(prompt_values_exports, {
  BasePromptValue: () => BasePromptValue,
  ChatPromptValue: () => ChatPromptValue,
  ImagePromptValue: () => ImagePromptValue,
  StringPromptValue: () => StringPromptValue
});
var BasePromptValue = class extends Serializable {
};
var StringPromptValue = class extends BasePromptValue {
  static lc_name() {
    return "StringPromptValue";
  }
  lc_namespace = ["langchain_core", "prompt_values"];
  lc_serializable = true;
  value;
  constructor(value) {
    super({ value });
    this.value = value;
  }
  toString() {
    return this.value;
  }
  toChatMessages() {
    return [new HumanMessage(this.value)];
  }
};
var ChatPromptValue = class extends BasePromptValue {
  lc_namespace = ["langchain_core", "prompt_values"];
  lc_serializable = true;
  static lc_name() {
    return "ChatPromptValue";
  }
  messages;
  constructor(fields) {
    if (Array.isArray(fields)) fields = { messages: fields };
    super(fields);
    this.messages = fields.messages;
  }
  toString() {
    return getBufferString(this.messages);
  }
  toChatMessages() {
    return this.messages;
  }
};
var ImagePromptValue = class extends BasePromptValue {
  lc_namespace = ["langchain_core", "prompt_values"];
  lc_serializable = true;
  static lc_name() {
    return "ImagePromptValue";
  }
  imageUrl;
  /** @ignore */
  value;
  constructor(fields) {
    if (!("imageUrl" in fields)) fields = { imageUrl: fields };
    super(fields);
    this.imageUrl = fields.imageUrl;
  }
  toString() {
    return this.imageUrl.url;
  }
  toChatMessages() {
    return [new HumanMessage({ content: [{
      type: "image_url",
      image_url: {
        detail: this.imageUrl.detail,
        url: this.imageUrl.url
      }
    }] })];
  }
};

// node_modules/@langchain/core/dist/utils/js-sha256/hash.js
var HEX_CHARS = "0123456789abcdef".split("");
var EXTRA = [
  -2147483648,
  8388608,
  32768,
  128
];
var SHIFT = [
  24,
  16,
  8,
  0
];
var K = [
  1116352408,
  1899447441,
  3049323471,
  3921009573,
  961987163,
  1508970993,
  2453635748,
  2870763221,
  3624381080,
  310598401,
  607225278,
  1426881987,
  1925078388,
  2162078206,
  2614888103,
  3248222580,
  3835390401,
  4022224774,
  264347078,
  604807628,
  770255983,
  1249150122,
  1555081692,
  1996064986,
  2554220882,
  2821834349,
  2952996808,
  3210313671,
  3336571891,
  3584528711,
  113926993,
  338241895,
  666307205,
  773529912,
  1294757372,
  1396182291,
  1695183700,
  1986661051,
  2177026350,
  2456956037,
  2730485921,
  2820302411,
  3259730800,
  3345764771,
  3516065817,
  3600352804,
  4094571909,
  275423344,
  430227734,
  506948616,
  659060556,
  883997877,
  958139571,
  1322822218,
  1537002063,
  1747873779,
  1955562222,
  2024104815,
  2227730452,
  2361852424,
  2428436474,
  2756734187,
  3204031479,
  3329325298
];
var blocks = [];
function Sha256(is224, sharedMemory) {
  if (sharedMemory) {
    blocks[0] = blocks[16] = blocks[1] = blocks[2] = blocks[3] = blocks[4] = blocks[5] = blocks[6] = blocks[7] = blocks[8] = blocks[9] = blocks[10] = blocks[11] = blocks[12] = blocks[13] = blocks[14] = blocks[15] = 0;
    this.blocks = blocks;
  } else this.blocks = [
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0,
    0
  ];
  if (is224) {
    this.h0 = 3238371032;
    this.h1 = 914150663;
    this.h2 = 812702999;
    this.h3 = 4144912697;
    this.h4 = 4290775857;
    this.h5 = 1750603025;
    this.h6 = 1694076839;
    this.h7 = 3204075428;
  } else {
    this.h0 = 1779033703;
    this.h1 = 3144134277;
    this.h2 = 1013904242;
    this.h3 = 2773480762;
    this.h4 = 1359893119;
    this.h5 = 2600822924;
    this.h6 = 528734635;
    this.h7 = 1541459225;
  }
  this.block = this.start = this.bytes = this.hBytes = 0;
  this.finalized = this.hashed = false;
  this.first = true;
  this.is224 = is224;
}
Sha256.prototype.update = function(message) {
  if (this.finalized) return;
  var notString, type = typeof message;
  if (type !== "string") {
    if (type === "object") {
      if (message === null) throw new Error(ERROR);
      else if (ARRAY_BUFFER && message.constructor === ArrayBuffer) message = new Uint8Array(message);
      else if (!Array.isArray(message)) {
        if (!ARRAY_BUFFER || !ArrayBuffer.isView(message)) throw new Error(ERROR);
      }
    } else throw new Error(ERROR);
    notString = true;
  }
  var code, index2 = 0, i, length = message.length, blocks$1 = this.blocks;
  while (index2 < length) {
    if (this.hashed) {
      this.hashed = false;
      blocks$1[0] = this.block;
      this.block = blocks$1[16] = blocks$1[1] = blocks$1[2] = blocks$1[3] = blocks$1[4] = blocks$1[5] = blocks$1[6] = blocks$1[7] = blocks$1[8] = blocks$1[9] = blocks$1[10] = blocks$1[11] = blocks$1[12] = blocks$1[13] = blocks$1[14] = blocks$1[15] = 0;
    }
    if (notString) for (i = this.start; index2 < length && i < 64; ++index2) blocks$1[i >>> 2] |= message[index2] << SHIFT[i++ & 3];
    else for (i = this.start; index2 < length && i < 64; ++index2) {
      code = message.charCodeAt(index2);
      if (code < 128) blocks$1[i >>> 2] |= code << SHIFT[i++ & 3];
      else if (code < 2048) {
        blocks$1[i >>> 2] |= (192 | code >>> 6) << SHIFT[i++ & 3];
        blocks$1[i >>> 2] |= (128 | code & 63) << SHIFT[i++ & 3];
      } else if (code < 55296 || code >= 57344) {
        blocks$1[i >>> 2] |= (224 | code >>> 12) << SHIFT[i++ & 3];
        blocks$1[i >>> 2] |= (128 | code >>> 6 & 63) << SHIFT[i++ & 3];
        blocks$1[i >>> 2] |= (128 | code & 63) << SHIFT[i++ & 3];
      } else {
        code = 65536 + ((code & 1023) << 10 | message.charCodeAt(++index2) & 1023);
        blocks$1[i >>> 2] |= (240 | code >>> 18) << SHIFT[i++ & 3];
        blocks$1[i >>> 2] |= (128 | code >>> 12 & 63) << SHIFT[i++ & 3];
        blocks$1[i >>> 2] |= (128 | code >>> 6 & 63) << SHIFT[i++ & 3];
        blocks$1[i >>> 2] |= (128 | code & 63) << SHIFT[i++ & 3];
      }
    }
    this.lastByteIndex = i;
    this.bytes += i - this.start;
    if (i >= 64) {
      this.block = blocks$1[16];
      this.start = i - 64;
      this.hash();
      this.hashed = true;
    } else this.start = i;
  }
  if (this.bytes > 4294967295) {
    this.hBytes += this.bytes / 4294967296 << 0;
    this.bytes = this.bytes % 4294967296;
  }
  return this;
};
Sha256.prototype.finalize = function() {
  if (this.finalized) return;
  this.finalized = true;
  var blocks$1 = this.blocks, i = this.lastByteIndex;
  blocks$1[16] = this.block;
  blocks$1[i >>> 2] |= EXTRA[i & 3];
  this.block = blocks$1[16];
  if (i >= 56) {
    if (!this.hashed) this.hash();
    blocks$1[0] = this.block;
    blocks$1[16] = blocks$1[1] = blocks$1[2] = blocks$1[3] = blocks$1[4] = blocks$1[5] = blocks$1[6] = blocks$1[7] = blocks$1[8] = blocks$1[9] = blocks$1[10] = blocks$1[11] = blocks$1[12] = blocks$1[13] = blocks$1[14] = blocks$1[15] = 0;
  }
  blocks$1[14] = this.hBytes << 3 | this.bytes >>> 29;
  blocks$1[15] = this.bytes << 3;
  this.hash();
};
Sha256.prototype.hash = function() {
  var a = this.h0, b = this.h1, c = this.h2, d = this.h3, e = this.h4, f = this.h5, g = this.h6, h = this.h7, blocks$1 = this.blocks, j, s0, s1, maj, t1, t2, ch, ab, da, cd, bc;
  for (j = 16; j < 64; ++j) {
    t1 = blocks$1[j - 15];
    s0 = (t1 >>> 7 | t1 << 25) ^ (t1 >>> 18 | t1 << 14) ^ t1 >>> 3;
    t1 = blocks$1[j - 2];
    s1 = (t1 >>> 17 | t1 << 15) ^ (t1 >>> 19 | t1 << 13) ^ t1 >>> 10;
    blocks$1[j] = blocks$1[j - 16] + s0 + blocks$1[j - 7] + s1 << 0;
  }
  bc = b & c;
  for (j = 0; j < 64; j += 4) {
    if (this.first) {
      if (this.is224) {
        ab = 300032;
        t1 = blocks$1[0] - 1413257819;
        h = t1 - 150054599 << 0;
        d = t1 + 24177077 << 0;
      } else {
        ab = 704751109;
        t1 = blocks$1[0] - 210244248;
        h = t1 - 1521486534 << 0;
        d = t1 + 143694565 << 0;
      }
      this.first = false;
    } else {
      s0 = (a >>> 2 | a << 30) ^ (a >>> 13 | a << 19) ^ (a >>> 22 | a << 10);
      s1 = (e >>> 6 | e << 26) ^ (e >>> 11 | e << 21) ^ (e >>> 25 | e << 7);
      ab = a & b;
      maj = ab ^ a & c ^ bc;
      ch = e & f ^ ~e & g;
      t1 = h + s1 + ch + K[j] + blocks$1[j];
      t2 = s0 + maj;
      h = d + t1 << 0;
      d = t1 + t2 << 0;
    }
    s0 = (d >>> 2 | d << 30) ^ (d >>> 13 | d << 19) ^ (d >>> 22 | d << 10);
    s1 = (h >>> 6 | h << 26) ^ (h >>> 11 | h << 21) ^ (h >>> 25 | h << 7);
    da = d & a;
    maj = da ^ d & b ^ ab;
    ch = g & h ^ ~g & e;
    t1 = f + s1 + ch + K[j + 1] + blocks$1[j + 1];
    t2 = s0 + maj;
    g = c + t1 << 0;
    c = t1 + t2 << 0;
    s0 = (c >>> 2 | c << 30) ^ (c >>> 13 | c << 19) ^ (c >>> 22 | c << 10);
    s1 = (g >>> 6 | g << 26) ^ (g >>> 11 | g << 21) ^ (g >>> 25 | g << 7);
    cd = c & d;
    maj = cd ^ c & a ^ da;
    ch = f & g ^ ~f & h;
    t1 = e + s1 + ch + K[j + 2] + blocks$1[j + 2];
    t2 = s0 + maj;
    f = b + t1 << 0;
    b = t1 + t2 << 0;
    s0 = (b >>> 2 | b << 30) ^ (b >>> 13 | b << 19) ^ (b >>> 22 | b << 10);
    s1 = (f >>> 6 | f << 26) ^ (f >>> 11 | f << 21) ^ (f >>> 25 | f << 7);
    bc = b & c;
    maj = bc ^ b & d ^ cd;
    ch = f & g ^ ~f & h;
    t1 = e + s1 + ch + K[j + 3] + blocks$1[j + 3];
    t2 = s0 + maj;
    e = a + t1 << 0;
    a = t1 + t2 << 0;
    this.chromeBugWorkAround = true;
  }
  this.h0 = this.h0 + a << 0;
  this.h1 = this.h1 + b << 0;
  this.h2 = this.h2 + c << 0;
  this.h3 = this.h3 + d << 0;
  this.h4 = this.h4 + e << 0;
  this.h5 = this.h5 + f << 0;
  this.h6 = this.h6 + g << 0;
  this.h7 = this.h7 + h << 0;
};
Sha256.prototype.hex = function() {
  this.finalize();
  var h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3, h4 = this.h4, h5 = this.h5, h6 = this.h6, h7 = this.h7;
  var hex2 = HEX_CHARS[h0 >>> 28 & 15] + HEX_CHARS[h0 >>> 24 & 15] + HEX_CHARS[h0 >>> 20 & 15] + HEX_CHARS[h0 >>> 16 & 15] + HEX_CHARS[h0 >>> 12 & 15] + HEX_CHARS[h0 >>> 8 & 15] + HEX_CHARS[h0 >>> 4 & 15] + HEX_CHARS[h0 & 15] + HEX_CHARS[h1 >>> 28 & 15] + HEX_CHARS[h1 >>> 24 & 15] + HEX_CHARS[h1 >>> 20 & 15] + HEX_CHARS[h1 >>> 16 & 15] + HEX_CHARS[h1 >>> 12 & 15] + HEX_CHARS[h1 >>> 8 & 15] + HEX_CHARS[h1 >>> 4 & 15] + HEX_CHARS[h1 & 15] + HEX_CHARS[h2 >>> 28 & 15] + HEX_CHARS[h2 >>> 24 & 15] + HEX_CHARS[h2 >>> 20 & 15] + HEX_CHARS[h2 >>> 16 & 15] + HEX_CHARS[h2 >>> 12 & 15] + HEX_CHARS[h2 >>> 8 & 15] + HEX_CHARS[h2 >>> 4 & 15] + HEX_CHARS[h2 & 15] + HEX_CHARS[h3 >>> 28 & 15] + HEX_CHARS[h3 >>> 24 & 15] + HEX_CHARS[h3 >>> 20 & 15] + HEX_CHARS[h3 >>> 16 & 15] + HEX_CHARS[h3 >>> 12 & 15] + HEX_CHARS[h3 >>> 8 & 15] + HEX_CHARS[h3 >>> 4 & 15] + HEX_CHARS[h3 & 15] + HEX_CHARS[h4 >>> 28 & 15] + HEX_CHARS[h4 >>> 24 & 15] + HEX_CHARS[h4 >>> 20 & 15] + HEX_CHARS[h4 >>> 16 & 15] + HEX_CHARS[h4 >>> 12 & 15] + HEX_CHARS[h4 >>> 8 & 15] + HEX_CHARS[h4 >>> 4 & 15] + HEX_CHARS[h4 & 15] + HEX_CHARS[h5 >>> 28 & 15] + HEX_CHARS[h5 >>> 24 & 15] + HEX_CHARS[h5 >>> 20 & 15] + HEX_CHARS[h5 >>> 16 & 15] + HEX_CHARS[h5 >>> 12 & 15] + HEX_CHARS[h5 >>> 8 & 15] + HEX_CHARS[h5 >>> 4 & 15] + HEX_CHARS[h5 & 15] + HEX_CHARS[h6 >>> 28 & 15] + HEX_CHARS[h6 >>> 24 & 15] + HEX_CHARS[h6 >>> 20 & 15] + HEX_CHARS[h6 >>> 16 & 15] + HEX_CHARS[h6 >>> 12 & 15] + HEX_CHARS[h6 >>> 8 & 15] + HEX_CHARS[h6 >>> 4 & 15] + HEX_CHARS[h6 & 15];
  if (!this.is224) hex2 += HEX_CHARS[h7 >>> 28 & 15] + HEX_CHARS[h7 >>> 24 & 15] + HEX_CHARS[h7 >>> 20 & 15] + HEX_CHARS[h7 >>> 16 & 15] + HEX_CHARS[h7 >>> 12 & 15] + HEX_CHARS[h7 >>> 8 & 15] + HEX_CHARS[h7 >>> 4 & 15] + HEX_CHARS[h7 & 15];
  return hex2;
};
Sha256.prototype.toString = Sha256.prototype.hex;
Sha256.prototype.digest = function() {
  this.finalize();
  var h0 = this.h0, h1 = this.h1, h2 = this.h2, h3 = this.h3, h4 = this.h4, h5 = this.h5, h6 = this.h6, h7 = this.h7;
  var arr2 = [
    h0 >>> 24 & 255,
    h0 >>> 16 & 255,
    h0 >>> 8 & 255,
    h0 & 255,
    h1 >>> 24 & 255,
    h1 >>> 16 & 255,
    h1 >>> 8 & 255,
    h1 & 255,
    h2 >>> 24 & 255,
    h2 >>> 16 & 255,
    h2 >>> 8 & 255,
    h2 & 255,
    h3 >>> 24 & 255,
    h3 >>> 16 & 255,
    h3 >>> 8 & 255,
    h3 & 255,
    h4 >>> 24 & 255,
    h4 >>> 16 & 255,
    h4 >>> 8 & 255,
    h4 & 255,
    h5 >>> 24 & 255,
    h5 >>> 16 & 255,
    h5 >>> 8 & 255,
    h5 & 255,
    h6 >>> 24 & 255,
    h6 >>> 16 & 255,
    h6 >>> 8 & 255,
    h6 & 255
  ];
  if (!this.is224) arr2.push(h7 >>> 24 & 255, h7 >>> 16 & 255, h7 >>> 8 & 255, h7 & 255);
  return arr2;
};
Sha256.prototype.array = Sha256.prototype.digest;
Sha256.prototype.arrayBuffer = function() {
  this.finalize();
  var buffer = new ArrayBuffer(this.is224 ? 28 : 32);
  var dataView = new DataView(buffer);
  dataView.setUint32(0, this.h0);
  dataView.setUint32(4, this.h1);
  dataView.setUint32(8, this.h2);
  dataView.setUint32(12, this.h3);
  dataView.setUint32(16, this.h4);
  dataView.setUint32(20, this.h5);
  dataView.setUint32(24, this.h6);
  if (!this.is224) dataView.setUint32(28, this.h7);
  return buffer;
};
var sha256 = (...strings) => {
  return new Sha256(false, true).update(strings.join("")).hex();
};

// node_modules/@langchain/core/dist/utils/hash.js
var hash_exports = {};
__export2(hash_exports, { sha256: () => sha256 });

// node_modules/@langchain/core/dist/caches/index.js
var caches_exports = {};
__export2(caches_exports, {
  BaseCache: () => BaseCache,
  InMemoryCache: () => InMemoryCache,
  defaultHashKeyEncoder: () => defaultHashKeyEncoder,
  deserializeStoredGeneration: () => deserializeStoredGeneration,
  serializeGeneration: () => serializeGeneration
});
var defaultHashKeyEncoder = (...strings) => sha256(strings.join("_"));
function deserializeStoredGeneration(storedGeneration) {
  if (storedGeneration.message !== void 0) return {
    text: storedGeneration.text,
    message: mapStoredMessageToChatMessage(storedGeneration.message)
  };
  else return { text: storedGeneration.text };
}
function serializeGeneration(generation) {
  const serializedValue = { text: generation.text };
  if (generation.message !== void 0) serializedValue.message = generation.message.toDict();
  return serializedValue;
}
var BaseCache = class {
  keyEncoder = defaultHashKeyEncoder;
  /**
  * Sets a custom key encoder function for the cache.
  * This function should take a prompt and an LLM key and return a string
  * that will be used as the cache key.
  * @param keyEncoderFn The custom key encoder function.
  */
  makeDefaultKeyEncoder(keyEncoderFn) {
    this.keyEncoder = keyEncoderFn;
  }
};
var GLOBAL_MAP = /* @__PURE__ */ new Map();
var InMemoryCache = class InMemoryCache2 extends BaseCache {
  cache;
  constructor(map2) {
    super();
    this.cache = map2 ?? /* @__PURE__ */ new Map();
  }
  /**
  * Retrieves data from the cache using a prompt and an LLM key. If the
  * data is not found, it returns null.
  * @param prompt The prompt used to find the data.
  * @param llmKey The LLM key used to find the data.
  * @returns The data corresponding to the prompt and LLM key, or null if not found.
  */
  lookup(prompt, llmKey) {
    return Promise.resolve(this.cache.get(this.keyEncoder(prompt, llmKey)) ?? null);
  }
  /**
  * Updates the cache with new data using a prompt and an LLM key.
  * @param prompt The prompt used to store the data.
  * @param llmKey The LLM key used to store the data.
  * @param value The data to be stored.
  */
  async update(prompt, llmKey, value) {
    this.cache.set(this.keyEncoder(prompt, llmKey), value);
  }
  /**
  * Returns a global instance of InMemoryCache using a predefined global
  * map as the initial cache.
  * @returns A global instance of InMemoryCache.
  */
  static global() {
    return new InMemoryCache2(GLOBAL_MAP);
  }
};

// node_modules/@langchain/core/dist/language_models/base.js
var base_exports3 = {};
__export2(base_exports3, {
  BaseLangChain: () => BaseLangChain,
  BaseLanguageModel: () => BaseLanguageModel,
  calculateMaxTokens: () => calculateMaxTokens,
  getEmbeddingContextSize: () => getEmbeddingContextSize,
  getModelContextSize: () => getModelContextSize,
  getModelNameForTiktoken: () => getModelNameForTiktoken,
  isOpenAITool: () => isOpenAITool
});
var getModelNameForTiktoken = (modelName) => {
  if (modelName.startsWith("gpt-5")) return "gpt-5";
  if (modelName.startsWith("gpt-3.5-turbo-16k")) return "gpt-3.5-turbo-16k";
  if (modelName.startsWith("gpt-3.5-turbo-")) return "gpt-3.5-turbo";
  if (modelName.startsWith("gpt-4-32k")) return "gpt-4-32k";
  if (modelName.startsWith("gpt-4-")) return "gpt-4";
  if (modelName.startsWith("gpt-4o")) return "gpt-4o";
  return modelName;
};
var getEmbeddingContextSize = (modelName) => {
  switch (modelName) {
    case "text-embedding-ada-002":
      return 8191;
    default:
      return 2046;
  }
};
var getModelContextSize = (modelName) => {
  const normalizedName = getModelNameForTiktoken(modelName);
  switch (normalizedName) {
    case "gpt-5":
    case "gpt-5-turbo":
    case "gpt-5-turbo-preview":
      return 4e5;
    case "gpt-4o":
    case "gpt-4o-mini":
    case "gpt-4o-2024-05-13":
    case "gpt-4o-2024-08-06":
      return 128e3;
    case "gpt-4-turbo":
    case "gpt-4-turbo-preview":
    case "gpt-4-turbo-2024-04-09":
    case "gpt-4-0125-preview":
    case "gpt-4-1106-preview":
      return 128e3;
    case "gpt-4-32k":
    case "gpt-4-32k-0314":
    case "gpt-4-32k-0613":
      return 32768;
    case "gpt-4":
    case "gpt-4-0314":
    case "gpt-4-0613":
      return 8192;
    case "gpt-3.5-turbo-16k":
    case "gpt-3.5-turbo-16k-0613":
      return 16384;
    case "gpt-3.5-turbo":
    case "gpt-3.5-turbo-0301":
    case "gpt-3.5-turbo-0613":
    case "gpt-3.5-turbo-1106":
    case "gpt-3.5-turbo-0125":
      return 4096;
    case "text-davinci-003":
    case "text-davinci-002":
      return 4097;
    case "text-davinci-001":
      return 2049;
    case "text-curie-001":
    case "text-babbage-001":
    case "text-ada-001":
      return 2048;
    case "code-davinci-002":
    case "code-davinci-001":
      return 8e3;
    case "code-cushman-001":
      return 2048;
    case "claude-3-5-sonnet-20241022":
    case "claude-3-5-sonnet-20240620":
    case "claude-3-opus-20240229":
    case "claude-3-sonnet-20240229":
    case "claude-3-haiku-20240307":
    case "claude-2.1":
      return 2e5;
    case "claude-2.0":
    case "claude-instant-1.2":
      return 1e5;
    case "gemini-1.5-pro":
    case "gemini-1.5-pro-latest":
    case "gemini-1.5-flash":
    case "gemini-1.5-flash-latest":
      return 1e6;
    case "gemini-pro":
    case "gemini-pro-vision":
      return 32768;
    default:
      return 4097;
  }
};
function isOpenAITool(tool2) {
  if (typeof tool2 !== "object" || !tool2) return false;
  if ("type" in tool2 && tool2.type === "function" && "function" in tool2 && typeof tool2.function === "object" && tool2.function && "name" in tool2.function && "parameters" in tool2.function) return true;
  return false;
}
var calculateMaxTokens = async ({ prompt, modelName }) => {
  let numTokens;
  try {
    numTokens = (await encodingForModel(getModelNameForTiktoken(modelName))).encode(prompt).length;
  } catch {
    console.warn("Failed to calculate number of tokens, falling back to approximate count");
    numTokens = Math.ceil(prompt.length / 4);
  }
  const maxTokens = getModelContextSize(modelName);
  return maxTokens - numTokens;
};
var getVerbosity = () => false;
var BaseLangChain = class extends Runnable {
  /**
  * Whether to print out response text.
  */
  verbose;
  callbacks;
  tags;
  metadata;
  get lc_attributes() {
    return {
      callbacks: void 0,
      verbose: void 0
    };
  }
  constructor(params) {
    super(params);
    this.verbose = params.verbose ?? getVerbosity();
    this.callbacks = params.callbacks;
    this.tags = params.tags ?? [];
    this.metadata = params.metadata ?? {};
  }
};
var BaseLanguageModel = class extends BaseLangChain {
  /**
  * Keys that the language model accepts as call options.
  */
  get callKeys() {
    return [
      "stop",
      "timeout",
      "signal",
      "tags",
      "metadata",
      "callbacks"
    ];
  }
  /**
  * The async caller should be used by subclasses to make any async calls,
  * which will thus benefit from the concurrency and retry logic.
  */
  caller;
  cache;
  constructor({ callbacks, callbackManager, ...params }) {
    const { cache, ...rest } = params;
    super({
      callbacks: callbacks ?? callbackManager,
      ...rest
    });
    if (typeof cache === "object") this.cache = cache;
    else if (cache) this.cache = InMemoryCache.global();
    else this.cache = void 0;
    this.caller = new AsyncCaller(params ?? {});
  }
  _encoding;
  /**
  * Get the number of tokens in the content.
  * @param content The content to get the number of tokens for.
  * @returns The number of tokens in the content.
  */
  async getNumTokens(content) {
    let textContent;
    if (typeof content === "string") textContent = content;
    else
      textContent = content.map((item) => {
        if (typeof item === "string") return item;
        if (item.type === "text" && "text" in item) return item.text;
        return "";
      }).join("");
    let numTokens = Math.ceil(textContent.length / 4);
    if (!this._encoding) try {
      this._encoding = await encodingForModel("modelName" in this ? getModelNameForTiktoken(this.modelName) : "gpt2");
    } catch (error) {
      console.warn("Failed to calculate number of tokens, falling back to approximate count", error);
    }
    if (this._encoding) try {
      numTokens = this._encoding.encode(textContent).length;
    } catch (error) {
      console.warn("Failed to calculate number of tokens, falling back to approximate count", error);
    }
    return numTokens;
  }
  static _convertInputToPromptValue(input) {
    if (typeof input === "string") return new StringPromptValue(input);
    else if (Array.isArray(input)) return new ChatPromptValue(input.map(coerceMessageLikeToMessage));
    else return input;
  }
  /**
  * Get the identifying parameters of the LLM.
  */
  _identifyingParams() {
    return {};
  }
  /**
  * Create a unique cache key for a specific call to a specific language model.
  * @param callOptions Call options for the model
  * @returns A unique cache key.
  */
  _getSerializedCacheKeyParametersForCall({ config: config2, ...callOptions }) {
    const params = {
      ...this._identifyingParams(),
      ...callOptions,
      _type: this._llmType(),
      _model: this._modelType()
    };
    const filteredEntries = Object.entries(params).filter(([_, value]) => value !== void 0);
    const serializedEntries = filteredEntries.map(([key, value]) => `${key}:${JSON.stringify(value)}`).sort().join(",");
    return serializedEntries;
  }
  /**
  * @deprecated
  * Return a json-like object representing this LLM.
  */
  serialize() {
    return {
      ...this._identifyingParams(),
      _type: this._llmType(),
      _model: this._modelType()
    };
  }
  /**
  * @deprecated
  * Load an LLM from a json-like object describing it.
  */
  static async deserialize(_data) {
    throw new Error("Use .toJSON() instead");
  }
  /**
  * Return profiling information for the model.
  *
  * @returns {ModelProfile} An object describing the model's capabilities and constraints
  */
  get profile() {
    return {};
  }
};

// node_modules/@langchain/core/dist/runnables/passthrough.js
var RunnablePassthrough = class extends Runnable {
  static lc_name() {
    return "RunnablePassthrough";
  }
  lc_namespace = ["langchain_core", "runnables"];
  lc_serializable = true;
  func;
  constructor(fields) {
    super(fields);
    if (fields) this.func = fields.func;
  }
  async invoke(input, options) {
    const config2 = ensureConfig(options);
    if (this.func) await this.func(input, config2);
    return this._callWithConfig((input$1) => Promise.resolve(input$1), input, config2);
  }
  async *transform(generator, options) {
    const config2 = ensureConfig(options);
    let finalOutput;
    let finalOutputSupported = true;
    for await (const chunk of this._transformStreamWithConfig(generator, (input) => input, config2)) {
      yield chunk;
      if (finalOutputSupported) if (finalOutput === void 0) finalOutput = chunk;
      else try {
        finalOutput = concat(finalOutput, chunk);
      } catch {
        finalOutput = void 0;
        finalOutputSupported = false;
      }
    }
    if (this.func && finalOutput !== void 0) await this.func(finalOutput, config2);
  }
  /**
  * A runnable that assigns key-value pairs to the input.
  *
  * The example below shows how you could use it with an inline function.
  *
  * @example
  * ```typescript
  * const prompt =
  *   PromptTemplate.fromTemplate(`Write a SQL query to answer the question using the following schema: {schema}
  * Question: {question}
  * SQL Query:`);
  *
  * // The `RunnablePassthrough.assign()` is used here to passthrough the input from the `.invoke()`
  * // call (in this example it's the question), along with any inputs passed to the `.assign()` method.
  * // In this case, we're passing the schema.
  * const sqlQueryGeneratorChain = RunnableSequence.from([
  *   RunnablePassthrough.assign({
  *     schema: async () => db.getTableInfo(),
  *   }),
  *   prompt,
  *   new ChatOpenAI({ model: "gpt-4o-mini" }).withConfig({ stop: ["\nSQLResult:"] }),
  *   new StringOutputParser(),
  * ]);
  * const result = await sqlQueryGeneratorChain.invoke({
  *   question: "How many employees are there?",
  * });
  * ```
  */
  static assign(mapping) {
    return new RunnableAssign(new RunnableMap({ steps: mapping }));
  }
};

// node_modules/@langchain/core/dist/language_models/utils.js
var iife2 = (fn) => fn();
function castStandardMessageContent(message) {
  const Cls = message.constructor;
  return new Cls({
    ...message,
    content: message.contentBlocks,
    response_metadata: {
      ...message.response_metadata,
      output_version: "v1"
    }
  });
}

// node_modules/@langchain/core/dist/language_models/chat_models.js
var chat_models_exports = {};
__export2(chat_models_exports, {
  BaseChatModel: () => BaseChatModel,
  SimpleChatModel: () => SimpleChatModel
});
function _formatForTracing(messages) {
  const messagesToTrace = [];
  for (const message of messages) {
    let messageToTrace = message;
    if (Array.isArray(message.content)) for (let idx = 0; idx < message.content.length; idx++) {
      const block = message.content[idx];
      if (isURLContentBlock(block) || isBase64ContentBlock(block)) {
        if (messageToTrace === message) messageToTrace = new message.constructor({
          ...messageToTrace,
          content: [
            ...message.content.slice(0, idx),
            convertToOpenAIImageBlock(block),
            ...message.content.slice(idx + 1)
          ]
        });
      }
    }
    messagesToTrace.push(messageToTrace);
  }
  return messagesToTrace;
}
var BaseChatModel = class BaseChatModel2 extends BaseLanguageModel {
  lc_namespace = [
    "langchain",
    "chat_models",
    this._llmType()
  ];
  disableStreaming = false;
  outputVersion;
  get callKeys() {
    return [...super.callKeys, "outputVersion"];
  }
  constructor(fields) {
    super(fields);
    this.outputVersion = iife2(() => {
      const outputVersion = fields.outputVersion ?? getEnvironmentVariable("LC_OUTPUT_VERSION");
      if (outputVersion && ["v0", "v1"].includes(outputVersion)) return outputVersion;
      return "v0";
    });
  }
  _separateRunnableConfigFromCallOptionsCompat(options) {
    const [runnableConfig, callOptions] = super._separateRunnableConfigFromCallOptions(options);
    callOptions.signal = runnableConfig.signal;
    return [runnableConfig, callOptions];
  }
  /**
  * Invokes the chat model with a single input.
  * @param input The input for the language model.
  * @param options The call options.
  * @returns A Promise that resolves to a BaseMessageChunk.
  */
  async invoke(input, options) {
    const promptValue = BaseChatModel2._convertInputToPromptValue(input);
    const result = await this.generatePrompt([promptValue], options, options?.callbacks);
    const chatGeneration = result.generations[0][0];
    return chatGeneration.message;
  }
  async *_streamResponseChunks(_messages, _options, _runManager) {
    throw new Error("Not implemented.");
  }
  async *_streamIterator(input, options) {
    if (this._streamResponseChunks === BaseChatModel2.prototype._streamResponseChunks || this.disableStreaming) yield this.invoke(input, options);
    else {
      const prompt = BaseChatModel2._convertInputToPromptValue(input);
      const messages = prompt.toChatMessages();
      const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(options);
      const inheritableMetadata = {
        ...runnableConfig.metadata,
        ...this.getLsParams(callOptions)
      };
      const callbackManager_ = await CallbackManager.configure(runnableConfig.callbacks, this.callbacks, runnableConfig.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });
      const extra = {
        options: callOptions,
        invocation_params: this?.invocationParams(callOptions),
        batch_size: 1
      };
      const outputVersion = callOptions.outputVersion ?? this.outputVersion;
      const runManagers = await callbackManager_?.handleChatModelStart(this.toJSON(), [_formatForTracing(messages)], runnableConfig.runId, void 0, extra, void 0, void 0, runnableConfig.runName);
      let generationChunk;
      let llmOutput;
      try {
        for await (const chunk of this._streamResponseChunks(messages, callOptions, runManagers?.[0])) {
          if (chunk.message.id == null) {
            const runId = runManagers?.at(0)?.runId;
            if (runId != null) chunk.message._updateId(`run-${runId}`);
          }
          chunk.message.response_metadata = {
            ...chunk.generationInfo,
            ...chunk.message.response_metadata
          };
          if (outputVersion === "v1") yield castStandardMessageContent(chunk.message);
          else yield chunk.message;
          if (!generationChunk) generationChunk = chunk;
          else generationChunk = generationChunk.concat(chunk);
          if (isAIMessageChunk(chunk.message) && chunk.message.usage_metadata !== void 0) llmOutput = { tokenUsage: {
            promptTokens: chunk.message.usage_metadata.input_tokens,
            completionTokens: chunk.message.usage_metadata.output_tokens,
            totalTokens: chunk.message.usage_metadata.total_tokens
          } };
        }
      } catch (err) {
        await Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMError(err)));
        throw err;
      }
      await Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMEnd({
        generations: [[generationChunk]],
        llmOutput
      })));
    }
  }
  getLsParams(options) {
    const providerName = this.getName().startsWith("Chat") ? this.getName().replace("Chat", "") : this.getName();
    return {
      ls_model_type: "chat",
      ls_stop: options.stop,
      ls_provider: providerName
    };
  }
  /** @ignore */
  async _generateUncached(messages, parsedOptions, handledOptions, startedRunManagers) {
    const baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));
    let runManagers;
    if (startedRunManagers !== void 0 && startedRunManagers.length === baseMessages.length) runManagers = startedRunManagers;
    else {
      const inheritableMetadata = {
        ...handledOptions.metadata,
        ...this.getLsParams(parsedOptions)
      };
      const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });
      const extra = {
        options: parsedOptions,
        invocation_params: this?.invocationParams(parsedOptions),
        batch_size: 1
      };
      runManagers = await callbackManager_?.handleChatModelStart(this.toJSON(), baseMessages.map(_formatForTracing), handledOptions.runId, void 0, extra, void 0, void 0, handledOptions.runName);
    }
    const outputVersion = parsedOptions.outputVersion ?? this.outputVersion;
    const generations = [];
    const llmOutputs = [];
    const hasStreamingHandler = !!runManagers?.[0].handlers.find(callbackHandlerPrefersStreaming);
    if (hasStreamingHandler && !this.disableStreaming && baseMessages.length === 1 && this._streamResponseChunks !== BaseChatModel2.prototype._streamResponseChunks) try {
      const stream = await this._streamResponseChunks(baseMessages[0], parsedOptions, runManagers?.[0]);
      let aggregated;
      let llmOutput;
      for await (const chunk of stream) {
        if (chunk.message.id == null) {
          const runId = runManagers?.at(0)?.runId;
          if (runId != null) chunk.message._updateId(`run-${runId}`);
        }
        if (aggregated === void 0) aggregated = chunk;
        else aggregated = concat(aggregated, chunk);
        if (isAIMessageChunk(chunk.message) && chunk.message.usage_metadata !== void 0) llmOutput = { tokenUsage: {
          promptTokens: chunk.message.usage_metadata.input_tokens,
          completionTokens: chunk.message.usage_metadata.output_tokens,
          totalTokens: chunk.message.usage_metadata.total_tokens
        } };
      }
      if (aggregated === void 0) throw new Error("Received empty response from chat model call.");
      generations.push([aggregated]);
      await runManagers?.[0].handleLLMEnd({
        generations,
        llmOutput
      });
    } catch (e) {
      await runManagers?.[0].handleLLMError(e);
      throw e;
    }
    else {
      const results = await Promise.allSettled(baseMessages.map(async (messageList, i) => {
        const generateResults = await this._generate(messageList, {
          ...parsedOptions,
          promptIndex: i
        }, runManagers?.[i]);
        if (outputVersion === "v1") for (const generation of generateResults.generations) generation.message = castStandardMessageContent(generation.message);
        return generateResults;
      }));
      await Promise.all(results.map(async (pResult, i) => {
        if (pResult.status === "fulfilled") {
          const result = pResult.value;
          for (const generation of result.generations) {
            if (generation.message.id == null) {
              const runId = runManagers?.at(0)?.runId;
              if (runId != null) generation.message._updateId(`run-${runId}`);
            }
            generation.message.response_metadata = {
              ...generation.generationInfo,
              ...generation.message.response_metadata
            };
          }
          if (result.generations.length === 1) result.generations[0].message.response_metadata = {
            ...result.llmOutput,
            ...result.generations[0].message.response_metadata
          };
          generations[i] = result.generations;
          llmOutputs[i] = result.llmOutput;
          return runManagers?.[i]?.handleLLMEnd({
            generations: [result.generations],
            llmOutput: result.llmOutput
          });
        } else {
          await runManagers?.[i]?.handleLLMError(pResult.reason);
          return Promise.reject(pResult.reason);
        }
      }));
    }
    const output = {
      generations,
      llmOutput: llmOutputs.length ? this._combineLLMOutput?.(...llmOutputs) : void 0
    };
    Object.defineProperty(output, RUN_KEY, {
      value: runManagers ? { runIds: runManagers?.map((manager) => manager.runId) } : void 0,
      configurable: true
    });
    return output;
  }
  async _generateCached({ messages, cache, llmStringKey, parsedOptions, handledOptions }) {
    const baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));
    const inheritableMetadata = {
      ...handledOptions.metadata,
      ...this.getLsParams(parsedOptions)
    };
    const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });
    const extra = {
      options: parsedOptions,
      invocation_params: this?.invocationParams(parsedOptions),
      batch_size: 1
    };
    const runManagers = await callbackManager_?.handleChatModelStart(this.toJSON(), baseMessages.map(_formatForTracing), handledOptions.runId, void 0, extra, void 0, void 0, handledOptions.runName);
    const missingPromptIndices = [];
    const results = await Promise.allSettled(baseMessages.map(async (baseMessage, index2) => {
      const prompt = BaseChatModel2._convertInputToPromptValue(baseMessage).toString();
      const result = await cache.lookup(prompt, llmStringKey);
      if (result == null) missingPromptIndices.push(index2);
      return result;
    }));
    const cachedResults = results.map((result, index2) => ({
      result,
      runManager: runManagers?.[index2]
    })).filter(({ result }) => result.status === "fulfilled" && result.value != null || result.status === "rejected");
    const outputVersion = parsedOptions.outputVersion ?? this.outputVersion;
    const generations = [];
    await Promise.all(cachedResults.map(async ({ result: promiseResult, runManager }, i) => {
      if (promiseResult.status === "fulfilled") {
        const result = promiseResult.value;
        generations[i] = result.map((result$1) => {
          if ("message" in result$1 && isBaseMessage(result$1.message) && isAIMessage(result$1.message)) {
            result$1.message.usage_metadata = {
              input_tokens: 0,
              output_tokens: 0,
              total_tokens: 0
            };
            if (outputVersion === "v1") result$1.message = castStandardMessageContent(result$1.message);
          }
          result$1.generationInfo = {
            ...result$1.generationInfo,
            tokenUsage: {}
          };
          return result$1;
        });
        if (result.length) await runManager?.handleLLMNewToken(result[0].text);
        return runManager?.handleLLMEnd({ generations: [result] }, void 0, void 0, void 0, { cached: true });
      } else {
        await runManager?.handleLLMError(promiseResult.reason, void 0, void 0, void 0, { cached: true });
        return Promise.reject(promiseResult.reason);
      }
    }));
    const output = {
      generations,
      missingPromptIndices,
      startedRunManagers: runManagers
    };
    Object.defineProperty(output, RUN_KEY, {
      value: runManagers ? { runIds: runManagers?.map((manager) => manager.runId) } : void 0,
      configurable: true
    });
    return output;
  }
  /**
  * Generates chat based on the input messages.
  * @param messages An array of arrays of BaseMessage instances.
  * @param options The call options or an array of stop sequences.
  * @param callbacks The callbacks for the language model.
  * @returns A Promise that resolves to an LLMResult.
  */
  async generate(messages, options, callbacks) {
    let parsedOptions;
    if (Array.isArray(options)) parsedOptions = { stop: options };
    else parsedOptions = options;
    const baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));
    const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(parsedOptions);
    runnableConfig.callbacks = runnableConfig.callbacks ?? callbacks;
    if (!this.cache) return this._generateUncached(baseMessages, callOptions, runnableConfig);
    const { cache } = this;
    const llmStringKey = this._getSerializedCacheKeyParametersForCall(callOptions);
    const { generations, missingPromptIndices, startedRunManagers } = await this._generateCached({
      messages: baseMessages,
      cache,
      llmStringKey,
      parsedOptions: callOptions,
      handledOptions: runnableConfig
    });
    let llmOutput = {};
    if (missingPromptIndices.length > 0) {
      const results = await this._generateUncached(missingPromptIndices.map((i) => baseMessages[i]), callOptions, runnableConfig, startedRunManagers !== void 0 ? missingPromptIndices.map((i) => startedRunManagers?.[i]) : void 0);
      await Promise.all(results.generations.map(async (generation, index2) => {
        const promptIndex = missingPromptIndices[index2];
        generations[promptIndex] = generation;
        const prompt = BaseChatModel2._convertInputToPromptValue(baseMessages[promptIndex]).toString();
        return cache.update(prompt, llmStringKey, generation);
      }));
      llmOutput = results.llmOutput ?? {};
    }
    return {
      generations,
      llmOutput
    };
  }
  /**
  * Get the parameters used to invoke the model
  */
  invocationParams(_options) {
    return {};
  }
  _modelType() {
    return "base_chat_model";
  }
  /**
  * Generates a prompt based on the input prompt values.
  * @param promptValues An array of BasePromptValue instances.
  * @param options The call options or an array of stop sequences.
  * @param callbacks The callbacks for the language model.
  * @returns A Promise that resolves to an LLMResult.
  */
  async generatePrompt(promptValues, options, callbacks) {
    const promptMessages = promptValues.map((promptValue) => promptValue.toChatMessages());
    return this.generate(promptMessages, options, callbacks);
  }
  withStructuredOutput(outputSchema, config2) {
    if (typeof this.bindTools !== "function") throw new Error(`Chat model must implement ".bindTools()" to use withStructuredOutput.`);
    if (config2?.strict) throw new Error(`"strict" mode is not supported for this model by default.`);
    const schema = outputSchema;
    const name = config2?.name;
    const description = getSchemaDescription(schema) ?? "A function available to call.";
    const method = config2?.method;
    const includeRaw = config2?.includeRaw;
    if (method === "jsonMode") throw new Error(`Base withStructuredOutput implementation only supports "functionCalling" as a method.`);
    let functionName = name ?? "extract";
    let tools;
    if (isInteropZodSchema(schema)) tools = [{
      type: "function",
      function: {
        name: functionName,
        description,
        parameters: toJsonSchema(schema)
      }
    }];
    else {
      if ("name" in schema) functionName = schema.name;
      tools = [{
        type: "function",
        function: {
          name: functionName,
          description,
          parameters: schema
        }
      }];
    }
    const llm = this.bindTools(tools);
    const outputParser = RunnableLambda.from((input) => {
      if (!AIMessageChunk.isInstance(input)) throw new Error("Input is not an AIMessageChunk.");
      if (!input.tool_calls || input.tool_calls.length === 0) throw new Error("No tool calls found in the response.");
      const toolCall = input.tool_calls.find((tc) => tc.name === functionName);
      if (!toolCall) throw new Error(`No tool call found with name ${functionName}.`);
      return toolCall.args;
    });
    if (!includeRaw) return llm.pipe(outputParser).withConfig({ runName: "StructuredOutput" });
    const parserAssign = RunnablePassthrough.assign({ parsed: (input, config$1) => outputParser.invoke(input.raw, config$1) });
    const parserNone = RunnablePassthrough.assign({ parsed: () => null });
    const parsedWithFallback = parserAssign.withFallbacks({ fallbacks: [parserNone] });
    return RunnableSequence.from([{ raw: llm }, parsedWithFallback]).withConfig({ runName: "StructuredOutputRunnable" });
  }
};
var SimpleChatModel = class extends BaseChatModel {
  async _generate(messages, options, runManager) {
    const text = await this._call(messages, options, runManager);
    const message = new AIMessage(text);
    if (typeof message.content !== "string") throw new Error("Cannot generate with a simple chat model when output is not a string.");
    return { generations: [{
      text: message.content,
      message
    }] };
  }
};

// node_modules/@langchain/core/dist/runnables/router.js
var RouterRunnable = class extends Runnable {
  static lc_name() {
    return "RouterRunnable";
  }
  lc_namespace = ["langchain_core", "runnables"];
  lc_serializable = true;
  runnables;
  constructor(fields) {
    super(fields);
    this.runnables = fields.runnables;
  }
  async invoke(input, options) {
    const { key, input: actualInput } = input;
    const runnable = this.runnables[key];
    if (runnable === void 0) throw new Error(`No runnable associated with key "${key}".`);
    return runnable.invoke(actualInput, ensureConfig(options));
  }
  async batch(inputs, options, batchOptions) {
    const keys = inputs.map((input) => input.key);
    const actualInputs = inputs.map((input) => input.input);
    const missingKey = keys.find((key) => this.runnables[key] === void 0);
    if (missingKey !== void 0) throw new Error(`One or more keys do not have a corresponding runnable.`);
    const runnables = keys.map((key) => this.runnables[key]);
    const optionsList = this._getOptionsList(options ?? {}, inputs.length);
    const maxConcurrency = optionsList[0]?.maxConcurrency ?? batchOptions?.maxConcurrency;
    const batchSize = maxConcurrency && maxConcurrency > 0 ? maxConcurrency : inputs.length;
    const batchResults = [];
    for (let i = 0; i < actualInputs.length; i += batchSize) {
      const batchPromises = actualInputs.slice(i, i + batchSize).map((actualInput, i$1) => runnables[i$1].invoke(actualInput, optionsList[i$1]));
      const batchResult = await Promise.all(batchPromises);
      batchResults.push(batchResult);
    }
    return batchResults.flat();
  }
  async stream(input, options) {
    const { key, input: actualInput } = input;
    const runnable = this.runnables[key];
    if (runnable === void 0) throw new Error(`No runnable associated with key "${key}".`);
    return runnable.stream(actualInput, options);
  }
};

// node_modules/@langchain/core/dist/runnables/branch.js
var RunnableBranch = class extends Runnable {
  static lc_name() {
    return "RunnableBranch";
  }
  lc_namespace = ["langchain_core", "runnables"];
  lc_serializable = true;
  default;
  branches;
  constructor(fields) {
    super(fields);
    this.branches = fields.branches;
    this.default = fields.default;
  }
  /**
  * Convenience method for instantiating a RunnableBranch from
  * RunnableLikes (objects, functions, or Runnables).
  *
  * Each item in the input except for the last one should be a
  * tuple with two items. The first is a "condition" RunnableLike that
  * returns "true" if the second RunnableLike in the tuple should run.
  *
  * The final item in the input should be a RunnableLike that acts as a
  * default branch if no other branches match.
  *
  * @example
  * ```ts
  * import { RunnableBranch } from "@langchain/core/runnables";
  *
  * const branch = RunnableBranch.from([
  *   [(x: number) => x > 0, (x: number) => x + 1],
  *   [(x: number) => x < 0, (x: number) => x - 1],
  *   (x: number) => x
  * ]);
  * ```
  * @param branches An array where the every item except the last is a tuple of [condition, runnable]
  *   pairs. The last item is a default runnable which is invoked if no other condition matches.
  * @returns A new RunnableBranch.
  */
  static from(branches) {
    if (branches.length < 1) throw new Error("RunnableBranch requires at least one branch");
    const branchLikes = branches.slice(0, -1);
    const coercedBranches = branchLikes.map(([condition, runnable]) => [_coerceToRunnable(condition), _coerceToRunnable(runnable)]);
    const defaultBranch = _coerceToRunnable(branches[branches.length - 1]);
    return new this({
      branches: coercedBranches,
      default: defaultBranch
    });
  }
  async _invoke(input, config2, runManager) {
    let result;
    for (let i = 0; i < this.branches.length; i += 1) {
      const [condition, branchRunnable] = this.branches[i];
      const conditionValue = await condition.invoke(input, patchConfig(config2, { callbacks: runManager?.getChild(`condition:${i + 1}`) }));
      if (conditionValue) {
        result = await branchRunnable.invoke(input, patchConfig(config2, { callbacks: runManager?.getChild(`branch:${i + 1}`) }));
        break;
      }
    }
    if (!result) result = await this.default.invoke(input, patchConfig(config2, { callbacks: runManager?.getChild("branch:default") }));
    return result;
  }
  async invoke(input, config2 = {}) {
    return this._callWithConfig(this._invoke, input, config2);
  }
  async *_streamIterator(input, config2) {
    const callbackManager_ = await getCallbackManagerForConfig(config2);
    const runManager = await callbackManager_?.handleChainStart(this.toJSON(), _coerceToDict(input, "input"), config2?.runId, void 0, void 0, void 0, config2?.runName);
    let finalOutput;
    let finalOutputSupported = true;
    let stream;
    try {
      for (let i = 0; i < this.branches.length; i += 1) {
        const [condition, branchRunnable] = this.branches[i];
        const conditionValue = await condition.invoke(input, patchConfig(config2, { callbacks: runManager?.getChild(`condition:${i + 1}`) }));
        if (conditionValue) {
          stream = await branchRunnable.stream(input, patchConfig(config2, { callbacks: runManager?.getChild(`branch:${i + 1}`) }));
          for await (const chunk of stream) {
            yield chunk;
            if (finalOutputSupported) if (finalOutput === void 0) finalOutput = chunk;
            else try {
              finalOutput = concat(finalOutput, chunk);
            } catch {
              finalOutput = void 0;
              finalOutputSupported = false;
            }
          }
          break;
        }
      }
      if (stream === void 0) {
        stream = await this.default.stream(input, patchConfig(config2, { callbacks: runManager?.getChild("branch:default") }));
        for await (const chunk of stream) {
          yield chunk;
          if (finalOutputSupported) if (finalOutput === void 0) finalOutput = chunk;
          else try {
            finalOutput = concat(finalOutput, chunk);
          } catch {
            finalOutput = void 0;
            finalOutputSupported = false;
          }
        }
      }
    } catch (e) {
      await runManager?.handleChainError(e);
      throw e;
    }
    await runManager?.handleChainEnd(finalOutput ?? {});
  }
};

// node_modules/@langchain/core/dist/runnables/history.js
var RunnableWithMessageHistory = class extends RunnableBinding {
  runnable;
  inputMessagesKey;
  outputMessagesKey;
  historyMessagesKey;
  getMessageHistory;
  constructor(fields) {
    let historyChain = RunnableLambda.from((input, options) => this._enterHistory(input, options ?? {})).withConfig({ runName: "loadHistory" });
    const messagesKey = fields.historyMessagesKey ?? fields.inputMessagesKey;
    if (messagesKey) historyChain = RunnablePassthrough.assign({ [messagesKey]: historyChain }).withConfig({ runName: "insertHistory" });
    const bound = historyChain.pipe(fields.runnable.withListeners({ onEnd: (run, config$1) => this._exitHistory(run, config$1 ?? {}) })).withConfig({ runName: "RunnableWithMessageHistory" });
    const config2 = fields.config ?? {};
    super({
      ...fields,
      config: config2,
      bound
    });
    this.runnable = fields.runnable;
    this.getMessageHistory = fields.getMessageHistory;
    this.inputMessagesKey = fields.inputMessagesKey;
    this.outputMessagesKey = fields.outputMessagesKey;
    this.historyMessagesKey = fields.historyMessagesKey;
  }
  _getInputMessages(inputValue) {
    let parsedInputValue;
    if (typeof inputValue === "object" && !Array.isArray(inputValue) && !isBaseMessage(inputValue)) {
      let key;
      if (this.inputMessagesKey) key = this.inputMessagesKey;
      else if (Object.keys(inputValue).length === 1) key = Object.keys(inputValue)[0];
      else key = "input";
      if (Array.isArray(inputValue[key]) && Array.isArray(inputValue[key][0])) parsedInputValue = inputValue[key][0];
      else parsedInputValue = inputValue[key];
    } else parsedInputValue = inputValue;
    if (typeof parsedInputValue === "string") return [new HumanMessage(parsedInputValue)];
    else if (Array.isArray(parsedInputValue)) return parsedInputValue;
    else if (isBaseMessage(parsedInputValue)) return [parsedInputValue];
    else throw new Error(`Expected a string, BaseMessage, or array of BaseMessages.
Got ${JSON.stringify(parsedInputValue, null, 2)}`);
  }
  _getOutputMessages(outputValue) {
    let parsedOutputValue;
    if (!Array.isArray(outputValue) && !isBaseMessage(outputValue) && typeof outputValue !== "string") {
      let key;
      if (this.outputMessagesKey !== void 0) key = this.outputMessagesKey;
      else if (Object.keys(outputValue).length === 1) key = Object.keys(outputValue)[0];
      else key = "output";
      if (outputValue.generations !== void 0) parsedOutputValue = outputValue.generations[0][0].message;
      else parsedOutputValue = outputValue[key];
    } else parsedOutputValue = outputValue;
    if (typeof parsedOutputValue === "string") return [new AIMessage(parsedOutputValue)];
    else if (Array.isArray(parsedOutputValue)) return parsedOutputValue;
    else if (isBaseMessage(parsedOutputValue)) return [parsedOutputValue];
    else throw new Error(`Expected a string, BaseMessage, or array of BaseMessages. Received: ${JSON.stringify(parsedOutputValue, null, 2)}`);
  }
  async _enterHistory(input, kwargs) {
    const history = kwargs?.configurable?.messageHistory;
    const messages = await history.getMessages();
    if (this.historyMessagesKey === void 0) return messages.concat(this._getInputMessages(input));
    return messages;
  }
  async _exitHistory(run, config2) {
    const history = config2.configurable?.messageHistory;
    let inputs;
    if (Array.isArray(run.inputs) && Array.isArray(run.inputs[0])) inputs = run.inputs[0];
    else inputs = run.inputs;
    let inputMessages = this._getInputMessages(inputs);
    if (this.historyMessagesKey === void 0) {
      const existingMessages = await history.getMessages();
      inputMessages = inputMessages.slice(existingMessages.length);
    }
    const outputValue = run.outputs;
    if (!outputValue) throw new Error(`Output values from 'Run' undefined. Run: ${JSON.stringify(run, null, 2)}`);
    const outputMessages = this._getOutputMessages(outputValue);
    await history.addMessages([...inputMessages, ...outputMessages]);
  }
  async _mergeConfig(...configs) {
    const config2 = await super._mergeConfig(...configs);
    if (!config2.configurable || !config2.configurable.sessionId) {
      const exampleInput = { [this.inputMessagesKey ?? "input"]: "foo" };
      const exampleConfig = { configurable: { sessionId: "123" } };
      throw new Error(`sessionId is required. Pass it in as part of the config argument to .invoke() or .stream()
eg. chain.invoke(${JSON.stringify(exampleInput)}, ${JSON.stringify(exampleConfig)})`);
    }
    const { sessionId } = config2.configurable;
    config2.configurable.messageHistory = await this.getMessageHistory(sessionId);
    return config2;
  }
};

// node_modules/@langchain/core/dist/runnables/index.js
var runnables_exports = {};
__export2(runnables_exports, {
  RouterRunnable: () => RouterRunnable,
  Runnable: () => Runnable,
  RunnableAssign: () => RunnableAssign,
  RunnableBinding: () => RunnableBinding,
  RunnableBranch: () => RunnableBranch,
  RunnableEach: () => RunnableEach,
  RunnableLambda: () => RunnableLambda,
  RunnableMap: () => RunnableMap,
  RunnableParallel: () => RunnableParallel,
  RunnablePassthrough: () => RunnablePassthrough,
  RunnablePick: () => RunnablePick,
  RunnableRetry: () => RunnableRetry,
  RunnableSequence: () => RunnableSequence,
  RunnableToolLike: () => RunnableToolLike,
  RunnableWithFallbacks: () => RunnableWithFallbacks,
  RunnableWithMessageHistory: () => RunnableWithMessageHistory,
  _coerceToRunnable: () => _coerceToRunnable,
  ensureConfig: () => ensureConfig,
  getCallbackManagerForConfig: () => getCallbackManagerForConfig,
  mergeConfigs: () => mergeConfigs,
  patchConfig: () => patchConfig,
  pickRunnableConfigKeys: () => pickRunnableConfigKeys,
  raceWithSignal: () => raceWithSignal
});

// node_modules/langchain/dist/chat_models/universal.js
var universal_exports = {};
__export3(universal_exports, {
  ConfigurableModel: () => ConfigurableModel,
  MODEL_PROVIDER_CONFIG: () => MODEL_PROVIDER_CONFIG,
  _inferModelProvider: () => _inferModelProvider,
  getChatModelByClassName: () => getChatModelByClassName,
  initChatModel: () => initChatModel
});
var MODEL_PROVIDER_CONFIG = {
  openai: {
    package: "@langchain/openai",
    className: "ChatOpenAI"
  },
  anthropic: {
    package: "@langchain/anthropic",
    className: "ChatAnthropic"
  },
  azure_openai: {
    package: "@langchain/openai",
    className: "AzureChatOpenAI"
  },
  cohere: {
    package: "@langchain/cohere",
    className: "ChatCohere"
  },
  "google-vertexai": {
    package: "@langchain/google-vertexai",
    className: "ChatVertexAI"
  },
  "google-vertexai-web": {
    package: "@langchain/google-vertexai-web",
    className: "ChatVertexAI"
  },
  "google-genai": {
    package: "@langchain/google-genai",
    className: "ChatGoogleGenerativeAI"
  },
  ollama: {
    package: "@langchain/ollama",
    className: "ChatOllama"
  },
  mistralai: {
    package: "@langchain/mistralai",
    className: "ChatMistralAI"
  },
  mistral: {
    package: "@langchain/mistralai",
    className: "ChatMistralAI"
  },
  groq: {
    package: "@langchain/groq",
    className: "ChatGroq"
  },
  cerebras: {
    package: "@langchain/cerebras",
    className: "ChatCerebras"
  },
  bedrock: {
    package: "@langchain/aws",
    className: "ChatBedrockConverse"
  },
  deepseek: {
    package: "@langchain/deepseek",
    className: "ChatDeepSeek"
  },
  xai: {
    package: "@langchain/xai",
    className: "ChatXAI"
  },
  fireworks: {
    package: "@langchain/community/chat_models/fireworks",
    className: "ChatFireworks",
    hasCircularDependency: true
  },
  together: {
    package: "@langchain/community/chat_models/togetherai",
    className: "ChatTogetherAI",
    hasCircularDependency: true
  },
  perplexity: {
    package: "@langchain/community/chat_models/perplexity",
    className: "ChatPerplexity",
    hasCircularDependency: true
  }
};
var SUPPORTED_PROVIDERS = Object.keys(MODEL_PROVIDER_CONFIG);
async function getChatModelByClassName(className) {
  const providerEntry = Object.entries(MODEL_PROVIDER_CONFIG).find(([, config$1]) => config$1.className === className);
  if (!providerEntry) return void 0;
  const [, config2] = providerEntry;
  try {
    const module = await import(config2.package);
    return module[config2.className];
  } catch (e) {
    const err = e;
    if ("code" in err && err.code?.toString().includes("ERR_MODULE_NOT_FOUND") && "message" in err && typeof err.message === "string") {
      const msg = err.message.startsWith("Error: ") ? err.message.slice(7) : err.message;
      const attemptedPackage = msg.split("Cannot find package '")[1].split("'")[0];
      throw new Error(`Unable to import ${attemptedPackage}. Please install with \`npm install ${attemptedPackage}\` or \`pnpm install ${attemptedPackage}\``);
    }
    throw e;
  }
}
async function _initChatModelHelper(model, modelProvider, params = {}) {
  const modelProviderCopy = modelProvider || _inferModelProvider(model);
  if (!modelProviderCopy) throw new Error(`Unable to infer model provider for { model: ${model} }, please specify modelProvider directly.`);
  const config2 = MODEL_PROVIDER_CONFIG[modelProviderCopy];
  if (!config2) {
    const supported = SUPPORTED_PROVIDERS.join(", ");
    throw new Error(`Unsupported { modelProvider: ${modelProviderCopy} }.

Supported model providers are: ${supported}`);
  }
  const { modelProvider: _unused, ...passedParams } = params;
  const ProviderClass = await getChatModelByClassName(config2.className);
  return new ProviderClass({
    model,
    ...passedParams
  });
}
function _inferModelProvider(modelName) {
  if (modelName.startsWith("gpt-3") || modelName.startsWith("gpt-4") || modelName.startsWith("gpt-5") || modelName.startsWith("o1") || modelName.startsWith("o3") || modelName.startsWith("o4")) return "openai";
  else if (modelName.startsWith("claude")) return "anthropic";
  else if (modelName.startsWith("command")) return "cohere";
  else if (modelName.startsWith("accounts/fireworks")) return "fireworks";
  else if (modelName.startsWith("gemini")) return "google-vertexai";
  else if (modelName.startsWith("amazon.")) return "bedrock";
  else if (modelName.startsWith("mistral")) return "mistralai";
  else if (modelName.startsWith("sonar") || modelName.startsWith("pplx")) return "perplexity";
  else return void 0;
}
var ConfigurableModel = class ConfigurableModel2 extends BaseChatModel {
  _llmType() {
    return "chat_model";
  }
  lc_namespace = ["langchain", "chat_models"];
  _defaultConfig = {};
  /**
  * @default "any"
  */
  _configurableFields = "any";
  /**
  * @default ""
  */
  _configPrefix;
  /**
  * Methods which should be called after the model is initialized.
  * The key will be the method name, and the value will be the arguments.
  */
  _queuedMethodOperations = {};
  /** @internal */
  _modelInstanceCache = /* @__PURE__ */ new Map();
  /** @internal */
  _profile;
  constructor(fields) {
    super(fields);
    this._defaultConfig = fields.defaultConfig ?? {};
    if (fields.configurableFields === "any") this._configurableFields = "any";
    else this._configurableFields = fields.configurableFields ?? ["model", "modelProvider"];
    if (fields.configPrefix) this._configPrefix = fields.configPrefix.endsWith("_") ? fields.configPrefix : `${fields.configPrefix}_`;
    else this._configPrefix = "";
    this._queuedMethodOperations = fields.queuedMethodOperations ?? this._queuedMethodOperations;
    this._profile = fields.profile ?? void 0;
  }
  async _getModelInstance(config2) {
    const cacheKey = JSON.stringify(config2 ?? {});
    const cachedModel = this._modelInstanceCache.get(cacheKey);
    if (cachedModel) return cachedModel;
    const params = {
      ...this._defaultConfig,
      ...this._modelParams(config2)
    };
    let initializedModel = await _initChatModelHelper(params.model, params.modelProvider, params);
    for (const [method, args] of Object.entries(this._queuedMethodOperations)) if (method in initializedModel && typeof initializedModel[method] === "function") initializedModel = await initializedModel[method](...args);
    this._modelInstanceCache.set(cacheKey, initializedModel);
    return initializedModel;
  }
  async _generate(messages, options, runManager) {
    const model = await this._getModelInstance(options);
    return model._generate(messages, options ?? {}, runManager);
  }
  bindTools(tools, params) {
    const newQueuedOperations = { ...this._queuedMethodOperations };
    newQueuedOperations.bindTools = [tools, params];
    return new ConfigurableModel2({
      defaultConfig: this._defaultConfig,
      configurableFields: this._configurableFields,
      configPrefix: this._configPrefix,
      queuedMethodOperations: newQueuedOperations
    });
  }
  withStructuredOutput = (schema, ...args) => {
    const newQueuedOperations = { ...this._queuedMethodOperations };
    newQueuedOperations.withStructuredOutput = [schema, ...args];
    return new ConfigurableModel2({
      defaultConfig: this._defaultConfig,
      configurableFields: this._configurableFields,
      configPrefix: this._configPrefix,
      queuedMethodOperations: newQueuedOperations
    });
  };
  _modelParams(config2) {
    const configurable = config2?.configurable ?? {};
    let modelParams = {};
    for (const [key, value] of Object.entries(configurable)) if (key.startsWith(this._configPrefix)) {
      const strippedKey = this._removePrefix(key, this._configPrefix);
      modelParams[strippedKey] = value;
    }
    if (this._configurableFields !== "any") modelParams = Object.fromEntries(Object.entries(modelParams).filter(([key]) => this._configurableFields.includes(key)));
    return modelParams;
  }
  _removePrefix(str, prefix) {
    return str.startsWith(prefix) ? str.slice(prefix.length) : str;
  }
  /**
  * Bind config to a Runnable, returning a new Runnable.
  * @param {RunnableConfig | undefined} [config] - The config to bind.
  * @returns {RunnableBinding<RunInput, RunOutput, CallOptions>} A new RunnableBinding with the bound config.
  */
  withConfig(config2) {
    const mergedConfig = { ...config2 || {} };
    const modelParams = this._modelParams(mergedConfig);
    const remainingConfig = Object.fromEntries(Object.entries(mergedConfig).filter(([k]) => k !== "configurable"));
    remainingConfig.configurable = Object.fromEntries(Object.entries(mergedConfig.configurable || {}).filter(([k]) => this._configPrefix && !Object.keys(modelParams).includes(this._removePrefix(k, this._configPrefix))));
    const newConfigurableModel = new ConfigurableModel2({
      defaultConfig: {
        ...this._defaultConfig,
        ...modelParams
      },
      configurableFields: Array.isArray(this._configurableFields) ? [...this._configurableFields] : this._configurableFields,
      configPrefix: this._configPrefix,
      queuedMethodOperations: this._queuedMethodOperations
    });
    return new RunnableBinding({
      config: mergedConfig,
      bound: newConfigurableModel
    });
  }
  async invoke(input, options) {
    const model = await this._getModelInstance(options);
    const config2 = ensureConfig(options);
    return model.invoke(input, config2);
  }
  async stream(input, options) {
    const model = await this._getModelInstance(options);
    const wrappedGenerator = new AsyncGeneratorWithSetup({
      generator: await model.stream(input, options),
      config: options
    });
    await wrappedGenerator.setup;
    return IterableReadableStream.fromAsyncGenerator(wrappedGenerator);
  }
  async batch(inputs, options, batchOptions) {
    return super.batch(inputs, options, batchOptions);
  }
  async *transform(generator, options) {
    const model = await this._getModelInstance(options);
    const config2 = ensureConfig(options);
    yield* model.transform(generator, config2);
  }
  async *streamLog(input, options, streamOptions) {
    const model = await this._getModelInstance(options);
    const config2 = ensureConfig(options);
    yield* model.streamLog(input, config2, {
      ...streamOptions,
      _schemaFormat: "original",
      includeNames: streamOptions?.includeNames,
      includeTypes: streamOptions?.includeTypes,
      includeTags: streamOptions?.includeTags,
      excludeNames: streamOptions?.excludeNames,
      excludeTypes: streamOptions?.excludeTypes,
      excludeTags: streamOptions?.excludeTags
    });
  }
  streamEvents(input, options, streamOptions) {
    const outerThis = this;
    async function* wrappedGenerator() {
      const model = await outerThis._getModelInstance(options);
      const config2 = ensureConfig(options);
      const eventStream = model.streamEvents(input, config2, streamOptions);
      for await (const chunk of eventStream) yield chunk;
    }
    return IterableReadableStream.fromAsyncGenerator(wrappedGenerator());
  }
  /**
  * Return profiling information for the model.
  *
  * @returns {ModelProfile} An object describing the model's capabilities and constraints
  */
  get profile() {
    if (this._profile) return this._profile;
    const cacheKey = JSON.stringify({});
    const instance = this._modelInstanceCache.get(cacheKey);
    return instance?.profile ?? {};
  }
};
async function initChatModel(model, fields) {
  let { configurableFields, configPrefix, modelProvider, profile, ...params } = {
    configPrefix: "",
    ...fields ?? {}
  };
  if (modelProvider === void 0 && model?.includes(":")) {
    const [provider, ...remainingParts] = model.split(":");
    const modelComponents = remainingParts.length === 0 ? [provider] : [provider, remainingParts.join(":")];
    if (SUPPORTED_PROVIDERS.includes(modelComponents[0])) [modelProvider, model] = modelComponents;
  }
  let configurableFieldsCopy = Array.isArray(configurableFields) ? [...configurableFields] : configurableFields;
  if (!model && configurableFieldsCopy === void 0) configurableFieldsCopy = ["model", "modelProvider"];
  if (configPrefix && configurableFieldsCopy === void 0) console.warn(`{ configPrefix: ${configPrefix} } has been set but no fields are configurable. Set { configurableFields: [...] } to specify the model params that are configurable.`);
  const paramsCopy = { ...params };
  let configurableModel;
  if (configurableFieldsCopy === void 0) configurableModel = new ConfigurableModel({
    defaultConfig: {
      ...paramsCopy,
      model,
      modelProvider
    },
    configPrefix,
    profile
  });
  else {
    if (model) paramsCopy.model = model;
    if (modelProvider) paramsCopy.modelProvider = modelProvider;
    configurableModel = new ConfigurableModel({
      defaultConfig: paramsCopy,
      configPrefix,
      configurableFields: configurableFieldsCopy,
      profile
    });
  }
  await configurableModel._getModelInstance();
  return configurableModel;
}

// node_modules/@langchain/langgraph/dist/setup/async_local_storage.js
var import_node_async_hooks = __toESM(require_node_async_hooks(), 1);
function initializeAsyncLocalStorageSingleton() {
  AsyncLocalStorageProviderSingleton.initializeGlobalInstance(new import_node_async_hooks.AsyncLocalStorage());
}

// node_modules/@langchain/langgraph/dist/errors.js
var BaseLangGraphError = class extends Error {
  lc_error_code;
  constructor(message, fields) {
    let finalMessage = message ?? "";
    if (fields?.lc_error_code) finalMessage = `${finalMessage}

Troubleshooting URL: https://docs.langchain.com/oss/javascript/langgraph/${fields.lc_error_code}/
`;
    super(finalMessage);
    this.lc_error_code = fields?.lc_error_code;
  }
};
var GraphBubbleUp = class extends BaseLangGraphError {
  get is_bubble_up() {
    return true;
  }
};
var GraphRecursionError = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "GraphRecursionError";
  }
  static get unminifiable_name() {
    return "GraphRecursionError";
  }
};
var GraphValueError = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "GraphValueError";
  }
  static get unminifiable_name() {
    return "GraphValueError";
  }
};
var GraphInterrupt = class extends GraphBubbleUp {
  interrupts;
  constructor(interrupts, fields) {
    super(JSON.stringify(interrupts, null, 2), fields);
    this.name = "GraphInterrupt";
    this.interrupts = interrupts ?? [];
  }
  static get unminifiable_name() {
    return "GraphInterrupt";
  }
};
var NodeInterrupt = class extends GraphInterrupt {
  constructor(message, fields) {
    super([{ value: message }], fields);
    this.name = "NodeInterrupt";
  }
  static get unminifiable_name() {
    return "NodeInterrupt";
  }
};
var ParentCommand = class extends GraphBubbleUp {
  command;
  constructor(command) {
    super();
    this.name = "ParentCommand";
    this.command = command;
  }
  static get unminifiable_name() {
    return "ParentCommand";
  }
};
function isParentCommand(e) {
  return e !== void 0 && e.name === ParentCommand.unminifiable_name;
}
function isGraphBubbleUp(e) {
  return e !== void 0 && e.is_bubble_up === true;
}
function isGraphInterrupt(e) {
  return e !== void 0 && [GraphInterrupt.unminifiable_name, NodeInterrupt.unminifiable_name].includes(e.name);
}
var EmptyInputError = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "EmptyInputError";
  }
  static get unminifiable_name() {
    return "EmptyInputError";
  }
};
var EmptyChannelError = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "EmptyChannelError";
  }
  static get unminifiable_name() {
    return "EmptyChannelError";
  }
};
var InvalidUpdateError = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "InvalidUpdateError";
  }
  static get unminifiable_name() {
    return "InvalidUpdateError";
  }
};
var UnreachableNodeError = class extends BaseLangGraphError {
  constructor(message, fields) {
    super(message, fields);
    this.name = "UnreachableNodeError";
  }
  static get unminifiable_name() {
    return "UnreachableNodeError";
  }
};
var StateGraphInputError = class extends BaseLangGraphError {
  /**
  * Create a new StateGraphInputError.
  * @param message - Optional custom error message.
  * @param fields - Optional additional error fields.
  */
  constructor(message, fields) {
    super(message, fields);
    this.name = "StateGraphInputError";
    this.message = "Invalid StateGraph input. Make sure to pass a valid StateDefinition, Annotation.Root, or Zod schema.";
  }
  /**
  * The unminifiable (static, human-readable) error name for this error class.
  */
  static get unminifiable_name() {
    return "StateGraphInputError";
  }
};

// node_modules/@langchain/langgraph-checkpoint/dist/id.js
function uuid6(clockseq) {
  return v6({ clockseq });
}
function uuid5(name, namespace) {
  const namespaceBytes = namespace.replace(/-/g, "").match(/.{2}/g).map((byte) => parseInt(byte, 16));
  return v5_default(name, new Uint8Array(namespaceBytes));
}

// node_modules/@langchain/langgraph-checkpoint/dist/serde/types.js
var ERROR2 = "__error__";
var SCHEDULED = "__scheduled__";
var INTERRUPT = "__interrupt__";
var RESUME = "__resume__";

// node_modules/@langchain/langgraph-checkpoint/dist/serde/utils/fast-safe-stringify/index.js
var LIMIT_REPLACE_NODE = "[...]";
var CIRCULAR_REPLACE_NODE = "[Circular]";
var arr = [];
var replacerStack = [];
function defaultOptions() {
  return {
    depthLimit: Number.MAX_SAFE_INTEGER,
    edgesLimit: Number.MAX_SAFE_INTEGER
  };
}
function stringify(obj, replacer, spacer, options) {
  if (typeof options === "undefined") options = defaultOptions();
  decirc(obj, "", 0, [], void 0, 0, options);
  var res;
  try {
    if (replacerStack.length === 0) res = JSON.stringify(obj, replacer, spacer);
    else res = JSON.stringify(obj, replaceGetterValues(replacer), spacer);
  } catch (_) {
    return JSON.stringify("[unable to serialize, circular reference is too complex to analyze]");
  } finally {
    while (arr.length !== 0) {
      var part = arr.pop();
      if (part.length === 4) Object.defineProperty(part[0], part[1], part[3]);
      else part[0][part[1]] = part[2];
    }
  }
  return res;
}
function setReplace(replace, val, k, parent) {
  var propertyDescriptor = Object.getOwnPropertyDescriptor(parent, k);
  if (propertyDescriptor.get !== void 0) if (propertyDescriptor.configurable) {
    Object.defineProperty(parent, k, { value: replace });
    arr.push([
      parent,
      k,
      val,
      propertyDescriptor
    ]);
  } else replacerStack.push([
    val,
    k,
    replace
  ]);
  else {
    parent[k] = replace;
    arr.push([
      parent,
      k,
      val
    ]);
  }
}
function decirc(val, k, edgeIndex, stack, parent, depth, options) {
  depth += 1;
  var i;
  if (typeof val === "object" && val !== null) {
    for (i = 0; i < stack.length; i++) if (stack[i] === val) {
      setReplace(CIRCULAR_REPLACE_NODE, val, k, parent);
      return;
    }
    if (typeof options.depthLimit !== "undefined" && depth > options.depthLimit) {
      setReplace(LIMIT_REPLACE_NODE, val, k, parent);
      return;
    }
    if (typeof options.edgesLimit !== "undefined" && edgeIndex + 1 > options.edgesLimit) {
      setReplace(LIMIT_REPLACE_NODE, val, k, parent);
      return;
    }
    stack.push(val);
    if (Array.isArray(val)) for (i = 0; i < val.length; i++) decirc(val[i], i, i, stack, val, depth, options);
    else {
      var keys = Object.keys(val);
      for (i = 0; i < keys.length; i++) {
        var key = keys[i];
        decirc(val[key], key, i, stack, val, depth, options);
      }
    }
    stack.pop();
  }
}
function replaceGetterValues(replacer) {
  replacer = typeof replacer !== "undefined" ? replacer : function(k, v) {
    return v;
  };
  return function(key, val) {
    if (replacerStack.length > 0) for (var i = 0; i < replacerStack.length; i++) {
      var part = replacerStack[i];
      if (part[1] === key && part[0] === val) {
        val = part[2];
        replacerStack.splice(i, 1);
        break;
      }
    }
    return replacer.call(this, key, val);
  };
}

// node_modules/@langchain/core/dist/load/import_constants.js
var optionalImportEntrypoints = [];

// node_modules/@langchain/core/dist/agents.js
var agents_exports = {};

// node_modules/@langchain/core/dist/chat_history.js
var chat_history_exports = {};
__export2(chat_history_exports, {
  BaseChatMessageHistory: () => BaseChatMessageHistory,
  BaseListChatMessageHistory: () => BaseListChatMessageHistory,
  InMemoryChatMessageHistory: () => InMemoryChatMessageHistory
});
var BaseChatMessageHistory = class extends Serializable {
  /**
  * Add a list of messages.
  *
  * Implementations should override this method to handle bulk addition of messages
  * in an efficient manner to avoid unnecessary round-trips to the underlying store.
  *
  * @param messages - A list of BaseMessage objects to store.
  */
  async addMessages(messages) {
    for (const message of messages) await this.addMessage(message);
  }
};
var BaseListChatMessageHistory = class extends Serializable {
  /**
  * This is a convenience method for adding a human message string to the store.
  * Please note that this is a convenience method. Code should favor the
  * bulk addMessages interface instead to save on round-trips to the underlying
  * persistence layer.
  * This method may be deprecated in a future release.
  */
  addUserMessage(message) {
    return this.addMessage(new HumanMessage(message));
  }
  /**
  * This is a convenience method for adding an AI message string to the store.
  * Please note that this is a convenience method. Code should favor the bulk
  * addMessages interface instead to save on round-trips to the underlying
  * persistence layer.
  * This method may be deprecated in a future release.
  */
  addAIMessage(message) {
    return this.addMessage(new AIMessage(message));
  }
  /**
  * Add a list of messages.
  *
  * Implementations should override this method to handle bulk addition of messages
  * in an efficient manner to avoid unnecessary round-trips to the underlying store.
  *
  * @param messages - A list of BaseMessage objects to store.
  */
  async addMessages(messages) {
    for (const message of messages) await this.addMessage(message);
  }
  /**
  * Remove all messages from the store.
  */
  clear() {
    throw new Error("Not implemented.");
  }
};
var InMemoryChatMessageHistory = class extends BaseListChatMessageHistory {
  lc_namespace = [
    "langchain",
    "stores",
    "message",
    "in_memory"
  ];
  messages = [];
  constructor(messages) {
    super(...arguments);
    this.messages = messages ?? [];
  }
  /**
  * Method to get all the messages stored in the ChatMessageHistory
  * instance.
  * @returns Array of stored BaseMessage instances.
  */
  async getMessages() {
    return this.messages;
  }
  /**
  * Method to add a new message to the ChatMessageHistory instance.
  * @param message The BaseMessage instance to add.
  * @returns A promise that resolves when the message has been added.
  */
  async addMessage(message) {
    this.messages.push(message);
  }
  /**
  * Method to clear all the messages from the ChatMessageHistory instance.
  * @returns A promise that resolves when all messages have been cleared.
  */
  async clear() {
    this.messages = [];
  }
};

// node_modules/@langchain/core/dist/embeddings.js
var embeddings_exports = {};
__export2(embeddings_exports, { Embeddings: () => Embeddings });
var Embeddings = class {
  /**
  * The async caller should be used by subclasses to make any async calls,
  * which will thus benefit from the concurrency and retry logic.
  */
  caller;
  constructor(params) {
    this.caller = new AsyncCaller(params ?? {});
  }
};

// node_modules/@langchain/core/dist/index.js
var src_exports = {};

// node_modules/@langchain/core/dist/memory.js
var memory_exports = {};
__export2(memory_exports, {
  BaseMemory: () => BaseMemory,
  getInputValue: () => getInputValue,
  getOutputValue: () => getOutputValue,
  getPromptInputKey: () => getPromptInputKey
});
var BaseMemory = class {
};
var getValue = (values, key) => {
  if (key !== void 0) return values[key];
  const keys = Object.keys(values);
  if (keys.length === 1) return values[keys[0]];
};
var getInputValue = (inputValues, inputKey) => {
  const value = getValue(inputValues, inputKey);
  if (!value) {
    const keys = Object.keys(inputValues);
    throw new Error(`input values have ${keys.length} keys, you must specify an input key or pass only 1 key as input`);
  }
  return value;
};
var getOutputValue = (outputValues, outputKey) => {
  const value = getValue(outputValues, outputKey);
  if (!value && value !== "") {
    const keys = Object.keys(outputValues);
    throw new Error(`output values have ${keys.length} keys, you must specify an output key or pass only 1 key as output`);
  }
  return value;
};
function getPromptInputKey(inputs, memoryVariables) {
  const promptInputKeys = Object.keys(inputs).filter((key) => !memoryVariables.includes(key) && key !== "stop");
  if (promptInputKeys.length !== 1) throw new Error(`One input key expected, but got ${promptInputKeys.length}`);
  return promptInputKeys[0];
}

// node_modules/@langchain/core/dist/stores.js
var stores_exports = {};
__export2(stores_exports, {
  BaseStore: () => BaseStore,
  InMemoryStore: () => InMemoryStore
});
var BaseStore = class extends Serializable {
};
var InMemoryStore = class extends BaseStore {
  lc_namespace = ["langchain", "storage"];
  store = {};
  /**
  * Retrieves the values associated with the given keys from the store.
  * @param keys Keys to retrieve values for.
  * @returns Array of values associated with the given keys.
  */
  async mget(keys) {
    return keys.map((key) => this.store[key]);
  }
  /**
  * Sets the values for the given keys in the store.
  * @param keyValuePairs Array of key-value pairs to set in the store.
  * @returns Promise that resolves when all key-value pairs have been set.
  */
  async mset(keyValuePairs) {
    for (const [key, value] of keyValuePairs) this.store[key] = value;
  }
  /**
  * Deletes the given keys and their associated values from the store.
  * @param keys Keys to delete from the store.
  * @returns Promise that resolves when all keys have been deleted.
  */
  async mdelete(keys) {
    for (const key of keys) delete this.store[key];
  }
  /**
  * Asynchronous generator that yields keys from the store. If a prefix is
  * provided, it only yields keys that start with the prefix.
  * @param prefix Optional prefix to filter keys.
  * @returns AsyncGenerator that yields keys from the store.
  */
  async *yieldKeys(prefix) {
    const keys = Object.keys(this.store);
    for (const key of keys) if (prefix === void 0 || key.startsWith(prefix)) yield key;
  }
};

// node_modules/@langchain/core/dist/retrievers/index.js
var retrievers_exports = {};
__export2(retrievers_exports, { BaseRetriever: () => BaseRetriever });
var BaseRetriever = class extends Runnable {
  /**
  * Optional callbacks to handle various events in the retrieval process.
  */
  callbacks;
  /**
  * Tags to label or categorize the retrieval operation.
  */
  tags;
  /**
  * Metadata to provide additional context or information about the retrieval
  * operation.
  */
  metadata;
  /**
  * If set to `true`, enables verbose logging for the retrieval process.
  */
  verbose;
  /**
  * Constructs a new `BaseRetriever` instance with optional configuration fields.
  *
  * @param fields - Optional input configuration that can include `callbacks`,
  *                 `tags`, `metadata`, and `verbose` settings for custom retriever behavior.
  */
  constructor(fields) {
    super(fields);
    this.callbacks = fields?.callbacks;
    this.tags = fields?.tags ?? [];
    this.metadata = fields?.metadata ?? {};
    this.verbose = fields?.verbose ?? false;
  }
  /**
  * TODO: This should be an abstract method, but we'd like to avoid breaking
  * changes to people currently using subclassed custom retrievers.
  * Change it on next major release.
  */
  /**
  * Placeholder method for retrieving relevant documents based on a query.
  *
  * This method is intended to be implemented by subclasses and will be
  * converted to an abstract method in the next major release. Currently, it
  * throws an error if not implemented, ensuring that custom retrievers define
  * the specific retrieval logic.
  *
  * @param _query - The query string used to search for relevant documents.
  * @param _callbacks - (optional) Callback manager for managing callbacks
  *                     during retrieval.
  * @returns A promise resolving to an array of `DocumentInterface` instances relevant to the query.
  * @throws {Error} Throws an error indicating the method is not implemented.
  */
  _getRelevantDocuments(_query, _callbacks) {
    throw new Error("Not implemented!");
  }
  /**
  * Executes a retrieval operation.
  *
  * @param input - The query string used to search for relevant documents.
  * @param options - (optional) Configuration options for the retrieval run,
  *                  which may include callbacks, tags, and metadata.
  * @returns A promise that resolves to an array of `DocumentInterface` instances
  *          representing the most relevant documents to the query.
  */
  async invoke(input, options) {
    const parsedConfig = ensureConfig(parseCallbackConfigArg(options));
    const callbackManager_ = await CallbackManager.configure(parsedConfig.callbacks, this.callbacks, parsedConfig.tags, this.tags, parsedConfig.metadata, this.metadata, { verbose: this.verbose });
    const runManager = await callbackManager_?.handleRetrieverStart(this.toJSON(), input, parsedConfig.runId, void 0, void 0, void 0, parsedConfig.runName);
    try {
      const results = await this._getRelevantDocuments(input, runManager);
      await runManager?.handleRetrieverEnd(results);
      return results;
    } catch (error) {
      await runManager?.handleRetrieverError(error);
      throw error;
    }
  }
};

// node_modules/@langchain/core/dist/vectorstores.js
var vectorstores_exports = {};
__export2(vectorstores_exports, {
  SaveableVectorStore: () => SaveableVectorStore,
  VectorStore: () => VectorStore,
  VectorStoreRetriever: () => VectorStoreRetriever
});
var VectorStoreRetriever = class extends BaseRetriever {
  static lc_name() {
    return "VectorStoreRetriever";
  }
  get lc_namespace() {
    return ["langchain_core", "vectorstores"];
  }
  /**
  * The instance of `VectorStore` used for storing and retrieving document embeddings.
  * This vector store must implement the `VectorStoreInterface` to be compatible
  * with the retrievers operations.
  */
  vectorStore;
  /**
  * Specifies the number of documents to retrieve for each search query.
  * Defaults to 4 if not specified, providing a basic result count for similarity or MMR searches.
  */
  k = 4;
  /**
  * Determines the type of search operation to perform on the vector store.
  *
  * - `"similarity"` (default): Conducts a similarity search based purely on vector similarity
  *   to the query.
  * - `"mmr"`: Executes a maximal marginal relevance (MMR) search, balancing relevance and
  *   diversity in the retrieved results.
  */
  searchType = "similarity";
  /**
  * Additional options specific to maximal marginal relevance (MMR) search, applicable
  * only if `searchType` is set to `"mmr"`.
  *
  * Includes:
  * - `fetchK`: The initial number of documents fetched before applying the MMR algorithm,
  *   allowing for a larger selection from which to choose the most diverse results.
  * - `lambda`: A parameter between 0 and 1 to adjust the relevance-diversity balance,
  *   where 0 prioritizes diversity and 1 prioritizes relevance.
  */
  searchKwargs;
  /**
  * Optional filter applied to search results, defined by the `FilterType` of the vector store.
  * Allows for refined, targeted results by restricting the returned documents based
  * on specified filter criteria.
  */
  filter;
  /**
  * Returns the type of vector store, as defined by the `vectorStore` instance.
  *
  * @returns {string} The vector store type.
  */
  _vectorstoreType() {
    return this.vectorStore._vectorstoreType();
  }
  /**
  * Initializes a new instance of `VectorStoreRetriever` with the specified configuration.
  *
  * This constructor configures the retriever to interact with a given `VectorStore`
  * and supports different retrieval strategies, including similarity search and maximal
  * marginal relevance (MMR) search. Various options allow customization of the number
  * of documents retrieved per query, filtering based on conditions, and fine-tuning
  * MMR-specific parameters.
  *
  * @param fields - Configuration options for setting up the retriever:
  *
  *   - `vectorStore` (required): The `VectorStore` instance implementing `VectorStoreInterface`
  *     that will be used to store and retrieve document embeddings. This is the core component
  *     of the retriever, enabling vector-based similarity and MMR searches.
  *
  *   - `k` (optional): Specifies the number of documents to retrieve per search query. If not
  *     provided, defaults to 4. This count determines the number of most relevant documents returned
  *     for each search operation, balancing performance with comprehensiveness.
  *
  *   - `searchType` (optional): Defines the search approach used by the retriever, allowing for
  *     flexibility between two methods:
  *       - `"similarity"` (default): A similarity-based search, retrieving documents with high vector
  *         similarity to the query. This type prioritizes relevance and is often used when diversity
  *         among results is less critical.
  *       - `"mmr"`: Maximal Marginal Relevance search, which combines relevance with diversity. MMR
  *         is useful for scenarios where varied content is essential, as it selects results that
  *         both match the query and introduce content diversity.
  *
  *   - `filter` (optional): A filter of type `FilterType`, defined by the vector store, that allows
  *     for refined and targeted search results. This filter applies specified conditions to limit
  *     which documents are eligible for retrieval, offering control over the scope of results.
  *
  *   - `searchKwargs` (optional, applicable only if `searchType` is `"mmr"`): Additional settings
  *     for configuring MMR-specific behavior. These parameters allow further tuning of the MMR
  *     search process:
  *       - `fetchK`: The initial number of documents fetched from the vector store before the MMR
  *         algorithm is applied. Fetching a larger set enables the algorithm to select a more
  *         diverse subset of documents.
  *       - `lambda`: A parameter controlling the relevance-diversity balance, where 0 emphasizes
  *         diversity and 1 prioritizes relevance. Intermediate values provide a blend of the two,
  *         allowing customization based on the importance of content variety relative to query relevance.
  */
  constructor(fields) {
    super(fields);
    this.vectorStore = fields.vectorStore;
    this.k = fields.k ?? this.k;
    this.searchType = fields.searchType ?? this.searchType;
    this.filter = fields.filter;
    if (fields.searchType === "mmr") this.searchKwargs = fields.searchKwargs;
  }
  /**
  * Retrieves relevant documents based on the specified query, using either
  * similarity or maximal marginal relevance (MMR) search.
  *
  * If `searchType` is set to `"mmr"`, performs an MMR search to balance
  * similarity and diversity among results. If `searchType` is `"similarity"`,
  * retrieves results purely based on similarity to the query.
  *
  * @param query - The query string used to find relevant documents.
  * @param runManager - Optional callback manager for tracking retrieval progress.
  * @returns A promise that resolves to an array of `DocumentInterface` instances
  *          representing the most relevant documents to the query.
  * @throws {Error} Throws an error if MMR search is requested but not supported
  *                 by the vector store.
  * @protected
  */
  async _getRelevantDocuments(query, runManager) {
    if (this.searchType === "mmr") {
      if (typeof this.vectorStore.maxMarginalRelevanceSearch !== "function") throw new Error(`The vector store backing this retriever, ${this._vectorstoreType()} does not support max marginal relevance search.`);
      return this.vectorStore.maxMarginalRelevanceSearch(query, {
        k: this.k,
        filter: this.filter,
        ...this.searchKwargs
      }, runManager?.getChild("vectorstore"));
    }
    return this.vectorStore.similaritySearch(query, this.k, this.filter, runManager?.getChild("vectorstore"));
  }
  /**
  * Adds an array of documents to the vector store, embedding them as part of
  * the storage process.
  *
  * This method delegates document embedding and storage to the `addDocuments`
  * method of the underlying vector store.
  *
  * @param documents - An array of documents to embed and add to the vector store.
  * @param options - Optional settings to customize document addition.
  * @returns A promise that resolves to an array of document IDs or `void`,
  *          depending on the vector store's implementation.
  */
  async addDocuments(documents, options) {
    return this.vectorStore.addDocuments(documents, options);
  }
};
var VectorStore = class extends Serializable {
  /**
  * Namespace within LangChain to uniquely identify this vector store's
  * location, based on the vector store type.
  *
  * @internal
  */
  lc_namespace = [
    "langchain",
    "vectorstores",
    this._vectorstoreType()
  ];
  /**
  * Embeddings interface for generating vector embeddings from text queries,
  * enabling vector-based similarity searches.
  */
  embeddings;
  /**
  * Initializes a new vector store with embeddings and database configuration.
  *
  * @param embeddings - Instance of `EmbeddingsInterface` used to embed queries.
  * @param dbConfig - Configuration settings for the database or storage system.
  */
  constructor(embeddings, dbConfig) {
    super(dbConfig);
    this.embeddings = embeddings;
  }
  /**
  * Deletes documents from the vector store based on the specified parameters.
  *
  * @param _params - Flexible key-value pairs defining conditions for document deletion.
  * @returns A promise that resolves once the deletion is complete.
  */
  async delete(_params) {
    throw new Error("Not implemented.");
  }
  /**
  * Searches for documents similar to a text query by embedding the query and
  * performing a similarity search on the resulting vector.
  *
  * @param query - Text query for finding similar documents.
  * @param k - Number of similar results to return. Defaults to 4.
  * @param filter - Optional filter based on `FilterType`.
  * @param _callbacks - Optional callbacks for monitoring search progress
  * @returns A promise resolving to an array of `DocumentInterface` instances representing similar documents.
  */
  async similaritySearch(query, k = 4, filter = void 0, _callbacks = void 0) {
    const results = await this.similaritySearchVectorWithScore(await this.embeddings.embedQuery(query), k, filter);
    return results.map((result) => result[0]);
  }
  /**
  * Searches for documents similar to a text query by embedding the query,
  * and returns results with similarity scores.
  *
  * @param query - Text query for finding similar documents.
  * @param k - Number of similar results to return. Defaults to 4.
  * @param filter - Optional filter based on `FilterType`.
  * @param _callbacks - Optional callbacks for monitoring search progress
  * @returns A promise resolving to an array of tuples, each containing a
  *          document and its similarity score.
  */
  async similaritySearchWithScore(query, k = 4, filter = void 0, _callbacks = void 0) {
    return this.similaritySearchVectorWithScore(await this.embeddings.embedQuery(query), k, filter);
  }
  /**
  * Creates a `VectorStore` instance from an array of text strings and optional
  * metadata, using the specified embeddings and database configuration.
  *
  * Subclasses must implement this method to define how text and metadata
  * are embedded and stored in the vector store. Throws an error if not overridden.
  *
  * @param _texts - Array of strings representing the text documents to be stored.
  * @param _metadatas - Metadata for the texts, either as an array (one for each text)
  *                     or a single object (applied to all texts).
  * @param _embeddings - Instance of `EmbeddingsInterface` to embed the texts.
  * @param _dbConfig - Database configuration settings.
  * @returns A promise that resolves to a new `VectorStore` instance.
  * @throws {Error} Throws an error if this method is not overridden by a subclass.
  */
  static fromTexts(_texts, _metadatas, _embeddings, _dbConfig) {
    throw new Error("the Langchain vectorstore implementation you are using forgot to override this, please report a bug");
  }
  /**
  * Creates a `VectorStore` instance from an array of documents, using the specified
  * embeddings and database configuration.
  *
  * Subclasses must implement this method to define how documents are embedded
  * and stored. Throws an error if not overridden.
  *
  * @param _docs - Array of `DocumentInterface` instances representing the documents to be stored.
  * @param _embeddings - Instance of `EmbeddingsInterface` to embed the documents.
  * @param _dbConfig - Database configuration settings.
  * @returns A promise that resolves to a new `VectorStore` instance.
  * @throws {Error} Throws an error if this method is not overridden by a subclass.
  */
  static fromDocuments(_docs, _embeddings, _dbConfig) {
    throw new Error("the Langchain vectorstore implementation you are using forgot to override this, please report a bug");
  }
  /**
  * Creates a `VectorStoreRetriever` instance with flexible configuration options.
  *
  * @param kOrFields
  *    - If a number is provided, it sets the `k` parameter (number of items to retrieve).
  *    - If an object is provided, it should contain various configuration options.
  * @param filter
  *    - Optional filter criteria to limit the items retrieved based on the specified filter type.
  * @param callbacks
  *    - Optional callbacks that may be triggered at specific stages of the retrieval process.
  * @param tags
  *    - Tags to categorize or label the `VectorStoreRetriever`. Defaults to an empty array if not provided.
  * @param metadata
  *    - Additional metadata as key-value pairs to add contextual information for the retrieval process.
  * @param verbose
  *    - If `true`, enables detailed logging for the retrieval process. Defaults to `false`.
  *
  * @returns
  *    - A configured `VectorStoreRetriever` instance based on the provided parameters.
  *
  * @example
  * Basic usage with a `k` value:
  * ```typescript
  * const retriever = myVectorStore.asRetriever(5);
  * ```
  *
  * Usage with a configuration object:
  * ```typescript
  * const retriever = myVectorStore.asRetriever({
  *   k: 10,
  *   filter: myFilter,
  *   tags: ['example', 'test'],
  *   verbose: true,
  *   searchType: 'mmr',
  *   searchKwargs: { alpha: 0.5 },
  * });
  * ```
  */
  asRetriever(kOrFields, filter, callbacks, tags, metadata, verbose) {
    if (typeof kOrFields === "number") return new VectorStoreRetriever({
      vectorStore: this,
      k: kOrFields,
      filter,
      tags: [...tags ?? [], this._vectorstoreType()],
      metadata,
      verbose,
      callbacks
    });
    else {
      const params = {
        vectorStore: this,
        k: kOrFields?.k,
        filter: kOrFields?.filter,
        tags: [...kOrFields?.tags ?? [], this._vectorstoreType()],
        metadata: kOrFields?.metadata,
        verbose: kOrFields?.verbose,
        callbacks: kOrFields?.callbacks,
        searchType: kOrFields?.searchType
      };
      if (kOrFields?.searchType === "mmr") return new VectorStoreRetriever({
        ...params,
        searchKwargs: kOrFields.searchKwargs
      });
      return new VectorStoreRetriever({ ...params });
    }
  }
};
var SaveableVectorStore = class extends VectorStore {
  /**
  * Loads a vector store instance from the specified directory, using the
  * provided embeddings to ensure compatibility.
  *
  * This static method reconstructs a `SaveableVectorStore` from previously
  * saved data. Implementations should interpret the saved data format to
  * recreate the vector store instance.
  *
  * @param _directory - The directory path from which the vector store
  * data will be loaded.
  * @param _embeddings - An instance of `EmbeddingsInterface` to align
  * the embeddings with the loaded vector data.
  * @returns A promise that resolves to a `SaveableVectorStore` instance
  * constructed from the saved data.
  */
  static load(_directory, _embeddings) {
    throw new Error("Not implemented");
  }
};

// node_modules/@langchain/core/dist/document_loaders/base.js
var base_exports4 = {};
__export2(base_exports4, { BaseDocumentLoader: () => BaseDocumentLoader });
var BaseDocumentLoader = class {
};

// node_modules/@langchain/core/dist/document_loaders/langsmith.js
var langsmith_exports = {};
__export2(langsmith_exports, { LangSmithLoader: () => LangSmithLoader });
var LangSmithLoader = class extends BaseDocumentLoader {
  datasetId;
  datasetName;
  exampleIds;
  asOf;
  splits;
  inlineS3Urls;
  offset;
  limit;
  metadata;
  filter;
  contentKey;
  formatContent;
  client;
  constructor(fields) {
    super();
    if (fields.client && fields.clientConfig) throw new Error("client and clientConfig cannot both be provided.");
    this.client = fields.client ?? new Client(fields?.clientConfig);
    this.contentKey = fields.contentKey ? fields.contentKey.split(".") : [];
    this.formatContent = fields.formatContent ?? _stringify;
    this.datasetId = fields.datasetId;
    this.datasetName = fields.datasetName;
    this.exampleIds = fields.exampleIds;
    this.asOf = fields.asOf;
    this.splits = fields.splits;
    this.inlineS3Urls = fields.inlineS3Urls;
    this.offset = fields.offset;
    this.limit = fields.limit;
    this.metadata = fields.metadata;
    this.filter = fields.filter;
  }
  async load() {
    const documents = [];
    for await (const example of this.client.listExamples({
      datasetId: this.datasetId,
      datasetName: this.datasetName,
      exampleIds: this.exampleIds,
      asOf: this.asOf,
      splits: this.splits,
      inlineS3Urls: this.inlineS3Urls,
      offset: this.offset,
      limit: this.limit,
      metadata: this.metadata,
      filter: this.filter
    })) {
      let content = example.inputs;
      for (const key of this.contentKey) content = content[key];
      const contentStr = this.formatContent(content);
      const metadata = example;
      ["created_at", "modified_at"].forEach((k) => {
        if (k in metadata) {
          if (typeof metadata[k] === "object") metadata[k] = metadata[k].toString();
        }
      });
      documents.push({
        pageContent: contentStr,
        metadata
      });
    }
    return documents;
  }
};
function _stringify(x) {
  if (typeof x === "string") return x;
  else try {
    return JSON.stringify(x, null, 2);
  } catch {
    return String(x);
  }
}

// node_modules/@langchain/core/dist/example_selectors/base.js
var BaseExampleSelector = class extends Serializable {
  lc_namespace = [
    "langchain_core",
    "example_selectors",
    "base"
  ];
};

// node_modules/@langchain/core/dist/example_selectors/conditional.js
var BasePromptSelector = class {
  /**
  * Asynchronous version of `getPrompt` that also accepts an options object
  * for partial variables.
  * @param llm The language model for which to get a prompt.
  * @param options Optional object for partial variables.
  * @returns A Promise that resolves to a prompt template.
  */
  async getPromptAsync(llm, options) {
    const prompt = this.getPrompt(llm);
    return prompt.partial(options?.partialVariables ?? {});
  }
};
var ConditionalPromptSelector = class extends BasePromptSelector {
  defaultPrompt;
  conditionals;
  constructor(default_prompt, conditionals = []) {
    super();
    this.defaultPrompt = default_prompt;
    this.conditionals = conditionals;
  }
  /**
  * Method that selects a prompt based on a set of conditions. If none of
  * the conditions are met, it returns the default prompt.
  * @param llm The language model for which to get a prompt.
  * @returns A prompt template.
  */
  getPrompt(llm) {
    for (const [condition, prompt] of this.conditionals) if (condition(llm)) return prompt;
    return this.defaultPrompt;
  }
};
function isLLM(llm) {
  return llm._modelType() === "base_llm";
}
function isChatModel(llm) {
  return llm._modelType() === "base_chat_model";
}

// node_modules/@langchain/core/dist/example_selectors/length_based.js
function getLengthBased(text) {
  return text.split(/\n| /).length;
}
var LengthBasedExampleSelector = class LengthBasedExampleSelector2 extends BaseExampleSelector {
  examples = [];
  examplePrompt;
  getTextLength = getLengthBased;
  maxLength = 2048;
  exampleTextLengths = [];
  constructor(data) {
    super(data);
    this.examplePrompt = data.examplePrompt;
    this.maxLength = data.maxLength ?? 2048;
    this.getTextLength = data.getTextLength ?? getLengthBased;
  }
  /**
  * Adds an example to the list of examples and calculates its length.
  * @param example The example to be added.
  * @returns Promise that resolves when the example has been added and its length calculated.
  */
  async addExample(example) {
    this.examples.push(example);
    const stringExample = await this.examplePrompt.format(example);
    this.exampleTextLengths.push(this.getTextLength(stringExample));
  }
  /**
  * Calculates the lengths of the examples.
  * @param v Array of lengths of the examples.
  * @param values Instance of LengthBasedExampleSelector.
  * @returns Promise that resolves with an array of lengths of the examples.
  */
  async calculateExampleTextLengths(v, values) {
    if (v.length > 0) return v;
    const { examples, examplePrompt } = values;
    const stringExamples = await Promise.all(examples.map((eg) => examplePrompt.format(eg)));
    return stringExamples.map((eg) => this.getTextLength(eg));
  }
  /**
  * Selects examples until the total length of the selected examples
  * reaches the maxLength.
  * @param inputVariables The input variables for the examples.
  * @returns Promise that resolves with an array of selected examples.
  */
  async selectExamples(inputVariables) {
    const inputs = Object.values(inputVariables).join(" ");
    let remainingLength = this.maxLength - this.getTextLength(inputs);
    let i = 0;
    const examples = [];
    while (remainingLength > 0 && i < this.examples.length) {
      const newLength = remainingLength - this.exampleTextLengths[i];
      if (newLength < 0) break;
      else {
        examples.push(this.examples[i]);
        remainingLength = newLength;
      }
      i += 1;
    }
    return examples;
  }
  /**
  * Creates a new instance of LengthBasedExampleSelector and adds a list of
  * examples to it.
  * @param examples Array of examples to be added.
  * @param args Input parameters for the LengthBasedExampleSelector.
  * @returns Promise that resolves with a new instance of LengthBasedExampleSelector with the examples added.
  */
  static async fromExamples(examples, args) {
    const selector = new LengthBasedExampleSelector2(args);
    await Promise.all(examples.map((eg) => selector.addExample(eg)));
    return selector;
  }
};

// node_modules/@langchain/core/dist/example_selectors/semantic_similarity.js
function sortedValues(values) {
  return Object.keys(values).sort().map((key) => values[key]);
}
var SemanticSimilarityExampleSelector = class SemanticSimilarityExampleSelector2 extends BaseExampleSelector {
  vectorStoreRetriever;
  exampleKeys;
  inputKeys;
  constructor(data) {
    super(data);
    this.exampleKeys = data.exampleKeys;
    this.inputKeys = data.inputKeys;
    if (data.vectorStore !== void 0) this.vectorStoreRetriever = data.vectorStore.asRetriever({
      k: data.k ?? 4,
      filter: data.filter
    });
    else if (data.vectorStoreRetriever) this.vectorStoreRetriever = data.vectorStoreRetriever;
    else throw new Error(`You must specify one of "vectorStore" and "vectorStoreRetriever".`);
  }
  /**
  * Method that adds a new example to the vectorStore. The example is
  * converted to a string and added to the vectorStore as a document.
  * @param example The example to be added to the vectorStore.
  * @returns Promise that resolves when the example has been added to the vectorStore.
  */
  async addExample(example) {
    const inputKeys = this.inputKeys ?? Object.keys(example);
    const stringExample = sortedValues(inputKeys.reduce((acc, key) => ({
      ...acc,
      [key]: example[key]
    }), {})).join(" ");
    await this.vectorStoreRetriever.addDocuments([new Document({
      pageContent: stringExample,
      metadata: example
    })]);
  }
  /**
  * Method that selects which examples to use based on semantic similarity.
  * It performs a similarity search in the vectorStore using the input
  * variables and returns the examples with the highest similarity.
  * @param inputVariables The input variables used for the similarity search.
  * @returns Promise that resolves with an array of the selected examples.
  */
  async selectExamples(inputVariables) {
    const inputKeys = this.inputKeys ?? Object.keys(inputVariables);
    const query = sortedValues(inputKeys.reduce((acc, key) => ({
      ...acc,
      [key]: inputVariables[key]
    }), {})).join(" ");
    const exampleDocs = await this.vectorStoreRetriever.invoke(query);
    const examples = exampleDocs.map((doc) => doc.metadata);
    if (this.exampleKeys) return examples.map((example) => this.exampleKeys.reduce((acc, key) => ({
      ...acc,
      [key]: example[key]
    }), {}));
    return examples;
  }
  /**
  * Static method that creates a new instance of
  * SemanticSimilarityExampleSelector. It takes a list of examples, an
  * instance of Embeddings, a VectorStore class, and an options object as
  * parameters. It converts the examples to strings, creates a VectorStore
  * from the strings and the embeddings, and returns a new
  * SemanticSimilarityExampleSelector with the created VectorStore and the
  * options provided.
  * @param examples The list of examples to be used.
  * @param embeddings The instance of Embeddings to be used.
  * @param vectorStoreCls The VectorStore class to be used.
  * @param options The options object for the SemanticSimilarityExampleSelector.
  * @returns Promise that resolves with a new instance of SemanticSimilarityExampleSelector.
  */
  static async fromExamples(examples, embeddings, vectorStoreCls, options = {}) {
    const inputKeys = options.inputKeys ?? null;
    const stringExamples = examples.map((example) => sortedValues(inputKeys ? inputKeys.reduce((acc, key) => ({
      ...acc,
      [key]: example[key]
    }), {}) : example).join(" "));
    const vectorStore = await vectorStoreCls.fromTexts(stringExamples, examples, embeddings, options);
    return new SemanticSimilarityExampleSelector2({
      vectorStore,
      k: options.k ?? 4,
      exampleKeys: options.exampleKeys,
      inputKeys: options.inputKeys
    });
  }
};

// node_modules/@langchain/core/dist/example_selectors/index.js
var example_selectors_exports = {};
__export2(example_selectors_exports, {
  BaseExampleSelector: () => BaseExampleSelector,
  BasePromptSelector: () => BasePromptSelector,
  ConditionalPromptSelector: () => ConditionalPromptSelector,
  LengthBasedExampleSelector: () => LengthBasedExampleSelector,
  SemanticSimilarityExampleSelector: () => SemanticSimilarityExampleSelector,
  isChatModel: () => isChatModel,
  isLLM: () => isLLM
});

// node_modules/@langchain/core/dist/indexing/record_manager.js
var UUIDV5_NAMESPACE = "10f90ea3-90a4-4962-bf75-83a0f3c1c62a";
var RecordManager = class extends Serializable {
  lc_namespace = ["langchain", "recordmanagers"];
};

// node_modules/@langchain/core/dist/indexing/base.js
var _HashedDocument = class {
  uid;
  hash_;
  contentHash;
  metadataHash;
  pageContent;
  metadata;
  keyEncoder = sha256;
  constructor(fields) {
    this.uid = fields.uid;
    this.pageContent = fields.pageContent;
    this.metadata = fields.metadata;
  }
  makeDefaultKeyEncoder(keyEncoderFn) {
    this.keyEncoder = keyEncoderFn;
  }
  calculateHashes() {
    const forbiddenKeys = [
      "hash_",
      "content_hash",
      "metadata_hash"
    ];
    for (const key of forbiddenKeys) if (key in this.metadata) throw new Error(`Metadata cannot contain key ${key} as it is reserved for internal use. Restricted keys: [${forbiddenKeys.join(", ")}]`);
    const contentHash = this._hashStringToUUID(this.pageContent);
    try {
      const metadataHash = this._hashNestedDictToUUID(this.metadata);
      this.contentHash = contentHash;
      this.metadataHash = metadataHash;
    } catch (e) {
      throw new Error(`Failed to hash metadata: ${e}. Please use a dict that can be serialized using json.`);
    }
    this.hash_ = this._hashStringToUUID(this.contentHash + this.metadataHash);
    if (!this.uid) this.uid = this.hash_;
  }
  toDocument() {
    return new Document({
      pageContent: this.pageContent,
      metadata: this.metadata
    });
  }
  static fromDocument(document, uid) {
    const doc = new this({
      pageContent: document.pageContent,
      metadata: document.metadata,
      uid: uid || document.uid
    });
    doc.calculateHashes();
    return doc;
  }
  _hashStringToUUID(inputString) {
    const hash_value = this.keyEncoder(inputString);
    return v5_default(hash_value, UUIDV5_NAMESPACE);
  }
  _hashNestedDictToUUID(data) {
    const serialized_data = JSON.stringify(data, Object.keys(data).sort());
    const hash_value = this.keyEncoder(serialized_data);
    return v5_default(hash_value, UUIDV5_NAMESPACE);
  }
};
function _batch(size, iterable) {
  const batches = [];
  let currentBatch = [];
  iterable.forEach((item) => {
    currentBatch.push(item);
    if (currentBatch.length >= size) {
      batches.push(currentBatch);
      currentBatch = [];
    }
  });
  if (currentBatch.length > 0) batches.push(currentBatch);
  return batches;
}
function _deduplicateInOrder(hashedDocuments) {
  const seen = /* @__PURE__ */ new Set();
  const deduplicated = [];
  for (const hashedDoc of hashedDocuments) {
    if (!hashedDoc.hash_) throw new Error("Hashed document does not have a hash");
    if (!seen.has(hashedDoc.hash_)) {
      seen.add(hashedDoc.hash_);
      deduplicated.push(hashedDoc);
    }
  }
  return deduplicated;
}
function _getSourceIdAssigner(sourceIdKey) {
  if (sourceIdKey === null) return (_doc) => null;
  else if (typeof sourceIdKey === "string") return (doc) => doc.metadata[sourceIdKey];
  else if (typeof sourceIdKey === "function") return sourceIdKey;
  else throw new Error(`sourceIdKey should be null, a string or a function, got ${typeof sourceIdKey}`);
}
var _isBaseDocumentLoader = (arg) => {
  if ("load" in arg && typeof arg.load === "function" && "loadAndSplit" in arg && typeof arg.loadAndSplit === "function") return true;
  return false;
};
async function index(args) {
  const { docsSource, recordManager, vectorStore, options } = args;
  const { batchSize = 100, cleanup, sourceIdKey, cleanupBatchSize = 1e3, forceUpdate = false } = options ?? {};
  if (cleanup === "incremental" && !sourceIdKey) throw new Error("sourceIdKey is required when cleanup mode is incremental. Please provide through 'options.sourceIdKey'.");
  const docs = _isBaseDocumentLoader(docsSource) ? await docsSource.load() : docsSource;
  const sourceIdAssigner = _getSourceIdAssigner(sourceIdKey ?? null);
  const indexStartDt = await recordManager.getTime();
  let numAdded = 0;
  let numDeleted = 0;
  let numUpdated = 0;
  let numSkipped = 0;
  const batches = _batch(batchSize ?? 100, docs);
  for (const batch of batches) {
    const hashedDocs = _deduplicateInOrder(batch.map((doc) => _HashedDocument.fromDocument(doc)));
    const sourceIds = hashedDocs.map((doc) => sourceIdAssigner(doc));
    if (cleanup === "incremental") hashedDocs.forEach((_hashedDoc, index$1) => {
      const source = sourceIds[index$1];
      if (source === null) throw new Error("sourceIdKey must be provided when cleanup is incremental");
    });
    const batchExists = await recordManager.exists(hashedDocs.map((doc) => doc.uid));
    const uids = [];
    const docsToIndex = [];
    const docsToUpdate = [];
    const seenDocs = /* @__PURE__ */ new Set();
    hashedDocs.forEach((hashedDoc, i) => {
      const docExists = batchExists[i];
      if (docExists) if (forceUpdate) seenDocs.add(hashedDoc.uid);
      else {
        docsToUpdate.push(hashedDoc.uid);
        return;
      }
      uids.push(hashedDoc.uid);
      docsToIndex.push(hashedDoc.toDocument());
    });
    if (docsToUpdate.length > 0) {
      await recordManager.update(docsToUpdate, { timeAtLeast: indexStartDt });
      numSkipped += docsToUpdate.length;
    }
    if (docsToIndex.length > 0) {
      await vectorStore.addDocuments(docsToIndex, { ids: uids });
      numAdded += docsToIndex.length - seenDocs.size;
      numUpdated += seenDocs.size;
    }
    await recordManager.update(hashedDocs.map((doc) => doc.uid), {
      timeAtLeast: indexStartDt,
      groupIds: sourceIds
    });
    if (cleanup === "incremental") {
      sourceIds.forEach((sourceId) => {
        if (!sourceId) throw new Error("Source id cannot be null");
      });
      const uidsToDelete = await recordManager.listKeys({
        before: indexStartDt,
        groupIds: sourceIds
      });
      if (uidsToDelete.length > 0) {
        await vectorStore.delete({ ids: uidsToDelete });
        await recordManager.deleteKeys(uidsToDelete);
        numDeleted += uidsToDelete.length;
      }
    }
  }
  if (cleanup === "full") {
    let uidsToDelete = await recordManager.listKeys({
      before: indexStartDt,
      limit: cleanupBatchSize
    });
    while (uidsToDelete.length > 0) {
      await vectorStore.delete({ ids: uidsToDelete });
      await recordManager.deleteKeys(uidsToDelete);
      numDeleted += uidsToDelete.length;
      uidsToDelete = await recordManager.listKeys({
        before: indexStartDt,
        limit: cleanupBatchSize
      });
    }
  }
  return {
    numAdded,
    numDeleted,
    numUpdated,
    numSkipped
  };
}

// node_modules/@langchain/core/dist/indexing/index.js
var indexing_exports = {};
__export2(indexing_exports, {
  RecordManager: () => RecordManager,
  UUIDV5_NAMESPACE: () => UUIDV5_NAMESPACE,
  _HashedDocument: () => _HashedDocument,
  _batch: () => _batch,
  _deduplicateInOrder: () => _deduplicateInOrder,
  _getSourceIdAssigner: () => _getSourceIdAssigner,
  _isBaseDocumentLoader: () => _isBaseDocumentLoader,
  index: () => index
});

// node_modules/@langchain/core/dist/language_models/llms.js
var llms_exports = {};
__export2(llms_exports, {
  BaseLLM: () => BaseLLM,
  LLM: () => LLM
});
var BaseLLM = class BaseLLM2 extends BaseLanguageModel {
  lc_namespace = [
    "langchain",
    "llms",
    this._llmType()
  ];
  /**
  * This method takes an input and options, and returns a string. It
  * converts the input to a prompt value and generates a result based on
  * the prompt.
  * @param input Input for the LLM.
  * @param options Options for the LLM call.
  * @returns A string result based on the prompt.
  */
  async invoke(input, options) {
    const promptValue = BaseLLM2._convertInputToPromptValue(input);
    const result = await this.generatePrompt([promptValue], options, options?.callbacks);
    return result.generations[0][0].text;
  }
  async *_streamResponseChunks(_input, _options, _runManager) {
    throw new Error("Not implemented.");
  }
  _separateRunnableConfigFromCallOptionsCompat(options) {
    const [runnableConfig, callOptions] = super._separateRunnableConfigFromCallOptions(options);
    callOptions.signal = runnableConfig.signal;
    return [runnableConfig, callOptions];
  }
  async *_streamIterator(input, options) {
    if (this._streamResponseChunks === BaseLLM2.prototype._streamResponseChunks) yield this.invoke(input, options);
    else {
      const prompt = BaseLLM2._convertInputToPromptValue(input);
      const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(options);
      const callbackManager_ = await CallbackManager.configure(runnableConfig.callbacks, this.callbacks, runnableConfig.tags, this.tags, runnableConfig.metadata, this.metadata, { verbose: this.verbose });
      const extra = {
        options: callOptions,
        invocation_params: this?.invocationParams(callOptions),
        batch_size: 1
      };
      const runManagers = await callbackManager_?.handleLLMStart(this.toJSON(), [prompt.toString()], runnableConfig.runId, void 0, extra, void 0, void 0, runnableConfig.runName);
      let generation = new GenerationChunk({ text: "" });
      try {
        for await (const chunk of this._streamResponseChunks(prompt.toString(), callOptions, runManagers?.[0])) {
          if (!generation) generation = chunk;
          else generation = generation.concat(chunk);
          if (typeof chunk.text === "string") yield chunk.text;
        }
      } catch (err) {
        await Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMError(err)));
        throw err;
      }
      await Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMEnd({ generations: [[generation]] })));
    }
  }
  /**
  * This method takes prompt values, options, and callbacks, and generates
  * a result based on the prompts.
  * @param promptValues Prompt values for the LLM.
  * @param options Options for the LLM call.
  * @param callbacks Callbacks for the LLM call.
  * @returns An LLMResult based on the prompts.
  */
  async generatePrompt(promptValues, options, callbacks) {
    const prompts = promptValues.map((promptValue) => promptValue.toString());
    return this.generate(prompts, options, callbacks);
  }
  /**
  * Get the parameters used to invoke the model
  */
  invocationParams(_options) {
    return {};
  }
  _flattenLLMResult(llmResult) {
    const llmResults = [];
    for (let i = 0; i < llmResult.generations.length; i += 1) {
      const genList = llmResult.generations[i];
      if (i === 0) llmResults.push({
        generations: [genList],
        llmOutput: llmResult.llmOutput
      });
      else {
        const llmOutput = llmResult.llmOutput ? {
          ...llmResult.llmOutput,
          tokenUsage: {}
        } : void 0;
        llmResults.push({
          generations: [genList],
          llmOutput
        });
      }
    }
    return llmResults;
  }
  /** @ignore */
  async _generateUncached(prompts, parsedOptions, handledOptions, startedRunManagers) {
    let runManagers;
    if (startedRunManagers !== void 0 && startedRunManagers.length === prompts.length) runManagers = startedRunManagers;
    else {
      const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, handledOptions.metadata, this.metadata, { verbose: this.verbose });
      const extra = {
        options: parsedOptions,
        invocation_params: this?.invocationParams(parsedOptions),
        batch_size: prompts.length
      };
      runManagers = await callbackManager_?.handleLLMStart(this.toJSON(), prompts, handledOptions.runId, void 0, extra, void 0, void 0, handledOptions?.runName);
    }
    const hasStreamingHandler = !!runManagers?.[0].handlers.find(callbackHandlerPrefersStreaming);
    let output;
    if (hasStreamingHandler && prompts.length === 1 && this._streamResponseChunks !== BaseLLM2.prototype._streamResponseChunks) try {
      const stream = await this._streamResponseChunks(prompts[0], parsedOptions, runManagers?.[0]);
      let aggregated;
      for await (const chunk of stream) if (aggregated === void 0) aggregated = chunk;
      else aggregated = concat(aggregated, chunk);
      if (aggregated === void 0) throw new Error("Received empty response from chat model call.");
      output = {
        generations: [[aggregated]],
        llmOutput: {}
      };
      await runManagers?.[0].handleLLMEnd(output);
    } catch (e) {
      await runManagers?.[0].handleLLMError(e);
      throw e;
    }
    else {
      try {
        output = await this._generate(prompts, parsedOptions, runManagers?.[0]);
      } catch (err) {
        await Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMError(err)));
        throw err;
      }
      const flattenedOutputs = this._flattenLLMResult(output);
      await Promise.all((runManagers ?? []).map((runManager, i) => runManager?.handleLLMEnd(flattenedOutputs[i])));
    }
    const runIds = runManagers?.map((manager) => manager.runId) || void 0;
    Object.defineProperty(output, RUN_KEY, {
      value: runIds ? { runIds } : void 0,
      configurable: true
    });
    return output;
  }
  async _generateCached({ prompts, cache, llmStringKey, parsedOptions, handledOptions, runId }) {
    const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, handledOptions.metadata, this.metadata, { verbose: this.verbose });
    const extra = {
      options: parsedOptions,
      invocation_params: this?.invocationParams(parsedOptions),
      batch_size: prompts.length
    };
    const runManagers = await callbackManager_?.handleLLMStart(this.toJSON(), prompts, runId, void 0, extra, void 0, void 0, handledOptions?.runName);
    const missingPromptIndices = [];
    const results = await Promise.allSettled(prompts.map(async (prompt, index2) => {
      const result = await cache.lookup(prompt, llmStringKey);
      if (result == null) missingPromptIndices.push(index2);
      return result;
    }));
    const cachedResults = results.map((result, index2) => ({
      result,
      runManager: runManagers?.[index2]
    })).filter(({ result }) => result.status === "fulfilled" && result.value != null || result.status === "rejected");
    const generations = [];
    await Promise.all(cachedResults.map(async ({ result: promiseResult, runManager }, i) => {
      if (promiseResult.status === "fulfilled") {
        const result = promiseResult.value;
        generations[i] = result.map((result$1) => {
          result$1.generationInfo = {
            ...result$1.generationInfo,
            tokenUsage: {}
          };
          return result$1;
        });
        if (result.length) await runManager?.handleLLMNewToken(result[0].text);
        return runManager?.handleLLMEnd({ generations: [result] }, void 0, void 0, void 0, { cached: true });
      } else {
        await runManager?.handleLLMError(promiseResult.reason, void 0, void 0, void 0, { cached: true });
        return Promise.reject(promiseResult.reason);
      }
    }));
    const output = {
      generations,
      missingPromptIndices,
      startedRunManagers: runManagers
    };
    Object.defineProperty(output, RUN_KEY, {
      value: runManagers ? { runIds: runManagers?.map((manager) => manager.runId) } : void 0,
      configurable: true
    });
    return output;
  }
  /**
  * Run the LLM on the given prompts and input, handling caching.
  */
  async generate(prompts, options, callbacks) {
    if (!Array.isArray(prompts)) throw new Error("Argument 'prompts' is expected to be a string[]");
    let parsedOptions;
    if (Array.isArray(options)) parsedOptions = { stop: options };
    else parsedOptions = options;
    const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(parsedOptions);
    runnableConfig.callbacks = runnableConfig.callbacks ?? callbacks;
    if (!this.cache) return this._generateUncached(prompts, callOptions, runnableConfig);
    const { cache } = this;
    const llmStringKey = this._getSerializedCacheKeyParametersForCall(callOptions);
    const { generations, missingPromptIndices, startedRunManagers } = await this._generateCached({
      prompts,
      cache,
      llmStringKey,
      parsedOptions: callOptions,
      handledOptions: runnableConfig,
      runId: runnableConfig.runId
    });
    let llmOutput = {};
    if (missingPromptIndices.length > 0) {
      const results = await this._generateUncached(missingPromptIndices.map((i) => prompts[i]), callOptions, runnableConfig, startedRunManagers !== void 0 ? missingPromptIndices.map((i) => startedRunManagers?.[i]) : void 0);
      await Promise.all(results.generations.map(async (generation, index2) => {
        const promptIndex = missingPromptIndices[index2];
        generations[promptIndex] = generation;
        return cache.update(prompts[promptIndex], llmStringKey, generation);
      }));
      llmOutput = results.llmOutput ?? {};
    }
    return {
      generations,
      llmOutput
    };
  }
  /**
  * Get the identifying parameters of the LLM.
  */
  _identifyingParams() {
    return {};
  }
  _modelType() {
    return "base_llm";
  }
};
var LLM = class extends BaseLLM {
  async _generate(prompts, options, runManager) {
    const generations = await Promise.all(prompts.map((prompt, promptIndex) => this._call(prompt, {
      ...options,
      promptIndex
    }, runManager).then((text) => [{ text }])));
    return { generations };
  }
};

// node_modules/@langchain/core/dist/language_models/profile.js
var profile_exports = {};

// node_modules/@langchain/core/dist/utils/json_patch.js
var json_patch_exports = {};
__export2(json_patch_exports, {
  applyPatch: () => applyPatch,
  compare: () => compare
});

// node_modules/@langchain/core/dist/output_parsers/base.js
var BaseLLMOutputParser = class extends Runnable {
  /**
  * Parses the result of an LLM call with a given prompt. By default, it
  * simply calls `parseResult`.
  * @param generations The generations from an LLM call.
  * @param _prompt The prompt used in the LLM call.
  * @param callbacks Optional callbacks.
  * @returns A promise of the parsed output.
  */
  parseResultWithPrompt(generations, _prompt, callbacks) {
    return this.parseResult(generations, callbacks);
  }
  _baseMessageToString(message) {
    return typeof message.content === "string" ? message.content : this._baseMessageContentToString(message.content);
  }
  _baseMessageContentToString(content) {
    return JSON.stringify(content);
  }
  /**
  * Calls the parser with a given input and optional configuration options.
  * If the input is a string, it creates a generation with the input as
  * text and calls `parseResult`. If the input is a `BaseMessage`, it
  * creates a generation with the input as a message and the content of the
  * input as text, and then calls `parseResult`.
  * @param input The input to the parser, which can be a string or a `BaseMessage`.
  * @param options Optional configuration options.
  * @returns A promise of the parsed output.
  */
  async invoke(input, options) {
    if (typeof input === "string") return this._callWithConfig(async (input$1, options$1) => this.parseResult([{ text: input$1 }], options$1?.callbacks), input, {
      ...options,
      runType: "parser"
    });
    else return this._callWithConfig(async (input$1, options$1) => this.parseResult([{
      message: input$1,
      text: this._baseMessageToString(input$1)
    }], options$1?.callbacks), input, {
      ...options,
      runType: "parser"
    });
  }
};
var BaseOutputParser = class extends BaseLLMOutputParser {
  parseResult(generations, callbacks) {
    return this.parse(generations[0].text, callbacks);
  }
  async parseWithPrompt(text, _prompt, callbacks) {
    return this.parse(text, callbacks);
  }
  /**
  * Return the string type key uniquely identifying this class of parser
  */
  _type() {
    throw new Error("_type not implemented");
  }
};
var OutputParserException = class extends Error {
  llmOutput;
  observation;
  sendToLLM;
  constructor(message, llmOutput, observation, sendToLLM = false) {
    super(message);
    this.llmOutput = llmOutput;
    this.observation = observation;
    this.sendToLLM = sendToLLM;
    if (sendToLLM) {
      if (observation === void 0 || llmOutput === void 0) throw new Error("Arguments 'observation' & 'llmOutput' are required if 'sendToLlm' is true");
    }
    addLangChainErrorFields(this, "OUTPUT_PARSING_FAILURE");
  }
};

// node_modules/@langchain/core/dist/output_parsers/transform.js
var BaseTransformOutputParser = class extends BaseOutputParser {
  async *_transform(inputGenerator) {
    for await (const chunk of inputGenerator) if (typeof chunk === "string") yield this.parseResult([{ text: chunk }]);
    else yield this.parseResult([{
      message: chunk,
      text: this._baseMessageToString(chunk)
    }]);
  }
  /**
  * Transforms an asynchronous generator of input into an asynchronous
  * generator of parsed output.
  * @param inputGenerator An asynchronous generator of input.
  * @param options A configuration object.
  * @returns An asynchronous generator of parsed output.
  */
  async *transform(inputGenerator, options) {
    yield* this._transformStreamWithConfig(inputGenerator, this._transform.bind(this), {
      ...options,
      runType: "parser"
    });
  }
};
var BaseCumulativeTransformOutputParser = class extends BaseTransformOutputParser {
  diff = false;
  constructor(fields) {
    super(fields);
    this.diff = fields?.diff ?? this.diff;
  }
  async *_transform(inputGenerator) {
    let prevParsed;
    let accGen;
    for await (const chunk of inputGenerator) {
      if (typeof chunk !== "string" && typeof chunk.content !== "string") throw new Error("Cannot handle non-string output.");
      let chunkGen;
      if (isBaseMessageChunk(chunk)) {
        if (typeof chunk.content !== "string") throw new Error("Cannot handle non-string message output.");
        chunkGen = new ChatGenerationChunk({
          message: chunk,
          text: chunk.content
        });
      } else if (isBaseMessage(chunk)) {
        if (typeof chunk.content !== "string") throw new Error("Cannot handle non-string message output.");
        chunkGen = new ChatGenerationChunk({
          message: convertToChunk(chunk),
          text: chunk.content
        });
      } else chunkGen = new GenerationChunk({ text: chunk });
      if (accGen === void 0) accGen = chunkGen;
      else accGen = accGen.concat(chunkGen);
      const parsed = await this.parsePartialResult([accGen]);
      if (parsed !== void 0 && parsed !== null && !deepCompareStrict(parsed, prevParsed)) {
        if (this.diff) yield this._diff(prevParsed, parsed);
        else yield parsed;
        prevParsed = parsed;
      }
    }
  }
  getFormatInstructions() {
    return "";
  }
};

// node_modules/@langchain/core/dist/output_parsers/bytes.js
var BytesOutputParser = class extends BaseTransformOutputParser {
  static lc_name() {
    return "BytesOutputParser";
  }
  lc_namespace = [
    "langchain_core",
    "output_parsers",
    "bytes"
  ];
  lc_serializable = true;
  textEncoder = new TextEncoder();
  parse(text) {
    return Promise.resolve(this.textEncoder.encode(text));
  }
  getFormatInstructions() {
    return "";
  }
};

// node_modules/@langchain/core/dist/output_parsers/list.js
var ListOutputParser = class extends BaseTransformOutputParser {
  re;
  async *_transform(inputGenerator) {
    let buffer = "";
    for await (const input of inputGenerator) {
      if (typeof input === "string") buffer += input;
      else buffer += input.content;
      if (!this.re) {
        const parts = await this.parse(buffer);
        if (parts.length > 1) {
          for (const part of parts.slice(0, -1)) yield [part];
          buffer = parts[parts.length - 1];
        }
      } else {
        const matches = [...buffer.matchAll(this.re)];
        if (matches.length > 1) {
          let doneIdx = 0;
          for (const match of matches.slice(0, -1)) {
            yield [match[1]];
            doneIdx += (match.index ?? 0) + match[0].length;
          }
          buffer = buffer.slice(doneIdx);
        }
      }
    }
    for (const part of await this.parse(buffer)) yield [part];
  }
};
var CommaSeparatedListOutputParser = class extends ListOutputParser {
  static lc_name() {
    return "CommaSeparatedListOutputParser";
  }
  lc_namespace = [
    "langchain_core",
    "output_parsers",
    "list"
  ];
  lc_serializable = true;
  /**
  * Parses the given text into an array of strings, using a comma as the
  * separator. If the parsing fails, throws an OutputParserException.
  * @param text The text to parse.
  * @returns An array of strings obtained by splitting the input text at each comma.
  */
  async parse(text) {
    try {
      return text.trim().split(",").map((s) => s.trim());
    } catch {
      throw new OutputParserException(`Could not parse output: ${text}`, text);
    }
  }
  /**
  * Provides instructions on the expected format of the response for the
  * CommaSeparatedListOutputParser.
  * @returns A string containing instructions on the expected format of the response.
  */
  getFormatInstructions() {
    return `Your response should be a list of comma separated values, eg: \`foo, bar, baz\``;
  }
};
var CustomListOutputParser = class extends ListOutputParser {
  lc_namespace = [
    "langchain_core",
    "output_parsers",
    "list"
  ];
  length;
  separator;
  constructor({ length, separator }) {
    super(...arguments);
    this.length = length;
    this.separator = separator || ",";
  }
  /**
  * Parses the given text into an array of strings, using the specified
  * separator. If the parsing fails or the number of items in the list
  * doesn't match the expected length, throws an OutputParserException.
  * @param text The text to parse.
  * @returns An array of strings obtained by splitting the input text at each occurrence of the specified separator.
  */
  async parse(text) {
    try {
      const items = text.trim().split(this.separator).map((s) => s.trim());
      if (this.length !== void 0 && items.length !== this.length) throw new OutputParserException(`Incorrect number of items. Expected ${this.length}, got ${items.length}.`);
      return items;
    } catch (e) {
      if (Object.getPrototypeOf(e) === OutputParserException.prototype) throw e;
      throw new OutputParserException(`Could not parse output: ${text}`);
    }
  }
  /**
  * Provides instructions on the expected format of the response for the
  * CustomListOutputParser, including the number of items and the
  * separator.
  * @returns A string containing instructions on the expected format of the response.
  */
  getFormatInstructions() {
    return `Your response should be a list of ${this.length === void 0 ? "" : `${this.length} `}items separated by "${this.separator}" (eg: \`foo${this.separator} bar${this.separator} baz\`)`;
  }
};
var NumberedListOutputParser = class extends ListOutputParser {
  static lc_name() {
    return "NumberedListOutputParser";
  }
  lc_namespace = [
    "langchain_core",
    "output_parsers",
    "list"
  ];
  lc_serializable = true;
  getFormatInstructions() {
    return `Your response should be a numbered list with each item on a new line. For example: 

1. foo

2. bar

3. baz`;
  }
  re = /\d+\.\s([^\n]+)/g;
  async parse(text) {
    return [...text.matchAll(this.re) ?? []].map((m) => m[1]);
  }
};
var MarkdownListOutputParser = class extends ListOutputParser {
  static lc_name() {
    return "NumberedListOutputParser";
  }
  lc_namespace = [
    "langchain_core",
    "output_parsers",
    "list"
  ];
  lc_serializable = true;
  getFormatInstructions() {
    return `Your response should be a numbered list with each item on a new line. For example: 

1. foo

2. bar

3. baz`;
  }
  re = /^\s*[-*]\s([^\n]+)$/gm;
  async parse(text) {
    return [...text.matchAll(this.re) ?? []].map((m) => m[1]);
  }
};

// node_modules/@langchain/core/dist/output_parsers/string.js
var StringOutputParser = class extends BaseTransformOutputParser {
  static lc_name() {
    return "StrOutputParser";
  }
  lc_namespace = [
    "langchain_core",
    "output_parsers",
    "string"
  ];
  lc_serializable = true;
  /**
  * Parses a string output from an LLM call. This method is meant to be
  * implemented by subclasses to define how a string output from an LLM
  * should be parsed.
  * @param text The string output from an LLM call.
  * @param callbacks Optional callbacks.
  * @returns A promise of the parsed output.
  */
  parse(text) {
    return Promise.resolve(text);
  }
  getFormatInstructions() {
    return "";
  }
  _textContentToString(content) {
    return content.text;
  }
  _imageUrlContentToString(_content) {
    throw new Error(`Cannot coerce a multimodal "image_url" message part into a string.`);
  }
  _messageContentToString(content) {
    switch (content.type) {
      case "text":
      case "text_delta":
        if ("text" in content) return this._textContentToString(content);
        break;
      case "image_url":
        if ("image_url" in content) return this._imageUrlContentToString(content);
        break;
      default:
        throw new Error(`Cannot coerce "${content.type}" message part into a string.`);
    }
    throw new Error(`Invalid content type: ${content.type}`);
  }
  _baseMessageContentToString(content) {
    return content.reduce((acc, item) => acc + this._messageContentToString(item), "");
  }
};

// node_modules/@langchain/core/dist/output_parsers/structured.js
var StructuredOutputParser = class extends BaseOutputParser {
  static lc_name() {
    return "StructuredOutputParser";
  }
  lc_namespace = [
    "langchain",
    "output_parsers",
    "structured"
  ];
  toJSON() {
    return this.toJSONNotImplemented();
  }
  constructor(schema) {
    super(schema);
    this.schema = schema;
  }
  /**
  * Creates a new StructuredOutputParser from a Zod schema.
  * @param schema The Zod schema which the output should match
  * @returns A new instance of StructuredOutputParser.
  */
  static fromZodSchema(schema) {
    return new this(schema);
  }
  /**
  * Creates a new StructuredOutputParser from a set of names and
  * descriptions.
  * @param schemas An object where each key is a name and each value is a description
  * @returns A new instance of StructuredOutputParser.
  */
  static fromNamesAndDescriptions(schemas) {
    const zodSchema = external_exports.object(Object.fromEntries(Object.entries(schemas).map(([name, description]) => [name, external_exports.string().describe(description)])));
    return new this(zodSchema);
  }
  /**
  * Returns a markdown code snippet with a JSON object formatted according
  * to the schema.
  * @param options Optional. The options for formatting the instructions
  * @returns A markdown code snippet with a JSON object formatted according to the schema.
  */
  getFormatInstructions() {
    return `You must format your output as a JSON value that adheres to a given "JSON Schema" instance.

"JSON Schema" is a declarative language that allows you to annotate and validate JSON documents.

For example, the example "JSON Schema" instance {{"properties": {{"foo": {{"description": "a list of test words", "type": "array", "items": {{"type": "string"}}}}}}, "required": ["foo"]}}
would match an object with one required property, "foo". The "type" property specifies "foo" must be an "array", and the "description" property semantically describes it as "a list of test words". The items within "foo" must be strings.
Thus, the object {{"foo": ["bar", "baz"]}} is a well-formatted instance of this example "JSON Schema". The object {{"properties": {{"foo": ["bar", "baz"]}}}} is not well-formatted.

Your output will be parsed and type-checked according to the provided schema instance, so make sure all fields in your output match the schema exactly and there are no trailing commas!

Here is the JSON Schema instance your output must adhere to. Include the enclosing markdown codeblock:
\`\`\`json
${JSON.stringify(toJsonSchema(this.schema))}
\`\`\`
`;
  }
  /**
  * Parses the given text according to the schema.
  * @param text The text to parse
  * @returns The parsed output.
  */
  async parse(text) {
    try {
      const trimmedText = text.trim();
      const json2 = trimmedText.match(/^```(?:json)?\s*([\s\S]*?)```/)?.[1] || trimmedText.match(/```json\s*([\s\S]*?)```/)?.[1] || trimmedText;
      const escapedJson = json2.replace(/"([^"\\]*(\\.[^"\\]*)*)"/g, (_match, capturedGroup) => {
        const escapedInsideQuotes = capturedGroup.replace(/\n/g, "\\n");
        return `"${escapedInsideQuotes}"`;
      }).replace(/\n/g, "");
      return await interopParseAsync(this.schema, JSON.parse(escapedJson));
    } catch (e) {
      throw new OutputParserException(`Failed to parse. Text: "${text}". Error: ${e}`, text);
    }
  }
};
var JsonMarkdownStructuredOutputParser = class extends StructuredOutputParser {
  static lc_name() {
    return "JsonMarkdownStructuredOutputParser";
  }
  getFormatInstructions(options) {
    const interpolationDepth = options?.interpolationDepth ?? 1;
    if (interpolationDepth < 1) throw new Error("f string interpolation depth must be at least 1");
    return `Return a markdown code snippet with a JSON object formatted to look like:
\`\`\`json
${this._schemaToInstruction(toJsonSchema(this.schema)).replaceAll("{", "{".repeat(interpolationDepth)).replaceAll("}", "}".repeat(interpolationDepth))}
\`\`\``;
  }
  _schemaToInstruction(schemaInput, indent = 2) {
    const schema = schemaInput;
    if ("type" in schema) {
      let nullable2 = false;
      let type;
      if (Array.isArray(schema.type)) {
        const nullIdx = schema.type.findIndex((type$1) => type$1 === "null");
        if (nullIdx !== -1) {
          nullable2 = true;
          schema.type.splice(nullIdx, 1);
        }
        type = schema.type.join(" | ");
      } else type = schema.type;
      if (schema.type === "object" && schema.properties) {
        const description$1 = schema.description ? ` // ${schema.description}` : "";
        const properties = Object.entries(schema.properties).map(([key, value]) => {
          const isOptional = schema.required?.includes(key) ? "" : " (optional)";
          return `${" ".repeat(indent)}"${key}": ${this._schemaToInstruction(value, indent + 2)}${isOptional}`;
        }).join("\n");
        return `{
${properties}
${" ".repeat(indent - 2)}}${description$1}`;
      }
      if (schema.type === "array" && schema.items) {
        const description$1 = schema.description ? ` // ${schema.description}` : "";
        return `array[
${" ".repeat(indent)}${this._schemaToInstruction(schema.items, indent + 2)}
${" ".repeat(indent - 2)}] ${description$1}`;
      }
      const isNullable = nullable2 ? " (nullable)" : "";
      const description = schema.description ? ` // ${schema.description}` : "";
      return `${type}${description}${isNullable}`;
    }
    if ("anyOf" in schema) return schema.anyOf.map((s) => this._schemaToInstruction(s, indent)).join(`
${" ".repeat(indent - 2)}`);
    throw new Error("unsupported schema type");
  }
  static fromZodSchema(schema) {
    return new this(schema);
  }
  static fromNamesAndDescriptions(schemas) {
    const zodSchema = external_exports.object(Object.fromEntries(Object.entries(schemas).map(([name, description]) => [name, external_exports.string().describe(description)])));
    return new this(zodSchema);
  }
};
var AsymmetricStructuredOutputParser = class extends BaseOutputParser {
  structuredInputParser;
  constructor({ inputSchema }) {
    super(...arguments);
    this.structuredInputParser = new JsonMarkdownStructuredOutputParser(inputSchema);
  }
  async parse(text) {
    let parsedInput;
    try {
      parsedInput = await this.structuredInputParser.parse(text);
    } catch (e) {
      throw new OutputParserException(`Failed to parse. Text: "${text}". Error: ${e}`, text);
    }
    return this.outputProcessor(parsedInput);
  }
  getFormatInstructions() {
    return this.structuredInputParser.getFormatInstructions();
  }
};

// node_modules/@langchain/core/dist/output_parsers/json.js
var JsonOutputParser = class extends BaseCumulativeTransformOutputParser {
  static lc_name() {
    return "JsonOutputParser";
  }
  lc_namespace = ["langchain_core", "output_parsers"];
  lc_serializable = true;
  /** @internal */
  _concatOutputChunks(first, second) {
    if (this.diff) return super._concatOutputChunks(first, second);
    return second;
  }
  _diff(prev, next) {
    if (!next) return void 0;
    if (!prev) return [{
      op: "replace",
      path: "",
      value: next
    }];
    return compare(prev, next);
  }
  async parsePartialResult(generations) {
    return parseJsonMarkdown(generations[0].text);
  }
  async parse(text) {
    return parseJsonMarkdown(text, JSON.parse);
  }
  getFormatInstructions() {
    return "";
  }
  /**
  * Extracts text content from a message for JSON parsing.
  * Uses the message's `.text` accessor which properly handles both
  * string content and ContentBlock[] arrays (extracting text from text blocks).
  * @param message The message to extract text from
  * @returns The text content of the message
  */
  _baseMessageToString(message) {
    return message.text;
  }
};

// node_modules/@langchain/core/dist/utils/sax-js/sax.js
var initializeSax = function() {
  const sax$1 = {};
  sax$1.parser = function(strict, opt) {
    return new SAXParser(strict, opt);
  };
  sax$1.SAXParser = SAXParser;
  sax$1.SAXStream = SAXStream;
  sax$1.createStream = createStream;
  sax$1.MAX_BUFFER_LENGTH = 64 * 1024;
  const buffers = [
    "comment",
    "sgmlDecl",
    "textNode",
    "tagName",
    "doctype",
    "procInstName",
    "procInstBody",
    "entity",
    "attribName",
    "attribValue",
    "cdata",
    "script"
  ];
  sax$1.EVENTS = [
    "text",
    "processinginstruction",
    "sgmldeclaration",
    "doctype",
    "comment",
    "opentagstart",
    "attribute",
    "opentag",
    "closetag",
    "opencdata",
    "cdata",
    "closecdata",
    "error",
    "end",
    "ready",
    "script",
    "opennamespace",
    "closenamespace"
  ];
  function SAXParser(strict, opt) {
    if (!(this instanceof SAXParser)) return new SAXParser(strict, opt);
    var parser = this;
    clearBuffers(parser);
    parser.q = parser.c = "";
    parser.bufferCheckPosition = sax$1.MAX_BUFFER_LENGTH;
    parser.opt = opt || {};
    parser.opt.lowercase = parser.opt.lowercase || parser.opt.lowercasetags;
    parser.looseCase = parser.opt.lowercase ? "toLowerCase" : "toUpperCase";
    parser.tags = [];
    parser.closed = parser.closedRoot = parser.sawRoot = false;
    parser.tag = parser.error = null;
    parser.strict = !!strict;
    parser.noscript = !!(strict || parser.opt.noscript);
    parser.state = S.BEGIN;
    parser.strictEntities = parser.opt.strictEntities;
    parser.ENTITIES = parser.strictEntities ? Object.create(sax$1.XML_ENTITIES) : Object.create(sax$1.ENTITIES);
    parser.attribList = [];
    if (parser.opt.xmlns) parser.ns = Object.create(rootNS);
    parser.trackPosition = parser.opt.position !== false;
    if (parser.trackPosition) parser.position = parser.line = parser.column = 0;
    emit(parser, "onready");
  }
  if (!Object.create) Object.create = function(o) {
    function F() {
    }
    F.prototype = o;
    var newf = new F();
    return newf;
  };
  if (!Object.keys) Object.keys = function(o) {
    var a = [];
    for (var i in o) if (o.hasOwnProperty(i)) a.push(i);
    return a;
  };
  function checkBufferLength(parser) {
    var maxAllowed = Math.max(sax$1.MAX_BUFFER_LENGTH, 10);
    var maxActual = 0;
    for (var i = 0, l = buffers.length; i < l; i++) {
      var len = parser[buffers[i]].length;
      if (len > maxAllowed) switch (buffers[i]) {
        case "textNode":
          closeText(parser);
          break;
        case "cdata":
          emitNode(parser, "oncdata", parser.cdata);
          parser.cdata = "";
          break;
        case "script":
          emitNode(parser, "onscript", parser.script);
          parser.script = "";
          break;
        default:
          error(parser, "Max buffer length exceeded: " + buffers[i]);
      }
      maxActual = Math.max(maxActual, len);
    }
    var m = sax$1.MAX_BUFFER_LENGTH - maxActual;
    parser.bufferCheckPosition = m + parser.position;
  }
  function clearBuffers(parser) {
    for (var i = 0, l = buffers.length; i < l; i++) parser[buffers[i]] = "";
  }
  function flushBuffers(parser) {
    closeText(parser);
    if (parser.cdata !== "") {
      emitNode(parser, "oncdata", parser.cdata);
      parser.cdata = "";
    }
    if (parser.script !== "") {
      emitNode(parser, "onscript", parser.script);
      parser.script = "";
    }
  }
  SAXParser.prototype = {
    end: function() {
      end(this);
    },
    write,
    resume: function() {
      this.error = null;
      return this;
    },
    close: function() {
      return this.write(null);
    },
    flush: function() {
      flushBuffers(this);
    }
  };
  var Stream = ReadableStream;
  if (!Stream) Stream = function() {
  };
  var streamWraps = sax$1.EVENTS.filter(function(ev) {
    return ev !== "error" && ev !== "end";
  });
  function createStream(strict, opt) {
    return new SAXStream(strict, opt);
  }
  function SAXStream(strict, opt) {
    if (!(this instanceof SAXStream)) return new SAXStream(strict, opt);
    Stream.apply(this);
    this._parser = new SAXParser(strict, opt);
    this.writable = true;
    this.readable = true;
    var me = this;
    this._parser.onend = function() {
      me.emit("end");
    };
    this._parser.onerror = function(er) {
      me.emit("error", er);
      me._parser.error = null;
    };
    this._decoder = null;
    streamWraps.forEach(function(ev) {
      Object.defineProperty(me, "on" + ev, {
        get: function() {
          return me._parser["on" + ev];
        },
        set: function(h) {
          if (!h) {
            me.removeAllListeners(ev);
            me._parser["on" + ev] = h;
            return h;
          }
          me.on(ev, h);
        },
        enumerable: true,
        configurable: false
      });
    });
  }
  SAXStream.prototype = Object.create(Stream.prototype, { constructor: { value: SAXStream } });
  SAXStream.prototype.write = function(data) {
    this._parser.write(data.toString());
    this.emit("data", data);
    return true;
  };
  SAXStream.prototype.end = function(chunk) {
    if (chunk && chunk.length) this.write(chunk);
    this._parser.end();
    return true;
  };
  SAXStream.prototype.on = function(ev, handler) {
    var me = this;
    if (!me._parser["on" + ev] && streamWraps.indexOf(ev) !== -1) me._parser["on" + ev] = function() {
      var args = arguments.length === 1 ? [arguments[0]] : Array.apply(null, arguments);
      args.splice(0, 0, ev);
      me.emit.apply(me, args);
    };
    return Stream.prototype.on.call(me, ev, handler);
  };
  var CDATA = "[CDATA[";
  var DOCTYPE = "DOCTYPE";
  var XML_NAMESPACE = "http://www.w3.org/XML/1998/namespace";
  var XMLNS_NAMESPACE = "http://www.w3.org/2000/xmlns/";
  var rootNS = {
    xml: XML_NAMESPACE,
    xmlns: XMLNS_NAMESPACE
  };
  var nameStart = /[:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD]/;
  var nameBody = /[:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\u00B7\u0300-\u036F\u203F-\u2040.\d-]/;
  var entityStart = /[#:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD]/;
  var entityBody = /[#:_A-Za-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\u00B7\u0300-\u036F\u203F-\u2040.\d-]/;
  function isWhitespace2(c) {
    return c === " " || c === "\n" || c === "\r" || c === "	";
  }
  function isQuote(c) {
    return c === '"' || c === "'";
  }
  function isAttribEnd(c) {
    return c === ">" || isWhitespace2(c);
  }
  function isMatch(regex, c) {
    return regex.test(c);
  }
  function notMatch(regex, c) {
    return !isMatch(regex, c);
  }
  var S = 0;
  sax$1.STATE = {
    BEGIN: S++,
    BEGIN_WHITESPACE: S++,
    TEXT: S++,
    TEXT_ENTITY: S++,
    OPEN_WAKA: S++,
    SGML_DECL: S++,
    SGML_DECL_QUOTED: S++,
    DOCTYPE: S++,
    DOCTYPE_QUOTED: S++,
    DOCTYPE_DTD: S++,
    DOCTYPE_DTD_QUOTED: S++,
    COMMENT_STARTING: S++,
    COMMENT: S++,
    COMMENT_ENDING: S++,
    COMMENT_ENDED: S++,
    CDATA: S++,
    CDATA_ENDING: S++,
    CDATA_ENDING_2: S++,
    PROC_INST: S++,
    PROC_INST_BODY: S++,
    PROC_INST_ENDING: S++,
    OPEN_TAG: S++,
    OPEN_TAG_SLASH: S++,
    ATTRIB: S++,
    ATTRIB_NAME: S++,
    ATTRIB_NAME_SAW_WHITE: S++,
    ATTRIB_VALUE: S++,
    ATTRIB_VALUE_QUOTED: S++,
    ATTRIB_VALUE_CLOSED: S++,
    ATTRIB_VALUE_UNQUOTED: S++,
    ATTRIB_VALUE_ENTITY_Q: S++,
    ATTRIB_VALUE_ENTITY_U: S++,
    CLOSE_TAG: S++,
    CLOSE_TAG_SAW_WHITE: S++,
    SCRIPT: S++,
    SCRIPT_ENDING: S++
  };
  sax$1.XML_ENTITIES = {
    amp: "&",
    gt: ">",
    lt: "<",
    quot: '"',
    apos: "'"
  };
  sax$1.ENTITIES = {
    amp: "&",
    gt: ">",
    lt: "<",
    quot: '"',
    apos: "'",
    AElig: 198,
    Aacute: 193,
    Acirc: 194,
    Agrave: 192,
    Aring: 197,
    Atilde: 195,
    Auml: 196,
    Ccedil: 199,
    ETH: 208,
    Eacute: 201,
    Ecirc: 202,
    Egrave: 200,
    Euml: 203,
    Iacute: 205,
    Icirc: 206,
    Igrave: 204,
    Iuml: 207,
    Ntilde: 209,
    Oacute: 211,
    Ocirc: 212,
    Ograve: 210,
    Oslash: 216,
    Otilde: 213,
    Ouml: 214,
    THORN: 222,
    Uacute: 218,
    Ucirc: 219,
    Ugrave: 217,
    Uuml: 220,
    Yacute: 221,
    aacute: 225,
    acirc: 226,
    aelig: 230,
    agrave: 224,
    aring: 229,
    atilde: 227,
    auml: 228,
    ccedil: 231,
    eacute: 233,
    ecirc: 234,
    egrave: 232,
    eth: 240,
    euml: 235,
    iacute: 237,
    icirc: 238,
    igrave: 236,
    iuml: 239,
    ntilde: 241,
    oacute: 243,
    ocirc: 244,
    ograve: 242,
    oslash: 248,
    otilde: 245,
    ouml: 246,
    szlig: 223,
    thorn: 254,
    uacute: 250,
    ucirc: 251,
    ugrave: 249,
    uuml: 252,
    yacute: 253,
    yuml: 255,
    copy: 169,
    reg: 174,
    nbsp: 160,
    iexcl: 161,
    cent: 162,
    pound: 163,
    curren: 164,
    yen: 165,
    brvbar: 166,
    sect: 167,
    uml: 168,
    ordf: 170,
    laquo: 171,
    not: 172,
    shy: 173,
    macr: 175,
    deg: 176,
    plusmn: 177,
    sup1: 185,
    sup2: 178,
    sup3: 179,
    acute: 180,
    micro: 181,
    para: 182,
    middot: 183,
    cedil: 184,
    ordm: 186,
    raquo: 187,
    frac14: 188,
    frac12: 189,
    frac34: 190,
    iquest: 191,
    times: 215,
    divide: 247,
    OElig: 338,
    oelig: 339,
    Scaron: 352,
    scaron: 353,
    Yuml: 376,
    fnof: 402,
    circ: 710,
    tilde: 732,
    Alpha: 913,
    Beta: 914,
    Gamma: 915,
    Delta: 916,
    Epsilon: 917,
    Zeta: 918,
    Eta: 919,
    Theta: 920,
    Iota: 921,
    Kappa: 922,
    Lambda: 923,
    Mu: 924,
    Nu: 925,
    Xi: 926,
    Omicron: 927,
    Pi: 928,
    Rho: 929,
    Sigma: 931,
    Tau: 932,
    Upsilon: 933,
    Phi: 934,
    Chi: 935,
    Psi: 936,
    Omega: 937,
    alpha: 945,
    beta: 946,
    gamma: 947,
    delta: 948,
    epsilon: 949,
    zeta: 950,
    eta: 951,
    theta: 952,
    iota: 953,
    kappa: 954,
    lambda: 955,
    mu: 956,
    nu: 957,
    xi: 958,
    omicron: 959,
    pi: 960,
    rho: 961,
    sigmaf: 962,
    sigma: 963,
    tau: 964,
    upsilon: 965,
    phi: 966,
    chi: 967,
    psi: 968,
    omega: 969,
    thetasym: 977,
    upsih: 978,
    piv: 982,
    ensp: 8194,
    emsp: 8195,
    thinsp: 8201,
    zwnj: 8204,
    zwj: 8205,
    lrm: 8206,
    rlm: 8207,
    ndash: 8211,
    mdash: 8212,
    lsquo: 8216,
    rsquo: 8217,
    sbquo: 8218,
    ldquo: 8220,
    rdquo: 8221,
    bdquo: 8222,
    dagger: 8224,
    Dagger: 8225,
    bull: 8226,
    hellip: 8230,
    permil: 8240,
    prime: 8242,
    Prime: 8243,
    lsaquo: 8249,
    rsaquo: 8250,
    oline: 8254,
    frasl: 8260,
    euro: 8364,
    image: 8465,
    weierp: 8472,
    real: 8476,
    trade: 8482,
    alefsym: 8501,
    larr: 8592,
    uarr: 8593,
    rarr: 8594,
    darr: 8595,
    harr: 8596,
    crarr: 8629,
    lArr: 8656,
    uArr: 8657,
    rArr: 8658,
    dArr: 8659,
    hArr: 8660,
    forall: 8704,
    part: 8706,
    exist: 8707,
    empty: 8709,
    nabla: 8711,
    isin: 8712,
    notin: 8713,
    ni: 8715,
    prod: 8719,
    sum: 8721,
    minus: 8722,
    lowast: 8727,
    radic: 8730,
    prop: 8733,
    infin: 8734,
    ang: 8736,
    and: 8743,
    or: 8744,
    cap: 8745,
    cup: 8746,
    int: 8747,
    there4: 8756,
    sim: 8764,
    cong: 8773,
    asymp: 8776,
    ne: 8800,
    equiv: 8801,
    le: 8804,
    ge: 8805,
    sub: 8834,
    sup: 8835,
    nsub: 8836,
    sube: 8838,
    supe: 8839,
    oplus: 8853,
    otimes: 8855,
    perp: 8869,
    sdot: 8901,
    lceil: 8968,
    rceil: 8969,
    lfloor: 8970,
    rfloor: 8971,
    lang: 9001,
    rang: 9002,
    loz: 9674,
    spades: 9824,
    clubs: 9827,
    hearts: 9829,
    diams: 9830
  };
  Object.keys(sax$1.ENTITIES).forEach(function(key) {
    var e = sax$1.ENTITIES[key];
    var s$1 = typeof e === "number" ? String.fromCharCode(e) : e;
    sax$1.ENTITIES[key] = s$1;
  });
  for (var s in sax$1.STATE) sax$1.STATE[sax$1.STATE[s]] = s;
  S = sax$1.STATE;
  function emit(parser, event, data) {
    parser[event] && parser[event](data);
  }
  function emitNode(parser, nodeType, data) {
    if (parser.textNode) closeText(parser);
    emit(parser, nodeType, data);
  }
  function closeText(parser) {
    parser.textNode = textopts(parser.opt, parser.textNode);
    if (parser.textNode) emit(parser, "ontext", parser.textNode);
    parser.textNode = "";
  }
  function textopts(opt, text) {
    if (opt.trim) text = text.trim();
    if (opt.normalize) text = text.replace(/\s+/g, " ");
    return text;
  }
  function error(parser, er) {
    closeText(parser);
    if (parser.trackPosition) er += "\nLine: " + parser.line + "\nColumn: " + parser.column + "\nChar: " + parser.c;
    er = new Error(er);
    parser.error = er;
    emit(parser, "onerror", er);
    return parser;
  }
  function end(parser) {
    if (parser.sawRoot && !parser.closedRoot) strictFail(parser, "Unclosed root tag");
    if (parser.state !== S.BEGIN && parser.state !== S.BEGIN_WHITESPACE && parser.state !== S.TEXT) error(parser, "Unexpected end");
    closeText(parser);
    parser.c = "";
    parser.closed = true;
    emit(parser, "onend");
    SAXParser.call(parser, parser.strict, parser.opt);
    return parser;
  }
  function strictFail(parser, message) {
    if (typeof parser !== "object" || !(parser instanceof SAXParser)) throw new Error("bad call to strictFail");
    if (parser.strict) error(parser, message);
  }
  function newTag(parser) {
    if (!parser.strict) parser.tagName = parser.tagName[parser.looseCase]();
    var parent = parser.tags[parser.tags.length - 1] || parser;
    var tag = parser.tag = {
      name: parser.tagName,
      attributes: {}
    };
    if (parser.opt.xmlns) tag.ns = parent.ns;
    parser.attribList.length = 0;
    emitNode(parser, "onopentagstart", tag);
  }
  function qname(name, attribute) {
    var i = name.indexOf(":");
    var qualName = i < 0 ? ["", name] : name.split(":");
    var prefix = qualName[0];
    var local = qualName[1];
    if (attribute && name === "xmlns") {
      prefix = "xmlns";
      local = "";
    }
    return {
      prefix,
      local
    };
  }
  function attrib(parser) {
    if (!parser.strict) parser.attribName = parser.attribName[parser.looseCase]();
    if (parser.attribList.indexOf(parser.attribName) !== -1 || parser.tag.attributes.hasOwnProperty(parser.attribName)) {
      parser.attribName = parser.attribValue = "";
      return;
    }
    if (parser.opt.xmlns) {
      var qn = qname(parser.attribName, true);
      var prefix = qn.prefix;
      var local = qn.local;
      if (prefix === "xmlns") if (local === "xml" && parser.attribValue !== XML_NAMESPACE) strictFail(parser, "xml: prefix must be bound to " + XML_NAMESPACE + "\nActual: " + parser.attribValue);
      else if (local === "xmlns" && parser.attribValue !== XMLNS_NAMESPACE) strictFail(parser, "xmlns: prefix must be bound to " + XMLNS_NAMESPACE + "\nActual: " + parser.attribValue);
      else {
        var tag = parser.tag;
        var parent = parser.tags[parser.tags.length - 1] || parser;
        if (tag.ns === parent.ns) tag.ns = Object.create(parent.ns);
        tag.ns[local] = parser.attribValue;
      }
      parser.attribList.push([parser.attribName, parser.attribValue]);
    } else {
      parser.tag.attributes[parser.attribName] = parser.attribValue;
      emitNode(parser, "onattribute", {
        name: parser.attribName,
        value: parser.attribValue
      });
    }
    parser.attribName = parser.attribValue = "";
  }
  function openTag(parser, selfClosing) {
    if (parser.opt.xmlns) {
      var tag = parser.tag;
      var qn = qname(parser.tagName);
      tag.prefix = qn.prefix;
      tag.local = qn.local;
      tag.uri = tag.ns[qn.prefix] || "";
      if (tag.prefix && !tag.uri) {
        strictFail(parser, "Unbound namespace prefix: " + JSON.stringify(parser.tagName));
        tag.uri = qn.prefix;
      }
      var parent = parser.tags[parser.tags.length - 1] || parser;
      if (tag.ns && parent.ns !== tag.ns) Object.keys(tag.ns).forEach(function(p) {
        emitNode(parser, "onopennamespace", {
          prefix: p,
          uri: tag.ns[p]
        });
      });
      for (var i = 0, l = parser.attribList.length; i < l; i++) {
        var nv = parser.attribList[i];
        var name = nv[0];
        var value = nv[1];
        var qualName = qname(name, true);
        var prefix = qualName.prefix;
        var local = qualName.local;
        var uri = prefix === "" ? "" : tag.ns[prefix] || "";
        var a = {
          name,
          value,
          prefix,
          local,
          uri
        };
        if (prefix && prefix !== "xmlns" && !uri) {
          strictFail(parser, "Unbound namespace prefix: " + JSON.stringify(prefix));
          a.uri = prefix;
        }
        parser.tag.attributes[name] = a;
        emitNode(parser, "onattribute", a);
      }
      parser.attribList.length = 0;
    }
    parser.tag.isSelfClosing = !!selfClosing;
    parser.sawRoot = true;
    parser.tags.push(parser.tag);
    emitNode(parser, "onopentag", parser.tag);
    if (!selfClosing) {
      if (!parser.noscript && parser.tagName.toLowerCase() === "script") parser.state = S.SCRIPT;
      else parser.state = S.TEXT;
      parser.tag = null;
      parser.tagName = "";
    }
    parser.attribName = parser.attribValue = "";
    parser.attribList.length = 0;
  }
  function closeTag(parser) {
    if (!parser.tagName) {
      strictFail(parser, "Weird empty close tag.");
      parser.textNode += "</>";
      parser.state = S.TEXT;
      return;
    }
    if (parser.script) {
      if (parser.tagName !== "script") {
        parser.script += "</" + parser.tagName + ">";
        parser.tagName = "";
        parser.state = S.SCRIPT;
        return;
      }
      emitNode(parser, "onscript", parser.script);
      parser.script = "";
    }
    var t = parser.tags.length;
    var tagName = parser.tagName;
    if (!parser.strict) tagName = tagName[parser.looseCase]();
    var closeTo = tagName;
    while (t--) {
      var close = parser.tags[t];
      if (close.name !== closeTo) strictFail(parser, "Unexpected close tag");
      else break;
    }
    if (t < 0) {
      strictFail(parser, "Unmatched closing tag: " + parser.tagName);
      parser.textNode += "</" + parser.tagName + ">";
      parser.state = S.TEXT;
      return;
    }
    parser.tagName = tagName;
    var s$1 = parser.tags.length;
    while (s$1-- > t) {
      var tag = parser.tag = parser.tags.pop();
      parser.tagName = parser.tag.name;
      emitNode(parser, "onclosetag", parser.tagName);
      var x = {};
      for (var i in tag.ns) x[i] = tag.ns[i];
      var parent = parser.tags[parser.tags.length - 1] || parser;
      if (parser.opt.xmlns && tag.ns !== parent.ns) Object.keys(tag.ns).forEach(function(p) {
        var n2 = tag.ns[p];
        emitNode(parser, "onclosenamespace", {
          prefix: p,
          uri: n2
        });
      });
    }
    if (t === 0) parser.closedRoot = true;
    parser.tagName = parser.attribValue = parser.attribName = "";
    parser.attribList.length = 0;
    parser.state = S.TEXT;
  }
  function parseEntity(parser) {
    var entity = parser.entity;
    var entityLC = entity.toLowerCase();
    var num;
    var numStr = "";
    if (parser.ENTITIES[entity]) return parser.ENTITIES[entity];
    if (parser.ENTITIES[entityLC]) return parser.ENTITIES[entityLC];
    entity = entityLC;
    if (entity.charAt(0) === "#") if (entity.charAt(1) === "x") {
      entity = entity.slice(2);
      num = parseInt(entity, 16);
      numStr = num.toString(16);
    } else {
      entity = entity.slice(1);
      num = parseInt(entity, 10);
      numStr = num.toString(10);
    }
    entity = entity.replace(/^0+/, "");
    if (isNaN(num) || numStr.toLowerCase() !== entity) {
      strictFail(parser, "Invalid character entity");
      return "&" + parser.entity + ";";
    }
    return String.fromCodePoint(num);
  }
  function beginWhiteSpace(parser, c) {
    if (c === "<") {
      parser.state = S.OPEN_WAKA;
      parser.startTagPosition = parser.position;
    } else if (!isWhitespace2(c)) {
      strictFail(parser, "Non-whitespace before first tag.");
      parser.textNode = c;
      parser.state = S.TEXT;
    }
  }
  function charAt(chunk, i) {
    var result = "";
    if (i < chunk.length) result = chunk.charAt(i);
    return result;
  }
  function write(chunk) {
    var parser = this;
    if (this.error) throw this.error;
    if (parser.closed) return error(parser, "Cannot write after close. Assign an onready handler.");
    if (chunk === null) return end(parser);
    if (typeof chunk === "object") chunk = chunk.toString();
    var i = 0;
    var c = "";
    while (true) {
      c = charAt(chunk, i++);
      parser.c = c;
      if (!c) break;
      if (parser.trackPosition) {
        parser.position++;
        if (c === "\n") {
          parser.line++;
          parser.column = 0;
        } else parser.column++;
      }
      switch (parser.state) {
        case S.BEGIN:
          parser.state = S.BEGIN_WHITESPACE;
          if (c === "\uFEFF") continue;
          beginWhiteSpace(parser, c);
          continue;
        case S.BEGIN_WHITESPACE:
          beginWhiteSpace(parser, c);
          continue;
        case S.TEXT:
          if (parser.sawRoot && !parser.closedRoot) {
            var starti = i - 1;
            while (c && c !== "<" && c !== "&") {
              c = charAt(chunk, i++);
              if (c && parser.trackPosition) {
                parser.position++;
                if (c === "\n") {
                  parser.line++;
                  parser.column = 0;
                } else parser.column++;
              }
            }
            parser.textNode += chunk.substring(starti, i - 1);
          }
          if (c === "<" && !(parser.sawRoot && parser.closedRoot && !parser.strict)) {
            parser.state = S.OPEN_WAKA;
            parser.startTagPosition = parser.position;
          } else {
            if (!isWhitespace2(c) && (!parser.sawRoot || parser.closedRoot)) strictFail(parser, "Text data outside of root node.");
            if (c === "&") parser.state = S.TEXT_ENTITY;
            else parser.textNode += c;
          }
          continue;
        case S.SCRIPT:
          if (c === "<") parser.state = S.SCRIPT_ENDING;
          else parser.script += c;
          continue;
        case S.SCRIPT_ENDING:
          if (c === "/") parser.state = S.CLOSE_TAG;
          else {
            parser.script += "<" + c;
            parser.state = S.SCRIPT;
          }
          continue;
        case S.OPEN_WAKA:
          if (c === "!") {
            parser.state = S.SGML_DECL;
            parser.sgmlDecl = "";
          } else if (isWhitespace2(c)) {
          } else if (isMatch(nameStart, c)) {
            parser.state = S.OPEN_TAG;
            parser.tagName = c;
          } else if (c === "/") {
            parser.state = S.CLOSE_TAG;
            parser.tagName = "";
          } else if (c === "?") {
            parser.state = S.PROC_INST;
            parser.procInstName = parser.procInstBody = "";
          } else {
            strictFail(parser, "Unencoded <");
            if (parser.startTagPosition + 1 < parser.position) {
              var pad = parser.position - parser.startTagPosition;
              c = new Array(pad).join(" ") + c;
            }
            parser.textNode += "<" + c;
            parser.state = S.TEXT;
          }
          continue;
        case S.SGML_DECL:
          if ((parser.sgmlDecl + c).toUpperCase() === CDATA) {
            emitNode(parser, "onopencdata");
            parser.state = S.CDATA;
            parser.sgmlDecl = "";
            parser.cdata = "";
          } else if (parser.sgmlDecl + c === "--") {
            parser.state = S.COMMENT;
            parser.comment = "";
            parser.sgmlDecl = "";
          } else if ((parser.sgmlDecl + c).toUpperCase() === DOCTYPE) {
            parser.state = S.DOCTYPE;
            if (parser.doctype || parser.sawRoot) strictFail(parser, "Inappropriately located doctype declaration");
            parser.doctype = "";
            parser.sgmlDecl = "";
          } else if (c === ">") {
            emitNode(parser, "onsgmldeclaration", parser.sgmlDecl);
            parser.sgmlDecl = "";
            parser.state = S.TEXT;
          } else if (isQuote(c)) {
            parser.state = S.SGML_DECL_QUOTED;
            parser.sgmlDecl += c;
          } else parser.sgmlDecl += c;
          continue;
        case S.SGML_DECL_QUOTED:
          if (c === parser.q) {
            parser.state = S.SGML_DECL;
            parser.q = "";
          }
          parser.sgmlDecl += c;
          continue;
        case S.DOCTYPE:
          if (c === ">") {
            parser.state = S.TEXT;
            emitNode(parser, "ondoctype", parser.doctype);
            parser.doctype = true;
          } else {
            parser.doctype += c;
            if (c === "[") parser.state = S.DOCTYPE_DTD;
            else if (isQuote(c)) {
              parser.state = S.DOCTYPE_QUOTED;
              parser.q = c;
            }
          }
          continue;
        case S.DOCTYPE_QUOTED:
          parser.doctype += c;
          if (c === parser.q) {
            parser.q = "";
            parser.state = S.DOCTYPE;
          }
          continue;
        case S.DOCTYPE_DTD:
          parser.doctype += c;
          if (c === "]") parser.state = S.DOCTYPE;
          else if (isQuote(c)) {
            parser.state = S.DOCTYPE_DTD_QUOTED;
            parser.q = c;
          }
          continue;
        case S.DOCTYPE_DTD_QUOTED:
          parser.doctype += c;
          if (c === parser.q) {
            parser.state = S.DOCTYPE_DTD;
            parser.q = "";
          }
          continue;
        case S.COMMENT:
          if (c === "-") parser.state = S.COMMENT_ENDING;
          else parser.comment += c;
          continue;
        case S.COMMENT_ENDING:
          if (c === "-") {
            parser.state = S.COMMENT_ENDED;
            parser.comment = textopts(parser.opt, parser.comment);
            if (parser.comment) emitNode(parser, "oncomment", parser.comment);
            parser.comment = "";
          } else {
            parser.comment += "-" + c;
            parser.state = S.COMMENT;
          }
          continue;
        case S.COMMENT_ENDED:
          if (c !== ">") {
            strictFail(parser, "Malformed comment");
            parser.comment += "--" + c;
            parser.state = S.COMMENT;
          } else parser.state = S.TEXT;
          continue;
        case S.CDATA:
          if (c === "]") parser.state = S.CDATA_ENDING;
          else parser.cdata += c;
          continue;
        case S.CDATA_ENDING:
          if (c === "]") parser.state = S.CDATA_ENDING_2;
          else {
            parser.cdata += "]" + c;
            parser.state = S.CDATA;
          }
          continue;
        case S.CDATA_ENDING_2:
          if (c === ">") {
            if (parser.cdata) emitNode(parser, "oncdata", parser.cdata);
            emitNode(parser, "onclosecdata");
            parser.cdata = "";
            parser.state = S.TEXT;
          } else if (c === "]") parser.cdata += "]";
          else {
            parser.cdata += "]]" + c;
            parser.state = S.CDATA;
          }
          continue;
        case S.PROC_INST:
          if (c === "?") parser.state = S.PROC_INST_ENDING;
          else if (isWhitespace2(c)) parser.state = S.PROC_INST_BODY;
          else parser.procInstName += c;
          continue;
        case S.PROC_INST_BODY:
          if (!parser.procInstBody && isWhitespace2(c)) continue;
          else if (c === "?") parser.state = S.PROC_INST_ENDING;
          else parser.procInstBody += c;
          continue;
        case S.PROC_INST_ENDING:
          if (c === ">") {
            emitNode(parser, "onprocessinginstruction", {
              name: parser.procInstName,
              body: parser.procInstBody
            });
            parser.procInstName = parser.procInstBody = "";
            parser.state = S.TEXT;
          } else {
            parser.procInstBody += "?" + c;
            parser.state = S.PROC_INST_BODY;
          }
          continue;
        case S.OPEN_TAG:
          if (isMatch(nameBody, c)) parser.tagName += c;
          else {
            newTag(parser);
            if (c === ">") openTag(parser);
            else if (c === "/") parser.state = S.OPEN_TAG_SLASH;
            else {
              if (!isWhitespace2(c)) strictFail(parser, "Invalid character in tag name");
              parser.state = S.ATTRIB;
            }
          }
          continue;
        case S.OPEN_TAG_SLASH:
          if (c === ">") {
            openTag(parser, true);
            closeTag(parser);
          } else {
            strictFail(parser, "Forward-slash in opening tag not followed by >");
            parser.state = S.ATTRIB;
          }
          continue;
        case S.ATTRIB:
          if (isWhitespace2(c)) continue;
          else if (c === ">") openTag(parser);
          else if (c === "/") parser.state = S.OPEN_TAG_SLASH;
          else if (isMatch(nameStart, c)) {
            parser.attribName = c;
            parser.attribValue = "";
            parser.state = S.ATTRIB_NAME;
          } else strictFail(parser, "Invalid attribute name");
          continue;
        case S.ATTRIB_NAME:
          if (c === "=") parser.state = S.ATTRIB_VALUE;
          else if (c === ">") {
            strictFail(parser, "Attribute without value");
            parser.attribValue = parser.attribName;
            attrib(parser);
            openTag(parser);
          } else if (isWhitespace2(c)) parser.state = S.ATTRIB_NAME_SAW_WHITE;
          else if (isMatch(nameBody, c)) parser.attribName += c;
          else strictFail(parser, "Invalid attribute name");
          continue;
        case S.ATTRIB_NAME_SAW_WHITE:
          if (c === "=") parser.state = S.ATTRIB_VALUE;
          else if (isWhitespace2(c)) continue;
          else {
            strictFail(parser, "Attribute without value");
            parser.tag.attributes[parser.attribName] = "";
            parser.attribValue = "";
            emitNode(parser, "onattribute", {
              name: parser.attribName,
              value: ""
            });
            parser.attribName = "";
            if (c === ">") openTag(parser);
            else if (isMatch(nameStart, c)) {
              parser.attribName = c;
              parser.state = S.ATTRIB_NAME;
            } else {
              strictFail(parser, "Invalid attribute name");
              parser.state = S.ATTRIB;
            }
          }
          continue;
        case S.ATTRIB_VALUE:
          if (isWhitespace2(c)) continue;
          else if (isQuote(c)) {
            parser.q = c;
            parser.state = S.ATTRIB_VALUE_QUOTED;
          } else {
            strictFail(parser, "Unquoted attribute value");
            parser.state = S.ATTRIB_VALUE_UNQUOTED;
            parser.attribValue = c;
          }
          continue;
        case S.ATTRIB_VALUE_QUOTED:
          if (c !== parser.q) {
            if (c === "&") parser.state = S.ATTRIB_VALUE_ENTITY_Q;
            else parser.attribValue += c;
            continue;
          }
          attrib(parser);
          parser.q = "";
          parser.state = S.ATTRIB_VALUE_CLOSED;
          continue;
        case S.ATTRIB_VALUE_CLOSED:
          if (isWhitespace2(c)) parser.state = S.ATTRIB;
          else if (c === ">") openTag(parser);
          else if (c === "/") parser.state = S.OPEN_TAG_SLASH;
          else if (isMatch(nameStart, c)) {
            strictFail(parser, "No whitespace between attributes");
            parser.attribName = c;
            parser.attribValue = "";
            parser.state = S.ATTRIB_NAME;
          } else strictFail(parser, "Invalid attribute name");
          continue;
        case S.ATTRIB_VALUE_UNQUOTED:
          if (!isAttribEnd(c)) {
            if (c === "&") parser.state = S.ATTRIB_VALUE_ENTITY_U;
            else parser.attribValue += c;
            continue;
          }
          attrib(parser);
          if (c === ">") openTag(parser);
          else parser.state = S.ATTRIB;
          continue;
        case S.CLOSE_TAG:
          if (!parser.tagName) if (isWhitespace2(c)) continue;
          else if (notMatch(nameStart, c)) if (parser.script) {
            parser.script += "</" + c;
            parser.state = S.SCRIPT;
          } else strictFail(parser, "Invalid tagname in closing tag.");
          else parser.tagName = c;
          else if (c === ">") closeTag(parser);
          else if (isMatch(nameBody, c)) parser.tagName += c;
          else if (parser.script) {
            parser.script += "</" + parser.tagName;
            parser.tagName = "";
            parser.state = S.SCRIPT;
          } else {
            if (!isWhitespace2(c)) strictFail(parser, "Invalid tagname in closing tag");
            parser.state = S.CLOSE_TAG_SAW_WHITE;
          }
          continue;
        case S.CLOSE_TAG_SAW_WHITE:
          if (isWhitespace2(c)) continue;
          if (c === ">") closeTag(parser);
          else strictFail(parser, "Invalid characters in closing tag");
          continue;
        case S.TEXT_ENTITY:
        case S.ATTRIB_VALUE_ENTITY_Q:
        case S.ATTRIB_VALUE_ENTITY_U:
          var returnState;
          var buffer;
          switch (parser.state) {
            case S.TEXT_ENTITY:
              returnState = S.TEXT;
              buffer = "textNode";
              break;
            case S.ATTRIB_VALUE_ENTITY_Q:
              returnState = S.ATTRIB_VALUE_QUOTED;
              buffer = "attribValue";
              break;
            case S.ATTRIB_VALUE_ENTITY_U:
              returnState = S.ATTRIB_VALUE_UNQUOTED;
              buffer = "attribValue";
              break;
          }
          if (c === ";") if (parser.opt.unparsedEntities) {
            var parsedEntity = parseEntity(parser);
            parser.entity = "";
            parser.state = returnState;
            parser.write(parsedEntity);
          } else {
            parser[buffer] += parseEntity(parser);
            parser.entity = "";
            parser.state = returnState;
          }
          else if (isMatch(parser.entity.length ? entityBody : entityStart, c)) parser.entity += c;
          else {
            strictFail(parser, "Invalid character in entity name");
            parser[buffer] += "&" + parser.entity + c;
            parser.entity = "";
            parser.state = returnState;
          }
          continue;
        default:
          throw new Error(parser, "Unknown state: " + parser.state);
      }
    }
    if (parser.position >= parser.bufferCheckPosition) checkBufferLength(parser);
    return parser;
  }
  if (!String.fromCodePoint) (function() {
    var stringFromCharCode = String.fromCharCode;
    var floor = Math.floor;
    var fromCodePoint = function() {
      var MAX_SIZE = 16384;
      var codeUnits = [];
      var highSurrogate;
      var lowSurrogate;
      var index2 = -1;
      var length = arguments.length;
      if (!length) return "";
      var result = "";
      while (++index2 < length) {
        var codePoint = Number(arguments[index2]);
        if (!isFinite(codePoint) || codePoint < 0 || codePoint > 1114111 || floor(codePoint) !== codePoint) throw RangeError("Invalid code point: " + codePoint);
        if (codePoint <= 65535) codeUnits.push(codePoint);
        else {
          codePoint -= 65536;
          highSurrogate = (codePoint >> 10) + 55296;
          lowSurrogate = codePoint % 1024 + 56320;
          codeUnits.push(highSurrogate, lowSurrogate);
        }
        if (index2 + 1 === length || codeUnits.length > MAX_SIZE) {
          result += stringFromCharCode.apply(null, codeUnits);
          codeUnits.length = 0;
        }
      }
      return result;
    };
    if (Object.defineProperty) Object.defineProperty(String, "fromCodePoint", {
      value: fromCodePoint,
      configurable: true,
      writable: true
    });
    else String.fromCodePoint = fromCodePoint;
  })();
  return sax$1;
};
var sax = initializeSax();

// node_modules/@langchain/core/dist/output_parsers/xml.js
var XML_FORMAT_INSTRUCTIONS = `The output should be formatted as a XML file.
1. Output should conform to the tags below. 
2. If tags are not given, make them on your own.
3. Remember to always open and close all the tags.

As an example, for the tags ["foo", "bar", "baz"]:
1. String "<foo>
   <bar>
      <baz></baz>
   </bar>
</foo>" is a well-formatted instance of the schema. 
2. String "<foo>
   <bar>
   </foo>" is a badly-formatted instance.
3. String "<foo>
   <tag>
   </tag>
</foo>" is a badly-formatted instance.

Here are the output tags:
\`\`\`
{tags}
\`\`\``;
var XMLOutputParser = class extends BaseCumulativeTransformOutputParser {
  tags;
  constructor(fields) {
    super(fields);
    this.tags = fields?.tags;
  }
  static lc_name() {
    return "XMLOutputParser";
  }
  lc_namespace = ["langchain_core", "output_parsers"];
  lc_serializable = true;
  _diff(prev, next) {
    if (!next) return void 0;
    if (!prev) return [{
      op: "replace",
      path: "",
      value: next
    }];
    return compare(prev, next);
  }
  async parsePartialResult(generations) {
    return parseXMLMarkdown(generations[0].text);
  }
  async parse(text) {
    return parseXMLMarkdown(text);
  }
  getFormatInstructions() {
    const withTags = !!(this.tags && this.tags.length > 0);
    return withTags ? XML_FORMAT_INSTRUCTIONS.replace("{tags}", this.tags?.join(", ") ?? "") : XML_FORMAT_INSTRUCTIONS;
  }
};
var strip = (text) => text.split("\n").map((line) => line.replace(/^\s+/, "")).join("\n").trim();
var parseParsedResult = (input) => {
  if (Object.keys(input).length === 0) return {};
  const result = {};
  if (input.children.length > 0) {
    result[input.name] = input.children.map(parseParsedResult);
    return result;
  } else {
    result[input.name] = input.text ?? void 0;
    return result;
  }
};
function parseXMLMarkdown(s) {
  const cleanedString = strip(s);
  const parser = sax.parser(true);
  let parsedResult = {};
  const elementStack = [];
  parser.onopentag = (node) => {
    const element = {
      name: node.name,
      attributes: node.attributes,
      children: [],
      text: "",
      isSelfClosing: node.isSelfClosing
    };
    if (elementStack.length > 0) {
      const parentElement = elementStack[elementStack.length - 1];
      parentElement.children.push(element);
    } else parsedResult = element;
    if (!node.isSelfClosing) elementStack.push(element);
  };
  parser.onclosetag = () => {
    if (elementStack.length > 0) {
      const lastElement = elementStack.pop();
      if (elementStack.length === 0 && lastElement) parsedResult = lastElement;
    }
  };
  parser.ontext = (text) => {
    if (elementStack.length > 0) {
      const currentElement = elementStack[elementStack.length - 1];
      currentElement.text += text;
    }
  };
  parser.onattribute = (attr) => {
    if (elementStack.length > 0) {
      const currentElement = elementStack[elementStack.length - 1];
      currentElement.attributes[attr.name] = attr.value;
    }
  };
  const match = /```(xml)?(.*)```/s.exec(cleanedString);
  const xmlString = match ? match[2] : cleanedString;
  parser.write(xmlString).close();
  if (parsedResult && parsedResult.name === "?xml") parsedResult = parsedResult.children[0];
  return parseParsedResult(parsedResult);
}

// node_modules/@langchain/core/dist/output_parsers/index.js
var output_parsers_exports = {};
__export2(output_parsers_exports, {
  AsymmetricStructuredOutputParser: () => AsymmetricStructuredOutputParser,
  BaseCumulativeTransformOutputParser: () => BaseCumulativeTransformOutputParser,
  BaseLLMOutputParser: () => BaseLLMOutputParser,
  BaseOutputParser: () => BaseOutputParser,
  BaseTransformOutputParser: () => BaseTransformOutputParser,
  BytesOutputParser: () => BytesOutputParser,
  CommaSeparatedListOutputParser: () => CommaSeparatedListOutputParser,
  CustomListOutputParser: () => CustomListOutputParser,
  JsonMarkdownStructuredOutputParser: () => JsonMarkdownStructuredOutputParser,
  JsonOutputParser: () => JsonOutputParser,
  ListOutputParser: () => ListOutputParser,
  MarkdownListOutputParser: () => MarkdownListOutputParser,
  NumberedListOutputParser: () => NumberedListOutputParser,
  OutputParserException: () => OutputParserException,
  StringOutputParser: () => StringOutputParser,
  StructuredOutputParser: () => StructuredOutputParser,
  XMLOutputParser: () => XMLOutputParser,
  XML_FORMAT_INSTRUCTIONS: () => XML_FORMAT_INSTRUCTIONS,
  parseJsonMarkdown: () => parseJsonMarkdown,
  parsePartialJson: () => parsePartialJson,
  parseXMLMarkdown: () => parseXMLMarkdown
});

// node_modules/@langchain/core/dist/output_parsers/openai_functions/json_output_functions_parsers.js
var OutputFunctionsParser = class extends BaseLLMOutputParser {
  static lc_name() {
    return "OutputFunctionsParser";
  }
  lc_namespace = [
    "langchain",
    "output_parsers",
    "openai_functions"
  ];
  lc_serializable = true;
  argsOnly = true;
  constructor(config2) {
    super();
    this.argsOnly = config2?.argsOnly ?? this.argsOnly;
  }
  /**
  * Parses the output and returns a string representation of the function
  * call or its arguments.
  * @param generations The output of the LLM to parse.
  * @returns A string representation of the function call or its arguments.
  */
  async parseResult(generations) {
    if ("message" in generations[0]) {
      const gen = generations[0];
      const functionCall = gen.message.additional_kwargs.function_call;
      if (!functionCall) throw new Error(`No function_call in message ${JSON.stringify(generations)}`);
      if (!functionCall.arguments) throw new Error(`No arguments in function_call ${JSON.stringify(generations)}`);
      if (this.argsOnly) return functionCall.arguments;
      return JSON.stringify(functionCall);
    } else throw new Error(`No message in generations ${JSON.stringify(generations)}`);
  }
};
var JsonOutputFunctionsParser = class extends BaseCumulativeTransformOutputParser {
  static lc_name() {
    return "JsonOutputFunctionsParser";
  }
  lc_namespace = [
    "langchain",
    "output_parsers",
    "openai_functions"
  ];
  lc_serializable = true;
  outputParser;
  argsOnly = true;
  constructor(config2) {
    super(config2);
    this.argsOnly = config2?.argsOnly ?? this.argsOnly;
    this.outputParser = new OutputFunctionsParser(config2);
  }
  _diff(prev, next) {
    if (!next) return void 0;
    const ops = compare(prev ?? {}, next);
    return ops;
  }
  async parsePartialResult(generations) {
    const generation = generations[0];
    if (!generation.message) return void 0;
    const { message } = generation;
    const functionCall = message.additional_kwargs.function_call;
    if (!functionCall) return void 0;
    if (this.argsOnly) return parsePartialJson(functionCall.arguments);
    return {
      ...functionCall,
      arguments: parsePartialJson(functionCall.arguments)
    };
  }
  /**
  * Parses the output and returns a JSON object. If `argsOnly` is true,
  * only the arguments of the function call are returned.
  * @param generations The output of the LLM to parse.
  * @returns A JSON object representation of the function call or its arguments.
  */
  async parseResult(generations) {
    const result = await this.outputParser.parseResult(generations);
    if (!result) throw new Error(`No result from "OutputFunctionsParser" ${JSON.stringify(generations)}`);
    return this.parse(result);
  }
  async parse(text) {
    const parsedResult = JSON.parse(text);
    if (this.argsOnly) return parsedResult;
    parsedResult.arguments = JSON.parse(parsedResult.arguments);
    return parsedResult;
  }
  getFormatInstructions() {
    return "";
  }
};
var JsonKeyOutputFunctionsParser = class extends BaseLLMOutputParser {
  static lc_name() {
    return "JsonKeyOutputFunctionsParser";
  }
  lc_namespace = [
    "langchain",
    "output_parsers",
    "openai_functions"
  ];
  lc_serializable = true;
  outputParser = new JsonOutputFunctionsParser();
  attrName;
  get lc_aliases() {
    return { attrName: "key_name" };
  }
  constructor(fields) {
    super(fields);
    this.attrName = fields.attrName;
  }
  /**
  * Parses the output and returns a specific attribute of the parsed JSON
  * object.
  * @param generations The output of the LLM to parse.
  * @returns The value of a specific attribute of the parsed JSON object.
  */
  async parseResult(generations) {
    const result = await this.outputParser.parseResult(generations);
    return result[this.attrName];
  }
};

// node_modules/@langchain/core/dist/output_parsers/openai_functions/index.js
var openai_functions_exports = {};
__export2(openai_functions_exports, {
  JsonKeyOutputFunctionsParser: () => JsonKeyOutputFunctionsParser,
  JsonOutputFunctionsParser: () => JsonOutputFunctionsParser,
  OutputFunctionsParser: () => OutputFunctionsParser
});

// node_modules/@langchain/core/dist/output_parsers/openai_tools/json_output_tools_parsers.js
function parseToolCall(rawToolCall, options) {
  if (rawToolCall.function === void 0) return void 0;
  let functionArgs;
  if (options?.partial) try {
    functionArgs = parsePartialJson(rawToolCall.function.arguments ?? "{}");
  } catch {
    return void 0;
  }
  else try {
    functionArgs = JSON.parse(rawToolCall.function.arguments);
  } catch (e) {
    throw new OutputParserException([
      `Function "${rawToolCall.function.name}" arguments:`,
      ``,
      rawToolCall.function.arguments,
      ``,
      `are not valid JSON.`,
      `Error: ${e.message}`
    ].join("\n"));
  }
  const parsedToolCall = {
    name: rawToolCall.function.name,
    args: functionArgs,
    type: "tool_call"
  };
  if (options?.returnId) parsedToolCall.id = rawToolCall.id;
  return parsedToolCall;
}
function convertLangChainToolCallToOpenAI(toolCall) {
  if (toolCall.id === void 0) throw new Error(`All OpenAI tool calls must have an "id" field.`);
  return {
    id: toolCall.id,
    type: "function",
    function: {
      name: toolCall.name,
      arguments: JSON.stringify(toolCall.args)
    }
  };
}
function makeInvalidToolCall(rawToolCall, errorMsg) {
  return {
    name: rawToolCall.function?.name,
    args: rawToolCall.function?.arguments,
    id: rawToolCall.id,
    error: errorMsg,
    type: "invalid_tool_call"
  };
}
var JsonOutputToolsParser = class extends BaseCumulativeTransformOutputParser {
  static lc_name() {
    return "JsonOutputToolsParser";
  }
  returnId = false;
  lc_namespace = [
    "langchain",
    "output_parsers",
    "openai_tools"
  ];
  lc_serializable = true;
  constructor(fields) {
    super(fields);
    this.returnId = fields?.returnId ?? this.returnId;
  }
  _diff() {
    throw new Error("Not supported.");
  }
  async parse() {
    throw new Error("Not implemented.");
  }
  async parseResult(generations) {
    const result = await this.parsePartialResult(generations, false);
    return result;
  }
  /**
  * Parses the output and returns a JSON object. If `argsOnly` is true,
  * only the arguments of the function call are returned.
  * @param generations The output of the LLM to parse.
  * @returns A JSON object representation of the function call or its arguments.
  */
  async parsePartialResult(generations, partial = true) {
    const message = generations[0].message;
    let toolCalls;
    if (isAIMessage(message) && message.tool_calls?.length) toolCalls = message.tool_calls.map((toolCall) => {
      const { id, ...rest } = toolCall;
      if (!this.returnId) return rest;
      return {
        id,
        ...rest
      };
    });
    else if (message.additional_kwargs.tool_calls !== void 0) {
      const rawToolCalls = JSON.parse(JSON.stringify(message.additional_kwargs.tool_calls));
      toolCalls = rawToolCalls.map((rawToolCall) => {
        return parseToolCall(rawToolCall, {
          returnId: this.returnId,
          partial
        });
      });
    }
    if (!toolCalls) return [];
    const parsedToolCalls = [];
    for (const toolCall of toolCalls) if (toolCall !== void 0) {
      const backwardsCompatibleToolCall = {
        type: toolCall.name,
        args: toolCall.args,
        id: toolCall.id
      };
      parsedToolCalls.push(backwardsCompatibleToolCall);
    }
    return parsedToolCalls;
  }
};
var JsonOutputKeyToolsParser = class extends JsonOutputToolsParser {
  static lc_name() {
    return "JsonOutputKeyToolsParser";
  }
  lc_namespace = [
    "langchain",
    "output_parsers",
    "openai_tools"
  ];
  lc_serializable = true;
  returnId = false;
  /** The type of tool calls to return. */
  keyName;
  /** Whether to return only the first tool call. */
  returnSingle = false;
  zodSchema;
  constructor(params) {
    super(params);
    this.keyName = params.keyName;
    this.returnSingle = params.returnSingle ?? this.returnSingle;
    this.zodSchema = params.zodSchema;
  }
  async _validateResult(result) {
    if (this.zodSchema === void 0) return result;
    const zodParsedResult = await interopSafeParseAsync(this.zodSchema, result);
    if (zodParsedResult.success) return zodParsedResult.data;
    else throw new OutputParserException(`Failed to parse. Text: "${JSON.stringify(result, null, 2)}". Error: ${JSON.stringify(zodParsedResult.error?.issues)}`, JSON.stringify(result, null, 2));
  }
  async parsePartialResult(generations) {
    const results = await super.parsePartialResult(generations);
    const matchingResults = results.filter((result) => result.type === this.keyName);
    let returnedValues = matchingResults;
    if (!matchingResults.length) return void 0;
    if (!this.returnId) returnedValues = matchingResults.map((result) => result.args);
    if (this.returnSingle) return returnedValues[0];
    return returnedValues;
  }
  async parseResult(generations) {
    const results = await super.parsePartialResult(generations, false);
    const matchingResults = results.filter((result) => result.type === this.keyName);
    let returnedValues = matchingResults;
    if (!matchingResults.length) return void 0;
    if (!this.returnId) returnedValues = matchingResults.map((result) => result.args);
    if (this.returnSingle) return this._validateResult(returnedValues[0]);
    const toolCallResults = await Promise.all(returnedValues.map((value) => this._validateResult(value)));
    return toolCallResults;
  }
};

// node_modules/@langchain/core/dist/output_parsers/openai_tools/index.js
var openai_tools_exports = {};
__export2(openai_tools_exports, {
  JsonOutputKeyToolsParser: () => JsonOutputKeyToolsParser,
  JsonOutputToolsParser: () => JsonOutputToolsParser,
  convertLangChainToolCallToOpenAI: () => convertLangChainToolCallToOpenAI,
  makeInvalidToolCall: () => makeInvalidToolCall,
  parseToolCall: () => parseToolCall
});

// node_modules/@langchain/core/dist/prompts/base.js
var BasePromptTemplate = class extends Runnable {
  lc_serializable = true;
  lc_namespace = [
    "langchain_core",
    "prompts",
    this._getPromptType()
  ];
  get lc_attributes() {
    return { partialVariables: void 0 };
  }
  inputVariables;
  outputParser;
  partialVariables;
  /**
  * Metadata to be used for tracing.
  */
  metadata;
  /** Tags to be used for tracing. */
  tags;
  constructor(input) {
    super(input);
    const { inputVariables } = input;
    if (inputVariables.includes("stop")) throw new Error("Cannot have an input variable named 'stop', as it is used internally, please rename.");
    Object.assign(this, input);
  }
  /**
  * Merges partial variables and user variables.
  * @param userVariables The user variables to merge with the partial variables.
  * @returns A Promise that resolves to an object containing the merged variables.
  */
  async mergePartialAndUserVariables(userVariables) {
    const partialVariables = this.partialVariables ?? {};
    const partialValues = {};
    for (const [key, value] of Object.entries(partialVariables)) if (typeof value === "string") partialValues[key] = value;
    else partialValues[key] = await value();
    const allKwargs = {
      ...partialValues,
      ...userVariables
    };
    return allKwargs;
  }
  /**
  * Invokes the prompt template with the given input and options.
  * @param input The input to invoke the prompt template with.
  * @param options Optional configuration for the callback.
  * @returns A Promise that resolves to the output of the prompt template.
  */
  async invoke(input, options) {
    const metadata = {
      ...this.metadata,
      ...options?.metadata
    };
    const tags = [...this.tags ?? [], ...options?.tags ?? []];
    return this._callWithConfig((input$1) => this.formatPromptValue(input$1), input, {
      ...options,
      tags,
      metadata,
      runType: "prompt"
    });
  }
};

// node_modules/@langchain/core/dist/prompts/string.js
var BaseStringPromptTemplate = class extends BasePromptTemplate {
  /**
  * Formats the prompt given the input values and returns a formatted
  * prompt value.
  * @param values The input values to format the prompt.
  * @returns A Promise that resolves to a formatted prompt value.
  */
  async formatPromptValue(values) {
    const formattedPrompt = await this.format(values);
    return new StringPromptValue(formattedPrompt);
  }
};

// node_modules/mustache/mustache.mjs
var objectToString = Object.prototype.toString;
var isArray = Array.isArray || function isArrayPolyfill(object2) {
  return objectToString.call(object2) === "[object Array]";
};
function isFunction(object2) {
  return typeof object2 === "function";
}
function typeStr(obj) {
  return isArray(obj) ? "array" : typeof obj;
}
function escapeRegExp(string3) {
  return string3.replace(/[\-\[\]{}()*+?.,\\\^$|#\s]/g, "\\$&");
}
function hasProperty(obj, propName) {
  return obj != null && typeof obj === "object" && propName in obj;
}
function primitiveHasOwnProperty(primitive, propName) {
  return primitive != null && typeof primitive !== "object" && primitive.hasOwnProperty && primitive.hasOwnProperty(propName);
}
var regExpTest = RegExp.prototype.test;
function testRegExp(re, string3) {
  return regExpTest.call(re, string3);
}
var nonSpaceRe = /\S/;
function isWhitespace(string3) {
  return !testRegExp(nonSpaceRe, string3);
}
var entityMap = {
  "&": "&amp;",
  "<": "&lt;",
  ">": "&gt;",
  '"': "&quot;",
  "'": "&#39;",
  "/": "&#x2F;",
  "`": "&#x60;",
  "=": "&#x3D;"
};
function escapeHtml(string3) {
  return String(string3).replace(/[&<>"'`=\/]/g, function fromEntityMap(s) {
    return entityMap[s];
  });
}
var whiteRe = /\s*/;
var spaceRe = /\s+/;
var equalsRe = /\s*=/;
var curlyRe = /\s*\}/;
var tagRe = /#|\^|\/|>|\{|&|=|!/;
function parseTemplate(template, tags) {
  if (!template)
    return [];
  var lineHasNonSpace = false;
  var sections = [];
  var tokens = [];
  var spaces = [];
  var hasTag = false;
  var nonSpace = false;
  var indentation = "";
  var tagIndex = 0;
  function stripSpace() {
    if (hasTag && !nonSpace) {
      while (spaces.length)
        delete tokens[spaces.pop()];
    } else {
      spaces = [];
    }
    hasTag = false;
    nonSpace = false;
  }
  var openingTagRe, closingTagRe, closingCurlyRe;
  function compileTags(tagsToCompile) {
    if (typeof tagsToCompile === "string")
      tagsToCompile = tagsToCompile.split(spaceRe, 2);
    if (!isArray(tagsToCompile) || tagsToCompile.length !== 2)
      throw new Error("Invalid tags: " + tagsToCompile);
    openingTagRe = new RegExp(escapeRegExp(tagsToCompile[0]) + "\\s*");
    closingTagRe = new RegExp("\\s*" + escapeRegExp(tagsToCompile[1]));
    closingCurlyRe = new RegExp("\\s*" + escapeRegExp("}" + tagsToCompile[1]));
  }
  compileTags(tags || mustache.tags);
  var scanner = new Scanner(template);
  var start, type, value, chr, token, openSection;
  while (!scanner.eos()) {
    start = scanner.pos;
    value = scanner.scanUntil(openingTagRe);
    if (value) {
      for (var i = 0, valueLength = value.length; i < valueLength; ++i) {
        chr = value.charAt(i);
        if (isWhitespace(chr)) {
          spaces.push(tokens.length);
          indentation += chr;
        } else {
          nonSpace = true;
          lineHasNonSpace = true;
          indentation += " ";
        }
        tokens.push(["text", chr, start, start + 1]);
        start += 1;
        if (chr === "\n") {
          stripSpace();
          indentation = "";
          tagIndex = 0;
          lineHasNonSpace = false;
        }
      }
    }
    if (!scanner.scan(openingTagRe))
      break;
    hasTag = true;
    type = scanner.scan(tagRe) || "name";
    scanner.scan(whiteRe);
    if (type === "=") {
      value = scanner.scanUntil(equalsRe);
      scanner.scan(equalsRe);
      scanner.scanUntil(closingTagRe);
    } else if (type === "{") {
      value = scanner.scanUntil(closingCurlyRe);
      scanner.scan(curlyRe);
      scanner.scanUntil(closingTagRe);
      type = "&";
    } else {
      value = scanner.scanUntil(closingTagRe);
    }
    if (!scanner.scan(closingTagRe))
      throw new Error("Unclosed tag at " + scanner.pos);
    if (type == ">") {
      token = [type, value, start, scanner.pos, indentation, tagIndex, lineHasNonSpace];
    } else {
      token = [type, value, start, scanner.pos];
    }
    tagIndex++;
    tokens.push(token);
    if (type === "#" || type === "^") {
      sections.push(token);
    } else if (type === "/") {
      openSection = sections.pop();
      if (!openSection)
        throw new Error('Unopened section "' + value + '" at ' + start);
      if (openSection[1] !== value)
        throw new Error('Unclosed section "' + openSection[1] + '" at ' + start);
    } else if (type === "name" || type === "{" || type === "&") {
      nonSpace = true;
    } else if (type === "=") {
      compileTags(value);
    }
  }
  stripSpace();
  openSection = sections.pop();
  if (openSection)
    throw new Error('Unclosed section "' + openSection[1] + '" at ' + scanner.pos);
  return nestTokens(squashTokens(tokens));
}
function squashTokens(tokens) {
  var squashedTokens = [];
  var token, lastToken;
  for (var i = 0, numTokens = tokens.length; i < numTokens; ++i) {
    token = tokens[i];
    if (token) {
      if (token[0] === "text" && lastToken && lastToken[0] === "text") {
        lastToken[1] += token[1];
        lastToken[3] = token[3];
      } else {
        squashedTokens.push(token);
        lastToken = token;
      }
    }
  }
  return squashedTokens;
}
function nestTokens(tokens) {
  var nestedTokens = [];
  var collector = nestedTokens;
  var sections = [];
  var token, section;
  for (var i = 0, numTokens = tokens.length; i < numTokens; ++i) {
    token = tokens[i];
    switch (token[0]) {
      case "#":
      case "^":
        collector.push(token);
        sections.push(token);
        collector = token[4] = [];
        break;
      case "/":
        section = sections.pop();
        section[5] = token[2];
        collector = sections.length > 0 ? sections[sections.length - 1][4] : nestedTokens;
        break;
      default:
        collector.push(token);
    }
  }
  return nestedTokens;
}
function Scanner(string3) {
  this.string = string3;
  this.tail = string3;
  this.pos = 0;
}
Scanner.prototype.eos = function eos() {
  return this.tail === "";
};
Scanner.prototype.scan = function scan(re) {
  var match = this.tail.match(re);
  if (!match || match.index !== 0)
    return "";
  var string3 = match[0];
  this.tail = this.tail.substring(string3.length);
  this.pos += string3.length;
  return string3;
};
Scanner.prototype.scanUntil = function scanUntil(re) {
  var index2 = this.tail.search(re), match;
  switch (index2) {
    case -1:
      match = this.tail;
      this.tail = "";
      break;
    case 0:
      match = "";
      break;
    default:
      match = this.tail.substring(0, index2);
      this.tail = this.tail.substring(index2);
  }
  this.pos += match.length;
  return match;
};
function Context(view2, parentContext) {
  this.view = view2;
  this.cache = { ".": this.view };
  this.parent = parentContext;
}
Context.prototype.push = function push(view2) {
  return new Context(view2, this);
};
Context.prototype.lookup = function lookup(name) {
  var cache = this.cache;
  var value;
  if (cache.hasOwnProperty(name)) {
    value = cache[name];
  } else {
    var context2 = this, intermediateValue, names, index2, lookupHit = false;
    while (context2) {
      if (name.indexOf(".") > 0) {
        intermediateValue = context2.view;
        names = name.split(".");
        index2 = 0;
        while (intermediateValue != null && index2 < names.length) {
          if (index2 === names.length - 1)
            lookupHit = hasProperty(intermediateValue, names[index2]) || primitiveHasOwnProperty(intermediateValue, names[index2]);
          intermediateValue = intermediateValue[names[index2++]];
        }
      } else {
        intermediateValue = context2.view[name];
        lookupHit = hasProperty(context2.view, name);
      }
      if (lookupHit) {
        value = intermediateValue;
        break;
      }
      context2 = context2.parent;
    }
    cache[name] = value;
  }
  if (isFunction(value))
    value = value.call(this.view);
  return value;
};
function Writer() {
  this.templateCache = {
    _cache: {},
    set: function set2(key, value) {
      this._cache[key] = value;
    },
    get: function get(key) {
      return this._cache[key];
    },
    clear: function clear() {
      this._cache = {};
    }
  };
}
Writer.prototype.clearCache = function clearCache() {
  if (typeof this.templateCache !== "undefined") {
    this.templateCache.clear();
  }
};
Writer.prototype.parse = function parse(template, tags) {
  var cache = this.templateCache;
  var cacheKey = template + ":" + (tags || mustache.tags).join(":");
  var isCacheEnabled = typeof cache !== "undefined";
  var tokens = isCacheEnabled ? cache.get(cacheKey) : void 0;
  if (tokens == void 0) {
    tokens = parseTemplate(template, tags);
    isCacheEnabled && cache.set(cacheKey, tokens);
  }
  return tokens;
};
Writer.prototype.render = function render(template, view2, partials, config2) {
  var tags = this.getConfigTags(config2);
  var tokens = this.parse(template, tags);
  var context2 = view2 instanceof Context ? view2 : new Context(view2, void 0);
  return this.renderTokens(tokens, context2, partials, template, config2);
};
Writer.prototype.renderTokens = function renderTokens(tokens, context2, partials, originalTemplate, config2) {
  var buffer = "";
  var token, symbol2, value;
  for (var i = 0, numTokens = tokens.length; i < numTokens; ++i) {
    value = void 0;
    token = tokens[i];
    symbol2 = token[0];
    if (symbol2 === "#") value = this.renderSection(token, context2, partials, originalTemplate, config2);
    else if (symbol2 === "^") value = this.renderInverted(token, context2, partials, originalTemplate, config2);
    else if (symbol2 === ">") value = this.renderPartial(token, context2, partials, config2);
    else if (symbol2 === "&") value = this.unescapedValue(token, context2);
    else if (symbol2 === "name") value = this.escapedValue(token, context2, config2);
    else if (symbol2 === "text") value = this.rawValue(token);
    if (value !== void 0)
      buffer += value;
  }
  return buffer;
};
Writer.prototype.renderSection = function renderSection(token, context2, partials, originalTemplate, config2) {
  var self = this;
  var buffer = "";
  var value = context2.lookup(token[1]);
  function subRender(template) {
    return self.render(template, context2, partials, config2);
  }
  if (!value) return;
  if (isArray(value)) {
    for (var j = 0, valueLength = value.length; j < valueLength; ++j) {
      buffer += this.renderTokens(token[4], context2.push(value[j]), partials, originalTemplate, config2);
    }
  } else if (typeof value === "object" || typeof value === "string" || typeof value === "number") {
    buffer += this.renderTokens(token[4], context2.push(value), partials, originalTemplate, config2);
  } else if (isFunction(value)) {
    if (typeof originalTemplate !== "string")
      throw new Error("Cannot use higher-order sections without the original template");
    value = value.call(context2.view, originalTemplate.slice(token[3], token[5]), subRender);
    if (value != null)
      buffer += value;
  } else {
    buffer += this.renderTokens(token[4], context2, partials, originalTemplate, config2);
  }
  return buffer;
};
Writer.prototype.renderInverted = function renderInverted(token, context2, partials, originalTemplate, config2) {
  var value = context2.lookup(token[1]);
  if (!value || isArray(value) && value.length === 0)
    return this.renderTokens(token[4], context2, partials, originalTemplate, config2);
};
Writer.prototype.indentPartial = function indentPartial(partial, indentation, lineHasNonSpace) {
  var filteredIndentation = indentation.replace(/[^ \t]/g, "");
  var partialByNl = partial.split("\n");
  for (var i = 0; i < partialByNl.length; i++) {
    if (partialByNl[i].length && (i > 0 || !lineHasNonSpace)) {
      partialByNl[i] = filteredIndentation + partialByNl[i];
    }
  }
  return partialByNl.join("\n");
};
Writer.prototype.renderPartial = function renderPartial(token, context2, partials, config2) {
  if (!partials) return;
  var tags = this.getConfigTags(config2);
  var value = isFunction(partials) ? partials(token[1]) : partials[token[1]];
  if (value != null) {
    var lineHasNonSpace = token[6];
    var tagIndex = token[5];
    var indentation = token[4];
    var indentedValue = value;
    if (tagIndex == 0 && indentation) {
      indentedValue = this.indentPartial(value, indentation, lineHasNonSpace);
    }
    var tokens = this.parse(indentedValue, tags);
    return this.renderTokens(tokens, context2, partials, indentedValue, config2);
  }
};
Writer.prototype.unescapedValue = function unescapedValue(token, context2) {
  var value = context2.lookup(token[1]);
  if (value != null)
    return value;
};
Writer.prototype.escapedValue = function escapedValue(token, context2, config2) {
  var escape = this.getConfigEscape(config2) || mustache.escape;
  var value = context2.lookup(token[1]);
  if (value != null)
    return typeof value === "number" && escape === mustache.escape ? String(value) : escape(value);
};
Writer.prototype.rawValue = function rawValue(token) {
  return token[1];
};
Writer.prototype.getConfigTags = function getConfigTags(config2) {
  if (isArray(config2)) {
    return config2;
  } else if (config2 && typeof config2 === "object") {
    return config2.tags;
  } else {
    return void 0;
  }
};
Writer.prototype.getConfigEscape = function getConfigEscape(config2) {
  if (config2 && typeof config2 === "object" && !isArray(config2)) {
    return config2.escape;
  } else {
    return void 0;
  }
};
var mustache = {
  name: "mustache.js",
  version: "4.2.0",
  tags: ["{{", "}}"],
  clearCache: void 0,
  escape: void 0,
  parse: void 0,
  render: void 0,
  Scanner: void 0,
  Context: void 0,
  Writer: void 0,
  /**
   * Allows a user to override the default caching strategy, by providing an
   * object with set, get and clear methods. This can also be used to disable
   * the cache by setting it to the literal `undefined`.
   */
  set templateCache(cache) {
    defaultWriter.templateCache = cache;
  },
  /**
   * Gets the default or overridden caching object from the default writer.
   */
  get templateCache() {
    return defaultWriter.templateCache;
  }
};
var defaultWriter = new Writer();
mustache.clearCache = function clearCache2() {
  return defaultWriter.clearCache();
};
mustache.parse = function parse2(template, tags) {
  return defaultWriter.parse(template, tags);
};
mustache.render = function render2(template, view2, partials, config2) {
  if (typeof template !== "string") {
    throw new TypeError('Invalid template! Template should be a "string" but "' + typeStr(template) + '" was given as the first argument for mustache#render(template, view, partials)');
  }
  return defaultWriter.render(template, view2, partials, config2);
};
mustache.escape = escapeHtml;
mustache.Scanner = Scanner;
mustache.Context = Context;
mustache.Writer = Writer;
var mustache_default = mustache;

// node_modules/@langchain/core/dist/prompts/template.js
function configureMustache() {
  mustache_default.escape = (text) => text;
}
var parseFString = (template) => {
  const chars = template.split("");
  const nodes = [];
  const nextBracket = (bracket, start) => {
    for (let i$1 = start; i$1 < chars.length; i$1 += 1) if (bracket.includes(chars[i$1])) return i$1;
    return -1;
  };
  let i = 0;
  while (i < chars.length) if (chars[i] === "{" && i + 1 < chars.length && chars[i + 1] === "{") {
    nodes.push({
      type: "literal",
      text: "{"
    });
    i += 2;
  } else if (chars[i] === "}" && i + 1 < chars.length && chars[i + 1] === "}") {
    nodes.push({
      type: "literal",
      text: "}"
    });
    i += 2;
  } else if (chars[i] === "{") {
    const j = nextBracket("}", i);
    if (j < 0) throw new Error("Unclosed '{' in template.");
    nodes.push({
      type: "variable",
      name: chars.slice(i + 1, j).join("")
    });
    i = j + 1;
  } else if (chars[i] === "}") throw new Error("Single '}' in template.");
  else {
    const next = nextBracket("{}", i);
    const text = (next < 0 ? chars.slice(i) : chars.slice(i, next)).join("");
    nodes.push({
      type: "literal",
      text
    });
    i = next < 0 ? chars.length : next;
  }
  return nodes;
};
var mustacheTemplateToNodes = (template, context2 = []) => {
  const nodes = [];
  for (const temp of template) if (temp[0] === "name") {
    const name = temp[1].includes(".") ? temp[1].split(".")[0] : temp[1];
    nodes.push({
      type: "variable",
      name
    });
  } else if ([
    "#",
    "&",
    "^",
    ">"
  ].includes(temp[0])) {
    nodes.push({
      type: "variable",
      name: temp[1]
    });
    if (temp[0] === "#" && temp.length > 4 && Array.isArray(temp[4])) {
      const newContext = [...context2, temp[1]];
      const nestedNodes = mustacheTemplateToNodes(temp[4], newContext);
      nodes.push(...nestedNodes);
    }
  } else nodes.push({
    type: "literal",
    text: temp[1]
  });
  return nodes;
};
var parseMustache = (template) => {
  configureMustache();
  const parsed = mustache_default.parse(template);
  return mustacheTemplateToNodes(parsed);
};
var interpolateFString = (template, values) => {
  return parseFString(template).reduce((res, node) => {
    if (node.type === "variable") {
      if (node.name in values) {
        const stringValue = typeof values[node.name] === "string" ? values[node.name] : JSON.stringify(values[node.name]);
        return res + stringValue;
      }
      throw new Error(`(f-string) Missing value for input ${node.name}`);
    }
    return res + node.text;
  }, "");
};
var interpolateMustache = (template, values) => {
  configureMustache();
  return mustache_default.render(template, values);
};
var DEFAULT_FORMATTER_MAPPING = {
  "f-string": interpolateFString,
  mustache: interpolateMustache
};
var DEFAULT_PARSER_MAPPING = {
  "f-string": parseFString,
  mustache: parseMustache
};
var renderTemplate = (template, templateFormat, inputValues) => {
  try {
    return DEFAULT_FORMATTER_MAPPING[templateFormat](template, inputValues);
  } catch (e) {
    const error = addLangChainErrorFields(e, "INVALID_PROMPT_INPUT");
    throw error;
  }
};
var parseTemplate2 = (template, templateFormat) => DEFAULT_PARSER_MAPPING[templateFormat](template);
var checkValidTemplate = (template, templateFormat, inputVariables) => {
  if (!(templateFormat in DEFAULT_FORMATTER_MAPPING)) {
    const validFormats = Object.keys(DEFAULT_FORMATTER_MAPPING);
    throw new Error(`Invalid template format. Got \`${templateFormat}\`;
                         should be one of ${validFormats}`);
  }
  try {
    const dummyInputs = Object.fromEntries(inputVariables.map((v) => [v, "foo"]));
    if (Array.isArray(template)) template.forEach((message) => {
      if (message.type === "text" && "text" in message && typeof message.text === "string") renderTemplate(message.text, templateFormat, dummyInputs);
      else if (message.type === "image_url") {
        if (typeof message.image_url === "string") renderTemplate(message.image_url, templateFormat, dummyInputs);
        else if (typeof message.image_url === "object" && message.image_url !== null && "url" in message.image_url && typeof message.image_url.url === "string") {
          const imageUrl = message.image_url.url;
          renderTemplate(imageUrl, templateFormat, dummyInputs);
        }
      } else throw new Error(`Invalid message template received. ${JSON.stringify(message, null, 2)}`);
    });
    else renderTemplate(template, templateFormat, dummyInputs);
  } catch (e) {
    throw new Error(`Invalid prompt schema: ${e.message}`);
  }
};

// node_modules/@langchain/core/dist/prompts/prompt.js
var PromptTemplate = class PromptTemplate2 extends BaseStringPromptTemplate {
  static lc_name() {
    return "PromptTemplate";
  }
  template;
  templateFormat = "f-string";
  validateTemplate = true;
  /**
  * Additional fields which should be included inside
  * the message content array if using a complex message
  * content.
  */
  additionalContentFields;
  constructor(input) {
    super(input);
    if (input.templateFormat === "mustache" && input.validateTemplate === void 0) this.validateTemplate = false;
    Object.assign(this, input);
    if (this.validateTemplate) {
      if (this.templateFormat === "mustache") throw new Error("Mustache templates cannot be validated.");
      let totalInputVariables = this.inputVariables;
      if (this.partialVariables) totalInputVariables = totalInputVariables.concat(Object.keys(this.partialVariables));
      checkValidTemplate(this.template, this.templateFormat, totalInputVariables);
    }
  }
  _getPromptType() {
    return "prompt";
  }
  /**
  * Formats the prompt template with the provided values.
  * @param values The values to be used to format the prompt template.
  * @returns A promise that resolves to a string which is the formatted prompt.
  */
  async format(values) {
    const allValues = await this.mergePartialAndUserVariables(values);
    return renderTemplate(this.template, this.templateFormat, allValues);
  }
  /**
  * Take examples in list format with prefix and suffix to create a prompt.
  *
  * Intended to be used a a way to dynamically create a prompt from examples.
  *
  * @param examples - List of examples to use in the prompt.
  * @param suffix - String to go after the list of examples. Should generally set up the user's input.
  * @param inputVariables - A list of variable names the final prompt template will expect
  * @param exampleSeparator - The separator to use in between examples
  * @param prefix - String that should go before any examples. Generally includes examples.
  *
  * @returns The final prompt template generated.
  */
  static fromExamples(examples, suffix, inputVariables, exampleSeparator = "\n\n", prefix = "") {
    const template = [
      prefix,
      ...examples,
      suffix
    ].join(exampleSeparator);
    return new PromptTemplate2({
      inputVariables,
      template
    });
  }
  static fromTemplate(template, options) {
    const { templateFormat = "f-string", ...rest } = options ?? {};
    const names = /* @__PURE__ */ new Set();
    parseTemplate2(template, templateFormat).forEach((node) => {
      if (node.type === "variable") names.add(node.name);
    });
    return new PromptTemplate2({
      inputVariables: [...names],
      templateFormat,
      template,
      ...rest
    });
  }
  /**
  * Partially applies values to the prompt template.
  * @param values The values to be partially applied to the prompt template.
  * @returns A new instance of PromptTemplate with the partially applied values.
  */
  async partial(values) {
    const newInputVariables = this.inputVariables.filter((iv) => !(iv in values));
    const newPartialVariables = {
      ...this.partialVariables ?? {},
      ...values
    };
    const promptDict = {
      ...this,
      inputVariables: newInputVariables,
      partialVariables: newPartialVariables
    };
    return new PromptTemplate2(promptDict);
  }
  serialize() {
    if (this.outputParser !== void 0) throw new Error("Cannot serialize a prompt template with an output parser");
    return {
      _type: this._getPromptType(),
      input_variables: this.inputVariables,
      template: this.template,
      template_format: this.templateFormat
    };
  }
  static async deserialize(data) {
    if (!data.template) throw new Error("Prompt template must have a template");
    const res = new PromptTemplate2({
      inputVariables: data.input_variables,
      template: data.template,
      templateFormat: data.template_format
    });
    return res;
  }
};

// node_modules/@langchain/core/dist/prompts/image.js
var ImagePromptTemplate = class ImagePromptTemplate2 extends BasePromptTemplate {
  static lc_name() {
    return "ImagePromptTemplate";
  }
  lc_namespace = [
    "langchain_core",
    "prompts",
    "image"
  ];
  template;
  templateFormat = "f-string";
  validateTemplate = true;
  /**
  * Additional fields which should be included inside
  * the message content array if using a complex message
  * content.
  */
  additionalContentFields;
  constructor(input) {
    super(input);
    this.template = input.template;
    this.templateFormat = input.templateFormat ?? this.templateFormat;
    this.validateTemplate = input.validateTemplate ?? this.validateTemplate;
    this.additionalContentFields = input.additionalContentFields;
    if (this.validateTemplate) {
      let totalInputVariables = this.inputVariables;
      if (this.partialVariables) totalInputVariables = totalInputVariables.concat(Object.keys(this.partialVariables));
      checkValidTemplate([{
        type: "image_url",
        image_url: this.template
      }], this.templateFormat, totalInputVariables);
    }
  }
  _getPromptType() {
    return "prompt";
  }
  /**
  * Partially applies values to the prompt template.
  * @param values The values to be partially applied to the prompt template.
  * @returns A new instance of ImagePromptTemplate with the partially applied values.
  */
  async partial(values) {
    const newInputVariables = this.inputVariables.filter((iv) => !(iv in values));
    const newPartialVariables = {
      ...this.partialVariables ?? {},
      ...values
    };
    const promptDict = {
      ...this,
      inputVariables: newInputVariables,
      partialVariables: newPartialVariables
    };
    return new ImagePromptTemplate2(promptDict);
  }
  /**
  * Formats the prompt template with the provided values.
  * @param values The values to be used to format the prompt template.
  * @returns A promise that resolves to a string which is the formatted prompt.
  */
  async format(values) {
    const formatted = {};
    for (const [key, value] of Object.entries(this.template)) if (typeof value === "string") formatted[key] = renderTemplate(value, this.templateFormat, values);
    else formatted[key] = value;
    const url2 = values.url || formatted.url;
    const detail = values.detail || formatted.detail;
    if (!url2) throw new Error("Must provide either an image URL.");
    if (typeof url2 !== "string") throw new Error("url must be a string.");
    const output = { url: url2 };
    if (detail) output.detail = detail;
    return output;
  }
  /**
  * Formats the prompt given the input values and returns a formatted
  * prompt value.
  * @param values The input values to format the prompt.
  * @returns A Promise that resolves to a formatted prompt value.
  */
  async formatPromptValue(values) {
    const formattedPrompt = await this.format(values);
    return new ImagePromptValue(formattedPrompt);
  }
};

// node_modules/@langchain/core/dist/prompts/dict.js
var DictPromptTemplate = class extends Runnable {
  lc_namespace = [
    "langchain_core",
    "prompts",
    "dict"
  ];
  lc_serializable = true;
  template;
  templateFormat;
  inputVariables;
  static lc_name() {
    return "DictPromptTemplate";
  }
  constructor(fields) {
    const templateFormat = fields.templateFormat ?? "f-string";
    const inputVariables = _getInputVariables(fields.template, templateFormat);
    super({
      inputVariables,
      ...fields
    });
    this.template = fields.template;
    this.templateFormat = templateFormat;
    this.inputVariables = inputVariables;
  }
  async format(values) {
    return _insertInputVariables(this.template, values, this.templateFormat);
  }
  async invoke(values) {
    return await this._callWithConfig(this.format.bind(this), values, { runType: "prompt" });
  }
};
function _getInputVariables(template, templateFormat) {
  const inputVariables = [];
  for (const v of Object.values(template)) if (typeof v === "string") parseTemplate2(v, templateFormat).forEach((t) => {
    if (t.type === "variable") inputVariables.push(t.name);
  });
  else if (Array.isArray(v)) {
    for (const x of v) if (typeof x === "string") parseTemplate2(x, templateFormat).forEach((t) => {
      if (t.type === "variable") inputVariables.push(t.name);
    });
    else if (typeof x === "object") inputVariables.push(..._getInputVariables(x, templateFormat));
  } else if (typeof v === "object" && v !== null) inputVariables.push(..._getInputVariables(v, templateFormat));
  return Array.from(new Set(inputVariables));
}
function _insertInputVariables(template, inputs, templateFormat) {
  const formatted = {};
  for (const [k, v] of Object.entries(template)) if (typeof v === "string") formatted[k] = renderTemplate(v, templateFormat, inputs);
  else if (Array.isArray(v)) {
    const formattedV = [];
    for (const x of v) if (typeof x === "string") formattedV.push(renderTemplate(x, templateFormat, inputs));
    else if (typeof x === "object") formattedV.push(_insertInputVariables(x, inputs, templateFormat));
    formatted[k] = formattedV;
  } else if (typeof v === "object" && v !== null) formatted[k] = _insertInputVariables(v, inputs, templateFormat);
  else formatted[k] = v;
  return formatted;
}

// node_modules/@langchain/core/dist/prompts/chat.js
var BaseMessagePromptTemplate = class extends Runnable {
  lc_namespace = [
    "langchain_core",
    "prompts",
    "chat"
  ];
  lc_serializable = true;
  /**
  * Calls the formatMessages method with the provided input and options.
  * @param input Input for the formatMessages method
  * @param options Optional BaseCallbackConfig
  * @returns Formatted output messages
  */
  async invoke(input, options) {
    return this._callWithConfig((input$1) => this.formatMessages(input$1), input, {
      ...options,
      runType: "prompt"
    });
  }
};
var MessagesPlaceholder = class extends BaseMessagePromptTemplate {
  static lc_name() {
    return "MessagesPlaceholder";
  }
  variableName;
  optional;
  constructor(fields) {
    if (typeof fields === "string") fields = { variableName: fields };
    super(fields);
    this.variableName = fields.variableName;
    this.optional = fields.optional ?? false;
  }
  get inputVariables() {
    return [this.variableName];
  }
  async formatMessages(values) {
    const input = values[this.variableName];
    if (this.optional && !input) return [];
    else if (!input) {
      const error = new Error(`Field "${this.variableName}" in prompt uses a MessagesPlaceholder, which expects an array of BaseMessages as an input value. Received: undefined`);
      error.name = "InputFormatError";
      throw error;
    }
    let formattedMessages;
    try {
      if (Array.isArray(input)) formattedMessages = input.map(coerceMessageLikeToMessage);
      else formattedMessages = [coerceMessageLikeToMessage(input)];
    } catch (e) {
      const readableInput = typeof input === "string" ? input : JSON.stringify(input, null, 2);
      const error = new Error([
        `Field "${this.variableName}" in prompt uses a MessagesPlaceholder, which expects an array of BaseMessages or coerceable values as input.`,
        `Received value: ${readableInput}`,
        `Additional message: ${e.message}`
      ].join("\n\n"));
      error.name = "InputFormatError";
      error.lc_error_code = e.lc_error_code;
      throw error;
    }
    return formattedMessages;
  }
};
var BaseMessageStringPromptTemplate = class extends BaseMessagePromptTemplate {
  prompt;
  constructor(fields) {
    if (!("prompt" in fields)) fields = { prompt: fields };
    super(fields);
    this.prompt = fields.prompt;
  }
  get inputVariables() {
    return this.prompt.inputVariables;
  }
  async formatMessages(values) {
    return [await this.format(values)];
  }
};
var BaseChatPromptTemplate = class extends BasePromptTemplate {
  constructor(input) {
    super(input);
  }
  async format(values) {
    return (await this.formatPromptValue(values)).toString();
  }
  async formatPromptValue(values) {
    const resultMessages = await this.formatMessages(values);
    return new ChatPromptValue(resultMessages);
  }
};
var ChatMessagePromptTemplate = class extends BaseMessageStringPromptTemplate {
  static lc_name() {
    return "ChatMessagePromptTemplate";
  }
  role;
  constructor(fields, role) {
    if (!("prompt" in fields)) fields = {
      prompt: fields,
      role
    };
    super(fields);
    this.role = fields.role;
  }
  async format(values) {
    return new ChatMessage(await this.prompt.format(values), this.role);
  }
  static fromTemplate(template, role, options) {
    return new this(PromptTemplate.fromTemplate(template, { templateFormat: options?.templateFormat }), role);
  }
};
function isTextTemplateParam(param) {
  if (param === null || typeof param !== "object" || Array.isArray(param)) return false;
  return Object.keys(param).length === 1 && "text" in param && typeof param.text === "string";
}
function isImageTemplateParam(param) {
  if (param === null || typeof param !== "object" || Array.isArray(param)) return false;
  return "image_url" in param && (typeof param.image_url === "string" || typeof param.image_url === "object" && param.image_url !== null && "url" in param.image_url && typeof param.image_url.url === "string");
}
var _StringImageMessagePromptTemplate = class extends BaseMessagePromptTemplate {
  lc_namespace = [
    "langchain_core",
    "prompts",
    "chat"
  ];
  lc_serializable = true;
  inputVariables = [];
  additionalOptions = {};
  prompt;
  messageClass;
  static _messageClass() {
    throw new Error("Can not invoke _messageClass from inside _StringImageMessagePromptTemplate");
  }
  chatMessageClass;
  constructor(fields, additionalOptions) {
    if (!("prompt" in fields)) fields = { prompt: fields };
    super(fields);
    this.prompt = fields.prompt;
    if (Array.isArray(this.prompt)) {
      let inputVariables = [];
      this.prompt.forEach((prompt) => {
        if ("inputVariables" in prompt) inputVariables = inputVariables.concat(prompt.inputVariables);
      });
      this.inputVariables = inputVariables;
    } else this.inputVariables = this.prompt.inputVariables;
    this.additionalOptions = additionalOptions ?? this.additionalOptions;
  }
  createMessage(content) {
    const constructor = this.constructor;
    if (constructor._messageClass()) {
      const MsgClass = constructor._messageClass();
      return new MsgClass({ content });
    } else if (constructor.chatMessageClass) {
      const MsgClass = constructor.chatMessageClass();
      return new MsgClass({
        content,
        role: this.getRoleFromMessageClass(MsgClass.lc_name())
      });
    } else throw new Error("No message class defined");
  }
  getRoleFromMessageClass(name) {
    switch (name) {
      case "HumanMessage":
        return "human";
      case "AIMessage":
        return "ai";
      case "SystemMessage":
        return "system";
      case "ChatMessage":
        return "chat";
      default:
        throw new Error("Invalid message class name");
    }
  }
  static fromTemplate(template, additionalOptions) {
    if (typeof template === "string") return new this(PromptTemplate.fromTemplate(template, additionalOptions));
    const prompt = [];
    for (const item of template) if (typeof item === "string") prompt.push(PromptTemplate.fromTemplate(item, additionalOptions));
    else if (item === null) {
    } else if (isTextTemplateParam(item)) {
      let text = "";
      if (typeof item.text === "string") text = item.text ?? "";
      const options = {
        ...additionalOptions,
        additionalContentFields: item
      };
      prompt.push(PromptTemplate.fromTemplate(text, options));
    } else if (isImageTemplateParam(item)) {
      let imgTemplate = item.image_url ?? "";
      let imgTemplateObject;
      let inputVariables = [];
      if (typeof imgTemplate === "string") {
        let parsedTemplate;
        if (additionalOptions?.templateFormat === "mustache") parsedTemplate = parseMustache(imgTemplate);
        else parsedTemplate = parseFString(imgTemplate);
        const variables = parsedTemplate.flatMap((item$1) => item$1.type === "variable" ? [item$1.name] : []);
        if ((variables?.length ?? 0) > 0) {
          if (variables.length > 1) throw new Error(`Only one format variable allowed per image template.
Got: ${variables}
From: ${imgTemplate}`);
          inputVariables = [variables[0]];
        } else inputVariables = [];
        imgTemplate = { url: imgTemplate };
        imgTemplateObject = new ImagePromptTemplate({
          template: imgTemplate,
          inputVariables,
          templateFormat: additionalOptions?.templateFormat,
          additionalContentFields: item
        });
      } else if (typeof imgTemplate === "object") {
        if ("url" in imgTemplate) {
          let parsedTemplate;
          if (additionalOptions?.templateFormat === "mustache") parsedTemplate = parseMustache(imgTemplate.url);
          else parsedTemplate = parseFString(imgTemplate.url);
          inputVariables = parsedTemplate.flatMap((item$1) => item$1.type === "variable" ? [item$1.name] : []);
        } else inputVariables = [];
        imgTemplateObject = new ImagePromptTemplate({
          template: imgTemplate,
          inputVariables,
          templateFormat: additionalOptions?.templateFormat,
          additionalContentFields: item
        });
      } else throw new Error("Invalid image template");
      prompt.push(imgTemplateObject);
    } else if (typeof item === "object") prompt.push(new DictPromptTemplate({
      template: item,
      templateFormat: additionalOptions?.templateFormat
    }));
    return new this({
      prompt,
      additionalOptions
    });
  }
  async format(input) {
    if (this.prompt instanceof BaseStringPromptTemplate) {
      const text = await this.prompt.format(input);
      return this.createMessage(text);
    } else {
      const content = [];
      for (const prompt of this.prompt) {
        let inputs = {};
        if (!("inputVariables" in prompt)) throw new Error(`Prompt ${prompt} does not have inputVariables defined.`);
        for (const item of prompt.inputVariables) {
          if (!inputs) inputs = { [item]: input[item] };
          inputs = {
            ...inputs,
            [item]: input[item]
          };
        }
        if (prompt instanceof BaseStringPromptTemplate) {
          const formatted = await prompt.format(inputs);
          let additionalContentFields;
          if ("additionalContentFields" in prompt) additionalContentFields = prompt.additionalContentFields;
          if (formatted !== "") content.push({
            ...additionalContentFields,
            type: "text",
            text: formatted
          });
        } else if (prompt instanceof ImagePromptTemplate) {
          const formatted = await prompt.format(inputs);
          let additionalContentFields;
          if ("additionalContentFields" in prompt) additionalContentFields = prompt.additionalContentFields;
          content.push({
            ...additionalContentFields,
            type: "image_url",
            image_url: formatted
          });
        } else if (prompt instanceof DictPromptTemplate) {
          const formatted = await prompt.format(inputs);
          let additionalContentFields;
          if ("additionalContentFields" in prompt) additionalContentFields = prompt.additionalContentFields;
          content.push({
            ...additionalContentFields,
            ...formatted
          });
        }
      }
      return this.createMessage(content);
    }
  }
  async formatMessages(values) {
    return [await this.format(values)];
  }
};
var HumanMessagePromptTemplate = class extends _StringImageMessagePromptTemplate {
  static _messageClass() {
    return HumanMessage;
  }
  static lc_name() {
    return "HumanMessagePromptTemplate";
  }
};
var AIMessagePromptTemplate = class extends _StringImageMessagePromptTemplate {
  static _messageClass() {
    return AIMessage;
  }
  static lc_name() {
    return "AIMessagePromptTemplate";
  }
};
var SystemMessagePromptTemplate = class extends _StringImageMessagePromptTemplate {
  static _messageClass() {
    return SystemMessage;
  }
  static lc_name() {
    return "SystemMessagePromptTemplate";
  }
};
function _isBaseMessagePromptTemplate(baseMessagePromptTemplateLike) {
  return typeof baseMessagePromptTemplateLike.formatMessages === "function";
}
function _coerceMessagePromptTemplateLike(messagePromptTemplateLike, extra) {
  if (_isBaseMessagePromptTemplate(messagePromptTemplateLike) || isBaseMessage(messagePromptTemplateLike)) return messagePromptTemplateLike;
  if (Array.isArray(messagePromptTemplateLike) && messagePromptTemplateLike[0] === "placeholder") {
    const messageContent = messagePromptTemplateLike[1];
    if (extra?.templateFormat === "mustache" && typeof messageContent === "string" && messageContent.slice(0, 2) === "{{" && messageContent.slice(-2) === "}}") {
      const variableName = messageContent.slice(2, -2);
      return new MessagesPlaceholder({
        variableName,
        optional: true
      });
    } else if (typeof messageContent === "string" && messageContent[0] === "{" && messageContent[messageContent.length - 1] === "}") {
      const variableName = messageContent.slice(1, -1);
      return new MessagesPlaceholder({
        variableName,
        optional: true
      });
    }
    throw new Error(`Invalid placeholder template for format ${extra?.templateFormat ?? `"f-string"`}: "${messagePromptTemplateLike[1]}". Expected a variable name surrounded by ${extra?.templateFormat === "mustache" ? "double" : "single"} curly braces.`);
  }
  const message = coerceMessageLikeToMessage(messagePromptTemplateLike);
  let templateData;
  if (typeof message.content === "string") templateData = message.content;
  else templateData = message.content.map((item) => {
    if ("text" in item) return {
      ...item,
      text: item.text
    };
    else if ("image_url" in item) return {
      ...item,
      image_url: item.image_url
    };
    else return item;
  });
  if (message._getType() === "human") return HumanMessagePromptTemplate.fromTemplate(templateData, extra);
  else if (message._getType() === "ai") return AIMessagePromptTemplate.fromTemplate(templateData, extra);
  else if (message._getType() === "system") return SystemMessagePromptTemplate.fromTemplate(templateData, extra);
  else if (ChatMessage.isInstance(message)) return ChatMessagePromptTemplate.fromTemplate(message.content, message.role, extra);
  else throw new Error(`Could not coerce message prompt template from input. Received message type: "${message._getType()}".`);
}
function isMessagesPlaceholder(x) {
  return x.constructor.lc_name() === "MessagesPlaceholder";
}
var ChatPromptTemplate = class ChatPromptTemplate2 extends BaseChatPromptTemplate {
  static lc_name() {
    return "ChatPromptTemplate";
  }
  get lc_aliases() {
    return { promptMessages: "messages" };
  }
  promptMessages;
  validateTemplate = true;
  templateFormat = "f-string";
  constructor(input) {
    super(input);
    if (input.templateFormat === "mustache" && input.validateTemplate === void 0) this.validateTemplate = false;
    Object.assign(this, input);
    if (this.validateTemplate) {
      const inputVariablesMessages = /* @__PURE__ */ new Set();
      for (const promptMessage of this.promptMessages) {
        if (promptMessage instanceof BaseMessage) continue;
        for (const inputVariable of promptMessage.inputVariables) inputVariablesMessages.add(inputVariable);
      }
      const totalInputVariables = this.inputVariables;
      const inputVariablesInstance = new Set(this.partialVariables ? totalInputVariables.concat(Object.keys(this.partialVariables)) : totalInputVariables);
      const difference = new Set([...inputVariablesInstance].filter((x) => !inputVariablesMessages.has(x)));
      if (difference.size > 0) throw new Error(`Input variables \`${[...difference]}\` are not used in any of the prompt messages.`);
      const otherDifference = new Set([...inputVariablesMessages].filter((x) => !inputVariablesInstance.has(x)));
      if (otherDifference.size > 0) throw new Error(`Input variables \`${[...otherDifference]}\` are used in prompt messages but not in the prompt template.`);
    }
  }
  _getPromptType() {
    return "chat";
  }
  async _parseImagePrompts(message, inputValues) {
    if (typeof message.content === "string") return message;
    const formattedMessageContent = await Promise.all(message.content.map(async (item) => {
      if (item.type !== "image_url") return item;
      let imageUrl = "";
      if (typeof item.image_url === "string") imageUrl = item.image_url;
      else if (typeof item.image_url === "object" && item.image_url !== null && "url" in item.image_url && typeof item.image_url.url === "string") imageUrl = item.image_url.url;
      const promptTemplatePlaceholder = PromptTemplate.fromTemplate(imageUrl, { templateFormat: this.templateFormat });
      const formattedUrl = await promptTemplatePlaceholder.format(inputValues);
      if (typeof item.image_url === "object" && item.image_url !== null && "url" in item.image_url) item.image_url.url = formattedUrl;
      else item.image_url = formattedUrl;
      return item;
    }));
    message.content = formattedMessageContent;
    return message;
  }
  async formatMessages(values) {
    const allValues = await this.mergePartialAndUserVariables(values);
    let resultMessages = [];
    for (const promptMessage of this.promptMessages) if (promptMessage instanceof BaseMessage) resultMessages.push(await this._parseImagePrompts(promptMessage, allValues));
    else {
      let inputValues;
      if (this.templateFormat === "mustache") inputValues = { ...allValues };
      else inputValues = promptMessage.inputVariables.reduce((acc, inputVariable) => {
        if (!(inputVariable in allValues) && !(isMessagesPlaceholder(promptMessage) && promptMessage.optional)) {
          const error = addLangChainErrorFields(new Error(`Missing value for input variable \`${inputVariable.toString()}\``), "INVALID_PROMPT_INPUT");
          throw error;
        }
        acc[inputVariable] = allValues[inputVariable];
        return acc;
      }, {});
      const message = await promptMessage.formatMessages(inputValues);
      resultMessages = resultMessages.concat(message);
    }
    return resultMessages;
  }
  async partial(values) {
    const newInputVariables = this.inputVariables.filter((iv) => !(iv in values));
    const newPartialVariables = {
      ...this.partialVariables ?? {},
      ...values
    };
    const promptDict = {
      ...this,
      inputVariables: newInputVariables,
      partialVariables: newPartialVariables
    };
    return new ChatPromptTemplate2(promptDict);
  }
  static fromTemplate(template, options) {
    const prompt = PromptTemplate.fromTemplate(template, options);
    const humanTemplate = new HumanMessagePromptTemplate({ prompt });
    return this.fromMessages([humanTemplate]);
  }
  /**
  * Create a chat model-specific prompt from individual chat messages
  * or message-like tuples.
  * @param promptMessages Messages to be passed to the chat model
  * @returns A new ChatPromptTemplate
  */
  static fromMessages(promptMessages, extra) {
    const flattenedMessages = promptMessages.reduce((acc, promptMessage) => acc.concat(promptMessage instanceof ChatPromptTemplate2 ? promptMessage.promptMessages : [_coerceMessagePromptTemplateLike(promptMessage, extra)]), []);
    const flattenedPartialVariables = promptMessages.reduce((acc, promptMessage) => promptMessage instanceof ChatPromptTemplate2 ? Object.assign(acc, promptMessage.partialVariables) : acc, /* @__PURE__ */ Object.create(null));
    const inputVariables = /* @__PURE__ */ new Set();
    for (const promptMessage of flattenedMessages) {
      if (promptMessage instanceof BaseMessage) continue;
      for (const inputVariable of promptMessage.inputVariables) {
        if (inputVariable in flattenedPartialVariables) continue;
        inputVariables.add(inputVariable);
      }
    }
    return new this({
      ...extra,
      inputVariables: [...inputVariables],
      promptMessages: flattenedMessages,
      partialVariables: flattenedPartialVariables,
      templateFormat: extra?.templateFormat
    });
  }
};

// node_modules/@langchain/core/dist/prompts/few_shot.js
var FewShotPromptTemplate = class FewShotPromptTemplate2 extends BaseStringPromptTemplate {
  lc_serializable = false;
  examples;
  exampleSelector;
  examplePrompt;
  suffix = "";
  exampleSeparator = "\n\n";
  prefix = "";
  templateFormat = "f-string";
  validateTemplate = true;
  constructor(input) {
    super(input);
    Object.assign(this, input);
    if (this.examples !== void 0 && this.exampleSelector !== void 0) throw new Error("Only one of 'examples' and 'example_selector' should be provided");
    if (this.examples === void 0 && this.exampleSelector === void 0) throw new Error("One of 'examples' and 'example_selector' should be provided");
    if (this.validateTemplate) {
      let totalInputVariables = this.inputVariables;
      if (this.partialVariables) totalInputVariables = totalInputVariables.concat(Object.keys(this.partialVariables));
      checkValidTemplate(this.prefix + this.suffix, this.templateFormat, totalInputVariables);
    }
  }
  _getPromptType() {
    return "few_shot";
  }
  static lc_name() {
    return "FewShotPromptTemplate";
  }
  async getExamples(inputVariables) {
    if (this.examples !== void 0) return this.examples;
    if (this.exampleSelector !== void 0) return this.exampleSelector.selectExamples(inputVariables);
    throw new Error("One of 'examples' and 'example_selector' should be provided");
  }
  async partial(values) {
    const newInputVariables = this.inputVariables.filter((iv) => !(iv in values));
    const newPartialVariables = {
      ...this.partialVariables ?? {},
      ...values
    };
    const promptDict = {
      ...this,
      inputVariables: newInputVariables,
      partialVariables: newPartialVariables
    };
    return new FewShotPromptTemplate2(promptDict);
  }
  /**
  * Formats the prompt with the given values.
  * @param values The values to format the prompt with.
  * @returns A promise that resolves to a string representing the formatted prompt.
  */
  async format(values) {
    const allValues = await this.mergePartialAndUserVariables(values);
    const examples = await this.getExamples(allValues);
    const exampleStrings = await Promise.all(examples.map((example) => this.examplePrompt.format(example)));
    const template = [
      this.prefix,
      ...exampleStrings,
      this.suffix
    ].join(this.exampleSeparator);
    return renderTemplate(template, this.templateFormat, allValues);
  }
  serialize() {
    if (this.exampleSelector || !this.examples) throw new Error("Serializing an example selector is not currently supported");
    if (this.outputParser !== void 0) throw new Error("Serializing an output parser is not currently supported");
    return {
      _type: this._getPromptType(),
      input_variables: this.inputVariables,
      example_prompt: this.examplePrompt.serialize(),
      example_separator: this.exampleSeparator,
      suffix: this.suffix,
      prefix: this.prefix,
      template_format: this.templateFormat,
      examples: this.examples
    };
  }
  static async deserialize(data) {
    const { example_prompt } = data;
    if (!example_prompt) throw new Error("Missing example prompt");
    const examplePrompt = await PromptTemplate.deserialize(example_prompt);
    let examples;
    if (Array.isArray(data.examples)) examples = data.examples;
    else throw new Error("Invalid examples format. Only list or string are supported.");
    return new FewShotPromptTemplate2({
      inputVariables: data.input_variables,
      examplePrompt,
      examples,
      exampleSeparator: data.example_separator,
      prefix: data.prefix,
      suffix: data.suffix,
      templateFormat: data.template_format
    });
  }
};
var FewShotChatMessagePromptTemplate = class FewShotChatMessagePromptTemplate2 extends BaseChatPromptTemplate {
  lc_serializable = true;
  examples;
  exampleSelector;
  examplePrompt;
  suffix = "";
  exampleSeparator = "\n\n";
  prefix = "";
  templateFormat = "f-string";
  validateTemplate = true;
  _getPromptType() {
    return "few_shot_chat";
  }
  static lc_name() {
    return "FewShotChatMessagePromptTemplate";
  }
  constructor(fields) {
    super(fields);
    this.examples = fields.examples;
    this.examplePrompt = fields.examplePrompt;
    this.exampleSeparator = fields.exampleSeparator ?? "\n\n";
    this.exampleSelector = fields.exampleSelector;
    this.prefix = fields.prefix ?? "";
    this.suffix = fields.suffix ?? "";
    this.templateFormat = fields.templateFormat ?? "f-string";
    this.validateTemplate = fields.validateTemplate ?? true;
    if (this.examples !== void 0 && this.exampleSelector !== void 0) throw new Error("Only one of 'examples' and 'example_selector' should be provided");
    if (this.examples === void 0 && this.exampleSelector === void 0) throw new Error("One of 'examples' and 'example_selector' should be provided");
    if (this.validateTemplate) {
      let totalInputVariables = this.inputVariables;
      if (this.partialVariables) totalInputVariables = totalInputVariables.concat(Object.keys(this.partialVariables));
      checkValidTemplate(this.prefix + this.suffix, this.templateFormat, totalInputVariables);
    }
  }
  async getExamples(inputVariables) {
    if (this.examples !== void 0) return this.examples;
    if (this.exampleSelector !== void 0) return this.exampleSelector.selectExamples(inputVariables);
    throw new Error("One of 'examples' and 'example_selector' should be provided");
  }
  /**
  * Formats the list of values and returns a list of formatted messages.
  * @param values The values to format the prompt with.
  * @returns A promise that resolves to a string representing the formatted prompt.
  */
  async formatMessages(values) {
    const allValues = await this.mergePartialAndUserVariables(values);
    let examples = await this.getExamples(allValues);
    examples = examples.map((example) => {
      const result = {};
      this.examplePrompt.inputVariables.forEach((inputVariable) => {
        result[inputVariable] = example[inputVariable];
      });
      return result;
    });
    const messages = [];
    for (const example of examples) {
      const exampleMessages = await this.examplePrompt.formatMessages(example);
      messages.push(...exampleMessages);
    }
    return messages;
  }
  /**
  * Formats the prompt with the given values.
  * @param values The values to format the prompt with.
  * @returns A promise that resolves to a string representing the formatted prompt.
  */
  async format(values) {
    const allValues = await this.mergePartialAndUserVariables(values);
    const examples = await this.getExamples(allValues);
    const exampleMessages = await Promise.all(examples.map((example) => this.examplePrompt.formatMessages(example)));
    const exampleStrings = exampleMessages.flat().map((message) => message.content);
    const template = [
      this.prefix,
      ...exampleStrings,
      this.suffix
    ].join(this.exampleSeparator);
    return renderTemplate(template, this.templateFormat, allValues);
  }
  /**
  * Partially formats the prompt with the given values.
  * @param values The values to partially format the prompt with.
  * @returns A promise that resolves to an instance of `FewShotChatMessagePromptTemplate` with the given values partially formatted.
  */
  async partial(values) {
    const newInputVariables = this.inputVariables.filter((variable) => !(variable in values));
    const newPartialVariables = {
      ...this.partialVariables ?? {},
      ...values
    };
    const promptDict = {
      ...this,
      inputVariables: newInputVariables,
      partialVariables: newPartialVariables
    };
    return new FewShotChatMessagePromptTemplate2(promptDict);
  }
};

// node_modules/@langchain/core/dist/prompts/pipeline.js
var PipelinePromptTemplate = class PipelinePromptTemplate2 extends BasePromptTemplate {
  static lc_name() {
    return "PipelinePromptTemplate";
  }
  pipelinePrompts;
  finalPrompt;
  constructor(input) {
    super({
      ...input,
      inputVariables: []
    });
    this.pipelinePrompts = input.pipelinePrompts;
    this.finalPrompt = input.finalPrompt;
    this.inputVariables = this.computeInputValues();
  }
  /**
  * Computes the input values required by the pipeline prompts.
  * @returns Array of input values required by the pipeline prompts.
  */
  computeInputValues() {
    const intermediateValues = this.pipelinePrompts.map((pipelinePrompt) => pipelinePrompt.name);
    const inputValues = this.pipelinePrompts.map((pipelinePrompt) => pipelinePrompt.prompt.inputVariables.filter((inputValue) => !intermediateValues.includes(inputValue))).flat();
    return [...new Set(inputValues)];
  }
  static extractRequiredInputValues(allValues, requiredValueNames) {
    return requiredValueNames.reduce((requiredValues, valueName) => {
      requiredValues[valueName] = allValues[valueName];
      return requiredValues;
    }, {});
  }
  /**
  * Formats the pipeline prompts based on the provided input values.
  * @param values Input values to format the pipeline prompts.
  * @returns Promise that resolves with the formatted input values.
  */
  async formatPipelinePrompts(values) {
    const allValues = await this.mergePartialAndUserVariables(values);
    for (const { name: pipelinePromptName, prompt: pipelinePrompt } of this.pipelinePrompts) {
      const pipelinePromptInputValues = PipelinePromptTemplate2.extractRequiredInputValues(allValues, pipelinePrompt.inputVariables);
      if (pipelinePrompt instanceof ChatPromptTemplate) allValues[pipelinePromptName] = await pipelinePrompt.formatMessages(pipelinePromptInputValues);
      else allValues[pipelinePromptName] = await pipelinePrompt.format(pipelinePromptInputValues);
    }
    return PipelinePromptTemplate2.extractRequiredInputValues(allValues, this.finalPrompt.inputVariables);
  }
  /**
  * Formats the final prompt value based on the provided input values.
  * @param values Input values to format the final prompt value.
  * @returns Promise that resolves with the formatted final prompt value.
  */
  async formatPromptValue(values) {
    return this.finalPrompt.formatPromptValue(await this.formatPipelinePrompts(values));
  }
  async format(values) {
    return this.finalPrompt.format(await this.formatPipelinePrompts(values));
  }
  /**
  * Handles partial prompts, which are prompts that have been partially
  * filled with input values.
  * @param values Partial input values.
  * @returns Promise that resolves with a new PipelinePromptTemplate instance with updated input variables.
  */
  async partial(values) {
    const promptDict = { ...this };
    promptDict.inputVariables = this.inputVariables.filter((iv) => !(iv in values));
    promptDict.partialVariables = {
      ...this.partialVariables ?? {},
      ...values
    };
    return new PipelinePromptTemplate2(promptDict);
  }
  serialize() {
    throw new Error("Not implemented.");
  }
  _getPromptType() {
    return "pipeline";
  }
};

// node_modules/@langchain/core/dist/prompts/structured.js
function isWithStructuredOutput(x) {
  return typeof x === "object" && x != null && "withStructuredOutput" in x && typeof x.withStructuredOutput === "function";
}
function isRunnableBinding(x) {
  return typeof x === "object" && x != null && "lc_id" in x && Array.isArray(x.lc_id) && x.lc_id.join("/") === "langchain_core/runnables/RunnableBinding";
}
var StructuredPrompt = class StructuredPrompt2 extends ChatPromptTemplate {
  schema;
  method;
  lc_namespace = [
    "langchain_core",
    "prompts",
    "structured"
  ];
  get lc_aliases() {
    return {
      ...super.lc_aliases,
      schema: "schema_"
    };
  }
  constructor(input) {
    super(input);
    this.schema = input.schema;
    this.method = input.method;
  }
  pipe(coerceable) {
    if (isWithStructuredOutput(coerceable)) return super.pipe(coerceable.withStructuredOutput(this.schema));
    if (isRunnableBinding(coerceable) && isWithStructuredOutput(coerceable.bound)) return super.pipe(new RunnableBinding({
      bound: coerceable.bound.withStructuredOutput(this.schema, ...this.method ? [{ method: this.method }] : []),
      kwargs: coerceable.kwargs ?? {},
      config: coerceable.config,
      configFactories: coerceable.configFactories
    }));
    throw new Error(`Structured prompts need to be piped to a language model that supports the "withStructuredOutput()" method.`);
  }
  static fromMessagesAndSchema(promptMessages, schema, method) {
    return StructuredPrompt2.fromMessages(promptMessages, {
      schema,
      method
    });
  }
};

// node_modules/@langchain/core/dist/prompts/index.js
var prompts_exports = {};
__export2(prompts_exports, {
  AIMessagePromptTemplate: () => AIMessagePromptTemplate,
  BaseChatPromptTemplate: () => BaseChatPromptTemplate,
  BaseMessagePromptTemplate: () => BaseMessagePromptTemplate,
  BaseMessageStringPromptTemplate: () => BaseMessageStringPromptTemplate,
  BasePromptTemplate: () => BasePromptTemplate,
  BaseStringPromptTemplate: () => BaseStringPromptTemplate,
  ChatMessagePromptTemplate: () => ChatMessagePromptTemplate,
  ChatPromptTemplate: () => ChatPromptTemplate,
  DEFAULT_FORMATTER_MAPPING: () => DEFAULT_FORMATTER_MAPPING,
  DEFAULT_PARSER_MAPPING: () => DEFAULT_PARSER_MAPPING,
  DictPromptTemplate: () => DictPromptTemplate,
  FewShotChatMessagePromptTemplate: () => FewShotChatMessagePromptTemplate,
  FewShotPromptTemplate: () => FewShotPromptTemplate,
  HumanMessagePromptTemplate: () => HumanMessagePromptTemplate,
  ImagePromptTemplate: () => ImagePromptTemplate,
  MessagesPlaceholder: () => MessagesPlaceholder,
  PipelinePromptTemplate: () => PipelinePromptTemplate,
  PromptTemplate: () => PromptTemplate,
  StructuredPrompt: () => StructuredPrompt,
  SystemMessagePromptTemplate: () => SystemMessagePromptTemplate,
  checkValidTemplate: () => checkValidTemplate,
  interpolateFString: () => interpolateFString,
  interpolateMustache: () => interpolateMustache,
  parseFString: () => parseFString,
  parseMustache: () => parseMustache,
  parseTemplate: () => parseTemplate2,
  renderTemplate: () => renderTemplate
});

// node_modules/@langchain/core/dist/retrievers/document_compressors/index.js
var document_compressors_exports = {};
__export2(document_compressors_exports, { BaseDocumentCompressor: () => BaseDocumentCompressor });
var BaseDocumentCompressor = class {
  static isBaseDocumentCompressor(x) {
    return x?.compressDocuments !== void 0;
  }
};

// node_modules/@langchain/core/dist/structured_query/ir.js
var Operators = {
  and: "and",
  or: "or",
  not: "not"
};
var Comparators = {
  eq: "eq",
  ne: "ne",
  lt: "lt",
  gt: "gt",
  lte: "lte",
  gte: "gte"
};
var Visitor = class {
};
var Expression = class {
  accept(visitor) {
    if (this.exprName === "Operation") return visitor.visitOperation(this);
    else if (this.exprName === "Comparison") return visitor.visitComparison(this);
    else if (this.exprName === "StructuredQuery") return visitor.visitStructuredQuery(this);
    else throw new Error("Unknown Expression type");
  }
};
var FilterDirective = class extends Expression {
};
var Comparison = class extends FilterDirective {
  exprName = "Comparison";
  constructor(comparator, attribute, value) {
    super();
    this.comparator = comparator;
    this.attribute = attribute;
    this.value = value;
  }
};
var Operation = class extends FilterDirective {
  exprName = "Operation";
  constructor(operator, args) {
    super();
    this.operator = operator;
    this.args = args;
  }
};
var StructuredQuery = class extends Expression {
  exprName = "StructuredQuery";
  constructor(query, filter) {
    super();
    this.query = query;
    this.filter = filter;
  }
};

// node_modules/@langchain/core/dist/structured_query/utils.js
function isObject(obj) {
  return obj && typeof obj === "object" && !Array.isArray(obj);
}
function isFilterEmpty(filter) {
  if (!filter) return true;
  if (typeof filter === "string" && filter.length > 0) return false;
  if (typeof filter === "function") return false;
  return isObject(filter) && Object.keys(filter).length === 0;
}
function isInt(value) {
  if (typeof value === "number") return value % 1 === 0;
  else if (typeof value === "string") {
    const numberValue = parseInt(value, 10);
    return !Number.isNaN(numberValue) && numberValue % 1 === 0 && numberValue.toString() === value;
  }
  return false;
}
function isFloat(value) {
  if (typeof value === "number") return value % 1 !== 0;
  else if (typeof value === "string") {
    const numberValue = parseFloat(value);
    return !Number.isNaN(numberValue) && numberValue % 1 !== 0 && numberValue.toString() === value;
  }
  return false;
}
function isString(value) {
  return typeof value === "string" && (Number.isNaN(parseFloat(value)) || parseFloat(value).toString() !== value);
}
function isBoolean(value) {
  return typeof value === "boolean";
}
function castValue(input) {
  let value;
  if (isString(input)) value = input;
  else if (isInt(input)) value = parseInt(input, 10);
  else if (isFloat(input)) value = parseFloat(input);
  else if (isBoolean(input)) value = Boolean(input);
  else throw new Error("Unsupported value type");
  return value;
}

// node_modules/@langchain/core/dist/structured_query/base.js
var BaseTranslator = class extends Visitor {
};
var BasicTranslator = class extends BaseTranslator {
  allowedOperators;
  allowedComparators;
  constructor(opts) {
    super();
    this.allowedOperators = opts?.allowedOperators ?? [Operators.and, Operators.or];
    this.allowedComparators = opts?.allowedComparators ?? [
      Comparators.eq,
      Comparators.ne,
      Comparators.gt,
      Comparators.gte,
      Comparators.lt,
      Comparators.lte
    ];
  }
  formatFunction(func) {
    if (func in Comparators) {
      if (this.allowedComparators.length > 0 && this.allowedComparators.indexOf(func) === -1) throw new Error(`Comparator ${func} not allowed. Allowed comparators: ${this.allowedComparators.join(", ")}`);
    } else if (func in Operators) {
      if (this.allowedOperators.length > 0 && this.allowedOperators.indexOf(func) === -1) throw new Error(`Operator ${func} not allowed. Allowed operators: ${this.allowedOperators.join(", ")}`);
    } else throw new Error("Unknown comparator or operator");
    return `$${func}`;
  }
  /**
  * Visits an operation and returns a result.
  * @param operation The operation to visit.
  * @returns The result of visiting the operation.
  */
  visitOperation(operation) {
    const args = operation.args?.map((arg) => arg.accept(this));
    return { [this.formatFunction(operation.operator)]: args };
  }
  /**
  * Visits a comparison and returns a result.
  * @param comparison The comparison to visit.
  * @returns The result of visiting the comparison.
  */
  visitComparison(comparison) {
    return { [comparison.attribute]: { [this.formatFunction(comparison.comparator)]: castValue(comparison.value) } };
  }
  /**
  * Visits a structured query and returns a result.
  * @param query The structured query to visit.
  * @returns The result of visiting the structured query.
  */
  visitStructuredQuery(query) {
    let nextArg = {};
    if (query.filter) nextArg = { filter: query.filter.accept(this) };
    return nextArg;
  }
  mergeFilters(defaultFilter, generatedFilter, mergeType = "and", forceDefaultFilter = false) {
    if (isFilterEmpty(defaultFilter) && isFilterEmpty(generatedFilter)) return void 0;
    if (isFilterEmpty(defaultFilter) || mergeType === "replace") {
      if (isFilterEmpty(generatedFilter)) return void 0;
      return generatedFilter;
    }
    if (isFilterEmpty(generatedFilter)) {
      if (forceDefaultFilter) return defaultFilter;
      if (mergeType === "and") return void 0;
      return defaultFilter;
    }
    if (mergeType === "and") return { $and: [defaultFilter, generatedFilter] };
    else if (mergeType === "or") return { $or: [defaultFilter, generatedFilter] };
    else throw new Error("Unknown merge type");
  }
};

// node_modules/@langchain/core/dist/structured_query/functional.js
var FunctionalTranslator = class extends BaseTranslator {
  allowedOperators = [Operators.and, Operators.or];
  allowedComparators = [
    Comparators.eq,
    Comparators.ne,
    Comparators.gt,
    Comparators.gte,
    Comparators.lt,
    Comparators.lte
  ];
  formatFunction() {
    throw new Error("Not implemented");
  }
  /**
  * Returns the allowed comparators for a given data type.
  * @param input The input value to get the allowed comparators for.
  * @returns An array of allowed comparators for the input data type.
  */
  getAllowedComparatorsForType(inputType) {
    switch (inputType) {
      case "string":
        return [
          Comparators.eq,
          Comparators.ne,
          Comparators.gt,
          Comparators.gte,
          Comparators.lt,
          Comparators.lte
        ];
      case "number":
        return [
          Comparators.eq,
          Comparators.ne,
          Comparators.gt,
          Comparators.gte,
          Comparators.lt,
          Comparators.lte
        ];
      case "boolean":
        return [Comparators.eq, Comparators.ne];
      default:
        throw new Error(`Unsupported data type: ${inputType}`);
    }
  }
  /**
  * Returns a function that performs a comparison based on the provided
  * comparator.
  * @param comparator The comparator to base the comparison function on.
  * @returns A function that takes two arguments and returns a boolean based on the comparison.
  */
  getComparatorFunction(comparator) {
    switch (comparator) {
      case Comparators.eq:
        return (a, b) => a === b;
      case Comparators.ne:
        return (a, b) => a !== b;
      case Comparators.gt:
        return (a, b) => a > b;
      case Comparators.gte:
        return (a, b) => a >= b;
      case Comparators.lt:
        return (a, b) => a < b;
      case Comparators.lte:
        return (a, b) => a <= b;
      default:
        throw new Error("Unknown comparator");
    }
  }
  /**
  * Returns a function that performs an operation based on the provided
  * operator.
  * @param operator The operator to base the operation function on.
  * @returns A function that takes two boolean arguments and returns a boolean based on the operation.
  */
  getOperatorFunction(operator) {
    switch (operator) {
      case Operators.and:
        return (a, b) => a && b;
      case Operators.or:
        return (a, b) => a || b;
      default:
        throw new Error("Unknown operator");
    }
  }
  /**
  * Visits the operation part of a structured query and translates it into
  * a functional filter.
  * @param operation The operation part of a structured query.
  * @returns A function that takes a `Document` as an argument and returns a boolean based on the operation.
  */
  visitOperation(operation) {
    const { operator, args } = operation;
    if (this.allowedOperators.includes(operator)) {
      const operatorFunction = this.getOperatorFunction(operator);
      return (document) => {
        if (!args) return true;
        return args.reduce((acc, arg) => {
          const result = arg.accept(this);
          if (typeof result === "function") return operatorFunction(acc, result(document));
          else throw new Error("Filter is not a function");
        }, true);
      };
    } else throw new Error("Operator not allowed");
  }
  /**
  * Visits the comparison part of a structured query and translates it into
  * a functional filter.
  * @param comparison The comparison part of a structured query.
  * @returns A function that takes a `Document` as an argument and returns a boolean based on the comparison.
  */
  visitComparison(comparison) {
    const { comparator, attribute, value } = comparison;
    const undefinedTrue = [Comparators.ne];
    if (this.allowedComparators.includes(comparator)) {
      if (!this.getAllowedComparatorsForType(typeof value).includes(comparator)) throw new Error(`'${comparator}' comparator not allowed to be used with ${typeof value}`);
      const comparatorFunction = this.getComparatorFunction(comparator);
      return (document) => {
        const documentValue = document.metadata[attribute];
        if (documentValue === void 0) {
          if (undefinedTrue.includes(comparator)) return true;
          return false;
        }
        return comparatorFunction(documentValue, castValue(value));
      };
    } else throw new Error("Comparator not allowed");
  }
  /**
  * Visits a structured query and translates it into a functional filter.
  * @param query The structured query to translate.
  * @returns An object containing a `filter` property, which is a function that takes a `Document` as an argument and returns a boolean based on the structured query.
  */
  visitStructuredQuery(query) {
    if (!query.filter) return {};
    const filterFunction = query.filter?.accept(this);
    if (typeof filterFunction !== "function") throw new Error("Structured query filter is not a function");
    return { filter: filterFunction };
  }
  /**
  * Merges two filters into one, based on the specified merge type.
  * @param defaultFilter The default filter function.
  * @param generatedFilter The generated filter function.
  * @param mergeType The type of merge to perform. Can be 'and', 'or', or 'replace'. Default is 'and'.
  * @returns A function that takes a `Document` as an argument and returns a boolean based on the merged filters, or `undefined` if both filters are empty.
  */
  mergeFilters(defaultFilter, generatedFilter, mergeType = "and") {
    if (isFilterEmpty(defaultFilter) && isFilterEmpty(generatedFilter)) return void 0;
    if (isFilterEmpty(defaultFilter) || mergeType === "replace") {
      if (isFilterEmpty(generatedFilter)) return void 0;
      return generatedFilter;
    }
    if (isFilterEmpty(generatedFilter)) {
      if (mergeType === "and") return void 0;
      return defaultFilter;
    }
    if (mergeType === "and") return (document) => defaultFilter(document) && generatedFilter(document);
    else if (mergeType === "or") return (document) => defaultFilter(document) || generatedFilter(document);
    else throw new Error("Unknown merge type");
  }
};

// node_modules/@langchain/core/dist/structured_query/index.js
var structured_query_exports = {};
__export2(structured_query_exports, {
  BaseTranslator: () => BaseTranslator,
  BasicTranslator: () => BasicTranslator,
  Comparators: () => Comparators,
  Comparison: () => Comparison,
  Expression: () => Expression,
  FilterDirective: () => FilterDirective,
  FunctionalTranslator: () => FunctionalTranslator,
  Operation: () => Operation,
  Operators: () => Operators,
  StructuredQuery: () => StructuredQuery,
  Visitor: () => Visitor,
  castValue: () => castValue,
  isBoolean: () => isBoolean,
  isFilterEmpty: () => isFilterEmpty,
  isFloat: () => isFloat,
  isInt: () => isInt,
  isObject: () => isObject,
  isString: () => isString
});

// node_modules/@langchain/core/dist/tools/types.js
function isStructuredTool(tool2) {
  return tool2 !== void 0 && Array.isArray(tool2.lc_namespace);
}
function isRunnableToolLike(tool2) {
  return tool2 !== void 0 && Runnable.isRunnable(tool2) && "lc_name" in tool2.constructor && typeof tool2.constructor.lc_name === "function" && tool2.constructor.lc_name() === "RunnableToolLike";
}
function isStructuredToolParams(tool2) {
  return !!tool2 && typeof tool2 === "object" && "name" in tool2 && "schema" in tool2 && (isInteropZodSchema(tool2.schema) || tool2.schema != null && typeof tool2.schema === "object" && "type" in tool2.schema && typeof tool2.schema.type === "string" && [
    "null",
    "boolean",
    "object",
    "array",
    "number",
    "string"
  ].includes(tool2.schema.type));
}
function isLangChainTool(tool2) {
  return isStructuredToolParams(tool2) || isRunnableToolLike(tool2) || isStructuredTool(tool2);
}

// node_modules/zod/v4/classic/external.js
var external_exports2 = {};
__export(external_exports2, {
  $brand: () => $brand,
  $input: () => $input,
  $output: () => $output,
  NEVER: () => NEVER,
  TimePrecision: () => TimePrecision,
  ZodAny: () => ZodAny,
  ZodArray: () => ZodArray,
  ZodBase64: () => ZodBase64,
  ZodBase64URL: () => ZodBase64URL,
  ZodBigInt: () => ZodBigInt,
  ZodBigIntFormat: () => ZodBigIntFormat,
  ZodBoolean: () => ZodBoolean,
  ZodCIDRv4: () => ZodCIDRv4,
  ZodCIDRv6: () => ZodCIDRv6,
  ZodCUID: () => ZodCUID,
  ZodCUID2: () => ZodCUID2,
  ZodCatch: () => ZodCatch,
  ZodCodec: () => ZodCodec,
  ZodCustom: () => ZodCustom,
  ZodCustomStringFormat: () => ZodCustomStringFormat,
  ZodDate: () => ZodDate,
  ZodDefault: () => ZodDefault,
  ZodDiscriminatedUnion: () => ZodDiscriminatedUnion,
  ZodE164: () => ZodE164,
  ZodEmail: () => ZodEmail,
  ZodEmoji: () => ZodEmoji,
  ZodEnum: () => ZodEnum,
  ZodError: () => ZodError,
  ZodExactOptional: () => ZodExactOptional,
  ZodFile: () => ZodFile,
  ZodFirstPartyTypeKind: () => ZodFirstPartyTypeKind,
  ZodFunction: () => ZodFunction,
  ZodGUID: () => ZodGUID,
  ZodIPv4: () => ZodIPv4,
  ZodIPv6: () => ZodIPv6,
  ZodISODate: () => ZodISODate,
  ZodISODateTime: () => ZodISODateTime,
  ZodISODuration: () => ZodISODuration,
  ZodISOTime: () => ZodISOTime,
  ZodIntersection: () => ZodIntersection,
  ZodIssueCode: () => ZodIssueCode,
  ZodJWT: () => ZodJWT,
  ZodKSUID: () => ZodKSUID,
  ZodLazy: () => ZodLazy,
  ZodLiteral: () => ZodLiteral,
  ZodMAC: () => ZodMAC,
  ZodMap: () => ZodMap,
  ZodNaN: () => ZodNaN,
  ZodNanoID: () => ZodNanoID,
  ZodNever: () => ZodNever,
  ZodNonOptional: () => ZodNonOptional,
  ZodNull: () => ZodNull,
  ZodNullable: () => ZodNullable,
  ZodNumber: () => ZodNumber,
  ZodNumberFormat: () => ZodNumberFormat,
  ZodObject: () => ZodObject,
  ZodOptional: () => ZodOptional,
  ZodPipe: () => ZodPipe,
  ZodPrefault: () => ZodPrefault,
  ZodPromise: () => ZodPromise,
  ZodReadonly: () => ZodReadonly,
  ZodRealError: () => ZodRealError,
  ZodRecord: () => ZodRecord,
  ZodSet: () => ZodSet,
  ZodString: () => ZodString,
  ZodStringFormat: () => ZodStringFormat,
  ZodSuccess: () => ZodSuccess,
  ZodSymbol: () => ZodSymbol,
  ZodTemplateLiteral: () => ZodTemplateLiteral,
  ZodTransform: () => ZodTransform,
  ZodTuple: () => ZodTuple,
  ZodType: () => ZodType,
  ZodULID: () => ZodULID,
  ZodURL: () => ZodURL,
  ZodUUID: () => ZodUUID,
  ZodUndefined: () => ZodUndefined,
  ZodUnion: () => ZodUnion,
  ZodUnknown: () => ZodUnknown,
  ZodVoid: () => ZodVoid,
  ZodXID: () => ZodXID,
  ZodXor: () => ZodXor,
  _ZodString: () => _ZodString,
  _default: () => _default,
  _function: () => _function,
  any: () => any,
  array: () => array,
  base64: () => base64,
  base64url: () => base64url,
  bigint: () => bigint,
  boolean: () => boolean,
  catch: () => _catch,
  check: () => check,
  cidrv4: () => cidrv4,
  cidrv6: () => cidrv6,
  clone: () => clone,
  codec: () => codec,
  coerce: () => coerce_exports,
  config: () => config,
  core: () => core_exports,
  cuid: () => cuid,
  cuid2: () => cuid2,
  custom: () => custom,
  date: () => date2,
  decode: () => decode,
  decodeAsync: () => decodeAsync,
  describe: () => describe2,
  discriminatedUnion: () => discriminatedUnion,
  e164: () => e164,
  email: () => email,
  emoji: () => emoji,
  encode: () => encode,
  encodeAsync: () => encodeAsync,
  endsWith: () => _endsWith,
  enum: () => _enum,
  exactOptional: () => exactOptional,
  file: () => file,
  flattenError: () => flattenError,
  float32: () => float32,
  float64: () => float64,
  formatError: () => formatError,
  fromJSONSchema: () => fromJSONSchema,
  function: () => _function,
  getErrorMap: () => getErrorMap,
  globalRegistry: () => globalRegistry,
  gt: () => _gt,
  gte: () => _gte,
  guid: () => guid,
  hash: () => hash,
  hex: () => hex,
  hostname: () => hostname,
  httpUrl: () => httpUrl,
  includes: () => _includes,
  instanceof: () => _instanceof,
  int: () => int,
  int32: () => int32,
  int64: () => int64,
  intersection: () => intersection,
  ipv4: () => ipv4,
  ipv6: () => ipv6,
  iso: () => iso_exports,
  json: () => json,
  jwt: () => jwt,
  keyof: () => keyof,
  ksuid: () => ksuid,
  lazy: () => lazy,
  length: () => _length,
  literal: () => literal,
  locales: () => locales_exports,
  looseObject: () => looseObject,
  looseRecord: () => looseRecord,
  lowercase: () => _lowercase,
  lt: () => _lt,
  lte: () => _lte,
  mac: () => mac,
  map: () => map,
  maxLength: () => _maxLength,
  maxSize: () => _maxSize,
  meta: () => meta2,
  mime: () => _mime,
  minLength: () => _minLength,
  minSize: () => _minSize,
  multipleOf: () => _multipleOf,
  nan: () => nan,
  nanoid: () => nanoid,
  nativeEnum: () => nativeEnum,
  negative: () => _negative,
  never: () => never,
  nonnegative: () => _nonnegative,
  nonoptional: () => nonoptional,
  nonpositive: () => _nonpositive,
  normalize: () => _normalize,
  null: () => _null2,
  nullable: () => nullable,
  nullish: () => nullish,
  number: () => number,
  object: () => object,
  optional: () => optional,
  overwrite: () => _overwrite,
  parse: () => parse3,
  parseAsync: () => parseAsync,
  partialRecord: () => partialRecord,
  pipe: () => pipe,
  positive: () => _positive,
  prefault: () => prefault,
  preprocess: () => preprocess,
  prettifyError: () => prettifyError,
  promise: () => promise,
  property: () => _property,
  readonly: () => readonly,
  record: () => record,
  refine: () => refine,
  regex: () => _regex,
  regexes: () => regexes_exports,
  registry: () => registry,
  safeDecode: () => safeDecode,
  safeDecodeAsync: () => safeDecodeAsync,
  safeEncode: () => safeEncode,
  safeEncodeAsync: () => safeEncodeAsync,
  safeParse: () => safeParse,
  safeParseAsync: () => safeParseAsync,
  set: () => set,
  setErrorMap: () => setErrorMap,
  size: () => _size,
  slugify: () => _slugify,
  startsWith: () => _startsWith,
  strictObject: () => strictObject,
  string: () => string,
  stringFormat: () => stringFormat,
  stringbool: () => stringbool,
  success: () => success,
  superRefine: () => superRefine,
  symbol: () => symbol,
  templateLiteral: () => templateLiteral,
  toJSONSchema: () => toJSONSchema,
  toLowerCase: () => _toLowerCase,
  toUpperCase: () => _toUpperCase,
  transform: () => transform,
  treeifyError: () => treeifyError,
  trim: () => _trim,
  tuple: () => tuple,
  uint32: () => uint32,
  uint64: () => uint64,
  ulid: () => ulid,
  undefined: () => _undefined2,
  union: () => union,
  unknown: () => unknown,
  uppercase: () => _uppercase,
  url: () => url,
  util: () => util_exports,
  uuid: () => uuid,
  uuidv4: () => uuidv4,
  uuidv6: () => uuidv6,
  uuidv7: () => uuidv7,
  void: () => _void2,
  xid: () => xid,
  xor: () => xor
});

// node_modules/zod/v4/classic/schemas.js
var schemas_exports = {};
__export(schemas_exports, {
  ZodAny: () => ZodAny,
  ZodArray: () => ZodArray,
  ZodBase64: () => ZodBase64,
  ZodBase64URL: () => ZodBase64URL,
  ZodBigInt: () => ZodBigInt,
  ZodBigIntFormat: () => ZodBigIntFormat,
  ZodBoolean: () => ZodBoolean,
  ZodCIDRv4: () => ZodCIDRv4,
  ZodCIDRv6: () => ZodCIDRv6,
  ZodCUID: () => ZodCUID,
  ZodCUID2: () => ZodCUID2,
  ZodCatch: () => ZodCatch,
  ZodCodec: () => ZodCodec,
  ZodCustom: () => ZodCustom,
  ZodCustomStringFormat: () => ZodCustomStringFormat,
  ZodDate: () => ZodDate,
  ZodDefault: () => ZodDefault,
  ZodDiscriminatedUnion: () => ZodDiscriminatedUnion,
  ZodE164: () => ZodE164,
  ZodEmail: () => ZodEmail,
  ZodEmoji: () => ZodEmoji,
  ZodEnum: () => ZodEnum,
  ZodExactOptional: () => ZodExactOptional,
  ZodFile: () => ZodFile,
  ZodFunction: () => ZodFunction,
  ZodGUID: () => ZodGUID,
  ZodIPv4: () => ZodIPv4,
  ZodIPv6: () => ZodIPv6,
  ZodIntersection: () => ZodIntersection,
  ZodJWT: () => ZodJWT,
  ZodKSUID: () => ZodKSUID,
  ZodLazy: () => ZodLazy,
  ZodLiteral: () => ZodLiteral,
  ZodMAC: () => ZodMAC,
  ZodMap: () => ZodMap,
  ZodNaN: () => ZodNaN,
  ZodNanoID: () => ZodNanoID,
  ZodNever: () => ZodNever,
  ZodNonOptional: () => ZodNonOptional,
  ZodNull: () => ZodNull,
  ZodNullable: () => ZodNullable,
  ZodNumber: () => ZodNumber,
  ZodNumberFormat: () => ZodNumberFormat,
  ZodObject: () => ZodObject,
  ZodOptional: () => ZodOptional,
  ZodPipe: () => ZodPipe,
  ZodPrefault: () => ZodPrefault,
  ZodPromise: () => ZodPromise,
  ZodReadonly: () => ZodReadonly,
  ZodRecord: () => ZodRecord,
  ZodSet: () => ZodSet,
  ZodString: () => ZodString,
  ZodStringFormat: () => ZodStringFormat,
  ZodSuccess: () => ZodSuccess,
  ZodSymbol: () => ZodSymbol,
  ZodTemplateLiteral: () => ZodTemplateLiteral,
  ZodTransform: () => ZodTransform,
  ZodTuple: () => ZodTuple,
  ZodType: () => ZodType,
  ZodULID: () => ZodULID,
  ZodURL: () => ZodURL,
  ZodUUID: () => ZodUUID,
  ZodUndefined: () => ZodUndefined,
  ZodUnion: () => ZodUnion,
  ZodUnknown: () => ZodUnknown,
  ZodVoid: () => ZodVoid,
  ZodXID: () => ZodXID,
  ZodXor: () => ZodXor,
  _ZodString: () => _ZodString,
  _default: () => _default,
  _function: () => _function,
  any: () => any,
  array: () => array,
  base64: () => base64,
  base64url: () => base64url,
  bigint: () => bigint,
  boolean: () => boolean,
  catch: () => _catch,
  check: () => check,
  cidrv4: () => cidrv4,
  cidrv6: () => cidrv6,
  codec: () => codec,
  cuid: () => cuid,
  cuid2: () => cuid2,
  custom: () => custom,
  date: () => date2,
  describe: () => describe2,
  discriminatedUnion: () => discriminatedUnion,
  e164: () => e164,
  email: () => email,
  emoji: () => emoji,
  enum: () => _enum,
  exactOptional: () => exactOptional,
  file: () => file,
  float32: () => float32,
  float64: () => float64,
  function: () => _function,
  guid: () => guid,
  hash: () => hash,
  hex: () => hex,
  hostname: () => hostname,
  httpUrl: () => httpUrl,
  instanceof: () => _instanceof,
  int: () => int,
  int32: () => int32,
  int64: () => int64,
  intersection: () => intersection,
  ipv4: () => ipv4,
  ipv6: () => ipv6,
  json: () => json,
  jwt: () => jwt,
  keyof: () => keyof,
  ksuid: () => ksuid,
  lazy: () => lazy,
  literal: () => literal,
  looseObject: () => looseObject,
  looseRecord: () => looseRecord,
  mac: () => mac,
  map: () => map,
  meta: () => meta2,
  nan: () => nan,
  nanoid: () => nanoid,
  nativeEnum: () => nativeEnum,
  never: () => never,
  nonoptional: () => nonoptional,
  null: () => _null2,
  nullable: () => nullable,
  nullish: () => nullish,
  number: () => number,
  object: () => object,
  optional: () => optional,
  partialRecord: () => partialRecord,
  pipe: () => pipe,
  prefault: () => prefault,
  preprocess: () => preprocess,
  promise: () => promise,
  readonly: () => readonly,
  record: () => record,
  refine: () => refine,
  set: () => set,
  strictObject: () => strictObject,
  string: () => string,
  stringFormat: () => stringFormat,
  stringbool: () => stringbool,
  success: () => success,
  superRefine: () => superRefine,
  symbol: () => symbol,
  templateLiteral: () => templateLiteral,
  transform: () => transform,
  tuple: () => tuple,
  uint32: () => uint32,
  uint64: () => uint64,
  ulid: () => ulid,
  undefined: () => _undefined2,
  union: () => union,
  unknown: () => unknown,
  url: () => url,
  uuid: () => uuid,
  uuidv4: () => uuidv4,
  uuidv6: () => uuidv6,
  uuidv7: () => uuidv7,
  void: () => _void2,
  xid: () => xid,
  xor: () => xor
});

// node_modules/zod/v4/classic/checks.js
var checks_exports = {};
__export(checks_exports, {
  endsWith: () => _endsWith,
  gt: () => _gt,
  gte: () => _gte,
  includes: () => _includes,
  length: () => _length,
  lowercase: () => _lowercase,
  lt: () => _lt,
  lte: () => _lte,
  maxLength: () => _maxLength,
  maxSize: () => _maxSize,
  mime: () => _mime,
  minLength: () => _minLength,
  minSize: () => _minSize,
  multipleOf: () => _multipleOf,
  negative: () => _negative,
  nonnegative: () => _nonnegative,
  nonpositive: () => _nonpositive,
  normalize: () => _normalize,
  overwrite: () => _overwrite,
  positive: () => _positive,
  property: () => _property,
  regex: () => _regex,
  size: () => _size,
  slugify: () => _slugify,
  startsWith: () => _startsWith,
  toLowerCase: () => _toLowerCase,
  toUpperCase: () => _toUpperCase,
  trim: () => _trim,
  uppercase: () => _uppercase
});

// node_modules/zod/v4/classic/iso.js
var iso_exports = {};
__export(iso_exports, {
  ZodISODate: () => ZodISODate,
  ZodISODateTime: () => ZodISODateTime,
  ZodISODuration: () => ZodISODuration,
  ZodISOTime: () => ZodISOTime,
  date: () => date,
  datetime: () => datetime,
  duration: () => duration,
  time: () => time
});
var ZodISODateTime = $constructor("ZodISODateTime", (inst, def) => {
  $ZodISODateTime.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function datetime(params) {
  return _isoDateTime(ZodISODateTime, params);
}
var ZodISODate = $constructor("ZodISODate", (inst, def) => {
  $ZodISODate.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function date(params) {
  return _isoDate(ZodISODate, params);
}
var ZodISOTime = $constructor("ZodISOTime", (inst, def) => {
  $ZodISOTime.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function time(params) {
  return _isoTime(ZodISOTime, params);
}
var ZodISODuration = $constructor("ZodISODuration", (inst, def) => {
  $ZodISODuration.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function duration(params) {
  return _isoDuration(ZodISODuration, params);
}

// node_modules/zod/v4/classic/errors.js
var initializer = (inst, issues) => {
  $ZodError.init(inst, issues);
  inst.name = "ZodError";
  Object.defineProperties(inst, {
    format: {
      value: (mapper) => formatError(inst, mapper)
      // enumerable: false,
    },
    flatten: {
      value: (mapper) => flattenError(inst, mapper)
      // enumerable: false,
    },
    addIssue: {
      value: (issue) => {
        inst.issues.push(issue);
        inst.message = JSON.stringify(inst.issues, jsonStringifyReplacer, 2);
      }
      // enumerable: false,
    },
    addIssues: {
      value: (issues2) => {
        inst.issues.push(...issues2);
        inst.message = JSON.stringify(inst.issues, jsonStringifyReplacer, 2);
      }
      // enumerable: false,
    },
    isEmpty: {
      get() {
        return inst.issues.length === 0;
      }
      // enumerable: false,
    }
  });
};
var ZodError = $constructor("ZodError", initializer);
var ZodRealError = $constructor("ZodError", initializer, {
  Parent: Error
});

// node_modules/zod/v4/classic/parse.js
var parse3 = _parse(ZodRealError);
var parseAsync = _parseAsync(ZodRealError);
var safeParse = _safeParse(ZodRealError);
var safeParseAsync = _safeParseAsync(ZodRealError);
var encode = _encode(ZodRealError);
var decode = _decode(ZodRealError);
var encodeAsync = _encodeAsync(ZodRealError);
var decodeAsync = _decodeAsync(ZodRealError);
var safeEncode = _safeEncode(ZodRealError);
var safeDecode = _safeDecode(ZodRealError);
var safeEncodeAsync = _safeEncodeAsync(ZodRealError);
var safeDecodeAsync = _safeDecodeAsync(ZodRealError);

// node_modules/zod/v4/classic/schemas.js
var ZodType = $constructor("ZodType", (inst, def) => {
  $ZodType.init(inst, def);
  Object.assign(inst["~standard"], {
    jsonSchema: {
      input: createStandardJSONSchemaMethod(inst, "input"),
      output: createStandardJSONSchemaMethod(inst, "output")
    }
  });
  inst.toJSONSchema = createToJSONSchemaMethod(inst, {});
  inst.def = def;
  inst.type = def.type;
  Object.defineProperty(inst, "_def", { value: def });
  inst.check = (...checks) => {
    return inst.clone(util_exports.mergeDefs(def, {
      checks: [
        ...def.checks ?? [],
        ...checks.map((ch) => typeof ch === "function" ? { _zod: { check: ch, def: { check: "custom" }, onattach: [] } } : ch)
      ]
    }), {
      parent: true
    });
  };
  inst.with = inst.check;
  inst.clone = (def2, params) => clone(inst, def2, params);
  inst.brand = () => inst;
  inst.register = ((reg, meta3) => {
    reg.add(inst, meta3);
    return inst;
  });
  inst.parse = (data, params) => parse3(inst, data, params, { callee: inst.parse });
  inst.safeParse = (data, params) => safeParse(inst, data, params);
  inst.parseAsync = async (data, params) => parseAsync(inst, data, params, { callee: inst.parseAsync });
  inst.safeParseAsync = async (data, params) => safeParseAsync(inst, data, params);
  inst.spa = inst.safeParseAsync;
  inst.encode = (data, params) => encode(inst, data, params);
  inst.decode = (data, params) => decode(inst, data, params);
  inst.encodeAsync = async (data, params) => encodeAsync(inst, data, params);
  inst.decodeAsync = async (data, params) => decodeAsync(inst, data, params);
  inst.safeEncode = (data, params) => safeEncode(inst, data, params);
  inst.safeDecode = (data, params) => safeDecode(inst, data, params);
  inst.safeEncodeAsync = async (data, params) => safeEncodeAsync(inst, data, params);
  inst.safeDecodeAsync = async (data, params) => safeDecodeAsync(inst, data, params);
  inst.refine = (check2, params) => inst.check(refine(check2, params));
  inst.superRefine = (refinement) => inst.check(superRefine(refinement));
  inst.overwrite = (fn) => inst.check(_overwrite(fn));
  inst.optional = () => optional(inst);
  inst.exactOptional = () => exactOptional(inst);
  inst.nullable = () => nullable(inst);
  inst.nullish = () => optional(nullable(inst));
  inst.nonoptional = (params) => nonoptional(inst, params);
  inst.array = () => array(inst);
  inst.or = (arg) => union([inst, arg]);
  inst.and = (arg) => intersection(inst, arg);
  inst.transform = (tx) => pipe(inst, transform(tx));
  inst.default = (def2) => _default(inst, def2);
  inst.prefault = (def2) => prefault(inst, def2);
  inst.catch = (params) => _catch(inst, params);
  inst.pipe = (target) => pipe(inst, target);
  inst.readonly = () => readonly(inst);
  inst.describe = (description) => {
    const cl = inst.clone();
    globalRegistry.add(cl, { description });
    return cl;
  };
  Object.defineProperty(inst, "description", {
    get() {
      return globalRegistry.get(inst)?.description;
    },
    configurable: true
  });
  inst.meta = (...args) => {
    if (args.length === 0) {
      return globalRegistry.get(inst);
    }
    const cl = inst.clone();
    globalRegistry.add(cl, args[0]);
    return cl;
  };
  inst.isOptional = () => inst.safeParse(void 0).success;
  inst.isNullable = () => inst.safeParse(null).success;
  inst.apply = (fn) => fn(inst);
  return inst;
});
var _ZodString = $constructor("_ZodString", (inst, def) => {
  $ZodString.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => stringProcessor(inst, ctx, json2, params);
  const bag = inst._zod.bag;
  inst.format = bag.format ?? null;
  inst.minLength = bag.minimum ?? null;
  inst.maxLength = bag.maximum ?? null;
  inst.regex = (...args) => inst.check(_regex(...args));
  inst.includes = (...args) => inst.check(_includes(...args));
  inst.startsWith = (...args) => inst.check(_startsWith(...args));
  inst.endsWith = (...args) => inst.check(_endsWith(...args));
  inst.min = (...args) => inst.check(_minLength(...args));
  inst.max = (...args) => inst.check(_maxLength(...args));
  inst.length = (...args) => inst.check(_length(...args));
  inst.nonempty = (...args) => inst.check(_minLength(1, ...args));
  inst.lowercase = (params) => inst.check(_lowercase(params));
  inst.uppercase = (params) => inst.check(_uppercase(params));
  inst.trim = () => inst.check(_trim());
  inst.normalize = (...args) => inst.check(_normalize(...args));
  inst.toLowerCase = () => inst.check(_toLowerCase());
  inst.toUpperCase = () => inst.check(_toUpperCase());
  inst.slugify = () => inst.check(_slugify());
});
var ZodString = $constructor("ZodString", (inst, def) => {
  $ZodString.init(inst, def);
  _ZodString.init(inst, def);
  inst.email = (params) => inst.check(_email(ZodEmail, params));
  inst.url = (params) => inst.check(_url(ZodURL, params));
  inst.jwt = (params) => inst.check(_jwt(ZodJWT, params));
  inst.emoji = (params) => inst.check(_emoji(ZodEmoji, params));
  inst.guid = (params) => inst.check(_guid(ZodGUID, params));
  inst.uuid = (params) => inst.check(_uuid(ZodUUID, params));
  inst.uuidv4 = (params) => inst.check(_uuidv4(ZodUUID, params));
  inst.uuidv6 = (params) => inst.check(_uuidv6(ZodUUID, params));
  inst.uuidv7 = (params) => inst.check(_uuidv7(ZodUUID, params));
  inst.nanoid = (params) => inst.check(_nanoid(ZodNanoID, params));
  inst.guid = (params) => inst.check(_guid(ZodGUID, params));
  inst.cuid = (params) => inst.check(_cuid(ZodCUID, params));
  inst.cuid2 = (params) => inst.check(_cuid2(ZodCUID2, params));
  inst.ulid = (params) => inst.check(_ulid(ZodULID, params));
  inst.base64 = (params) => inst.check(_base64(ZodBase64, params));
  inst.base64url = (params) => inst.check(_base64url(ZodBase64URL, params));
  inst.xid = (params) => inst.check(_xid(ZodXID, params));
  inst.ksuid = (params) => inst.check(_ksuid(ZodKSUID, params));
  inst.ipv4 = (params) => inst.check(_ipv4(ZodIPv4, params));
  inst.ipv6 = (params) => inst.check(_ipv6(ZodIPv6, params));
  inst.cidrv4 = (params) => inst.check(_cidrv4(ZodCIDRv4, params));
  inst.cidrv6 = (params) => inst.check(_cidrv6(ZodCIDRv6, params));
  inst.e164 = (params) => inst.check(_e164(ZodE164, params));
  inst.datetime = (params) => inst.check(datetime(params));
  inst.date = (params) => inst.check(date(params));
  inst.time = (params) => inst.check(time(params));
  inst.duration = (params) => inst.check(duration(params));
});
function string(params) {
  return _string(ZodString, params);
}
var ZodStringFormat = $constructor("ZodStringFormat", (inst, def) => {
  $ZodStringFormat.init(inst, def);
  _ZodString.init(inst, def);
});
var ZodEmail = $constructor("ZodEmail", (inst, def) => {
  $ZodEmail.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function email(params) {
  return _email(ZodEmail, params);
}
var ZodGUID = $constructor("ZodGUID", (inst, def) => {
  $ZodGUID.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function guid(params) {
  return _guid(ZodGUID, params);
}
var ZodUUID = $constructor("ZodUUID", (inst, def) => {
  $ZodUUID.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function uuid(params) {
  return _uuid(ZodUUID, params);
}
function uuidv4(params) {
  return _uuidv4(ZodUUID, params);
}
function uuidv6(params) {
  return _uuidv6(ZodUUID, params);
}
function uuidv7(params) {
  return _uuidv7(ZodUUID, params);
}
var ZodURL = $constructor("ZodURL", (inst, def) => {
  $ZodURL.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function url(params) {
  return _url(ZodURL, params);
}
function httpUrl(params) {
  return _url(ZodURL, {
    protocol: /^https?$/,
    hostname: regexes_exports.domain,
    ...util_exports.normalizeParams(params)
  });
}
var ZodEmoji = $constructor("ZodEmoji", (inst, def) => {
  $ZodEmoji.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function emoji(params) {
  return _emoji(ZodEmoji, params);
}
var ZodNanoID = $constructor("ZodNanoID", (inst, def) => {
  $ZodNanoID.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function nanoid(params) {
  return _nanoid(ZodNanoID, params);
}
var ZodCUID = $constructor("ZodCUID", (inst, def) => {
  $ZodCUID.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function cuid(params) {
  return _cuid(ZodCUID, params);
}
var ZodCUID2 = $constructor("ZodCUID2", (inst, def) => {
  $ZodCUID2.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function cuid2(params) {
  return _cuid2(ZodCUID2, params);
}
var ZodULID = $constructor("ZodULID", (inst, def) => {
  $ZodULID.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function ulid(params) {
  return _ulid(ZodULID, params);
}
var ZodXID = $constructor("ZodXID", (inst, def) => {
  $ZodXID.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function xid(params) {
  return _xid(ZodXID, params);
}
var ZodKSUID = $constructor("ZodKSUID", (inst, def) => {
  $ZodKSUID.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function ksuid(params) {
  return _ksuid(ZodKSUID, params);
}
var ZodIPv4 = $constructor("ZodIPv4", (inst, def) => {
  $ZodIPv4.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function ipv4(params) {
  return _ipv4(ZodIPv4, params);
}
var ZodMAC = $constructor("ZodMAC", (inst, def) => {
  $ZodMAC.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function mac(params) {
  return _mac(ZodMAC, params);
}
var ZodIPv6 = $constructor("ZodIPv6", (inst, def) => {
  $ZodIPv6.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function ipv6(params) {
  return _ipv6(ZodIPv6, params);
}
var ZodCIDRv4 = $constructor("ZodCIDRv4", (inst, def) => {
  $ZodCIDRv4.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function cidrv4(params) {
  return _cidrv4(ZodCIDRv4, params);
}
var ZodCIDRv6 = $constructor("ZodCIDRv6", (inst, def) => {
  $ZodCIDRv6.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function cidrv6(params) {
  return _cidrv6(ZodCIDRv6, params);
}
var ZodBase64 = $constructor("ZodBase64", (inst, def) => {
  $ZodBase64.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function base64(params) {
  return _base64(ZodBase64, params);
}
var ZodBase64URL = $constructor("ZodBase64URL", (inst, def) => {
  $ZodBase64URL.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function base64url(params) {
  return _base64url(ZodBase64URL, params);
}
var ZodE164 = $constructor("ZodE164", (inst, def) => {
  $ZodE164.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function e164(params) {
  return _e164(ZodE164, params);
}
var ZodJWT = $constructor("ZodJWT", (inst, def) => {
  $ZodJWT.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function jwt(params) {
  return _jwt(ZodJWT, params);
}
var ZodCustomStringFormat = $constructor("ZodCustomStringFormat", (inst, def) => {
  $ZodCustomStringFormat.init(inst, def);
  ZodStringFormat.init(inst, def);
});
function stringFormat(format, fnOrRegex, _params = {}) {
  return _stringFormat(ZodCustomStringFormat, format, fnOrRegex, _params);
}
function hostname(_params) {
  return _stringFormat(ZodCustomStringFormat, "hostname", regexes_exports.hostname, _params);
}
function hex(_params) {
  return _stringFormat(ZodCustomStringFormat, "hex", regexes_exports.hex, _params);
}
function hash(alg, params) {
  const enc = params?.enc ?? "hex";
  const format = `${alg}_${enc}`;
  const regex = regexes_exports[format];
  if (!regex)
    throw new Error(`Unrecognized hash format: ${format}`);
  return _stringFormat(ZodCustomStringFormat, format, regex, params);
}
var ZodNumber = $constructor("ZodNumber", (inst, def) => {
  $ZodNumber.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => numberProcessor(inst, ctx, json2, params);
  inst.gt = (value, params) => inst.check(_gt(value, params));
  inst.gte = (value, params) => inst.check(_gte(value, params));
  inst.min = (value, params) => inst.check(_gte(value, params));
  inst.lt = (value, params) => inst.check(_lt(value, params));
  inst.lte = (value, params) => inst.check(_lte(value, params));
  inst.max = (value, params) => inst.check(_lte(value, params));
  inst.int = (params) => inst.check(int(params));
  inst.safe = (params) => inst.check(int(params));
  inst.positive = (params) => inst.check(_gt(0, params));
  inst.nonnegative = (params) => inst.check(_gte(0, params));
  inst.negative = (params) => inst.check(_lt(0, params));
  inst.nonpositive = (params) => inst.check(_lte(0, params));
  inst.multipleOf = (value, params) => inst.check(_multipleOf(value, params));
  inst.step = (value, params) => inst.check(_multipleOf(value, params));
  inst.finite = () => inst;
  const bag = inst._zod.bag;
  inst.minValue = Math.max(bag.minimum ?? Number.NEGATIVE_INFINITY, bag.exclusiveMinimum ?? Number.NEGATIVE_INFINITY) ?? null;
  inst.maxValue = Math.min(bag.maximum ?? Number.POSITIVE_INFINITY, bag.exclusiveMaximum ?? Number.POSITIVE_INFINITY) ?? null;
  inst.isInt = (bag.format ?? "").includes("int") || Number.isSafeInteger(bag.multipleOf ?? 0.5);
  inst.isFinite = true;
  inst.format = bag.format ?? null;
});
function number(params) {
  return _number(ZodNumber, params);
}
var ZodNumberFormat = $constructor("ZodNumberFormat", (inst, def) => {
  $ZodNumberFormat.init(inst, def);
  ZodNumber.init(inst, def);
});
function int(params) {
  return _int(ZodNumberFormat, params);
}
function float32(params) {
  return _float32(ZodNumberFormat, params);
}
function float64(params) {
  return _float64(ZodNumberFormat, params);
}
function int32(params) {
  return _int32(ZodNumberFormat, params);
}
function uint32(params) {
  return _uint32(ZodNumberFormat, params);
}
var ZodBoolean = $constructor("ZodBoolean", (inst, def) => {
  $ZodBoolean.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => booleanProcessor(inst, ctx, json2, params);
});
function boolean(params) {
  return _boolean(ZodBoolean, params);
}
var ZodBigInt = $constructor("ZodBigInt", (inst, def) => {
  $ZodBigInt.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => bigintProcessor(inst, ctx, json2, params);
  inst.gte = (value, params) => inst.check(_gte(value, params));
  inst.min = (value, params) => inst.check(_gte(value, params));
  inst.gt = (value, params) => inst.check(_gt(value, params));
  inst.gte = (value, params) => inst.check(_gte(value, params));
  inst.min = (value, params) => inst.check(_gte(value, params));
  inst.lt = (value, params) => inst.check(_lt(value, params));
  inst.lte = (value, params) => inst.check(_lte(value, params));
  inst.max = (value, params) => inst.check(_lte(value, params));
  inst.positive = (params) => inst.check(_gt(BigInt(0), params));
  inst.negative = (params) => inst.check(_lt(BigInt(0), params));
  inst.nonpositive = (params) => inst.check(_lte(BigInt(0), params));
  inst.nonnegative = (params) => inst.check(_gte(BigInt(0), params));
  inst.multipleOf = (value, params) => inst.check(_multipleOf(value, params));
  const bag = inst._zod.bag;
  inst.minValue = bag.minimum ?? null;
  inst.maxValue = bag.maximum ?? null;
  inst.format = bag.format ?? null;
});
function bigint(params) {
  return _bigint(ZodBigInt, params);
}
var ZodBigIntFormat = $constructor("ZodBigIntFormat", (inst, def) => {
  $ZodBigIntFormat.init(inst, def);
  ZodBigInt.init(inst, def);
});
function int64(params) {
  return _int64(ZodBigIntFormat, params);
}
function uint64(params) {
  return _uint64(ZodBigIntFormat, params);
}
var ZodSymbol = $constructor("ZodSymbol", (inst, def) => {
  $ZodSymbol.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => symbolProcessor(inst, ctx, json2, params);
});
function symbol(params) {
  return _symbol(ZodSymbol, params);
}
var ZodUndefined = $constructor("ZodUndefined", (inst, def) => {
  $ZodUndefined.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => undefinedProcessor(inst, ctx, json2, params);
});
function _undefined2(params) {
  return _undefined(ZodUndefined, params);
}
var ZodNull = $constructor("ZodNull", (inst, def) => {
  $ZodNull.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => nullProcessor(inst, ctx, json2, params);
});
function _null2(params) {
  return _null(ZodNull, params);
}
var ZodAny = $constructor("ZodAny", (inst, def) => {
  $ZodAny.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => anyProcessor(inst, ctx, json2, params);
});
function any() {
  return _any(ZodAny);
}
var ZodUnknown = $constructor("ZodUnknown", (inst, def) => {
  $ZodUnknown.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => unknownProcessor(inst, ctx, json2, params);
});
function unknown() {
  return _unknown(ZodUnknown);
}
var ZodNever = $constructor("ZodNever", (inst, def) => {
  $ZodNever.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => neverProcessor(inst, ctx, json2, params);
});
function never(params) {
  return _never(ZodNever, params);
}
var ZodVoid = $constructor("ZodVoid", (inst, def) => {
  $ZodVoid.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => voidProcessor(inst, ctx, json2, params);
});
function _void2(params) {
  return _void(ZodVoid, params);
}
var ZodDate = $constructor("ZodDate", (inst, def) => {
  $ZodDate.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => dateProcessor(inst, ctx, json2, params);
  inst.min = (value, params) => inst.check(_gte(value, params));
  inst.max = (value, params) => inst.check(_lte(value, params));
  const c = inst._zod.bag;
  inst.minDate = c.minimum ? new Date(c.minimum) : null;
  inst.maxDate = c.maximum ? new Date(c.maximum) : null;
});
function date2(params) {
  return _date(ZodDate, params);
}
var ZodArray = $constructor("ZodArray", (inst, def) => {
  $ZodArray.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => arrayProcessor(inst, ctx, json2, params);
  inst.element = def.element;
  inst.min = (minLength, params) => inst.check(_minLength(minLength, params));
  inst.nonempty = (params) => inst.check(_minLength(1, params));
  inst.max = (maxLength, params) => inst.check(_maxLength(maxLength, params));
  inst.length = (len, params) => inst.check(_length(len, params));
  inst.unwrap = () => inst.element;
});
function array(element, params) {
  return _array(ZodArray, element, params);
}
function keyof(schema) {
  const shape = schema._zod.def.shape;
  return _enum(Object.keys(shape));
}
var ZodObject = $constructor("ZodObject", (inst, def) => {
  $ZodObjectJIT.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => objectProcessor(inst, ctx, json2, params);
  util_exports.defineLazy(inst, "shape", () => {
    return def.shape;
  });
  inst.keyof = () => _enum(Object.keys(inst._zod.def.shape));
  inst.catchall = (catchall) => inst.clone({ ...inst._zod.def, catchall });
  inst.passthrough = () => inst.clone({ ...inst._zod.def, catchall: unknown() });
  inst.loose = () => inst.clone({ ...inst._zod.def, catchall: unknown() });
  inst.strict = () => inst.clone({ ...inst._zod.def, catchall: never() });
  inst.strip = () => inst.clone({ ...inst._zod.def, catchall: void 0 });
  inst.extend = (incoming) => {
    return util_exports.extend(inst, incoming);
  };
  inst.safeExtend = (incoming) => {
    return util_exports.safeExtend(inst, incoming);
  };
  inst.merge = (other) => util_exports.merge(inst, other);
  inst.pick = (mask) => util_exports.pick(inst, mask);
  inst.omit = (mask) => util_exports.omit(inst, mask);
  inst.partial = (...args) => util_exports.partial(ZodOptional, inst, args[0]);
  inst.required = (...args) => util_exports.required(ZodNonOptional, inst, args[0]);
});
function object(shape, params) {
  const def = {
    type: "object",
    shape: shape ?? {},
    ...util_exports.normalizeParams(params)
  };
  return new ZodObject(def);
}
function strictObject(shape, params) {
  return new ZodObject({
    type: "object",
    shape,
    catchall: never(),
    ...util_exports.normalizeParams(params)
  });
}
function looseObject(shape, params) {
  return new ZodObject({
    type: "object",
    shape,
    catchall: unknown(),
    ...util_exports.normalizeParams(params)
  });
}
var ZodUnion = $constructor("ZodUnion", (inst, def) => {
  $ZodUnion.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => unionProcessor(inst, ctx, json2, params);
  inst.options = def.options;
});
function union(options, params) {
  return new ZodUnion({
    type: "union",
    options,
    ...util_exports.normalizeParams(params)
  });
}
var ZodXor = $constructor("ZodXor", (inst, def) => {
  ZodUnion.init(inst, def);
  $ZodXor.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => unionProcessor(inst, ctx, json2, params);
  inst.options = def.options;
});
function xor(options, params) {
  return new ZodXor({
    type: "union",
    options,
    inclusive: false,
    ...util_exports.normalizeParams(params)
  });
}
var ZodDiscriminatedUnion = $constructor("ZodDiscriminatedUnion", (inst, def) => {
  ZodUnion.init(inst, def);
  $ZodDiscriminatedUnion.init(inst, def);
});
function discriminatedUnion(discriminator, options, params) {
  return new ZodDiscriminatedUnion({
    type: "union",
    options,
    discriminator,
    ...util_exports.normalizeParams(params)
  });
}
var ZodIntersection = $constructor("ZodIntersection", (inst, def) => {
  $ZodIntersection.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => intersectionProcessor(inst, ctx, json2, params);
});
function intersection(left, right) {
  return new ZodIntersection({
    type: "intersection",
    left,
    right
  });
}
var ZodTuple = $constructor("ZodTuple", (inst, def) => {
  $ZodTuple.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => tupleProcessor(inst, ctx, json2, params);
  inst.rest = (rest) => inst.clone({
    ...inst._zod.def,
    rest
  });
});
function tuple(items, _paramsOrRest, _params) {
  const hasRest = _paramsOrRest instanceof $ZodType;
  const params = hasRest ? _params : _paramsOrRest;
  const rest = hasRest ? _paramsOrRest : null;
  return new ZodTuple({
    type: "tuple",
    items,
    rest,
    ...util_exports.normalizeParams(params)
  });
}
var ZodRecord = $constructor("ZodRecord", (inst, def) => {
  $ZodRecord.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => recordProcessor(inst, ctx, json2, params);
  inst.keyType = def.keyType;
  inst.valueType = def.valueType;
});
function record(keyType, valueType, params) {
  return new ZodRecord({
    type: "record",
    keyType,
    valueType,
    ...util_exports.normalizeParams(params)
  });
}
function partialRecord(keyType, valueType, params) {
  const k = clone(keyType);
  k._zod.values = void 0;
  return new ZodRecord({
    type: "record",
    keyType: k,
    valueType,
    ...util_exports.normalizeParams(params)
  });
}
function looseRecord(keyType, valueType, params) {
  return new ZodRecord({
    type: "record",
    keyType,
    valueType,
    mode: "loose",
    ...util_exports.normalizeParams(params)
  });
}
var ZodMap = $constructor("ZodMap", (inst, def) => {
  $ZodMap.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => mapProcessor(inst, ctx, json2, params);
  inst.keyType = def.keyType;
  inst.valueType = def.valueType;
  inst.min = (...args) => inst.check(_minSize(...args));
  inst.nonempty = (params) => inst.check(_minSize(1, params));
  inst.max = (...args) => inst.check(_maxSize(...args));
  inst.size = (...args) => inst.check(_size(...args));
});
function map(keyType, valueType, params) {
  return new ZodMap({
    type: "map",
    keyType,
    valueType,
    ...util_exports.normalizeParams(params)
  });
}
var ZodSet = $constructor("ZodSet", (inst, def) => {
  $ZodSet.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => setProcessor(inst, ctx, json2, params);
  inst.min = (...args) => inst.check(_minSize(...args));
  inst.nonempty = (params) => inst.check(_minSize(1, params));
  inst.max = (...args) => inst.check(_maxSize(...args));
  inst.size = (...args) => inst.check(_size(...args));
});
function set(valueType, params) {
  return new ZodSet({
    type: "set",
    valueType,
    ...util_exports.normalizeParams(params)
  });
}
var ZodEnum = $constructor("ZodEnum", (inst, def) => {
  $ZodEnum.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => enumProcessor(inst, ctx, json2, params);
  inst.enum = def.entries;
  inst.options = Object.values(def.entries);
  const keys = new Set(Object.keys(def.entries));
  inst.extract = (values, params) => {
    const newEntries = {};
    for (const value of values) {
      if (keys.has(value)) {
        newEntries[value] = def.entries[value];
      } else
        throw new Error(`Key ${value} not found in enum`);
    }
    return new ZodEnum({
      ...def,
      checks: [],
      ...util_exports.normalizeParams(params),
      entries: newEntries
    });
  };
  inst.exclude = (values, params) => {
    const newEntries = { ...def.entries };
    for (const value of values) {
      if (keys.has(value)) {
        delete newEntries[value];
      } else
        throw new Error(`Key ${value} not found in enum`);
    }
    return new ZodEnum({
      ...def,
      checks: [],
      ...util_exports.normalizeParams(params),
      entries: newEntries
    });
  };
});
function _enum(values, params) {
  const entries = Array.isArray(values) ? Object.fromEntries(values.map((v) => [v, v])) : values;
  return new ZodEnum({
    type: "enum",
    entries,
    ...util_exports.normalizeParams(params)
  });
}
function nativeEnum(entries, params) {
  return new ZodEnum({
    type: "enum",
    entries,
    ...util_exports.normalizeParams(params)
  });
}
var ZodLiteral = $constructor("ZodLiteral", (inst, def) => {
  $ZodLiteral.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => literalProcessor(inst, ctx, json2, params);
  inst.values = new Set(def.values);
  Object.defineProperty(inst, "value", {
    get() {
      if (def.values.length > 1) {
        throw new Error("This schema contains multiple valid literal values. Use `.values` instead.");
      }
      return def.values[0];
    }
  });
});
function literal(value, params) {
  return new ZodLiteral({
    type: "literal",
    values: Array.isArray(value) ? value : [value],
    ...util_exports.normalizeParams(params)
  });
}
var ZodFile = $constructor("ZodFile", (inst, def) => {
  $ZodFile.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => fileProcessor(inst, ctx, json2, params);
  inst.min = (size, params) => inst.check(_minSize(size, params));
  inst.max = (size, params) => inst.check(_maxSize(size, params));
  inst.mime = (types, params) => inst.check(_mime(Array.isArray(types) ? types : [types], params));
});
function file(params) {
  return _file(ZodFile, params);
}
var ZodTransform = $constructor("ZodTransform", (inst, def) => {
  $ZodTransform.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => transformProcessor(inst, ctx, json2, params);
  inst._zod.parse = (payload, _ctx) => {
    if (_ctx.direction === "backward") {
      throw new $ZodEncodeError(inst.constructor.name);
    }
    payload.addIssue = (issue) => {
      if (typeof issue === "string") {
        payload.issues.push(util_exports.issue(issue, payload.value, def));
      } else {
        const _issue = issue;
        if (_issue.fatal)
          _issue.continue = false;
        _issue.code ?? (_issue.code = "custom");
        _issue.input ?? (_issue.input = payload.value);
        _issue.inst ?? (_issue.inst = inst);
        payload.issues.push(util_exports.issue(_issue));
      }
    };
    const output = def.transform(payload.value, payload);
    if (output instanceof Promise) {
      return output.then((output2) => {
        payload.value = output2;
        return payload;
      });
    }
    payload.value = output;
    return payload;
  };
});
function transform(fn) {
  return new ZodTransform({
    type: "transform",
    transform: fn
  });
}
var ZodOptional = $constructor("ZodOptional", (inst, def) => {
  $ZodOptional.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => optionalProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
});
function optional(innerType) {
  return new ZodOptional({
    type: "optional",
    innerType
  });
}
var ZodExactOptional = $constructor("ZodExactOptional", (inst, def) => {
  $ZodExactOptional.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => optionalProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
});
function exactOptional(innerType) {
  return new ZodExactOptional({
    type: "optional",
    innerType
  });
}
var ZodNullable = $constructor("ZodNullable", (inst, def) => {
  $ZodNullable.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => nullableProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
});
function nullable(innerType) {
  return new ZodNullable({
    type: "nullable",
    innerType
  });
}
function nullish(innerType) {
  return optional(nullable(innerType));
}
var ZodDefault = $constructor("ZodDefault", (inst, def) => {
  $ZodDefault.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => defaultProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
  inst.removeDefault = inst.unwrap;
});
function _default(innerType, defaultValue) {
  return new ZodDefault({
    type: "default",
    innerType,
    get defaultValue() {
      return typeof defaultValue === "function" ? defaultValue() : util_exports.shallowClone(defaultValue);
    }
  });
}
var ZodPrefault = $constructor("ZodPrefault", (inst, def) => {
  $ZodPrefault.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => prefaultProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
});
function prefault(innerType, defaultValue) {
  return new ZodPrefault({
    type: "prefault",
    innerType,
    get defaultValue() {
      return typeof defaultValue === "function" ? defaultValue() : util_exports.shallowClone(defaultValue);
    }
  });
}
var ZodNonOptional = $constructor("ZodNonOptional", (inst, def) => {
  $ZodNonOptional.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => nonoptionalProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
});
function nonoptional(innerType, params) {
  return new ZodNonOptional({
    type: "nonoptional",
    innerType,
    ...util_exports.normalizeParams(params)
  });
}
var ZodSuccess = $constructor("ZodSuccess", (inst, def) => {
  $ZodSuccess.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => successProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
});
function success(innerType) {
  return new ZodSuccess({
    type: "success",
    innerType
  });
}
var ZodCatch = $constructor("ZodCatch", (inst, def) => {
  $ZodCatch.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => catchProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
  inst.removeCatch = inst.unwrap;
});
function _catch(innerType, catchValue) {
  return new ZodCatch({
    type: "catch",
    innerType,
    catchValue: typeof catchValue === "function" ? catchValue : () => catchValue
  });
}
var ZodNaN = $constructor("ZodNaN", (inst, def) => {
  $ZodNaN.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => nanProcessor(inst, ctx, json2, params);
});
function nan(params) {
  return _nan(ZodNaN, params);
}
var ZodPipe = $constructor("ZodPipe", (inst, def) => {
  $ZodPipe.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => pipeProcessor(inst, ctx, json2, params);
  inst.in = def.in;
  inst.out = def.out;
});
function pipe(in_, out) {
  return new ZodPipe({
    type: "pipe",
    in: in_,
    out
    // ...util.normalizeParams(params),
  });
}
var ZodCodec = $constructor("ZodCodec", (inst, def) => {
  ZodPipe.init(inst, def);
  $ZodCodec.init(inst, def);
});
function codec(in_, out, params) {
  return new ZodCodec({
    type: "pipe",
    in: in_,
    out,
    transform: params.decode,
    reverseTransform: params.encode
  });
}
var ZodReadonly = $constructor("ZodReadonly", (inst, def) => {
  $ZodReadonly.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => readonlyProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
});
function readonly(innerType) {
  return new ZodReadonly({
    type: "readonly",
    innerType
  });
}
var ZodTemplateLiteral = $constructor("ZodTemplateLiteral", (inst, def) => {
  $ZodTemplateLiteral.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => templateLiteralProcessor(inst, ctx, json2, params);
});
function templateLiteral(parts, params) {
  return new ZodTemplateLiteral({
    type: "template_literal",
    parts,
    ...util_exports.normalizeParams(params)
  });
}
var ZodLazy = $constructor("ZodLazy", (inst, def) => {
  $ZodLazy.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => lazyProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.getter();
});
function lazy(getter) {
  return new ZodLazy({
    type: "lazy",
    getter
  });
}
var ZodPromise = $constructor("ZodPromise", (inst, def) => {
  $ZodPromise.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => promiseProcessor(inst, ctx, json2, params);
  inst.unwrap = () => inst._zod.def.innerType;
});
function promise(innerType) {
  return new ZodPromise({
    type: "promise",
    innerType
  });
}
var ZodFunction = $constructor("ZodFunction", (inst, def) => {
  $ZodFunction.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => functionProcessor(inst, ctx, json2, params);
});
function _function(params) {
  return new ZodFunction({
    type: "function",
    input: Array.isArray(params?.input) ? tuple(params?.input) : params?.input ?? array(unknown()),
    output: params?.output ?? unknown()
  });
}
var ZodCustom = $constructor("ZodCustom", (inst, def) => {
  $ZodCustom.init(inst, def);
  ZodType.init(inst, def);
  inst._zod.processJSONSchema = (ctx, json2, params) => customProcessor(inst, ctx, json2, params);
});
function check(fn) {
  const ch = new $ZodCheck({
    check: "custom"
    // ...util.normalizeParams(params),
  });
  ch._zod.check = fn;
  return ch;
}
function custom(fn, _params) {
  return _custom(ZodCustom, fn ?? (() => true), _params);
}
function refine(fn, _params = {}) {
  return _refine(ZodCustom, fn, _params);
}
function superRefine(fn) {
  return _superRefine(fn);
}
var describe2 = describe;
var meta2 = meta;
function _instanceof(cls, params = {}) {
  const inst = new ZodCustom({
    type: "custom",
    check: "custom",
    fn: (data) => data instanceof cls,
    abort: true,
    ...util_exports.normalizeParams(params)
  });
  inst._zod.bag.Class = cls;
  inst._zod.check = (payload) => {
    if (!(payload.value instanceof cls)) {
      payload.issues.push({
        code: "invalid_type",
        expected: cls.name,
        input: payload.value,
        inst,
        path: [...inst._zod.def.path ?? []]
      });
    }
  };
  return inst;
}
var stringbool = (...args) => _stringbool({
  Codec: ZodCodec,
  Boolean: ZodBoolean,
  String: ZodString
}, ...args);
function json(params) {
  const jsonSchema = lazy(() => {
    return union([string(params), number(), boolean(), _null2(), array(jsonSchema), record(string(), jsonSchema)]);
  });
  return jsonSchema;
}
function preprocess(fn, schema) {
  return pipe(transform(fn), schema);
}

// node_modules/zod/v4/classic/compat.js
var ZodIssueCode = {
  invalid_type: "invalid_type",
  too_big: "too_big",
  too_small: "too_small",
  invalid_format: "invalid_format",
  not_multiple_of: "not_multiple_of",
  unrecognized_keys: "unrecognized_keys",
  invalid_union: "invalid_union",
  invalid_key: "invalid_key",
  invalid_element: "invalid_element",
  invalid_value: "invalid_value",
  custom: "custom"
};
function setErrorMap(map2) {
  config({
    customError: map2
  });
}
function getErrorMap() {
  return config().customError;
}
var ZodFirstPartyTypeKind;
/* @__PURE__ */ (function(ZodFirstPartyTypeKind2) {
})(ZodFirstPartyTypeKind || (ZodFirstPartyTypeKind = {}));

// node_modules/zod/v4/classic/from-json-schema.js
var z = {
  ...schemas_exports,
  ...checks_exports,
  iso: iso_exports
};
var RECOGNIZED_KEYS = /* @__PURE__ */ new Set([
  // Schema identification
  "$schema",
  "$ref",
  "$defs",
  "definitions",
  // Core schema keywords
  "$id",
  "id",
  "$comment",
  "$anchor",
  "$vocabulary",
  "$dynamicRef",
  "$dynamicAnchor",
  // Type
  "type",
  "enum",
  "const",
  // Composition
  "anyOf",
  "oneOf",
  "allOf",
  "not",
  // Object
  "properties",
  "required",
  "additionalProperties",
  "patternProperties",
  "propertyNames",
  "minProperties",
  "maxProperties",
  // Array
  "items",
  "prefixItems",
  "additionalItems",
  "minItems",
  "maxItems",
  "uniqueItems",
  "contains",
  "minContains",
  "maxContains",
  // String
  "minLength",
  "maxLength",
  "pattern",
  "format",
  // Number
  "minimum",
  "maximum",
  "exclusiveMinimum",
  "exclusiveMaximum",
  "multipleOf",
  // Already handled metadata
  "description",
  "default",
  // Content
  "contentEncoding",
  "contentMediaType",
  "contentSchema",
  // Unsupported (error-throwing)
  "unevaluatedItems",
  "unevaluatedProperties",
  "if",
  "then",
  "else",
  "dependentSchemas",
  "dependentRequired",
  // OpenAPI
  "nullable",
  "readOnly"
]);
function detectVersion(schema, defaultTarget) {
  const $schema = schema.$schema;
  if ($schema === "https://json-schema.org/draft/2020-12/schema") {
    return "draft-2020-12";
  }
  if ($schema === "http://json-schema.org/draft-07/schema#") {
    return "draft-7";
  }
  if ($schema === "http://json-schema.org/draft-04/schema#") {
    return "draft-4";
  }
  return defaultTarget ?? "draft-2020-12";
}
function resolveRef(ref, ctx) {
  if (!ref.startsWith("#")) {
    throw new Error("External $ref is not supported, only local refs (#/...) are allowed");
  }
  const path = ref.slice(1).split("/").filter(Boolean);
  if (path.length === 0) {
    return ctx.rootSchema;
  }
  const defsKey = ctx.version === "draft-2020-12" ? "$defs" : "definitions";
  if (path[0] === defsKey) {
    const key = path[1];
    if (!key || !ctx.defs[key]) {
      throw new Error(`Reference not found: ${ref}`);
    }
    return ctx.defs[key];
  }
  throw new Error(`Reference not found: ${ref}`);
}
function convertBaseSchema(schema, ctx) {
  if (schema.not !== void 0) {
    if (typeof schema.not === "object" && Object.keys(schema.not).length === 0) {
      return z.never();
    }
    throw new Error("not is not supported in Zod (except { not: {} } for never)");
  }
  if (schema.unevaluatedItems !== void 0) {
    throw new Error("unevaluatedItems is not supported");
  }
  if (schema.unevaluatedProperties !== void 0) {
    throw new Error("unevaluatedProperties is not supported");
  }
  if (schema.if !== void 0 || schema.then !== void 0 || schema.else !== void 0) {
    throw new Error("Conditional schemas (if/then/else) are not supported");
  }
  if (schema.dependentSchemas !== void 0 || schema.dependentRequired !== void 0) {
    throw new Error("dependentSchemas and dependentRequired are not supported");
  }
  if (schema.$ref) {
    const refPath = schema.$ref;
    if (ctx.refs.has(refPath)) {
      return ctx.refs.get(refPath);
    }
    if (ctx.processing.has(refPath)) {
      return z.lazy(() => {
        if (!ctx.refs.has(refPath)) {
          throw new Error(`Circular reference not resolved: ${refPath}`);
        }
        return ctx.refs.get(refPath);
      });
    }
    ctx.processing.add(refPath);
    const resolved = resolveRef(refPath, ctx);
    const zodSchema2 = convertSchema(resolved, ctx);
    ctx.refs.set(refPath, zodSchema2);
    ctx.processing.delete(refPath);
    return zodSchema2;
  }
  if (schema.enum !== void 0) {
    const enumValues = schema.enum;
    if (ctx.version === "openapi-3.0" && schema.nullable === true && enumValues.length === 1 && enumValues[0] === null) {
      return z.null();
    }
    if (enumValues.length === 0) {
      return z.never();
    }
    if (enumValues.length === 1) {
      return z.literal(enumValues[0]);
    }
    if (enumValues.every((v) => typeof v === "string")) {
      return z.enum(enumValues);
    }
    const literalSchemas = enumValues.map((v) => z.literal(v));
    if (literalSchemas.length < 2) {
      return literalSchemas[0];
    }
    return z.union([literalSchemas[0], literalSchemas[1], ...literalSchemas.slice(2)]);
  }
  if (schema.const !== void 0) {
    return z.literal(schema.const);
  }
  const type = schema.type;
  if (Array.isArray(type)) {
    const typeSchemas = type.map((t) => {
      const typeSchema = { ...schema, type: t };
      return convertBaseSchema(typeSchema, ctx);
    });
    if (typeSchemas.length === 0) {
      return z.never();
    }
    if (typeSchemas.length === 1) {
      return typeSchemas[0];
    }
    return z.union(typeSchemas);
  }
  if (!type) {
    return z.any();
  }
  let zodSchema;
  switch (type) {
    case "string": {
      let stringSchema = z.string();
      if (schema.format) {
        const format = schema.format;
        if (format === "email") {
          stringSchema = stringSchema.check(z.email());
        } else if (format === "uri" || format === "uri-reference") {
          stringSchema = stringSchema.check(z.url());
        } else if (format === "uuid" || format === "guid") {
          stringSchema = stringSchema.check(z.uuid());
        } else if (format === "date-time") {
          stringSchema = stringSchema.check(z.iso.datetime());
        } else if (format === "date") {
          stringSchema = stringSchema.check(z.iso.date());
        } else if (format === "time") {
          stringSchema = stringSchema.check(z.iso.time());
        } else if (format === "duration") {
          stringSchema = stringSchema.check(z.iso.duration());
        } else if (format === "ipv4") {
          stringSchema = stringSchema.check(z.ipv4());
        } else if (format === "ipv6") {
          stringSchema = stringSchema.check(z.ipv6());
        } else if (format === "mac") {
          stringSchema = stringSchema.check(z.mac());
        } else if (format === "cidr") {
          stringSchema = stringSchema.check(z.cidrv4());
        } else if (format === "cidr-v6") {
          stringSchema = stringSchema.check(z.cidrv6());
        } else if (format === "base64") {
          stringSchema = stringSchema.check(z.base64());
        } else if (format === "base64url") {
          stringSchema = stringSchema.check(z.base64url());
        } else if (format === "e164") {
          stringSchema = stringSchema.check(z.e164());
        } else if (format === "jwt") {
          stringSchema = stringSchema.check(z.jwt());
        } else if (format === "emoji") {
          stringSchema = stringSchema.check(z.emoji());
        } else if (format === "nanoid") {
          stringSchema = stringSchema.check(z.nanoid());
        } else if (format === "cuid") {
          stringSchema = stringSchema.check(z.cuid());
        } else if (format === "cuid2") {
          stringSchema = stringSchema.check(z.cuid2());
        } else if (format === "ulid") {
          stringSchema = stringSchema.check(z.ulid());
        } else if (format === "xid") {
          stringSchema = stringSchema.check(z.xid());
        } else if (format === "ksuid") {
          stringSchema = stringSchema.check(z.ksuid());
        }
      }
      if (typeof schema.minLength === "number") {
        stringSchema = stringSchema.min(schema.minLength);
      }
      if (typeof schema.maxLength === "number") {
        stringSchema = stringSchema.max(schema.maxLength);
      }
      if (schema.pattern) {
        stringSchema = stringSchema.regex(new RegExp(schema.pattern));
      }
      zodSchema = stringSchema;
      break;
    }
    case "number":
    case "integer": {
      let numberSchema = type === "integer" ? z.number().int() : z.number();
      if (typeof schema.minimum === "number") {
        numberSchema = numberSchema.min(schema.minimum);
      }
      if (typeof schema.maximum === "number") {
        numberSchema = numberSchema.max(schema.maximum);
      }
      if (typeof schema.exclusiveMinimum === "number") {
        numberSchema = numberSchema.gt(schema.exclusiveMinimum);
      } else if (schema.exclusiveMinimum === true && typeof schema.minimum === "number") {
        numberSchema = numberSchema.gt(schema.minimum);
      }
      if (typeof schema.exclusiveMaximum === "number") {
        numberSchema = numberSchema.lt(schema.exclusiveMaximum);
      } else if (schema.exclusiveMaximum === true && typeof schema.maximum === "number") {
        numberSchema = numberSchema.lt(schema.maximum);
      }
      if (typeof schema.multipleOf === "number") {
        numberSchema = numberSchema.multipleOf(schema.multipleOf);
      }
      zodSchema = numberSchema;
      break;
    }
    case "boolean": {
      zodSchema = z.boolean();
      break;
    }
    case "null": {
      zodSchema = z.null();
      break;
    }
    case "object": {
      const shape = {};
      const properties = schema.properties || {};
      const requiredSet = new Set(schema.required || []);
      for (const [key, propSchema] of Object.entries(properties)) {
        const propZodSchema = convertSchema(propSchema, ctx);
        shape[key] = requiredSet.has(key) ? propZodSchema : propZodSchema.optional();
      }
      if (schema.propertyNames) {
        const keySchema = convertSchema(schema.propertyNames, ctx);
        const valueSchema = schema.additionalProperties && typeof schema.additionalProperties === "object" ? convertSchema(schema.additionalProperties, ctx) : z.any();
        if (Object.keys(shape).length === 0) {
          zodSchema = z.record(keySchema, valueSchema);
          break;
        }
        const objectSchema2 = z.object(shape).passthrough();
        const recordSchema = z.looseRecord(keySchema, valueSchema);
        zodSchema = z.intersection(objectSchema2, recordSchema);
        break;
      }
      if (schema.patternProperties) {
        const patternProps = schema.patternProperties;
        const patternKeys = Object.keys(patternProps);
        const looseRecords = [];
        for (const pattern of patternKeys) {
          const patternValue = convertSchema(patternProps[pattern], ctx);
          const keySchema = z.string().regex(new RegExp(pattern));
          looseRecords.push(z.looseRecord(keySchema, patternValue));
        }
        const schemasToIntersect = [];
        if (Object.keys(shape).length > 0) {
          schemasToIntersect.push(z.object(shape).passthrough());
        }
        schemasToIntersect.push(...looseRecords);
        if (schemasToIntersect.length === 0) {
          zodSchema = z.object({}).passthrough();
        } else if (schemasToIntersect.length === 1) {
          zodSchema = schemasToIntersect[0];
        } else {
          let result = z.intersection(schemasToIntersect[0], schemasToIntersect[1]);
          for (let i = 2; i < schemasToIntersect.length; i++) {
            result = z.intersection(result, schemasToIntersect[i]);
          }
          zodSchema = result;
        }
        break;
      }
      const objectSchema = z.object(shape);
      if (schema.additionalProperties === false) {
        zodSchema = objectSchema.strict();
      } else if (typeof schema.additionalProperties === "object") {
        zodSchema = objectSchema.catchall(convertSchema(schema.additionalProperties, ctx));
      } else {
        zodSchema = objectSchema.passthrough();
      }
      break;
    }
    case "array": {
      const prefixItems = schema.prefixItems;
      const items = schema.items;
      if (prefixItems && Array.isArray(prefixItems)) {
        const tupleItems = prefixItems.map((item) => convertSchema(item, ctx));
        const rest = items && typeof items === "object" && !Array.isArray(items) ? convertSchema(items, ctx) : void 0;
        if (rest) {
          zodSchema = z.tuple(tupleItems).rest(rest);
        } else {
          zodSchema = z.tuple(tupleItems);
        }
        if (typeof schema.minItems === "number") {
          zodSchema = zodSchema.check(z.minLength(schema.minItems));
        }
        if (typeof schema.maxItems === "number") {
          zodSchema = zodSchema.check(z.maxLength(schema.maxItems));
        }
      } else if (Array.isArray(items)) {
        const tupleItems = items.map((item) => convertSchema(item, ctx));
        const rest = schema.additionalItems && typeof schema.additionalItems === "object" ? convertSchema(schema.additionalItems, ctx) : void 0;
        if (rest) {
          zodSchema = z.tuple(tupleItems).rest(rest);
        } else {
          zodSchema = z.tuple(tupleItems);
        }
        if (typeof schema.minItems === "number") {
          zodSchema = zodSchema.check(z.minLength(schema.minItems));
        }
        if (typeof schema.maxItems === "number") {
          zodSchema = zodSchema.check(z.maxLength(schema.maxItems));
        }
      } else if (items !== void 0) {
        const element = convertSchema(items, ctx);
        let arraySchema = z.array(element);
        if (typeof schema.minItems === "number") {
          arraySchema = arraySchema.min(schema.minItems);
        }
        if (typeof schema.maxItems === "number") {
          arraySchema = arraySchema.max(schema.maxItems);
        }
        zodSchema = arraySchema;
      } else {
        zodSchema = z.array(z.any());
      }
      break;
    }
    default:
      throw new Error(`Unsupported type: ${type}`);
  }
  if (schema.description) {
    zodSchema = zodSchema.describe(schema.description);
  }
  if (schema.default !== void 0) {
    zodSchema = zodSchema.default(schema.default);
  }
  return zodSchema;
}
function convertSchema(schema, ctx) {
  if (typeof schema === "boolean") {
    return schema ? z.any() : z.never();
  }
  let baseSchema = convertBaseSchema(schema, ctx);
  const hasExplicitType = schema.type || schema.enum !== void 0 || schema.const !== void 0;
  if (schema.anyOf && Array.isArray(schema.anyOf)) {
    const options = schema.anyOf.map((s) => convertSchema(s, ctx));
    const anyOfUnion = z.union(options);
    baseSchema = hasExplicitType ? z.intersection(baseSchema, anyOfUnion) : anyOfUnion;
  }
  if (schema.oneOf && Array.isArray(schema.oneOf)) {
    const options = schema.oneOf.map((s) => convertSchema(s, ctx));
    const oneOfUnion = z.xor(options);
    baseSchema = hasExplicitType ? z.intersection(baseSchema, oneOfUnion) : oneOfUnion;
  }
  if (schema.allOf && Array.isArray(schema.allOf)) {
    if (schema.allOf.length === 0) {
      baseSchema = hasExplicitType ? baseSchema : z.any();
    } else {
      let result = hasExplicitType ? baseSchema : convertSchema(schema.allOf[0], ctx);
      const startIdx = hasExplicitType ? 0 : 1;
      for (let i = startIdx; i < schema.allOf.length; i++) {
        result = z.intersection(result, convertSchema(schema.allOf[i], ctx));
      }
      baseSchema = result;
    }
  }
  if (schema.nullable === true && ctx.version === "openapi-3.0") {
    baseSchema = z.nullable(baseSchema);
  }
  if (schema.readOnly === true) {
    baseSchema = z.readonly(baseSchema);
  }
  const extraMeta = {};
  const coreMetadataKeys = ["$id", "id", "$comment", "$anchor", "$vocabulary", "$dynamicRef", "$dynamicAnchor"];
  for (const key of coreMetadataKeys) {
    if (key in schema) {
      extraMeta[key] = schema[key];
    }
  }
  const contentMetadataKeys = ["contentEncoding", "contentMediaType", "contentSchema"];
  for (const key of contentMetadataKeys) {
    if (key in schema) {
      extraMeta[key] = schema[key];
    }
  }
  for (const key of Object.keys(schema)) {
    if (!RECOGNIZED_KEYS.has(key)) {
      extraMeta[key] = schema[key];
    }
  }
  if (Object.keys(extraMeta).length > 0) {
    ctx.registry.add(baseSchema, extraMeta);
  }
  return baseSchema;
}
function fromJSONSchema(schema, params) {
  if (typeof schema === "boolean") {
    return schema ? z.any() : z.never();
  }
  const version = detectVersion(schema, params?.defaultTarget);
  const defs = schema.$defs || schema.definitions || {};
  const ctx = {
    version,
    defs,
    refs: /* @__PURE__ */ new Map(),
    processing: /* @__PURE__ */ new Set(),
    rootSchema: schema,
    registry: params?.registry ?? globalRegistry
  };
  return convertSchema(schema, ctx);
}

// node_modules/zod/v4/classic/coerce.js
var coerce_exports = {};
__export(coerce_exports, {
  bigint: () => bigint2,
  boolean: () => boolean2,
  date: () => date3,
  number: () => number2,
  string: () => string2
});
function string2(params) {
  return _coercedString(ZodString, params);
}
function number2(params) {
  return _coercedNumber(ZodNumber, params);
}
function boolean2(params) {
  return _coercedBoolean(ZodBoolean, params);
}
function bigint2(params) {
  return _coercedBigint(ZodBigInt, params);
}
function date3(params) {
  return _coercedDate(ZodDate, params);
}

// node_modules/zod/v4/classic/external.js
config(en_default());

// node_modules/@langchain/core/dist/tools/index.js
var tools_exports = {};
__export2(tools_exports, {
  BaseToolkit: () => BaseToolkit,
  DynamicStructuredTool: () => DynamicStructuredTool,
  DynamicTool: () => DynamicTool,
  StructuredTool: () => StructuredTool,
  Tool: () => Tool,
  ToolInputParsingException: () => ToolInputParsingException,
  isLangChainTool: () => isLangChainTool,
  isRunnableToolLike: () => isRunnableToolLike,
  isStructuredTool: () => isStructuredTool,
  isStructuredToolParams: () => isStructuredToolParams,
  tool: () => tool
});
var StructuredTool = class extends BaseLangChain {
  /**
  * Optional provider-specific extra fields for the tool.
  *
  * This is used to pass provider-specific configuration that doesn't fit into
  * standard tool fields.
  */
  extras;
  /**
  * Whether to return the tool's output directly.
  *
  * Setting this to true means that after the tool is called,
  * an agent should stop looping.
  */
  returnDirect = false;
  verboseParsingErrors = false;
  get lc_namespace() {
    return ["langchain", "tools"];
  }
  /**
  * The tool response format.
  *
  * If "content" then the output of the tool is interpreted as the contents of a
  * ToolMessage. If "content_and_artifact" then the output is expected to be a
  * two-tuple corresponding to the (content, artifact) of a ToolMessage.
  *
  * @default "content"
  */
  responseFormat = "content";
  /**
  * Default config object for the tool runnable.
  */
  defaultConfig;
  constructor(fields) {
    super(fields ?? {});
    this.verboseParsingErrors = fields?.verboseParsingErrors ?? this.verboseParsingErrors;
    this.responseFormat = fields?.responseFormat ?? this.responseFormat;
    this.defaultConfig = fields?.defaultConfig ?? this.defaultConfig;
    this.metadata = fields?.metadata ?? this.metadata;
    this.extras = fields?.extras ?? this.extras;
  }
  /**
  * Invokes the tool with the provided input and configuration.
  * @param input The input for the tool.
  * @param config Optional configuration for the tool.
  * @returns A Promise that resolves with the tool's output.
  */
  async invoke(input, config2) {
    let toolInput;
    let enrichedConfig = ensureConfig(mergeConfigs(this.defaultConfig, config2));
    if (_isToolCall(input)) {
      toolInput = input.args;
      enrichedConfig = {
        ...enrichedConfig,
        toolCall: input
      };
    } else toolInput = input;
    return this.call(toolInput, enrichedConfig);
  }
  /**
  * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
  *
  * Calls the tool with the provided argument, configuration, and tags. It
  * parses the input according to the schema, handles any errors, and
  * manages callbacks.
  * @param arg The input argument for the tool.
  * @param configArg Optional configuration or callbacks for the tool.
  * @param tags Optional tags for the tool.
  * @returns A Promise that resolves with a string.
  */
  async call(arg, configArg, tags) {
    const inputForValidation = _isToolCall(arg) ? arg.args : arg;
    let parsed;
    if (isInteropZodSchema(this.schema)) try {
      parsed = await interopParseAsync(this.schema, inputForValidation);
    } catch (e) {
      let message = `Received tool input did not match expected schema`;
      if (this.verboseParsingErrors) message = `${message}
Details: ${e.message}`;
      if (isInteropZodError(e)) message = `${message}

${external_exports2.prettifyError(e)}`;
      throw new ToolInputParsingException(message, JSON.stringify(arg));
    }
    else {
      const result$1 = validate(inputForValidation, this.schema);
      if (!result$1.valid) {
        let message = `Received tool input did not match expected schema`;
        if (this.verboseParsingErrors) message = `${message}
Details: ${result$1.errors.map((e) => `${e.keywordLocation}: ${e.error}`).join("\n")}`;
        throw new ToolInputParsingException(message, JSON.stringify(arg));
      }
      parsed = inputForValidation;
    }
    const config2 = parseCallbackConfigArg(configArg);
    const callbackManager_ = CallbackManager.configure(config2.callbacks, this.callbacks, config2.tags || tags, this.tags, config2.metadata, this.metadata, { verbose: this.verbose });
    const runManager = await callbackManager_?.handleToolStart(this.toJSON(), typeof arg === "string" ? arg : JSON.stringify(arg), config2.runId, void 0, void 0, void 0, config2.runName);
    delete config2.runId;
    let result;
    try {
      result = await this._call(parsed, runManager, config2);
    } catch (e) {
      await runManager?.handleToolError(e);
      throw e;
    }
    let content;
    let artifact;
    if (this.responseFormat === "content_and_artifact") if (Array.isArray(result) && result.length === 2) [content, artifact] = result;
    else throw new Error(`Tool response format is "content_and_artifact" but the output was not a two-tuple.
Result: ${JSON.stringify(result)}`);
    else content = result;
    let toolCallId;
    if (_isToolCall(arg)) toolCallId = arg.id;
    if (!toolCallId && _configHasToolCallId(config2)) toolCallId = config2.toolCall.id;
    const formattedOutput = _formatToolOutput({
      content,
      artifact,
      toolCallId,
      name: this.name,
      metadata: this.metadata
    });
    await runManager?.handleToolEnd(formattedOutput);
    return formattedOutput;
  }
};
var Tool = class extends StructuredTool {
  schema = external_exports.object({ input: external_exports.string().optional() }).transform((obj) => obj.input);
  constructor(fields) {
    super(fields);
  }
  /**
  * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
  *
  * Calls the tool with the provided argument and callbacks. It handles
  * string inputs specifically.
  * @param arg The input argument for the tool, which can be a string, undefined, or an input of the tool's schema.
  * @param callbacks Optional callbacks for the tool.
  * @returns A Promise that resolves with a string.
  */
  call(arg, callbacks) {
    const structuredArg = typeof arg === "string" || arg == null ? { input: arg } : arg;
    return super.call(structuredArg, callbacks);
  }
};
var DynamicTool = class extends Tool {
  static lc_name() {
    return "DynamicTool";
  }
  name;
  description;
  func;
  constructor(fields) {
    super(fields);
    this.name = fields.name;
    this.description = fields.description;
    this.func = fields.func;
    this.returnDirect = fields.returnDirect ?? this.returnDirect;
  }
  /**
  * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
  */
  async call(arg, configArg) {
    const config2 = parseCallbackConfigArg(configArg);
    if (config2.runName === void 0) config2.runName = this.name;
    return super.call(arg, config2);
  }
  /** @ignore */
  async _call(input, runManager, parentConfig) {
    return this.func(input, runManager, parentConfig);
  }
};
var DynamicStructuredTool = class extends StructuredTool {
  static lc_name() {
    return "DynamicStructuredTool";
  }
  description;
  func;
  schema;
  constructor(fields) {
    super(fields);
    this.name = fields.name;
    this.description = fields.description;
    this.func = fields.func;
    this.returnDirect = fields.returnDirect ?? this.returnDirect;
    this.schema = fields.schema;
  }
  /**
  * @deprecated Use .invoke() instead. Will be removed in 0.3.0.
  */
  async call(arg, configArg, tags) {
    const config2 = parseCallbackConfigArg(configArg);
    if (config2.runName === void 0) config2.runName = this.name;
    return super.call(arg, config2, tags);
  }
  _call(arg, runManager, parentConfig) {
    return this.func(arg, runManager, parentConfig);
  }
};
var BaseToolkit = class {
  getTools() {
    return this.tools;
  }
};
function tool(func, fields) {
  const isSimpleStringSchema = isSimpleStringZodSchema(fields.schema);
  const isStringJSONSchema = validatesOnlyStrings(fields.schema);
  if (!fields.schema || isSimpleStringSchema || isStringJSONSchema) return new DynamicTool({
    ...fields,
    description: fields.description ?? fields.schema?.description ?? `${fields.name} tool`,
    func: async (input, runManager, config2) => {
      return new Promise((resolve, reject) => {
        const childConfig = patchConfig(config2, { callbacks: runManager?.getChild() });
        AsyncLocalStorageProviderSingleton.runWithConfig(pickRunnableConfigKeys(childConfig), async () => {
          try {
            resolve(func(input, childConfig));
          } catch (e) {
            reject(e);
          }
        });
      });
    }
  });
  const schema = fields.schema;
  const description = fields.description ?? fields.schema.description ?? `${fields.name} tool`;
  return new DynamicStructuredTool({
    ...fields,
    description,
    schema,
    func: async (input, runManager, config2) => {
      return new Promise((resolve, reject) => {
        let listener;
        const cleanup = () => {
          if (config2?.signal && listener) config2.signal.removeEventListener("abort", listener);
        };
        if (config2?.signal) {
          listener = () => {
            cleanup();
            reject(getAbortSignalError(config2.signal));
          };
          config2.signal.addEventListener("abort", listener);
        }
        const childConfig = patchConfig(config2, { callbacks: runManager?.getChild() });
        AsyncLocalStorageProviderSingleton.runWithConfig(pickRunnableConfigKeys(childConfig), async () => {
          try {
            const result = await func(input, childConfig);
            if (config2?.signal?.aborted) {
              cleanup();
              return;
            }
            cleanup();
            resolve(result);
          } catch (e) {
            cleanup();
            reject(e);
          }
        });
      });
    }
  });
}
function _formatToolOutput(params) {
  const { content, artifact, toolCallId, metadata } = params;
  if (toolCallId && !isDirectToolOutput(content)) if (typeof content === "string" || Array.isArray(content) && content.every((item) => typeof item === "object")) return new ToolMessage({
    status: "success",
    content,
    artifact,
    tool_call_id: toolCallId,
    name: params.name,
    metadata
  });
  else return new ToolMessage({
    status: "success",
    content: _stringify2(content),
    artifact,
    tool_call_id: toolCallId,
    name: params.name,
    metadata
  });
  else return content;
}
function _stringify2(content) {
  try {
    return JSON.stringify(content) ?? "";
  } catch (_noOp) {
    return `${content}`;
  }
}

// node_modules/@langchain/core/dist/tracers/run_collector.js
var run_collector_exports = {};
__export2(run_collector_exports, { RunCollectorCallbackHandler: () => RunCollectorCallbackHandler });
var RunCollectorCallbackHandler = class extends BaseTracer {
  /** The name of the callback handler. */
  name = "run_collector";
  /** The ID of the example. */
  exampleId;
  /** An array of traced runs. */
  tracedRuns;
  /**
  * Creates a new instance of the RunCollectorCallbackHandler class.
  * @param exampleId The ID of the example.
  */
  constructor({ exampleId } = {}) {
    super({ _awaitHandler: true });
    this.exampleId = exampleId;
    this.tracedRuns = [];
  }
  /**
  * Persists the given run object.
  * @param run The run object to persist.
  */
  async persistRun(run) {
    const run_ = { ...run };
    run_.reference_example_id = this.exampleId;
    this.tracedRuns.push(run_);
  }
};

// node_modules/@langchain/core/dist/types/stream.js
var stream_exports2 = {};

// node_modules/@langchain/core/dist/utils/chunk_array.js
var chunk_array_exports = {};
__export2(chunk_array_exports, { chunkArray: () => chunkArray });
var chunkArray = (arr2, chunkSize) => arr2.reduce((chunks, elem, index2) => {
  const chunkIndex = Math.floor(index2 / chunkSize);
  const chunk = chunks[chunkIndex] || [];
  chunks[chunkIndex] = chunk.concat([elem]);
  return chunks;
}, []);

// node_modules/@langchain/core/dist/utils/context.js
var context_exports = {};
__export2(context_exports, { context: () => context });
function context(strings, ...values) {
  const raw = strings.raw;
  let result = "";
  for (let i = 0; i < raw.length; i++) {
    const next = raw[i].replace(/\\\n[ \t]*/g, "").replace(/\\`/g, "`").replace(/\\\$/g, "$").replace(/\\\{/g, "{");
    result += next;
    if (i < values.length) {
      const value = alignValue(values[i], result);
      result += typeof value === "string" ? value : JSON.stringify(value);
    }
  }
  result = stripIndent(result);
  result = result.trim();
  result = result.replace(/\\n/g, "\n");
  return result;
}
function alignValue(value, precedingText) {
  if (typeof value !== "string" || !value.includes("\n")) return value;
  const currentLine = precedingText.slice(precedingText.lastIndexOf("\n") + 1);
  const indentMatch = currentLine.match(/^(\s+)/);
  if (indentMatch) {
    const indent = indentMatch[1];
    return value.replace(/\n/g, `
${indent}`);
  }
  return value;
}
function stripIndent(text) {
  const lines = text.split("\n");
  let minIndent = null;
  for (const line of lines) {
    const match = line.match(/^(\s+)\S+/);
    if (match) {
      const indent = match[1].length;
      if (minIndent === null) minIndent = indent;
      else minIndent = Math.min(minIndent, indent);
    }
  }
  if (minIndent === null) return text;
  return lines.map((line) => line[0] === " " || line[0] === "	" ? line.slice(minIndent) : line).join("\n");
}

// node_modules/@langchain/core/dist/utils/event_source_parse.js
var event_source_parse_exports = {};
__export2(event_source_parse_exports, {
  EventStreamContentType: () => EventStreamContentType,
  convertEventStreamToIterableReadableDataStream: () => convertEventStreamToIterableReadableDataStream,
  getBytes: () => getBytes,
  getLines: () => getLines,
  getMessages: () => getMessages
});
var EventStreamContentType = "text/event-stream";
async function getBytes(stream, onChunk) {
  if (stream instanceof ReadableStream) {
    const reader = stream.getReader();
    while (true) {
      const result = await reader.read();
      if (result.done) {
        onChunk(new Uint8Array(), true);
        break;
      }
      onChunk(result.value);
    }
  } else try {
    for await (const chunk of stream) onChunk(new Uint8Array(chunk));
    onChunk(new Uint8Array(), true);
  } catch (e) {
    throw new Error([
      "Parsing event source stream failed.",
      "Ensure your implementation of fetch returns a web or Node readable stream.",
      `Error: ${e.message}`
    ].join("\n"));
  }
}
var ControlChars = (function(ControlChars$1) {
  ControlChars$1[ControlChars$1["NewLine"] = 10] = "NewLine";
  ControlChars$1[ControlChars$1["CarriageReturn"] = 13] = "CarriageReturn";
  ControlChars$1[ControlChars$1["Space"] = 32] = "Space";
  ControlChars$1[ControlChars$1["Colon"] = 58] = "Colon";
  return ControlChars$1;
})(ControlChars || {});
function getLines(onLine) {
  let buffer;
  let position;
  let fieldLength;
  let discardTrailingNewline = false;
  return function onChunk(arr2, flush) {
    if (flush) {
      onLine(arr2, 0, true);
      return;
    }
    if (buffer === void 0) {
      buffer = arr2;
      position = 0;
      fieldLength = -1;
    } else buffer = concat2(buffer, arr2);
    const bufLength = buffer.length;
    let lineStart = 0;
    while (position < bufLength) {
      if (discardTrailingNewline) {
        if (buffer[position] === ControlChars.NewLine) lineStart = ++position;
        discardTrailingNewline = false;
      }
      let lineEnd = -1;
      for (; position < bufLength && lineEnd === -1; ++position) switch (buffer[position]) {
        case ControlChars.Colon:
          if (fieldLength === -1) fieldLength = position - lineStart;
          break;
        case ControlChars.CarriageReturn:
          discardTrailingNewline = true;
        case ControlChars.NewLine:
          lineEnd = position;
          break;
      }
      if (lineEnd === -1) break;
      onLine(buffer.subarray(lineStart, lineEnd), fieldLength);
      lineStart = position;
      fieldLength = -1;
    }
    if (lineStart === bufLength) buffer = void 0;
    else if (lineStart !== 0) {
      buffer = buffer.subarray(lineStart);
      position -= lineStart;
    }
  };
}
function getMessages(onMessage, onId, onRetry) {
  let message = newMessage();
  const decoder = new TextDecoder();
  return function onLine(line, fieldLength, flush) {
    if (flush) {
      if (!isEmpty(message)) {
        onMessage?.(message);
        message = newMessage();
      }
      return;
    }
    if (line.length === 0) {
      onMessage?.(message);
      message = newMessage();
    } else if (fieldLength > 0) {
      const field = decoder.decode(line.subarray(0, fieldLength));
      const valueOffset = fieldLength + (line[fieldLength + 1] === ControlChars.Space ? 2 : 1);
      const value = decoder.decode(line.subarray(valueOffset));
      switch (field) {
        case "data":
          message.data = message.data ? message.data + "\n" + value : value;
          break;
        case "event":
          message.event = value;
          break;
        case "id":
          onId?.(message.id = value);
          break;
        case "retry": {
          const retry = parseInt(value, 10);
          if (!Number.isNaN(retry)) onRetry?.(message.retry = retry);
          break;
        }
      }
    }
  };
}
function concat2(a, b) {
  const res = new Uint8Array(a.length + b.length);
  res.set(a);
  res.set(b, a.length);
  return res;
}
function newMessage() {
  return {
    data: "",
    event: "",
    id: "",
    retry: void 0
  };
}
function convertEventStreamToIterableReadableDataStream(stream, onMetadataEvent) {
  const dataStream = new ReadableStream({ async start(controller) {
    const enqueueLine = getMessages((msg) => {
      if (msg.event === "error") throw new Error(msg.data ?? "Unspecified event streaming error.");
      else if (msg.event === "metadata") onMetadataEvent?.(msg);
      else if (msg.data) controller.enqueue(msg.data);
    });
    const onLine = (line, fieldLength, flush) => {
      enqueueLine(line, fieldLength, flush);
      if (flush) controller.close();
    };
    await getBytes(stream, getLines(onLine));
  } });
  return IterableReadableStream.fromReadableStream(dataStream);
}
function isEmpty(message) {
  return message.data === "" && message.event === "" && message.id === "" && message.retry === void 0;
}

// node_modules/@langchain/core/dist/utils/format.js
var format_exports = {};

// node_modules/@langchain/core/dist/utils/function_calling.js
var function_calling_exports = {};
__export2(function_calling_exports, {
  convertToOpenAIFunction: () => convertToOpenAIFunction,
  convertToOpenAITool: () => convertToOpenAITool,
  isLangChainTool: () => isLangChainTool,
  isRunnableToolLike: () => isRunnableToolLike,
  isStructuredTool: () => isStructuredTool,
  isStructuredToolParams: () => isStructuredToolParams
});
function convertToOpenAIFunction(tool2, fields) {
  const fieldsCopy = typeof fields === "number" ? void 0 : fields;
  return {
    name: tool2.name,
    description: tool2.description,
    parameters: toJsonSchema(tool2.schema),
    ...fieldsCopy?.strict !== void 0 ? { strict: fieldsCopy.strict } : {}
  };
}
function convertToOpenAITool(tool2, fields) {
  const fieldsCopy = typeof fields === "number" ? void 0 : fields;
  let toolDef;
  if (isLangChainTool(tool2)) toolDef = {
    type: "function",
    function: convertToOpenAIFunction(tool2)
  };
  else toolDef = tool2;
  if (fieldsCopy?.strict !== void 0) toolDef.function.strict = fieldsCopy.strict;
  return toolDef;
}

// node_modules/@langchain/core/dist/utils/ml-distance/similarities.js
function cosine(a, b) {
  let p = 0;
  let p2 = 0;
  let q2 = 0;
  for (let i = 0; i < a.length; i++) {
    p += a[i] * b[i];
    p2 += a[i] * a[i];
    q2 += b[i] * b[i];
  }
  return p / (Math.sqrt(p2) * Math.sqrt(q2));
}

// node_modules/@langchain/core/dist/utils/ml-distance/distances.js
function innerProduct(a, b) {
  let ans = 0;
  for (let i = 0; i < a.length; i++) ans += a[i] * b[i];
  return ans;
}

// node_modules/@langchain/core/dist/utils/ml-distance-euclidean/euclidean.js
function squaredEuclidean(p, q) {
  let d = 0;
  for (let i = 0; i < p.length; i++) d += (p[i] - q[i]) * (p[i] - q[i]);
  return d;
}
function euclidean(p, q) {
  return Math.sqrt(squaredEuclidean(p, q));
}

// node_modules/@langchain/core/dist/utils/math.js
var math_exports = {};
__export2(math_exports, {
  cosineSimilarity: () => cosineSimilarity,
  euclideanDistance: () => euclideanDistance,
  innerProduct: () => innerProduct$1,
  matrixFunc: () => matrixFunc,
  maximalMarginalRelevance: () => maximalMarginalRelevance,
  normalize: () => normalize
});
function matrixFunc(X, Y, func) {
  if (X.length === 0 || X[0].length === 0 || Y.length === 0 || Y[0].length === 0) return [[]];
  if (X[0].length !== Y[0].length) throw new Error(`Number of columns in X and Y must be the same. X has shape ${[X.length, X[0].length]} and Y has shape ${[Y.length, Y[0].length]}.`);
  return X.map((xVector) => Y.map((yVector) => func(xVector, yVector)).map((similarity) => Number.isNaN(similarity) ? 0 : similarity));
}
function normalize(M, similarity = false) {
  const max = matrixMaxVal(M);
  return M.map((row) => row.map((val) => similarity ? 1 - val / max : val / max));
}
function cosineSimilarity(X, Y) {
  return matrixFunc(X, Y, cosine);
}
function innerProduct$1(X, Y) {
  return matrixFunc(X, Y, innerProduct);
}
function euclideanDistance(X, Y) {
  return matrixFunc(X, Y, euclidean);
}
function maximalMarginalRelevance(queryEmbedding, embeddingList, lambda = 0.5, k = 4) {
  if (Math.min(k, embeddingList.length) <= 0) return [];
  const queryEmbeddingExpanded = Array.isArray(queryEmbedding[0]) ? queryEmbedding : [queryEmbedding];
  const similarityToQuery = cosineSimilarity(queryEmbeddingExpanded, embeddingList)[0];
  const mostSimilarEmbeddingIndex = argMax(similarityToQuery).maxIndex;
  const selectedEmbeddings = [embeddingList[mostSimilarEmbeddingIndex]];
  const selectedEmbeddingsIndexes = [mostSimilarEmbeddingIndex];
  while (selectedEmbeddingsIndexes.length < Math.min(k, embeddingList.length)) {
    let bestScore = -Infinity;
    let bestIndex = -1;
    const similarityToSelected = cosineSimilarity(embeddingList, selectedEmbeddings);
    similarityToQuery.forEach((queryScore, queryScoreIndex) => {
      if (selectedEmbeddingsIndexes.includes(queryScoreIndex)) return;
      const maxSimilarityToSelected = Math.max(...similarityToSelected[queryScoreIndex]);
      const score = lambda * queryScore - (1 - lambda) * maxSimilarityToSelected;
      if (score > bestScore) {
        bestScore = score;
        bestIndex = queryScoreIndex;
      }
    });
    selectedEmbeddings.push(embeddingList[bestIndex]);
    selectedEmbeddingsIndexes.push(bestIndex);
  }
  return selectedEmbeddingsIndexes;
}
function argMax(array2) {
  if (array2.length === 0) return {
    maxIndex: -1,
    maxValue: NaN
  };
  let maxValue = array2[0];
  let maxIndex = 0;
  for (let i = 1; i < array2.length; i += 1) if (array2[i] > maxValue) {
    maxIndex = i;
    maxValue = array2[i];
  }
  return {
    maxIndex,
    maxValue
  };
}
function matrixMaxVal(arrays) {
  return arrays.reduce((acc, array2) => Math.max(acc, argMax(array2).maxValue), 0);
}

// node_modules/@langchain/core/dist/utils/testing/chat_models.js
var FakeChatModel = class extends BaseChatModel {
  _combineLLMOutput() {
    return [];
  }
  _llmType() {
    return "fake";
  }
  async _generate(messages, options, runManager) {
    if (options?.stop?.length) return { generations: [{
      message: new AIMessage(options.stop[0]),
      text: options.stop[0]
    }] };
    const text = messages.map((m) => {
      if (typeof m.content === "string") return m.content;
      return JSON.stringify(m.content, null, 2);
    }).join("\n");
    await runManager?.handleLLMNewToken(text);
    return {
      generations: [{
        message: new AIMessage(text),
        text
      }],
      llmOutput: {}
    };
  }
};
var FakeStreamingChatModel = class FakeStreamingChatModel2 extends BaseChatModel {
  sleep = 50;
  responses = [];
  chunks = [];
  toolStyle = "openai";
  thrownErrorString;
  tools = [];
  constructor({ sleep: sleep2 = 50, responses = [], chunks = [], toolStyle = "openai", thrownErrorString, ...rest }) {
    super(rest);
    this.sleep = sleep2;
    this.responses = responses;
    this.chunks = chunks;
    this.toolStyle = toolStyle;
    this.thrownErrorString = thrownErrorString;
  }
  _llmType() {
    return "fake";
  }
  bindTools(tools) {
    const merged = [...this.tools, ...tools];
    const toolDicts = merged.map((t) => {
      switch (this.toolStyle) {
        case "openai":
          return {
            type: "function",
            function: {
              name: t.name,
              description: t.description,
              parameters: toJsonSchema(t.schema)
            }
          };
        case "anthropic":
          return {
            name: t.name,
            description: t.description,
            input_schema: toJsonSchema(t.schema)
          };
        case "bedrock":
          return { toolSpec: {
            name: t.name,
            description: t.description,
            inputSchema: toJsonSchema(t.schema)
          } };
        case "google":
          return {
            name: t.name,
            description: t.description,
            parameters: toJsonSchema(t.schema)
          };
        default:
          throw new Error(`Unsupported tool style: ${this.toolStyle}`);
      }
    });
    const wrapped = this.toolStyle === "google" ? [{ functionDeclarations: toolDicts }] : toolDicts;
    const next = new FakeStreamingChatModel2({
      sleep: this.sleep,
      responses: this.responses,
      chunks: this.chunks,
      toolStyle: this.toolStyle,
      thrownErrorString: this.thrownErrorString
    });
    next.tools = merged;
    return next.withConfig({ tools: wrapped });
  }
  async _generate(messages, _options, _runManager) {
    if (this.thrownErrorString) throw new Error(this.thrownErrorString);
    const content = this.responses?.[0]?.content ?? messages[0].content ?? "";
    const generation = { generations: [{
      text: "",
      message: new AIMessage({
        content,
        tool_calls: this.chunks?.[0]?.tool_calls
      })
    }] };
    return generation;
  }
  async *_streamResponseChunks(_messages, options, runManager) {
    if (this.thrownErrorString) throw new Error(this.thrownErrorString);
    if (this.chunks?.length) {
      for (const msgChunk of this.chunks) {
        const cg = new ChatGenerationChunk({
          message: new AIMessageChunk({
            content: msgChunk.content,
            tool_calls: msgChunk.tool_calls,
            additional_kwargs: msgChunk.additional_kwargs ?? {}
          }),
          text: msgChunk.content?.toString() ?? ""
        });
        if (options.signal?.aborted) break;
        yield cg;
        await runManager?.handleLLMNewToken(msgChunk.content, void 0, void 0, void 0, void 0, { chunk: cg });
      }
      return;
    }
    const fallback = this.responses?.[0] ?? new AIMessage(typeof _messages[0].content === "string" ? _messages[0].content : "");
    const text = typeof fallback.content === "string" ? fallback.content : "";
    for (const ch of text) {
      await new Promise((r) => setTimeout(r, this.sleep));
      const cg = new ChatGenerationChunk({
        message: new AIMessageChunk({ content: ch }),
        text: ch
      });
      if (options.signal?.aborted) break;
      yield cg;
      await runManager?.handleLLMNewToken(ch, void 0, void 0, void 0, void 0, { chunk: cg });
    }
  }
};
var FakeListChatModel = class FakeListChatModel2 extends BaseChatModel {
  static lc_name() {
    return "FakeListChatModel";
  }
  lc_serializable = true;
  responses;
  i = 0;
  sleep;
  emitCustomEvent = false;
  generationInfo;
  tools = [];
  toolStyle = "openai";
  constructor(params) {
    super(params);
    const { responses, sleep: sleep2, emitCustomEvent, generationInfo } = params;
    this.responses = responses;
    this.sleep = sleep2;
    this.emitCustomEvent = emitCustomEvent ?? this.emitCustomEvent;
    this.generationInfo = generationInfo;
  }
  _combineLLMOutput() {
    return [];
  }
  _llmType() {
    return "fake-list";
  }
  async _generate(_messages, options, runManager) {
    await this._sleepIfRequested();
    if (options?.thrownErrorString) throw new Error(options.thrownErrorString);
    if (this.emitCustomEvent) await runManager?.handleCustomEvent("some_test_event", { someval: true });
    if (options?.stop?.length) return { generations: [this._formatGeneration(options.stop[0])] };
    else {
      const response = this._currentResponse();
      this._incrementResponse();
      return {
        generations: [this._formatGeneration(response)],
        llmOutput: {}
      };
    }
  }
  _formatGeneration(text) {
    return {
      message: new AIMessage(text),
      text
    };
  }
  async *_streamResponseChunks(_messages, options, runManager) {
    const response = this._currentResponse();
    this._incrementResponse();
    if (this.emitCustomEvent) await runManager?.handleCustomEvent("some_test_event", { someval: true });
    const responseChars = [...response];
    for (let i = 0; i < responseChars.length; i++) {
      const text = responseChars[i];
      const isLastChunk = i === responseChars.length - 1;
      await this._sleepIfRequested();
      if (options?.thrownErrorString) throw new Error(options.thrownErrorString);
      const chunk = this._createResponseChunk(text, isLastChunk ? this.generationInfo : void 0);
      if (options.signal?.aborted) break;
      yield chunk;
      runManager?.handleLLMNewToken(text);
    }
  }
  async _sleepIfRequested() {
    if (this.sleep !== void 0) await this._sleep();
  }
  async _sleep() {
    return new Promise((resolve) => {
      setTimeout(() => resolve(), this.sleep);
    });
  }
  _createResponseChunk(text, generationInfo) {
    return new ChatGenerationChunk({
      message: new AIMessageChunk({ content: text }),
      text,
      generationInfo
    });
  }
  _currentResponse() {
    return this.responses[this.i];
  }
  _incrementResponse() {
    if (this.i < this.responses.length - 1) this.i += 1;
    else this.i = 0;
  }
  bindTools(tools) {
    const merged = [...this.tools, ...tools];
    const toolDicts = merged.map((t) => {
      switch (this.toolStyle) {
        case "openai":
          return {
            type: "function",
            function: {
              name: t.name,
              description: t.description,
              parameters: toJsonSchema(t.schema)
            }
          };
        case "anthropic":
          return {
            name: t.name,
            description: t.description,
            input_schema: toJsonSchema(t.schema)
          };
        case "bedrock":
          return { toolSpec: {
            name: t.name,
            description: t.description,
            inputSchema: toJsonSchema(t.schema)
          } };
        case "google":
          return {
            name: t.name,
            description: t.description,
            parameters: toJsonSchema(t.schema)
          };
        default:
          throw new Error(`Unsupported tool style: ${this.toolStyle}`);
      }
    });
    const wrapped = this.toolStyle === "google" ? [{ functionDeclarations: toolDicts }] : toolDicts;
    const next = new FakeListChatModel2({
      responses: this.responses,
      sleep: this.sleep,
      emitCustomEvent: this.emitCustomEvent,
      generationInfo: this.generationInfo
    });
    next.tools = merged;
    next.toolStyle = this.toolStyle;
    next.i = this.i;
    return next.withConfig({ tools: wrapped });
  }
  withStructuredOutput(_params, _config) {
    return RunnableLambda.from(async (input) => {
      const message = await this.invoke(input);
      if (message.tool_calls?.[0]?.args) return message.tool_calls[0].args;
      if (typeof message.content === "string") return JSON.parse(message.content);
      throw new Error("No structured output found");
    });
  }
};

// node_modules/@langchain/core/dist/utils/testing/embeddings.js
var SyntheticEmbeddings = class extends Embeddings {
  vectorSize;
  constructor(params) {
    super(params ?? {});
    this.vectorSize = params?.vectorSize ?? 4;
  }
  /**
  * Generates synthetic embeddings for a list of documents.
  * @param documents List of documents to generate embeddings for.
  * @returns A promise that resolves with a list of synthetic embeddings for each document.
  */
  async embedDocuments(documents) {
    return Promise.all(documents.map((doc) => this.embedQuery(doc)));
  }
  /**
  * Generates a synthetic embedding for a document. The document is
  * converted into chunks, a numerical value is calculated for each chunk,
  * and an array of these values is returned as the embedding.
  * @param document The document to generate an embedding for.
  * @returns A promise that resolves with a synthetic embedding for the document.
  */
  async embedQuery(document) {
    let doc = document;
    doc = doc.toLowerCase().replaceAll(/[^a-z ]/g, "");
    const padMod = doc.length % this.vectorSize;
    const padGapSize = padMod === 0 ? 0 : this.vectorSize - padMod;
    const padSize = doc.length + padGapSize;
    doc = doc.padEnd(padSize, " ");
    const chunkSize = doc.length / this.vectorSize;
    const docChunk = [];
    for (let co = 0; co < doc.length; co += chunkSize) docChunk.push(doc.slice(co, co + chunkSize));
    const ret = docChunk.map((s) => {
      let sum = 0;
      for (let co = 0; co < s.length; co += 1) sum += s === " " ? 0 : s.charCodeAt(co);
      const ret$1 = sum % 26 / 26;
      return ret$1;
    });
    return ret;
  }
};
var FakeEmbeddings = class extends Embeddings {
  constructor(params) {
    super(params ?? {});
  }
  /**
  * Generates fixed embeddings for a list of documents.
  * @param documents List of documents to generate embeddings for.
  * @returns A promise that resolves with a list of fixed embeddings for each document.
  */
  embedDocuments(documents) {
    return Promise.resolve(documents.map(() => [
      0.1,
      0.2,
      0.3,
      0.4
    ]));
  }
  /**
  * Generates a fixed embedding for a query.
  * @param _ The query to generate an embedding for.
  * @returns A promise that resolves with a fixed embedding for the query.
  */
  embedQuery(_) {
    return Promise.resolve([
      0.1,
      0.2,
      0.3,
      0.4
    ]);
  }
};

// node_modules/@langchain/core/dist/utils/testing/llms.js
var FakeLLM = class extends LLM {
  response;
  thrownErrorString;
  constructor(fields) {
    super(fields);
    this.response = fields.response;
    this.thrownErrorString = fields.thrownErrorString;
  }
  _llmType() {
    return "fake";
  }
  async _call(prompt, _options, runManager) {
    if (this.thrownErrorString) throw new Error(this.thrownErrorString);
    const response = this.response ?? prompt;
    await runManager?.handleLLMNewToken(response);
    return response;
  }
};
var FakeStreamingLLM = class extends LLM {
  sleep = 50;
  responses;
  thrownErrorString;
  constructor(fields) {
    super(fields);
    this.sleep = fields.sleep ?? this.sleep;
    this.responses = fields.responses;
    this.thrownErrorString = fields.thrownErrorString;
  }
  _llmType() {
    return "fake";
  }
  async _call(prompt) {
    if (this.thrownErrorString) throw new Error(this.thrownErrorString);
    const response = this.responses?.[0];
    this.responses = this.responses?.slice(1);
    return response ?? prompt;
  }
  async *_streamResponseChunks(input, _options, runManager) {
    if (this.thrownErrorString) throw new Error(this.thrownErrorString);
    const response = this.responses?.[0];
    this.responses = this.responses?.slice(1);
    for (const c of response ?? input) {
      await new Promise((resolve) => setTimeout(resolve, this.sleep));
      yield {
        text: c,
        generationInfo: {}
      };
      await runManager?.handleLLMNewToken(c);
    }
  }
};

// node_modules/@langchain/core/dist/utils/testing/message_history.js
var FakeChatMessageHistory = class extends BaseChatMessageHistory {
  lc_namespace = [
    "langchain_core",
    "message",
    "fake"
  ];
  messages = [];
  constructor() {
    super();
  }
  async getMessages() {
    return this.messages;
  }
  async addMessage(message) {
    this.messages.push(message);
  }
  async addUserMessage(message) {
    this.messages.push(new HumanMessage(message));
  }
  async addAIMessage(message) {
    this.messages.push(new AIMessage(message));
  }
  async clear() {
    this.messages = [];
  }
};
var FakeListChatMessageHistory = class extends BaseListChatMessageHistory {
  lc_namespace = [
    "langchain_core",
    "message",
    "fake"
  ];
  messages = [];
  constructor() {
    super();
  }
  async addMessage(message) {
    this.messages.push(message);
  }
  async getMessages() {
    return this.messages;
  }
};
var FakeTracer = class extends BaseTracer {
  name = "fake_tracer";
  runs = [];
  constructor() {
    super();
  }
  persistRun(run) {
    this.runs.push(run);
    return Promise.resolve();
  }
};

// node_modules/@langchain/core/dist/utils/testing/output_parsers.js
var FakeSplitIntoListParser = class extends BaseOutputParser {
  lc_namespace = ["tests", "fake"];
  getFormatInstructions() {
    return "";
  }
  async parse(text) {
    return text.split(",").map((value) => value.trim());
  }
};

// node_modules/@langchain/core/dist/utils/testing/retrievers.js
var FakeRetriever = class extends BaseRetriever {
  lc_namespace = ["test", "fake"];
  output = [new Document({ pageContent: "foo" }), new Document({ pageContent: "bar" })];
  constructor(fields) {
    super();
    this.output = fields?.output ?? this.output;
  }
  async _getRelevantDocuments(_query) {
    return this.output;
  }
};

// node_modules/@langchain/core/dist/utils/testing/runnables.js
var FakeRunnable = class extends Runnable {
  lc_namespace = ["tests", "fake"];
  returnOptions;
  constructor(fields) {
    super(fields);
    this.returnOptions = fields.returnOptions;
  }
  async invoke(input, options) {
    if (this.returnOptions) return options ?? {};
    return { input };
  }
};

// node_modules/@langchain/core/dist/utils/testing/tools.js
var FakeTool = class extends StructuredTool {
  name;
  description;
  schema;
  constructor(fields) {
    super(fields);
    this.name = fields.name;
    this.description = fields.description;
    this.schema = fields.schema;
  }
  async _call(arg, _runManager) {
    return JSON.stringify(arg);
  }
};

// node_modules/@langchain/core/dist/utils/testing/tracers.js
var SingleRunExtractor = class extends BaseTracer {
  runPromiseResolver;
  runPromise;
  /** The name of the callback handler. */
  name = "single_run_extractor";
  constructor() {
    super();
    this.runPromise = new Promise((extract) => {
      this.runPromiseResolver = extract;
    });
  }
  async persistRun(run) {
    this.runPromiseResolver(run);
  }
  async extract() {
    return this.runPromise;
  }
};

// node_modules/@langchain/core/dist/utils/testing/vectorstores.js
var FakeVectorStore = class FakeVectorStore2 extends VectorStore {
  memoryVectors = [];
  similarity;
  _vectorstoreType() {
    return "memory";
  }
  constructor(embeddings, { similarity, ...rest } = {}) {
    super(embeddings, rest);
    this.similarity = similarity ?? cosine;
  }
  /**
  * Method to add documents to the memory vector store. It extracts the
  * text from each document, generates embeddings for them, and adds the
  * resulting vectors to the store.
  * @param documents Array of `Document` instances to be added to the store.
  * @returns Promise that resolves when all documents have been added.
  */
  async addDocuments(documents) {
    const texts = documents.map(({ pageContent }) => pageContent);
    return this.addVectors(await this.embeddings.embedDocuments(texts), documents);
  }
  /**
  * Method to add vectors to the memory vector store. It creates
  * `MemoryVector` instances for each vector and document pair and adds
  * them to the store.
  * @param vectors Array of vectors to be added to the store.
  * @param documents Array of `Document` instances corresponding to the vectors.
  * @returns Promise that resolves when all vectors have been added.
  */
  async addVectors(vectors, documents) {
    const memoryVectors = vectors.map((embedding, idx) => ({
      content: documents[idx].pageContent,
      embedding,
      metadata: documents[idx].metadata
    }));
    this.memoryVectors = this.memoryVectors.concat(memoryVectors);
  }
  /**
  * Method to perform a similarity search in the memory vector store. It
  * calculates the similarity between the query vector and each vector in
  * the store, sorts the results by similarity, and returns the top `k`
  * results along with their scores.
  * @param query Query vector to compare against the vectors in the store.
  * @param k Number of top results to return.
  * @param filter Optional filter function to apply to the vectors before performing the search.
  * @returns Promise that resolves with an array of tuples, each containing a `Document` and its similarity score.
  */
  async similaritySearchVectorWithScore(query, k, filter) {
    const filterFunction = (memoryVector) => {
      if (!filter) return true;
      const doc = new Document({
        metadata: memoryVector.metadata,
        pageContent: memoryVector.content
      });
      return filter(doc);
    };
    const filteredMemoryVectors = this.memoryVectors.filter(filterFunction);
    const searches = filteredMemoryVectors.map((vector, index2) => ({
      similarity: this.similarity(query, vector.embedding),
      index: index2
    })).sort((a, b) => a.similarity > b.similarity ? -1 : 0).slice(0, k);
    const result = searches.map((search) => [new Document({
      metadata: filteredMemoryVectors[search.index].metadata,
      pageContent: filteredMemoryVectors[search.index].content
    }), search.similarity]);
    return result;
  }
  /**
  * Static method to create a `FakeVectorStore` instance from an array of
  * texts. It creates a `Document` for each text and metadata pair, and
  * adds them to the store.
  * @param texts Array of texts to be added to the store.
  * @param metadatas Array or single object of metadata corresponding to the texts.
  * @param embeddings `Embeddings` instance used to generate embeddings for the texts.
  * @param dbConfig Optional `FakeVectorStoreArgs` to configure the `FakeVectorStore` instance.
  * @returns Promise that resolves with a new `FakeVectorStore` instance.
  */
  static async fromTexts(texts, metadatas, embeddings, dbConfig) {
    const docs = [];
    for (let i = 0; i < texts.length; i += 1) {
      const metadata = Array.isArray(metadatas) ? metadatas[i] : metadatas;
      const newDoc = new Document({
        pageContent: texts[i],
        metadata
      });
      docs.push(newDoc);
    }
    return FakeVectorStore2.fromDocuments(docs, embeddings, dbConfig);
  }
  /**
  * Static method to create a `FakeVectorStore` instance from an array of
  * `Document` instances. It adds the documents to the store.
  * @param docs Array of `Document` instances to be added to the store.
  * @param embeddings `Embeddings` instance used to generate embeddings for the documents.
  * @param dbConfig Optional `FakeVectorStoreArgs` to configure the `FakeVectorStore` instance.
  * @returns Promise that resolves with a new `FakeVectorStore` instance.
  */
  static async fromDocuments(docs, embeddings, dbConfig) {
    const instance = new this(embeddings, dbConfig);
    await instance.addDocuments(docs);
    return instance;
  }
  /**
  * Static method to create a `FakeVectorStore` instance from an existing
  * index. It creates a new `FakeVectorStore` instance without adding any
  * documents or vectors.
  * @param embeddings `Embeddings` instance used to generate embeddings for the documents.
  * @param dbConfig Optional `FakeVectorStoreArgs` to configure the `FakeVectorStore` instance.
  * @returns Promise that resolves with a new `FakeVectorStore` instance.
  */
  static async fromExistingIndex(embeddings, dbConfig) {
    const instance = new this(embeddings, dbConfig);
    return instance;
  }
};

// node_modules/@langchain/core/dist/utils/testing/index.js
var testing_exports = {};
__export2(testing_exports, {
  FakeChatMessageHistory: () => FakeChatMessageHistory,
  FakeChatModel: () => FakeChatModel,
  FakeEmbeddings: () => FakeEmbeddings,
  FakeLLM: () => FakeLLM,
  FakeListChatMessageHistory: () => FakeListChatMessageHistory,
  FakeListChatModel: () => FakeListChatModel,
  FakeRetriever: () => FakeRetriever,
  FakeRunnable: () => FakeRunnable,
  FakeSplitIntoListParser: () => FakeSplitIntoListParser,
  FakeStreamingChatModel: () => FakeStreamingChatModel,
  FakeStreamingLLM: () => FakeStreamingLLM,
  FakeTool: () => FakeTool,
  FakeTracer: () => FakeTracer,
  FakeVectorStore: () => FakeVectorStore,
  SingleRunExtractor: () => SingleRunExtractor,
  SyntheticEmbeddings: () => SyntheticEmbeddings
});

// node_modules/@langchain/core/dist/utils/types/index.js
var types_exports = {};
__export2(types_exports, {
  extendInteropZodObject: () => extendInteropZodObject,
  getInteropZodDefaultGetter: () => getInteropZodDefaultGetter,
  getInteropZodObjectShape: () => getInteropZodObjectShape,
  getSchemaDescription: () => getSchemaDescription,
  interopParse: () => interopParse,
  interopParseAsync: () => interopParseAsync,
  interopSafeParse: () => interopSafeParse,
  interopSafeParseAsync: () => interopSafeParseAsync,
  interopZodObjectMakeFieldsOptional: () => interopZodObjectMakeFieldsOptional,
  interopZodObjectPartial: () => interopZodObjectPartial,
  interopZodObjectPassthrough: () => interopZodObjectPassthrough,
  interopZodObjectStrict: () => interopZodObjectStrict,
  interopZodTransformInputSchema: () => interopZodTransformInputSchema,
  isInteropZodError: () => isInteropZodError,
  isInteropZodLiteral: () => isInteropZodLiteral,
  isInteropZodObject: () => isInteropZodObject,
  isInteropZodSchema: () => isInteropZodSchema,
  isShapelessZodSchema: () => isShapelessZodSchema,
  isSimpleStringZodSchema: () => isSimpleStringZodSchema,
  isZodArrayV4: () => isZodArrayV4,
  isZodLiteralV3: () => isZodLiteralV3,
  isZodLiteralV4: () => isZodLiteralV4,
  isZodNullableV4: () => isZodNullableV4,
  isZodObjectV3: () => isZodObjectV3,
  isZodObjectV4: () => isZodObjectV4,
  isZodOptionalV4: () => isZodOptionalV4,
  isZodSchema: () => isZodSchema,
  isZodSchemaV3: () => isZodSchemaV3,
  isZodSchemaV4: () => isZodSchemaV4
});

// node_modules/@langchain/core/dist/load/import_map.js
var import_map_exports = {};
__export2(import_map_exports, {
  agents: () => agents_exports,
  caches: () => caches_exports,
  callbacks__base: () => base_exports,
  callbacks__manager: () => manager_exports,
  callbacks__promises: () => promises_exports,
  chat_history: () => chat_history_exports,
  document_loaders__base: () => base_exports4,
  document_loaders__langsmith: () => langsmith_exports,
  documents: () => documents_exports,
  embeddings: () => embeddings_exports,
  example_selectors: () => example_selectors_exports,
  index: () => src_exports,
  indexing: () => indexing_exports,
  language_models__base: () => base_exports3,
  language_models__chat_models: () => chat_models_exports,
  language_models__llms: () => llms_exports,
  language_models__profile: () => profile_exports,
  load__serializable: () => serializable_exports,
  memory: () => memory_exports,
  messages: () => messages_exports,
  messages__tool: () => tool_exports,
  output_parsers: () => output_parsers_exports,
  output_parsers__openai_functions: () => openai_functions_exports,
  output_parsers__openai_tools: () => openai_tools_exports,
  outputs: () => outputs_exports,
  prompt_values: () => prompt_values_exports,
  prompts: () => prompts_exports,
  retrievers: () => retrievers_exports,
  retrievers__document_compressors: () => document_compressors_exports,
  runnables: () => runnables_exports,
  runnables__graph: () => graph_exports,
  singletons: () => singletons_exports,
  stores: () => stores_exports,
  structured_query: () => structured_query_exports,
  tools: () => tools_exports,
  tracers__base: () => base_exports2,
  tracers__console: () => console_exports,
  tracers__log_stream: () => log_stream_exports,
  tracers__run_collector: () => run_collector_exports,
  tracers__tracer_langchain: () => tracer_langchain_exports,
  types__stream: () => stream_exports2,
  utils__async_caller: () => async_caller_exports,
  utils__chunk_array: () => chunk_array_exports,
  utils__context: () => context_exports,
  utils__env: () => env_exports,
  utils__event_source_parse: () => event_source_parse_exports,
  utils__format: () => format_exports,
  utils__function_calling: () => function_calling_exports,
  utils__hash: () => hash_exports,
  utils__json_patch: () => json_patch_exports,
  utils__json_schema: () => json_schema_exports,
  utils__math: () => math_exports,
  utils__stream: () => stream_exports,
  utils__testing: () => testing_exports,
  utils__tiktoken: () => tiktoken_exports,
  utils__types: () => types_exports,
  vectorstores: () => vectorstores_exports
});

// node_modules/@langchain/core/dist/load/index.js
var DEFAULT_MAX_DEPTH = 50;
function combineAliasesAndInvert(constructor) {
  const aliases = {};
  for (let current = constructor; current && current.prototype; current = Object.getPrototypeOf(current)) Object.assign(aliases, Reflect.get(current.prototype, "lc_aliases"));
  return Object.entries(aliases).reduce((acc, [key, value]) => {
    acc[value] = key;
    return acc;
  }, {});
}
async function reviver(value) {
  const { optionalImportsMap, optionalImportEntrypoints: optionalImportEntrypoints$1, importMap, secretsMap, secretsFromEnv, path, depth, maxDepth } = this;
  const pathStr = path.join(".");
  if (depth > maxDepth) throw new Error(`Maximum recursion depth (${maxDepth}) exceeded during deserialization. This may indicate a malicious payload or you may need to increase maxDepth.`);
  if (typeof value !== "object" || value == null) return value;
  if (Array.isArray(value)) return Promise.all(value.map((v, i) => reviver.call({
    ...this,
    path: [...path, `${i}`],
    depth: depth + 1
  }, v)));
  const record2 = value;
  if (isEscapedObject(record2)) return unescapeValue(record2);
  if ("lc" in record2 && "type" in record2 && "id" in record2 && record2.lc === 1 && record2.type === "secret") {
    const serialized = record2;
    const [key] = serialized.id;
    if (key in secretsMap) return secretsMap[key];
    else if (secretsFromEnv) {
      const secretValueInEnv = getEnvironmentVariable(key);
      if (secretValueInEnv) return secretValueInEnv;
    }
    throw new Error(`Missing secret "${key}" at ${pathStr}`);
  }
  if ("lc" in record2 && "type" in record2 && "id" in record2 && record2.lc === 1 && record2.type === "not_implemented") {
    const serialized = record2;
    const str = JSON.stringify(serialized);
    throw new Error(`Trying to load an object that doesn't implement serialization: ${pathStr} -> ${str}`);
  }
  if ("lc" in record2 && "type" in record2 && "id" in record2 && "kwargs" in record2 && record2.lc === 1 && record2.type === "constructor") {
    const serialized = record2;
    const str = JSON.stringify(serialized);
    const [name, ...namespaceReverse] = serialized.id.slice().reverse();
    const namespace = namespaceReverse.reverse();
    const importMaps = {
      langchain_core: import_map_exports,
      langchain: importMap
    };
    let module = null;
    const optionalImportNamespaceAliases = [namespace.join("/")];
    if (namespace[0] === "langchain_community") optionalImportNamespaceAliases.push(["langchain", ...namespace.slice(1)].join("/"));
    const matchingNamespaceAlias = optionalImportNamespaceAliases.find((alias) => alias in optionalImportsMap);
    if (optionalImportEntrypoints.concat(optionalImportEntrypoints$1).includes(namespace.join("/")) || matchingNamespaceAlias) if (matchingNamespaceAlias !== void 0) module = await optionalImportsMap[matchingNamespaceAlias];
    else throw new Error(`Missing key "${namespace.join("/")}" for ${pathStr} in load(optionalImportsMap={})`);
    else {
      let finalImportMap;
      if (namespace[0] === "langchain" || namespace[0] === "langchain_core") {
        finalImportMap = importMaps[namespace[0]];
        namespace.shift();
      } else throw new Error(`Invalid namespace: ${pathStr} -> ${str}`);
      if (namespace.length === 0) throw new Error(`Invalid namespace: ${pathStr} -> ${str}`);
      let importMapKey;
      do {
        importMapKey = namespace.join("__");
        if (importMapKey in finalImportMap) break;
        else namespace.pop();
      } while (namespace.length > 0);
      if (importMapKey in finalImportMap) module = finalImportMap[importMapKey];
    }
    if (typeof module !== "object" || module === null) throw new Error(`Invalid namespace: ${pathStr} -> ${str}`);
    const builder = module[name] ?? Object.values(module).find((v) => typeof v === "function" && get_lc_unique_name(v) === name);
    if (typeof builder !== "function") throw new Error(`Invalid identifer: ${pathStr} -> ${str}`);
    const kwargs = await reviver.call({
      ...this,
      path: [...path, "kwargs"],
      depth: depth + 1
    }, serialized.kwargs);
    const instance = new builder(mapKeys(kwargs, keyFromJson, combineAliasesAndInvert(builder)));
    Object.defineProperty(instance.constructor, "name", { value: name });
    return instance;
  }
  const result = {};
  for (const [key, val] of Object.entries(record2)) result[key] = await reviver.call({
    ...this,
    path: [...path, key],
    depth: depth + 1
  }, val);
  return result;
}
async function load(text, options) {
  const json2 = JSON.parse(text);
  const context2 = {
    optionalImportsMap: options?.optionalImportsMap ?? {},
    optionalImportEntrypoints: options?.optionalImportEntrypoints ?? [],
    secretsMap: options?.secretsMap ?? {},
    secretsFromEnv: options?.secretsFromEnv ?? false,
    importMap: options?.importMap ?? {},
    path: ["$"],
    depth: 0,
    maxDepth: options?.maxDepth ?? DEFAULT_MAX_DEPTH
  };
  return reviver.call(context2, json2);
}

// node_modules/@langchain/langgraph-checkpoint/dist/serde/jsonplus.js
function isLangChainSerializedObject(value) {
  return value !== null && value.lc === 1 && value.type === "constructor" && Array.isArray(value.id);
}
async function _reviver(value) {
  if (value && typeof value === "object") if (Array.isArray(value)) {
    const revivedArray = await Promise.all(value.map((item) => _reviver(item)));
    return revivedArray;
  } else {
    const revivedObj = {};
    for (const [k, v] of Object.entries(value)) revivedObj[k] = await _reviver(v);
    if (revivedObj.lc === 2 && revivedObj.type === "undefined") return void 0;
    else if (revivedObj.lc === 2 && revivedObj.type === "constructor" && Array.isArray(revivedObj.id)) try {
      const constructorName = revivedObj.id[revivedObj.id.length - 1];
      let constructor;
      switch (constructorName) {
        case "Set":
          constructor = Set;
          break;
        case "Map":
          constructor = Map;
          break;
        case "RegExp":
          constructor = RegExp;
          break;
        case "Error":
          constructor = Error;
          break;
        default:
          return revivedObj;
      }
      if (revivedObj.method) return constructor[revivedObj.method](...revivedObj.args || []);
      else return new constructor(...revivedObj.args || []);
    } catch (error) {
      return revivedObj;
    }
    else if (isLangChainSerializedObject(revivedObj)) return load(JSON.stringify(revivedObj));
    return revivedObj;
  }
  return value;
}
function _encodeConstructorArgs(constructor, method, args, kwargs) {
  return {
    lc: 2,
    type: "constructor",
    id: [constructor.name],
    method: method ?? null,
    args: args ?? [],
    kwargs: kwargs ?? {}
  };
}
function _default2(obj) {
  if (obj === void 0) return {
    lc: 2,
    type: "undefined"
  };
  else if (obj instanceof Set || obj instanceof Map) return _encodeConstructorArgs(obj.constructor, void 0, [Array.from(obj)]);
  else if (obj instanceof RegExp) return _encodeConstructorArgs(RegExp, void 0, [obj.source, obj.flags]);
  else if (obj instanceof Error) return _encodeConstructorArgs(obj.constructor, void 0, [obj.message]);
  else if (obj?.lg_name === "Send") return {
    node: obj.node,
    args: obj.args
  };
  else return obj;
}
var JsonPlusSerializer = class {
  _dumps(obj) {
    const encoder = new TextEncoder();
    return encoder.encode(stringify(obj, (_, value) => {
      return _default2(value);
    }));
  }
  async dumpsTyped(obj) {
    if (obj instanceof Uint8Array) return ["bytes", obj];
    else return ["json", this._dumps(obj)];
  }
  async _loads(data) {
    const parsed = JSON.parse(data);
    return _reviver(parsed);
  }
  async loadsTyped(type, data) {
    if (type === "bytes") return typeof data === "string" ? new TextEncoder().encode(data) : data;
    else if (type === "json") return this._loads(typeof data === "string" ? data : new TextDecoder().decode(data));
    else throw new Error(`Unknown serialization type: ${type}`);
  }
};

// node_modules/@langchain/langgraph-checkpoint/dist/base.js
function deepCopy(obj) {
  if (typeof obj !== "object" || obj === null) return obj;
  const newObj = Array.isArray(obj) ? [] : {};
  for (const key in obj) if (Object.prototype.hasOwnProperty.call(obj, key)) newObj[key] = deepCopy(obj[key]);
  return newObj;
}
function emptyCheckpoint() {
  return {
    v: 4,
    id: uuid6(-2),
    ts: (/* @__PURE__ */ new Date()).toISOString(),
    channel_values: {},
    channel_versions: {},
    versions_seen: {}
  };
}
function copyCheckpoint(checkpoint) {
  return {
    v: checkpoint.v,
    id: checkpoint.id,
    ts: checkpoint.ts,
    channel_values: { ...checkpoint.channel_values },
    channel_versions: { ...checkpoint.channel_versions },
    versions_seen: deepCopy(checkpoint.versions_seen)
  };
}
function compareChannelVersions(a, b) {
  if (typeof a === "number" && typeof b === "number") return Math.sign(a - b);
  return String(a).localeCompare(String(b));
}
function maxChannelVersion(...versions) {
  return versions.reduce((max, version, idx) => {
    if (idx === 0) return version;
    return compareChannelVersions(max, version) >= 0 ? max : version;
  });
}
var WRITES_IDX_MAP = {
  [ERROR2]: -1,
  [SCHEDULED]: -2,
  [INTERRUPT]: -3,
  [RESUME]: -4
};

// node_modules/@langchain/langgraph-checkpoint/dist/store/base.js
var InvalidNamespaceError = class extends Error {
  constructor(message) {
    super(message);
    this.name = "InvalidNamespaceError";
  }
};
function validateNamespace(namespace) {
  if (namespace.length === 0) throw new InvalidNamespaceError("Namespace cannot be empty.");
  for (const label of namespace) {
    if (typeof label !== "string") throw new InvalidNamespaceError(`Invalid namespace label '${label}' found in ${namespace}. Namespace labels must be strings, but got ${typeof label}.`);
    if (label.includes(".")) throw new InvalidNamespaceError(`Invalid namespace label '${label}' found in ${namespace}. Namespace labels cannot contain periods ('.').`);
    if (label === "") throw new InvalidNamespaceError(`Namespace labels cannot be empty strings. Got ${label} in ${namespace}`);
  }
  if (namespace[0] === "langgraph") throw new InvalidNamespaceError(`Root label for namespace cannot be "langgraph". Got: ${namespace}`);
}
var BaseStore2 = class {
  /**
  * Retrieve a single item by its namespace and key.
  *
  * @param namespace Hierarchical path for the item
  * @param key Unique identifier within the namespace
  * @returns Promise resolving to the item or null if not found
  */
  async get(namespace, key) {
    return (await this.batch([{
      namespace,
      key
    }]))[0];
  }
  /**
  * Search for items within a namespace prefix.
  * Supports both metadata filtering and vector similarity search.
  *
  * @param namespacePrefix Hierarchical path prefix to search within
  * @param options Search options for filtering and pagination
  * @returns Promise resolving to list of matching items with relevance scores
  *
  * @example
  * // Search with filters
  * await store.search(["documents"], {
  *   filter: { type: "report", status: "active" },
  *   limit: 5,
  *   offset: 10
  * });
  *
  * // Vector similarity search
  * await store.search(["users", "content"], {
  *   query: "technical documentation about APIs",
  *   limit: 20
  * });
  */
  async search(namespacePrefix, options = {}) {
    const { filter, limit = 10, offset = 0, query } = options;
    return (await this.batch([{
      namespacePrefix,
      filter,
      limit,
      offset,
      query
    }]))[0];
  }
  /**
  * Store or update an item.
  *
  * @param namespace Hierarchical path for the item
  * @param key Unique identifier within the namespace
  * @param value Object containing the item's data
  * @param index Optional indexing configuration
  *
  * @example
  * // Simple storage
  * await store.put(["docs"], "report", { title: "Annual Report" });
  *
  * // With specific field indexing
  * await store.put(
  *   ["docs"],
  *   "report",
  *   {
  *     title: "Q4 Report",
  *     chapters: [{ content: "..." }, { content: "..." }]
  *   },
  *   ["title", "chapters[*].content"]
  * );
  */
  async put(namespace, key, value, index2) {
    validateNamespace(namespace);
    await this.batch([{
      namespace,
      key,
      value,
      index: index2
    }]);
  }
  /**
  * Delete an item from the store.
  *
  * @param namespace Hierarchical path for the item
  * @param key Unique identifier within the namespace
  */
  async delete(namespace, key) {
    await this.batch([{
      namespace,
      key,
      value: null
    }]);
  }
  /**
  * List and filter namespaces in the store.
  * Used to explore data organization and navigate the namespace hierarchy.
  *
  * @param options Options for listing namespaces
  * @returns Promise resolving to list of namespace paths
  *
  * @example
  * // List all namespaces under "documents"
  * await store.listNamespaces({
  *   prefix: ["documents"],
  *   maxDepth: 2
  * });
  *
  * // List namespaces ending with "v1"
  * await store.listNamespaces({
  *   suffix: ["v1"],
  *   limit: 50
  * });
  */
  async listNamespaces(options = {}) {
    const { prefix, suffix, maxDepth, limit = 100, offset = 0 } = options;
    const matchConditions = [];
    if (prefix) matchConditions.push({
      matchType: "prefix",
      path: prefix
    });
    if (suffix) matchConditions.push({
      matchType: "suffix",
      path: suffix
    });
    return (await this.batch([{
      matchConditions: matchConditions.length ? matchConditions : void 0,
      maxDepth,
      limit,
      offset
    }]))[0];
  }
  /**
  * Start the store. Override if initialization is needed.
  */
  start() {
  }
  /**
  * Stop the store. Override if cleanup is needed.
  */
  stop() {
  }
};

// node_modules/@langchain/langgraph-checkpoint/dist/store/batch.js
var extractStore = (input) => {
  if ("lg_name" in input && input.lg_name === "AsyncBatchedStore") return input.store;
  return input;
};
var AsyncBatchedStore = class extends BaseStore2 {
  lg_name = "AsyncBatchedStore";
  store;
  queue = /* @__PURE__ */ new Map();
  nextKey = 0;
  running = false;
  processingTask = null;
  constructor(store) {
    super();
    this.store = extractStore(store);
  }
  get isRunning() {
    return this.running;
  }
  /**
  * @ignore
  * Batch is not implemented here as we're only extending `BaseStore`
  * to allow it to be passed where `BaseStore` is expected, and implement
  * the convenience methods (get, search, put, delete).
  */
  async batch(_operations) {
    throw new Error("The `batch` method is not implemented on `AsyncBatchedStore`.\n Instead, it calls the `batch` method on the wrapped store.\n If you are seeing this error, something is wrong.");
  }
  async get(namespace, key) {
    return this.enqueueOperation({
      namespace,
      key
    });
  }
  async search(namespacePrefix, options) {
    const { filter, limit = 10, offset = 0, query } = options || {};
    return this.enqueueOperation({
      namespacePrefix,
      filter,
      limit,
      offset,
      query
    });
  }
  async put(namespace, key, value) {
    return this.enqueueOperation({
      namespace,
      key,
      value
    });
  }
  async delete(namespace, key) {
    return this.enqueueOperation({
      namespace,
      key,
      value: null
    });
  }
  start() {
    if (!this.running) {
      this.running = true;
      this.processingTask = this.processBatchQueue();
    }
  }
  async stop() {
    this.running = false;
    if (this.processingTask) await this.processingTask;
  }
  enqueueOperation(operation) {
    return new Promise((resolve, reject) => {
      const key = this.nextKey;
      this.nextKey += 1;
      this.queue.set(key, {
        operation,
        resolve,
        reject
      });
    });
  }
  async processBatchQueue() {
    while (this.running) {
      await new Promise((resolve) => {
        setTimeout(resolve, 0);
      });
      if (this.queue.size === 0) continue;
      const batch = new Map(this.queue);
      this.queue.clear();
      try {
        const operations = Array.from(batch.values()).map(({ operation }) => operation);
        const results = await this.store.batch(operations);
        batch.forEach(({ resolve }, key) => {
          const index2 = Array.from(batch.keys()).indexOf(key);
          resolve(results[index2]);
        });
      } catch (e) {
        batch.forEach(({ reject }) => {
          reject(e);
        });
      }
    }
  }
  toJSON() {
    return {
      queue: this.queue,
      nextKey: this.nextKey,
      running: this.running,
      store: "[LangGraphStore]"
    };
  }
};

// node_modules/@langchain/langgraph-checkpoint/dist/cache/base.js
var BaseCache2 = class {
  serde = new JsonPlusSerializer();
  /**
  * Initialize the cache with a serializer.
  *
  * @param serde - The serializer to use.
  */
  constructor(serde) {
    this.serde = serde || this.serde;
  }
};

// node_modules/@langchain/langgraph/dist/channels/base.js
function isBaseChannel(obj) {
  return obj != null && obj.lg_is_channel === true;
}
var BaseChannel = class {
  ValueType;
  UpdateType;
  /** @ignore */
  lg_is_channel = true;
  /**
  * Mark the current value of the channel as consumed. By default, no-op.
  * A channel can use this method to modify its state, preventing the value
  * from being consumed again.
  *
  * Returns True if the channel was updated, False otherwise.
  */
  consume() {
    return false;
  }
  /**
  * Notify the channel that the Pregel run is finishing. By default, no-op.
  * A channel can use this method to modify its state, preventing finish.
  *
  * Returns True if the channel was updated, False otherwise.
  */
  finish() {
    return false;
  }
  /**
  * Return True if the channel is available (not empty), False otherwise.
  * Subclasses should override this method to provide a more efficient
  * implementation than calling get() and catching EmptyChannelError.
  */
  isAvailable() {
    try {
      this.get();
      return true;
    } catch (error) {
      if (error.name === EmptyChannelError.unminifiable_name) return false;
      throw error;
    }
  }
  /**
  * Compare this channel with another channel for equality.
  * Used to determine if two channels with the same key are semantically equivalent.
  * Subclasses should override this method to provide a meaningful comparison.
  *
  * @param {BaseChannel} other - The other channel to compare with.
  * @returns {boolean} True if the channels are equal, false otherwise.
  */
  equals(other) {
    return this === other;
  }
};
var IS_ONLY_BASE_CHANNEL = /* @__PURE__ */ Symbol.for("LG_IS_ONLY_BASE_CHANNEL");
function getOnlyChannels(channels) {
  if (channels[IS_ONLY_BASE_CHANNEL] === true) return channels;
  const newChannels = {};
  for (const k in channels) {
    if (!Object.prototype.hasOwnProperty.call(channels, k)) continue;
    const value = channels[k];
    if (isBaseChannel(value)) newChannels[k] = value;
  }
  Object.assign(newChannels, { [IS_ONLY_BASE_CHANNEL]: true });
  return newChannels;
}
function emptyChannels(channels, checkpoint) {
  const filteredChannels = getOnlyChannels(channels);
  const newChannels = {};
  for (const k in filteredChannels) {
    if (!Object.prototype.hasOwnProperty.call(filteredChannels, k)) continue;
    const channelValue = checkpoint.channel_values[k];
    newChannels[k] = filteredChannels[k].fromCheckpoint(channelValue);
  }
  Object.assign(newChannels, { [IS_ONLY_BASE_CHANNEL]: true });
  return newChannels;
}
function createCheckpoint(checkpoint, channels, step, options) {
  let values;
  if (channels === void 0) values = checkpoint.channel_values;
  else {
    values = {};
    for (const k in channels) {
      if (!Object.prototype.hasOwnProperty.call(channels, k)) continue;
      try {
        values[k] = channels[k].checkpoint();
      } catch (error) {
        if (error.name === EmptyChannelError.unminifiable_name) {
        } else throw error;
      }
    }
  }
  return {
    v: 4,
    id: options?.id ?? uuid6(step),
    ts: (/* @__PURE__ */ new Date()).toISOString(),
    channel_values: values,
    channel_versions: checkpoint.channel_versions,
    versions_seen: checkpoint.versions_seen
  };
}

// node_modules/@langchain/langgraph/dist/channels/binop.js
var isBinaryOperatorAggregate = (value) => {
  return value != null && value.lc_graph_name === "BinaryOperatorAggregate";
};
var BinaryOperatorAggregate = class BinaryOperatorAggregate2 extends BaseChannel {
  lc_graph_name = "BinaryOperatorAggregate";
  value;
  operator;
  initialValueFactory;
  constructor(operator, initialValueFactory) {
    super();
    this.operator = operator;
    this.initialValueFactory = initialValueFactory;
    this.value = initialValueFactory?.();
  }
  fromCheckpoint(checkpoint) {
    const empty = new BinaryOperatorAggregate2(this.operator, this.initialValueFactory);
    if (typeof checkpoint !== "undefined") empty.value = checkpoint;
    return empty;
  }
  update(values) {
    let newValues = values;
    if (!newValues.length) return false;
    if (this.value === void 0) {
      [this.value] = newValues;
      newValues = newValues.slice(1);
    }
    for (const value of newValues) if (this.value !== void 0) this.value = this.operator(this.value, value);
    return true;
  }
  get() {
    if (this.value === void 0) throw new EmptyChannelError();
    return this.value;
  }
  checkpoint() {
    if (this.value === void 0) throw new EmptyChannelError();
    return this.value;
  }
  isAvailable() {
    return this.value !== void 0;
  }
  /**
  * Compare this channel with another channel for equality.
  * Two BinaryOperatorAggregate channels are equal if they have the same operator function.
  * This follows the Python implementation which compares operator references.
  */
  equals(other) {
    if (this === other) return true;
    if (!isBinaryOperatorAggregate(other)) return false;
    return this.operator === other.operator;
  }
};

// node_modules/@langchain/langgraph/dist/channels/last_value.js
var LastValue = class LastValue2 extends BaseChannel {
  lc_graph_name = "LastValue";
  value = [];
  constructor(initialValueFactory) {
    super();
    this.initialValueFactory = initialValueFactory;
    if (initialValueFactory) this.value = [initialValueFactory()];
  }
  fromCheckpoint(checkpoint) {
    const empty = new LastValue2(this.initialValueFactory);
    if (typeof checkpoint !== "undefined") empty.value = [checkpoint];
    return empty;
  }
  update(values) {
    if (values.length === 0) return false;
    if (values.length !== 1) throw new InvalidUpdateError("LastValue can only receive one value per step.", { lc_error_code: "INVALID_CONCURRENT_GRAPH_UPDATE" });
    this.value = [values[values.length - 1]];
    return true;
  }
  get() {
    if (this.value.length === 0) throw new EmptyChannelError();
    return this.value[0];
  }
  checkpoint() {
    if (this.value.length === 0) throw new EmptyChannelError();
    return this.value[0];
  }
  isAvailable() {
    return this.value.length !== 0;
  }
};
var LastValueAfterFinish = class LastValueAfterFinish2 extends BaseChannel {
  lc_graph_name = "LastValueAfterFinish";
  value = [];
  finished = false;
  fromCheckpoint(checkpoint) {
    const empty = new LastValueAfterFinish2();
    if (typeof checkpoint !== "undefined") {
      const [value, finished] = checkpoint;
      empty.value = [value];
      empty.finished = finished;
    }
    return empty;
  }
  update(values) {
    if (values.length === 0) return false;
    this.finished = false;
    this.value = [values[values.length - 1]];
    return true;
  }
  get() {
    if (this.value.length === 0 || !this.finished) throw new EmptyChannelError();
    return this.value[0];
  }
  checkpoint() {
    if (this.value.length === 0) return void 0;
    return [this.value[0], this.finished];
  }
  consume() {
    if (this.finished) {
      this.finished = false;
      this.value = [];
      return true;
    }
    return false;
  }
  finish() {
    if (!this.finished && this.value.length > 0) {
      this.finished = true;
      return true;
    }
    return false;
  }
  isAvailable() {
    return this.value.length !== 0 && this.finished;
  }
};

// node_modules/@langchain/langgraph/dist/graph/annotation.js
var AnnotationRoot = class {
  lc_graph_name = "AnnotationRoot";
  spec;
  constructor(s) {
    this.spec = s;
  }
  static isInstance(value) {
    return typeof value === "object" && value !== null && "lc_graph_name" in value && value.lc_graph_name === "AnnotationRoot";
  }
};
var Annotation = function(annotation) {
  if (annotation) return getChannel(annotation);
  else return new LastValue();
};
Annotation.Root = (sd) => new AnnotationRoot(sd);
function getChannel(reducer) {
  if (typeof reducer === "object" && reducer && "reducer" in reducer && reducer.reducer) return new BinaryOperatorAggregate(reducer.reducer, reducer.default);
  if (typeof reducer === "object" && reducer && "value" in reducer && reducer.value) return new BinaryOperatorAggregate(reducer.value, reducer.default);
  return new LastValue();
}

// node_modules/@langchain/langgraph/dist/constants.js
var START = "__start__";
var END = "__end__";
var INPUT = "__input__";
var COPY = "__copy__";
var ERROR3 = "__error__";
var CACHE_NS_WRITES = "__pregel_ns_writes";
var CONFIG_KEY_SEND = "__pregel_send";
var CONFIG_KEY_CALL = "__pregel_call";
var CONFIG_KEY_READ = "__pregel_read";
var CONFIG_KEY_CHECKPOINTER = "__pregel_checkpointer";
var CONFIG_KEY_RESUMING = "__pregel_resuming";
var CONFIG_KEY_TASK_ID = "__pregel_task_id";
var CONFIG_KEY_STREAM = "__pregel_stream";
var CONFIG_KEY_RESUME_VALUE = "__pregel_resume_value";
var CONFIG_KEY_RESUME_MAP = "__pregel_resume_map";
var CONFIG_KEY_SCRATCHPAD = "__pregel_scratchpad";
var CONFIG_KEY_PREVIOUS_STATE = "__pregel_previous";
var CONFIG_KEY_DURABILITY = "__pregel_durability";
var CONFIG_KEY_CHECKPOINT_ID = "checkpoint_id";
var CONFIG_KEY_CHECKPOINT_NS = "checkpoint_ns";
var CONFIG_KEY_NODE_FINISHED = "__pregel_node_finished";
var CONFIG_KEY_CHECKPOINT_MAP = "checkpoint_map";
var CONFIG_KEY_ABORT_SIGNALS = "__pregel_abort_signals";
var INTERRUPT2 = "__interrupt__";
var RESUME2 = "__resume__";
var NO_WRITES = "__no_writes__";
var RETURN = "__return__";
var PREVIOUS = "__previous__";
var TAG_HIDDEN = "langsmith:hidden";
var TAG_NOSTREAM = "langsmith:nostream";
var SELF = "__self__";
var TASKS2 = "__pregel_tasks";
var PUSH = "__pregel_push";
var PULL = "__pregel_pull";
var NULL_TASK_ID = "00000000-0000-0000-0000-000000000000";
var RESERVED = [
  TAG_HIDDEN,
  INPUT,
  INTERRUPT2,
  RESUME2,
  ERROR3,
  NO_WRITES,
  CONFIG_KEY_SEND,
  CONFIG_KEY_READ,
  CONFIG_KEY_CHECKPOINTER,
  CONFIG_KEY_DURABILITY,
  CONFIG_KEY_STREAM,
  CONFIG_KEY_RESUMING,
  CONFIG_KEY_TASK_ID,
  CONFIG_KEY_CALL,
  CONFIG_KEY_RESUME_VALUE,
  CONFIG_KEY_SCRATCHPAD,
  CONFIG_KEY_PREVIOUS_STATE,
  CONFIG_KEY_CHECKPOINT_MAP,
  CONFIG_KEY_CHECKPOINT_NS,
  CONFIG_KEY_CHECKPOINT_ID
];
var CHECKPOINT_NAMESPACE_SEPARATOR = "|";
var CHECKPOINT_NAMESPACE_END = ":";
var COMMAND_SYMBOL = /* @__PURE__ */ Symbol.for("langgraph.command");
var CommandInstance = class {
  [COMMAND_SYMBOL];
  constructor(args) {
    this[COMMAND_SYMBOL] = args;
  }
};
function _isSendInterface(x) {
  const operation = x;
  return operation !== null && operation !== void 0 && typeof operation.node === "string" && operation.args !== void 0;
}
var Send = class {
  lg_name = "Send";
  node;
  args;
  constructor(node, args) {
    this.node = node;
    this.args = _deserializeCommandSendObjectGraph(args);
  }
  toJSON() {
    return {
      lg_name: this.lg_name,
      node: this.node,
      args: this.args
    };
  }
};
function _isSend(x) {
  return x instanceof Send;
}
function isInterrupted(values) {
  if (!values || typeof values !== "object") return false;
  if (!(INTERRUPT2 in values)) return false;
  return Array.isArray(values[INTERRUPT2]);
}
var Command = class extends CommandInstance {
  lg_name = "Command";
  lc_direct_tool_output = true;
  /**
  * Graph to send the command to. Supported values are:
  *   - None: the current graph (default)
  *   - The specific name of the graph to send the command to
  *   - {@link Command.PARENT}: closest parent graph (only supported when returned from a node in a subgraph)
  */
  graph;
  /**
  * Update to apply to the graph's state as a result of executing the node that is returning the command.
  * Written to the state as if the node had simply returned this value instead of the Command object.
  */
  update;
  /**
  * Value to resume execution with. To be used together with {@link interrupt}.
  */
  resume;
  /**
  * Can be one of the following:
  *   - name of the node to navigate to next (any node that belongs to the specified `graph`)
  *   - sequence of node names to navigate to next
  *   - {@link Send} object (to execute a node with the exact input provided in the {@link Send} object)
  *   - sequence of {@link Send} objects
  */
  goto = [];
  static PARENT = "__parent__";
  constructor(args) {
    super(args);
    this.resume = args.resume;
    this.graph = args.graph;
    this.update = args.update;
    if (args.goto) this.goto = Array.isArray(args.goto) ? _deserializeCommandSendObjectGraph(args.goto) : [_deserializeCommandSendObjectGraph(args.goto)];
  }
  /**
  * Convert the update field to a list of {@link PendingWrite} tuples
  * @returns List of {@link PendingWrite} tuples of the form `[channelKey, value]`.
  * @internal
  */
  _updateAsTuples() {
    if (this.update && typeof this.update === "object" && !Array.isArray(this.update)) return Object.entries(this.update);
    else if (Array.isArray(this.update) && this.update.every((t) => Array.isArray(t) && t.length === 2 && typeof t[0] === "string")) return this.update;
    else return [["__root__", this.update]];
  }
  toJSON() {
    let serializedGoto;
    if (typeof this.goto === "string") serializedGoto = this.goto;
    else if (_isSend(this.goto)) serializedGoto = this.goto.toJSON();
    else serializedGoto = this.goto?.map((innerGoto) => {
      if (typeof innerGoto === "string") return innerGoto;
      else return innerGoto.toJSON();
    });
    return {
      lg_name: this.lg_name,
      update: this.update,
      resume: this.resume,
      goto: serializedGoto
    };
  }
};
function isCommand(x) {
  if (typeof x !== "object") return false;
  if (x === null || x === void 0) return false;
  if ("lg_name" in x && x.lg_name === "Command") return true;
  return false;
}
function _deserializeCommandSendObjectGraph(x, seen = /* @__PURE__ */ new Map()) {
  if (x !== void 0 && x !== null && typeof x === "object") {
    if (seen.has(x)) return seen.get(x);
    let result;
    if (Array.isArray(x)) {
      result = [];
      seen.set(x, result);
      x.forEach((item, index2) => {
        result[index2] = _deserializeCommandSendObjectGraph(item, seen);
      });
    } else if (isCommand(x) && !(x instanceof Command)) {
      result = new Command(x);
      seen.set(x, result);
    } else if (_isSendInterface(x) && !(x instanceof Send)) {
      result = new Send(x.node, x.args);
      seen.set(x, result);
    } else if (isCommand(x) || _isSend(x)) {
      result = x;
      seen.set(x, result);
    } else if ("lc_serializable" in x && x.lc_serializable) {
      result = x;
      seen.set(x, result);
    } else {
      result = {};
      seen.set(x, result);
      for (const [key, value] of Object.entries(x)) result[key] = _deserializeCommandSendObjectGraph(value, seen);
    }
    return result;
  }
  return x;
}

// node_modules/@langchain/langgraph/dist/pregel/utils/config.js
var COPIABLE_KEYS = [
  "tags",
  "metadata",
  "callbacks",
  "configurable"
];
var CONFIG_KEYS = [
  "tags",
  "metadata",
  "callbacks",
  "runName",
  "maxConcurrency",
  "recursionLimit",
  "configurable",
  "runId",
  "outputKeys",
  "streamMode",
  "store",
  "writer",
  "interrupt",
  "context",
  "interruptBefore",
  "interruptAfter",
  "checkpointDuring",
  "durability",
  "signal"
];
var DEFAULT_RECURSION_LIMIT = 25;
function ensureLangGraphConfig(...configs) {
  const empty = {
    tags: [],
    metadata: {},
    callbacks: void 0,
    recursionLimit: DEFAULT_RECURSION_LIMIT,
    configurable: {}
  };
  const implicitConfig = AsyncLocalStorageProviderSingleton.getRunnableConfig();
  if (implicitConfig !== void 0) {
    for (const [k, v] of Object.entries(implicitConfig)) if (v !== void 0) if (COPIABLE_KEYS.includes(k)) {
      let copiedValue;
      if (Array.isArray(v)) copiedValue = [...v];
      else if (typeof v === "object") if (k === "callbacks" && "copy" in v && typeof v.copy === "function") copiedValue = v.copy();
      else copiedValue = { ...v };
      else copiedValue = v;
      empty[k] = copiedValue;
    } else empty[k] = v;
  }
  for (const config2 of configs) {
    if (config2 === void 0) continue;
    for (const [k, v] of Object.entries(config2)) if (v !== void 0 && CONFIG_KEYS.includes(k)) empty[k] = v;
  }
  for (const [key, value] of Object.entries(empty.configurable)) {
    empty.metadata = empty.metadata ?? {};
    if (!key.startsWith("__") && (typeof value === "string" || typeof value === "number" || typeof value === "boolean") && !(key in empty.metadata)) empty.metadata[key] = value;
  }
  return empty;
}
function getConfig() {
  return AsyncLocalStorageProviderSingleton.getRunnableConfig();
}
function recastCheckpointNamespace(namespace) {
  return namespace.split(CHECKPOINT_NAMESPACE_SEPARATOR).filter((part) => !part.match(/^\d+$/)).map((part) => part.split(CHECKPOINT_NAMESPACE_END)[0]).join(CHECKPOINT_NAMESPACE_SEPARATOR);
}
function getParentCheckpointNamespace(namespace) {
  const parts = namespace.split(CHECKPOINT_NAMESPACE_SEPARATOR);
  while (parts.length > 1 && parts[parts.length - 1].match(/^\d+$/)) parts.pop();
  return parts.slice(0, -1).join(CHECKPOINT_NAMESPACE_SEPARATOR);
}

// node_modules/@langchain/langgraph/dist/hash.js
var n = (n2) => BigInt(n2);
var view = (data, offset = 0) => new DataView(data.buffer, data.byteOffset + offset, data.byteLength - offset);
var PRIME32_1 = n("0x9E3779B1");
var PRIME32_2 = n("0x85EBCA77");
var PRIME32_3 = n("0xC2B2AE3D");
var PRIME64_1 = n("0x9E3779B185EBCA87");
var PRIME64_2 = n("0xC2B2AE3D27D4EB4F");
var PRIME64_3 = n("0x165667B19E3779F9");
var PRIME64_4 = n("0x85EBCA77C2B2AE63");
var PRIME64_5 = n("0x27D4EB2F165667C5");
var PRIME_MX1 = n("0x165667919E3779F9");
var PRIME_MX2 = n("0x9FB21C651E98DF25");
var hexToUint8Array = (hex2) => {
  const strLen = hex2.length;
  if (strLen % 2 !== 0) throw new Error("String should have an even number of characters");
  const maxLength = strLen / 2;
  const bytes = new Uint8Array(maxLength);
  let read = 0;
  let write = 0;
  while (write < maxLength) {
    const slice = hex2.slice(read, read += 2);
    bytes[write] = Number.parseInt(slice, 16);
    write += 1;
  }
  return view(bytes);
};
var kkey = hexToUint8Array("b8fe6c3923a44bbe7c01812cf721ad1cded46de9839097db7240a4a4b7b3671fcb79e64eccc0e578825ad07dccff7221b8084674f743248ee03590e6813a264c3c2852bb91c300cb88d0658b1b532ea371644897a20df94e3819ef46a9deacd8a8fa763fe39c343ff9dcbbc7c70b4f1d8a51e04bcdb45931c89f7ec9d9787364eac5ac8334d3ebc3c581a0fffa1363eb170ddd51b7f0da49d316552629d4689e2b16be587d47a1fc8ff8b8d17ad031ce45cb3a8f95160428afd7fbcabb4b407e");
var mask128 = (n(1) << n(128)) - n(1);
var mask64 = (n(1) << n(64)) - n(1);
var mask32 = (n(1) << n(32)) - n(1);
var STRIPE_LEN = 64;
var ACC_NB = STRIPE_LEN / 8;
var _U64 = 8;
var _U32 = 4;
function assert(a) {
  if (!a) throw new Error("Assert failed");
}
function bswap64(a) {
  const scratchbuf = new DataView(new ArrayBuffer(8));
  scratchbuf.setBigUint64(0, a, true);
  return scratchbuf.getBigUint64(0, false);
}
function bswap32(input) {
  let a = input;
  a = (a & n(65535)) << n(16) | (a & n(4294901760)) >> n(16);
  a = (a & n(16711935)) << n(8) | (a & n(4278255360)) >> n(8);
  return a;
}
function XXH_mult32to64(a, b) {
  return (a & mask32) * (b & mask32) & mask64;
}
function rotl32(a, b) {
  return (a << b | a >> n(32) - b) & mask32;
}
function XXH3_accumulate_512(acc, dataView, keyView) {
  for (let i = 0; i < ACC_NB; i += 1) {
    const data_val = dataView.getBigUint64(i * 8, true);
    const data_key = data_val ^ keyView.getBigUint64(i * 8, true);
    acc[i ^ 1] += data_val;
    acc[i] += XXH_mult32to64(data_key, data_key >> n(32));
  }
  return acc;
}
function XXH3_accumulate(acc, dataView, keyView, nbStripes) {
  for (let n2 = 0; n2 < nbStripes; n2 += 1) XXH3_accumulate_512(acc, view(dataView, n2 * STRIPE_LEN), view(keyView, n2 * 8));
  return acc;
}
function XXH3_scrambleAcc(acc, key) {
  for (let i = 0; i < ACC_NB; i += 1) {
    const key64 = key.getBigUint64(i * 8, true);
    let acc64 = acc[i];
    acc64 = xorshift64(acc64, n(47));
    acc64 ^= key64;
    acc64 *= PRIME32_1;
    acc[i] = acc64 & mask64;
  }
  return acc;
}
function XXH3_mix2Accs(acc, key) {
  return XXH3_mul128_fold64(acc[0] ^ key.getBigUint64(0, true), acc[1] ^ key.getBigUint64(_U64, true));
}
function XXH3_mergeAccs(acc, key, start) {
  let result64 = start;
  result64 += XXH3_mix2Accs(acc.slice(0), view(key, 0 * _U32));
  result64 += XXH3_mix2Accs(acc.slice(2), view(key, 4 * _U32));
  result64 += XXH3_mix2Accs(acc.slice(4), view(key, 8 * _U32));
  result64 += XXH3_mix2Accs(acc.slice(6), view(key, 12 * _U32));
  return XXH3_avalanche(result64 & mask64);
}
function XXH3_hashLong(input, data, secret, f_acc, f_scramble) {
  let acc = input;
  const nbStripesPerBlock = Math.floor((secret.byteLength - STRIPE_LEN) / 8);
  const block_len = STRIPE_LEN * nbStripesPerBlock;
  const nb_blocks = Math.floor((data.byteLength - 1) / block_len);
  for (let n2 = 0; n2 < nb_blocks; n2 += 1) {
    acc = XXH3_accumulate(acc, view(data, n2 * block_len), secret, nbStripesPerBlock);
    acc = f_scramble(acc, view(secret, secret.byteLength - STRIPE_LEN));
  }
  {
    const nbStripes = Math.floor((data.byteLength - 1 - block_len * nb_blocks) / STRIPE_LEN);
    acc = XXH3_accumulate(acc, view(data, nb_blocks * block_len), secret, nbStripes);
    acc = f_acc(acc, view(data, data.byteLength - STRIPE_LEN), view(secret, secret.byteLength - STRIPE_LEN - 7));
  }
  return acc;
}
function XXH3_hashLong_128b(data, secret) {
  let acc = new BigUint64Array([
    PRIME32_3,
    PRIME64_1,
    PRIME64_2,
    PRIME64_3,
    PRIME64_4,
    PRIME32_2,
    PRIME64_5,
    PRIME32_1
  ]);
  assert(data.byteLength > 128);
  acc = XXH3_hashLong(acc, data, secret, XXH3_accumulate_512, XXH3_scrambleAcc);
  assert(acc.length * 8 === 64);
  {
    const low64 = XXH3_mergeAccs(acc, view(secret, 11), n(data.byteLength) * PRIME64_1 & mask64);
    return XXH3_mergeAccs(acc, view(secret, secret.byteLength - STRIPE_LEN - 11), ~(n(data.byteLength) * PRIME64_2) & mask64) << n(64) | low64;
  }
}
function XXH3_mul128_fold64(a, b) {
  const lll = a * b & mask128;
  return lll & mask64 ^ lll >> n(64);
}
function XXH3_mix16B(dataView, keyView, seed) {
  return XXH3_mul128_fold64((dataView.getBigUint64(0, true) ^ keyView.getBigUint64(0, true) + seed) & mask64, (dataView.getBigUint64(8, true) ^ keyView.getBigUint64(8, true) - seed) & mask64);
}
function XXH3_mix32B(acc, data1, data2, key, seed) {
  let accl = acc & mask64;
  let acch = acc >> n(64) & mask64;
  accl += XXH3_mix16B(data1, key, seed);
  accl ^= data2.getBigUint64(0, true) + data2.getBigUint64(8, true);
  accl &= mask64;
  acch += XXH3_mix16B(data2, view(key, 16), seed);
  acch ^= data1.getBigUint64(0, true) + data1.getBigUint64(8, true);
  acch &= mask64;
  return acch << n(64) | accl;
}
function XXH3_avalanche(input) {
  let h64 = input;
  h64 ^= h64 >> n(37);
  h64 *= PRIME_MX1;
  h64 &= mask64;
  h64 ^= h64 >> n(32);
  return h64;
}
function XXH3_avalanche64(input) {
  let h64 = input;
  h64 ^= h64 >> n(33);
  h64 *= PRIME64_2;
  h64 &= mask64;
  h64 ^= h64 >> n(29);
  h64 *= PRIME64_3;
  h64 &= mask64;
  h64 ^= h64 >> n(32);
  return h64;
}
function XXH3_len_1to3_128b(data, key32, seed) {
  const len = data.byteLength;
  assert(len > 0 && len <= 3);
  const combined = n(data.getUint8(len - 1)) | n(len << 8) | n(data.getUint8(0) << 16) | n(data.getUint8(len >> 1) << 24);
  const low = (combined ^ (n(key32.getUint32(0, true)) ^ n(key32.getUint32(4, true))) + seed) & mask64;
  const bhigh = (n(key32.getUint32(8, true)) ^ n(key32.getUint32(12, true))) - seed;
  return (XXH3_avalanche64((rotl32(bswap32(combined), n(13)) ^ bhigh) & mask64) & mask64) << n(64) | XXH3_avalanche64(low);
}
function xorshift64(b, shift) {
  return b ^ b >> shift;
}
function XXH3_len_4to8_128b(data, key32, seed) {
  const len = data.byteLength;
  assert(len >= 4 && len <= 8);
  {
    const l1 = data.getUint32(0, true);
    const l2 = data.getUint32(len - 4, true);
    let m128 = ((n(l1) | n(l2) << n(32)) ^ (key32.getBigUint64(16, true) ^ key32.getBigUint64(24, true)) + seed & mask64) * (PRIME64_1 + (n(len) << n(2))) & mask128;
    m128 += (m128 & mask64) << n(65);
    m128 &= mask128;
    m128 ^= m128 >> n(67);
    return xorshift64(xorshift64(m128 & mask64, n(35)) * PRIME_MX2 & mask64, n(28)) | XXH3_avalanche(m128 >> n(64)) << n(64);
  }
}
function XXH3_len_9to16_128b(data, key64, seed) {
  const len = data.byteLength;
  assert(len >= 9 && len <= 16);
  {
    const bitflipl = (key64.getBigUint64(32, true) ^ key64.getBigUint64(40, true)) + seed & mask64;
    const bitfliph = (key64.getBigUint64(48, true) ^ key64.getBigUint64(56, true)) - seed & mask64;
    const ll1 = data.getBigUint64(0, true);
    let ll2 = data.getBigUint64(len - 8, true);
    let m128 = (ll1 ^ ll2 ^ bitflipl) * PRIME64_1;
    const m128_l = (m128 & mask64) + (n(len - 1) << n(54));
    m128 = m128 & (mask128 ^ mask64) | m128_l;
    ll2 ^= bitfliph;
    m128 += ll2 + (ll2 & mask32) * (PRIME32_2 - n(1)) << n(64);
    m128 &= mask128;
    m128 ^= bswap64(m128 >> n(64));
    let h128 = (m128 & mask64) * PRIME64_2;
    h128 += (m128 >> n(64)) * PRIME64_2 << n(64);
    h128 &= mask128;
    return XXH3_avalanche(h128 & mask64) | XXH3_avalanche(h128 >> n(64)) << n(64);
  }
}
function XXH3_len_0to16_128b(data, seed) {
  const len = data.byteLength;
  assert(len <= 16);
  if (len > 8) return XXH3_len_9to16_128b(data, kkey, seed);
  if (len >= 4) return XXH3_len_4to8_128b(data, kkey, seed);
  if (len > 0) return XXH3_len_1to3_128b(data, kkey, seed);
  return XXH3_avalanche64(seed ^ kkey.getBigUint64(64, true) ^ kkey.getBigUint64(72, true)) | XXH3_avalanche64(seed ^ kkey.getBigUint64(80, true) ^ kkey.getBigUint64(88, true)) << n(64);
}
function inv64(x) {
  return ~x + n(1) & mask64;
}
function XXH3_len_17to128_128b(data, secret, seed) {
  let acc = n(data.byteLength) * PRIME64_1 & mask64;
  let i = n(data.byteLength - 1) / n(32);
  while (i >= 0) {
    const ni = Number(i);
    acc = XXH3_mix32B(acc, view(data, 16 * ni), view(data, data.byteLength - 16 * (ni + 1)), view(secret, 32 * ni), seed);
    i -= n(1);
  }
  let h128l = acc + (acc >> n(64)) & mask64;
  h128l = XXH3_avalanche(h128l);
  let h128h = (acc & mask64) * PRIME64_1 + (acc >> n(64)) * PRIME64_4 + (n(data.byteLength) - seed & mask64) * PRIME64_2;
  h128h &= mask64;
  h128h = inv64(XXH3_avalanche(h128h));
  return h128l | h128h << n(64);
}
function XXH3_len_129to240_128b(data, secret, seed) {
  let acc = n(data.byteLength) * PRIME64_1 & mask64;
  for (let i = 32; i < 160; i += 32) acc = XXH3_mix32B(acc, view(data, i - 32), view(data, i - 16), view(secret, i - 32), seed);
  acc = XXH3_avalanche(acc & mask64) | XXH3_avalanche(acc >> n(64)) << n(64);
  for (let i = 160; i <= data.byteLength; i += 32) acc = XXH3_mix32B(acc, view(data, i - 32), view(data, i - 16), view(secret, 3 + i - 160), seed);
  acc = XXH3_mix32B(acc, view(data, data.byteLength - 16), view(data, data.byteLength - 32), view(secret, 103), inv64(seed));
  let h128l = acc + (acc >> n(64)) & mask64;
  h128l = XXH3_avalanche(h128l);
  let h128h = (acc & mask64) * PRIME64_1 + (acc >> n(64)) * PRIME64_4 + (n(data.byteLength) - seed & mask64) * PRIME64_2;
  h128h &= mask64;
  h128h = inv64(XXH3_avalanche(h128h));
  return h128l | h128h << n(64);
}
function XXH3(input, seed = n(0)) {
  const encoder = new TextEncoder();
  const data = view(typeof input === "string" ? encoder.encode(input) : input);
  const len = data.byteLength;
  const hexDigest = (data2) => data2.toString(16).padStart(32, "0");
  if (len <= 16) return hexDigest(XXH3_len_0to16_128b(data, seed));
  if (len <= 128) return hexDigest(XXH3_len_17to128_128b(data, kkey, seed));
  if (len <= 240) return hexDigest(XXH3_len_129to240_128b(data, kkey, seed));
  return hexDigest(XXH3_hashLong_128b(data, kkey));
}
function isXXH3(value) {
  return /^[0-9a-f]{32}$/.test(value);
}

// node_modules/@langchain/langgraph/dist/interrupt.js
function interrupt(value) {
  const config2 = AsyncLocalStorageProviderSingleton.getRunnableConfig();
  if (!config2) throw new Error("Called interrupt() outside the context of a graph.");
  const conf = config2.configurable;
  if (!conf) throw new Error("No configurable found in config");
  if (!conf[CONFIG_KEY_CHECKPOINTER]) throw new GraphValueError("No checkpointer set", { lc_error_code: "MISSING_CHECKPOINTER" });
  const scratchpad = conf[CONFIG_KEY_SCRATCHPAD];
  scratchpad.interruptCounter += 1;
  const idx = scratchpad.interruptCounter;
  if (scratchpad.resume.length > 0 && idx < scratchpad.resume.length) {
    conf[CONFIG_KEY_SEND]?.([[RESUME2, scratchpad.resume]]);
    return scratchpad.resume[idx];
  }
  if (scratchpad.nullResume !== void 0) {
    if (scratchpad.resume.length !== idx) throw new Error(`Resume length mismatch: ${scratchpad.resume.length} !== ${idx}`);
    const v = scratchpad.consumeNullResume();
    scratchpad.resume.push(v);
    conf[CONFIG_KEY_SEND]?.([[RESUME2, scratchpad.resume]]);
    return v;
  }
  const ns = conf[CONFIG_KEY_CHECKPOINT_NS]?.split(CHECKPOINT_NAMESPACE_SEPARATOR);
  throw new GraphInterrupt([{
    id: ns ? XXH3(ns.join(CHECKPOINT_NAMESPACE_SEPARATOR)) : void 0,
    value
  }]);
}

// node_modules/@langchain/langgraph/dist/utils.js
var RunnableCallable = class extends Runnable {
  lc_namespace = ["langgraph"];
  func;
  tags;
  config;
  trace = true;
  recurse = true;
  constructor(fields) {
    super();
    this.name = fields.name ?? fields.func.name;
    this.func = fields.func;
    this.config = fields.tags ? { tags: fields.tags } : void 0;
    this.trace = fields.trace ?? this.trace;
    this.recurse = fields.recurse ?? this.recurse;
  }
  async _tracedInvoke(input, config2, runManager) {
    return new Promise((resolve, reject) => {
      const childConfig = patchConfig(config2, { callbacks: runManager?.getChild() });
      AsyncLocalStorageProviderSingleton.runWithConfig(childConfig, async () => {
        try {
          resolve(await this.func(input, childConfig));
        } catch (e) {
          reject(e);
        }
      });
    });
  }
  async invoke(input, options) {
    let returnValue;
    const config2 = ensureLangGraphConfig(options);
    const mergedConfig = mergeConfigs(this.config, config2);
    if (this.trace) returnValue = await this._callWithConfig(this._tracedInvoke, input, mergedConfig);
    else returnValue = await AsyncLocalStorageProviderSingleton.runWithConfig(mergedConfig, async () => this.func(input, mergedConfig));
    if (Runnable.isRunnable(returnValue) && this.recurse) return await AsyncLocalStorageProviderSingleton.runWithConfig(mergedConfig, async () => returnValue.invoke(input, mergedConfig));
    return returnValue;
  }
};
function* prefixGenerator(generator, prefix) {
  if (prefix === void 0) yield* generator;
  else for (const value of generator) yield [prefix, value];
}
async function gatherIterator(i) {
  const out = [];
  for await (const item of await i) out.push(item);
  return out;
}
function gatherIteratorSync(i) {
  const out = [];
  for (const item of i) out.push(item);
  return out;
}
function patchConfigurable(config2, patch) {
  if (!config2) return { configurable: patch };
  else if (!("configurable" in config2)) return {
    ...config2,
    configurable: patch
  };
  else return {
    ...config2,
    configurable: {
      ...config2.configurable,
      ...patch
    }
  };
}
function isAsyncGeneratorFunction(val) {
  return val != null && typeof val === "function" && val instanceof Object.getPrototypeOf(async function* () {
  }).constructor;
}
function isGeneratorFunction(val) {
  return val != null && typeof val === "function" && val instanceof Object.getPrototypeOf(function* () {
  }).constructor;
}

// node_modules/@langchain/langgraph/dist/pregel/write.js
var SKIP_WRITE = { [/* @__PURE__ */ Symbol.for("LG_SKIP_WRITE")]: true };
function _isSkipWrite(x) {
  return typeof x === "object" && x?.[/* @__PURE__ */ Symbol.for("LG_SKIP_WRITE")] !== void 0;
}
var PASSTHROUGH = { [/* @__PURE__ */ Symbol.for("LG_PASSTHROUGH")]: true };
function _isPassthrough(x) {
  return typeof x === "object" && x?.[/* @__PURE__ */ Symbol.for("LG_PASSTHROUGH")] !== void 0;
}
var IS_WRITER = /* @__PURE__ */ Symbol("IS_WRITER");
var ChannelWrite = class ChannelWrite2 extends RunnableCallable {
  writes;
  constructor(writes, tags) {
    const name = `ChannelWrite<${writes.map((packet) => {
      if (_isSend(packet)) return packet.node;
      else if ("channel" in packet) return packet.channel;
      return "...";
    }).join(",")}>`;
    super({
      writes,
      name,
      tags,
      func: async (input, config2) => {
        return this._write(input, config2 ?? {});
      }
    });
    this.writes = writes;
  }
  async _write(input, config2) {
    const writes = this.writes.map((write) => {
      if (_isChannelWriteTupleEntry(write) && _isPassthrough(write.value)) return {
        mapper: write.mapper,
        value: input
      };
      else if (_isChannelWriteEntry(write) && _isPassthrough(write.value)) return {
        channel: write.channel,
        value: input,
        skipNone: write.skipNone,
        mapper: write.mapper
      };
      else return write;
    });
    await ChannelWrite2.doWrite(config2, writes);
    return input;
  }
  static async doWrite(config2, writes) {
    for (const w of writes) {
      if (_isChannelWriteEntry(w)) {
        if (w.channel === TASKS2) throw new InvalidUpdateError("Cannot write to the reserved channel TASKS");
        if (_isPassthrough(w.value)) throw new InvalidUpdateError("PASSTHROUGH value must be replaced");
      }
      if (_isChannelWriteTupleEntry(w)) {
        if (_isPassthrough(w.value)) throw new InvalidUpdateError("PASSTHROUGH value must be replaced");
      }
    }
    const writeEntries = [];
    for (const w of writes) if (_isSend(w)) writeEntries.push([TASKS2, w]);
    else if (_isChannelWriteTupleEntry(w)) {
      const mappedResult = await w.mapper.invoke(w.value, config2);
      if (mappedResult != null && mappedResult.length > 0) writeEntries.push(...mappedResult);
    } else if (_isChannelWriteEntry(w)) {
      const mappedValue = w.mapper !== void 0 ? await w.mapper.invoke(w.value, config2) : w.value;
      if (_isSkipWrite(mappedValue)) continue;
      if (w.skipNone && mappedValue === void 0) continue;
      writeEntries.push([w.channel, mappedValue]);
    } else throw new Error(`Invalid write entry: ${JSON.stringify(w)}`);
    const write = config2.configurable?.[CONFIG_KEY_SEND];
    write(writeEntries);
  }
  static isWriter(runnable) {
    return runnable instanceof ChannelWrite2 || IS_WRITER in runnable && !!runnable[IS_WRITER];
  }
  static registerWriter(runnable) {
    return Object.defineProperty(runnable, IS_WRITER, { value: true });
  }
};
function _isChannelWriteEntry(x) {
  return x !== void 0 && typeof x.channel === "string";
}
function _isChannelWriteTupleEntry(x) {
  return x !== void 0 && !_isChannelWriteEntry(x) && Runnable.isRunnable(x.mapper);
}

// node_modules/@langchain/langgraph/dist/pregel/read.js
var ChannelRead = class ChannelRead2 extends RunnableCallable {
  lc_graph_name = "ChannelRead";
  channel;
  fresh = false;
  mapper;
  constructor(channel, mapper, fresh = false) {
    super({ func: (_, config2) => ChannelRead2.doRead(config2, this.channel, this.fresh, this.mapper) });
    this.fresh = fresh;
    this.mapper = mapper;
    this.channel = channel;
    this.name = Array.isArray(channel) ? `ChannelRead<${channel.join(",")}>` : `ChannelRead<${channel}>`;
  }
  static doRead(config2, channel, fresh, mapper) {
    const read = config2.configurable?.[CONFIG_KEY_READ];
    if (!read) throw new Error("Runnable is not configured with a read function. Make sure to call in the context of a Pregel process");
    if (mapper) return mapper(read(channel, fresh));
    else return read(channel, fresh);
  }
};
var defaultRunnableBound = new RunnablePassthrough();
var PregelNode = class PregelNode2 extends RunnableBinding {
  lc_graph_name = "PregelNode";
  channels;
  triggers = [];
  mapper;
  writers = [];
  bound = defaultRunnableBound;
  kwargs = {};
  metadata = {};
  tags = [];
  retryPolicy;
  cachePolicy;
  subgraphs;
  ends;
  constructor(fields) {
    const { channels, triggers, mapper, writers, bound, kwargs, metadata, retryPolicy, cachePolicy, tags, subgraphs, ends } = fields;
    const mergedTags = [...fields.config?.tags ? fields.config.tags : [], ...tags ?? []];
    super({
      ...fields,
      bound: fields.bound ?? defaultRunnableBound,
      config: {
        ...fields.config ? fields.config : {},
        tags: mergedTags
      }
    });
    this.channels = channels;
    this.triggers = triggers;
    this.mapper = mapper;
    this.writers = writers ?? this.writers;
    this.bound = bound ?? this.bound;
    this.kwargs = kwargs ?? this.kwargs;
    this.metadata = metadata ?? this.metadata;
    this.tags = mergedTags;
    this.retryPolicy = retryPolicy;
    this.cachePolicy = cachePolicy;
    this.subgraphs = subgraphs;
    this.ends = ends;
  }
  getWriters() {
    const newWriters = [...this.writers];
    while (newWriters.length > 1 && newWriters[newWriters.length - 1] instanceof ChannelWrite && newWriters[newWriters.length - 2] instanceof ChannelWrite) {
      const endWriters = newWriters.slice(-2);
      const combinedWrites = endWriters[0].writes.concat(endWriters[1].writes);
      newWriters[newWriters.length - 2] = new ChannelWrite(combinedWrites, endWriters[0].config?.tags);
      newWriters.pop();
    }
    return newWriters;
  }
  getNode() {
    const writers = this.getWriters();
    if (this.bound === defaultRunnableBound && writers.length === 0) return;
    else if (this.bound === defaultRunnableBound && writers.length === 1) return writers[0];
    else if (this.bound === defaultRunnableBound) return new RunnableSequence({
      first: writers[0],
      middle: writers.slice(1, writers.length - 1),
      last: writers[writers.length - 1],
      omitSequenceTags: true
    });
    else if (writers.length > 0) return new RunnableSequence({
      first: this.bound,
      middle: writers.slice(0, writers.length - 1),
      last: writers[writers.length - 1],
      omitSequenceTags: true
    });
    else return this.bound;
  }
  join(channels) {
    if (!Array.isArray(channels)) throw new Error("channels must be a list");
    if (typeof this.channels !== "object") throw new Error("all channels must be named when using .join()");
    return new PregelNode2({
      channels: {
        ...this.channels,
        ...Object.fromEntries(channels.map((chan) => [chan, chan]))
      },
      triggers: this.triggers,
      mapper: this.mapper,
      writers: this.writers,
      bound: this.bound,
      kwargs: this.kwargs,
      config: this.config,
      retryPolicy: this.retryPolicy,
      cachePolicy: this.cachePolicy
    });
  }
  pipe(coerceable) {
    if (ChannelWrite.isWriter(coerceable)) return new PregelNode2({
      channels: this.channels,
      triggers: this.triggers,
      mapper: this.mapper,
      writers: [...this.writers, coerceable],
      bound: this.bound,
      config: this.config,
      kwargs: this.kwargs,
      retryPolicy: this.retryPolicy,
      cachePolicy: this.cachePolicy
    });
    else if (this.bound === defaultRunnableBound) return new PregelNode2({
      channels: this.channels,
      triggers: this.triggers,
      mapper: this.mapper,
      writers: this.writers,
      bound: _coerceToRunnable(coerceable),
      config: this.config,
      kwargs: this.kwargs,
      retryPolicy: this.retryPolicy,
      cachePolicy: this.cachePolicy
    });
    else return new PregelNode2({
      channels: this.channels,
      triggers: this.triggers,
      mapper: this.mapper,
      writers: this.writers,
      bound: this.bound.pipe(coerceable),
      config: this.config,
      kwargs: this.kwargs,
      retryPolicy: this.retryPolicy,
      cachePolicy: this.cachePolicy
    });
  }
};

// node_modules/@langchain/langgraph/dist/pregel/utils/subgraph.js
function isRunnableSequence(x) {
  return "steps" in x && Array.isArray(x.steps);
}
function isPregelLike(x) {
  return "lg_is_pregel" in x && x.lg_is_pregel === true;
}
function findSubgraphPregel(candidate) {
  const candidates = [candidate];
  for (const candidate2 of candidates) if (isPregelLike(candidate2)) return candidate2;
  else if (isRunnableSequence(candidate2)) candidates.push(...candidate2.steps);
}

// node_modules/@langchain/langgraph/dist/pregel/io.js
function readChannel(channels, chan, catchErrors = true, returnException = false) {
  try {
    return channels[chan].get();
  } catch (e) {
    if (e.name === EmptyChannelError.unminifiable_name) {
      if (returnException) return e;
      else if (catchErrors) return null;
    }
    throw e;
  }
}
function readChannels(channels, select, skipEmpty = true) {
  if (Array.isArray(select)) {
    const values = {};
    for (const k of select) try {
      values[k] = readChannel(channels, k, !skipEmpty);
    } catch (e) {
      if (e.name === EmptyChannelError.unminifiable_name) continue;
    }
    return values;
  } else return readChannel(channels, select);
}
function* mapCommand(cmd, pendingWrites) {
  if (cmd.graph === Command.PARENT) throw new InvalidUpdateError("There is no parent graph.");
  if (cmd.goto) {
    let sends;
    if (Array.isArray(cmd.goto)) sends = cmd.goto;
    else sends = [cmd.goto];
    for (const send of sends) if (_isSend(send)) yield [
      NULL_TASK_ID,
      TASKS2,
      send
    ];
    else if (typeof send === "string") yield [
      NULL_TASK_ID,
      `branch:to:${send}`,
      "__start__"
    ];
    else throw new Error(`In Command.send, expected Send or string, got ${typeof send}`);
  }
  if (cmd.resume) if (typeof cmd.resume === "object" && Object.keys(cmd.resume).length && Object.keys(cmd.resume).every(isXXH3)) for (const [tid, resume] of Object.entries(cmd.resume)) {
    const existing = pendingWrites.filter((w) => w[0] === tid && w[1] === RESUME2).map((w) => w[2]).slice(0, 1) ?? [];
    existing.push(resume);
    yield [
      tid,
      RESUME2,
      existing
    ];
  }
  else yield [
    NULL_TASK_ID,
    RESUME2,
    cmd.resume
  ];
  if (cmd.update) {
    if (typeof cmd.update !== "object" || !cmd.update) throw new Error("Expected cmd.update to be a dict mapping channel names to update values");
    if (Array.isArray(cmd.update)) for (const [k, v] of cmd.update) yield [
      NULL_TASK_ID,
      k,
      v
    ];
    else for (const [k, v] of Object.entries(cmd.update)) yield [
      NULL_TASK_ID,
      k,
      v
    ];
  }
}
function* mapInput(inputChannels, chunk) {
  if (chunk !== void 0 && chunk !== null) if (Array.isArray(inputChannels) && typeof chunk === "object" && !Array.isArray(chunk)) {
    for (const k in chunk) if (inputChannels.includes(k)) yield [k, chunk[k]];
  } else if (Array.isArray(inputChannels)) throw new Error(`Input chunk must be an object when "inputChannels" is an array`);
  else yield [inputChannels, chunk];
}
function* mapOutputValues(outputChannels, pendingWrites, channels) {
  if (Array.isArray(outputChannels)) {
    if (pendingWrites === true || pendingWrites.find(([chan, _]) => outputChannels.includes(chan))) yield readChannels(channels, outputChannels);
  } else if (pendingWrites === true || pendingWrites.some(([chan, _]) => chan === outputChannels)) yield readChannel(channels, outputChannels);
}
function* mapOutputUpdates(outputChannels, tasks, cached) {
  const outputTasks = tasks.filter(([task2, ww]) => {
    return (task2.config === void 0 || !task2.config.tags?.includes(TAG_HIDDEN)) && ww[0][0] !== ERROR3 && ww[0][0] !== INTERRUPT2;
  });
  if (!outputTasks.length) return;
  let updated;
  if (outputTasks.some(([task2]) => task2.writes.some(([chan, _]) => chan === RETURN))) updated = outputTasks.flatMap(([task2]) => task2.writes.filter(([chan, _]) => chan === RETURN).map(([_, value]) => [task2.name, value]));
  else if (!Array.isArray(outputChannels)) updated = outputTasks.flatMap(([task2]) => task2.writes.filter(([chan, _]) => chan === outputChannels).map(([_, value]) => [task2.name, value]));
  else updated = outputTasks.flatMap(([task2]) => {
    const { writes } = task2;
    const counts = {};
    for (const [chan] of writes) if (outputChannels.includes(chan)) counts[chan] = (counts[chan] || 0) + 1;
    if (Object.values(counts).some((count) => count > 1)) return writes.filter(([chan]) => outputChannels.includes(chan)).map(([chan, value]) => [task2.name, { [chan]: value }]);
    else return [[task2.name, Object.fromEntries(writes.filter(([chan]) => outputChannels.includes(chan)))]];
  });
  const grouped = {};
  for (const [node, value] of updated) {
    if (!(node in grouped)) grouped[node] = [];
    grouped[node].push(value);
  }
  const flattened = {};
  for (const node in grouped) if (grouped[node].length === 1) {
    const [write] = grouped[node];
    flattened[node] = write;
  } else flattened[node] = grouped[node];
  if (cached) flattened["__metadata__"] = { cached };
  yield flattened;
}

// node_modules/@langchain/langgraph/dist/pregel/utils/index.js
function getNullChannelVersion(currentVersions) {
  const startVersion = typeof currentVersions[START];
  if (startVersion === "number") return 0;
  if (startVersion === "string") return "";
  for (const key in currentVersions) {
    if (!Object.prototype.hasOwnProperty.call(currentVersions, key)) continue;
    const versionType = typeof currentVersions[key];
    if (versionType === "number") return 0;
    if (versionType === "string") return "";
    break;
  }
}
function getNewChannelVersions(previousVersions, currentVersions) {
  if (Object.keys(previousVersions).length > 0) {
    const nullVersion = getNullChannelVersion(currentVersions);
    return Object.fromEntries(Object.entries(currentVersions).filter(([k, v]) => v > (previousVersions[k] ?? nullVersion)));
  } else return currentVersions;
}
function _coerceToDict2(value, defaultKey) {
  return value && !Array.isArray(value) && !(value instanceof Date) && typeof value === "object" ? value : { [defaultKey]: value };
}
function patchConfigurable2(config2, patch) {
  if (config2 === null) return { configurable: patch };
  else if (config2?.configurable === void 0) return {
    ...config2,
    configurable: patch
  };
  else return {
    ...config2,
    configurable: {
      ...config2.configurable,
      ...patch
    }
  };
}
function patchCheckpointMap(config2, metadata) {
  const parents = metadata?.parents ?? {};
  if (Object.keys(parents).length > 0) return patchConfigurable2(config2, { [CONFIG_KEY_CHECKPOINT_MAP]: {
    ...parents,
    [config2.configurable?.checkpoint_ns ?? ""]: config2.configurable?.checkpoint_id
  } });
  else return config2;
}
function combineAbortSignals(...x) {
  const signals = [...new Set(x.filter(Boolean))];
  if (signals.length === 0) return {
    signal: void 0,
    dispose: void 0
  };
  if (signals.length === 1) return {
    signal: signals[0],
    dispose: void 0
  };
  const combinedController = new AbortController();
  const listener = () => {
    const reason = signals.find((s) => s.aborted)?.reason;
    combinedController.abort(reason);
    signals.forEach((s) => s.removeEventListener("abort", listener));
  };
  signals.forEach((s) => s.addEventListener("abort", listener, { once: true }));
  const hasAlreadyAbortedSignal = signals.find((s) => s.aborted);
  if (hasAlreadyAbortedSignal) combinedController.abort(hasAlreadyAbortedSignal.reason);
  return {
    signal: combinedController.signal,
    dispose: () => {
      signals.forEach((s) => s.removeEventListener("abort", listener));
    }
  };
}
var combineCallbacks = (callback1, callback2) => {
  if (!callback1 && !callback2) return;
  if (!callback1) return callback2;
  if (!callback2) return callback1;
  if (Array.isArray(callback1) && Array.isArray(callback2)) return [...callback1, ...callback2];
  if (Array.isArray(callback1)) return [...callback1, callback2];
  if (Array.isArray(callback2)) return [callback1, ...callback2];
  return [callback1, callback2];
};

// node_modules/@langchain/langgraph/dist/pregel/types.js
var Call = class {
  func;
  name;
  input;
  retry;
  cache;
  callbacks;
  __lg_type = "call";
  constructor({ func, name, input, retry, cache, callbacks }) {
    this.func = func;
    this.name = name;
    this.input = input;
    this.retry = retry;
    this.cache = cache;
    this.callbacks = callbacks;
  }
};
function isCall(value) {
  return typeof value === "object" && value !== null && "__lg_type" in value && value.__lg_type === "call";
}

// node_modules/@langchain/langgraph/dist/pregel/call.js
function getRunnableForFunc(name, func) {
  return new RunnableSequence({
    name,
    first: new RunnableCallable({
      func: (input) => func(...input),
      name,
      trace: false,
      recurse: false
    }),
    last: new ChannelWrite([{
      channel: RETURN,
      value: PASSTHROUGH
    }], [TAG_HIDDEN])
  });
}
function getRunnableForEntrypoint(name, func) {
  return new RunnableCallable({
    func: (input, config2) => {
      return func(input, config2);
    },
    name,
    trace: false,
    recurse: false
  });
}

// node_modules/@langchain/langgraph/dist/pregel/algo.js
var increment = (current) => {
  return current !== void 0 ? current + 1 : 1;
};
function triggersNextStep(updatedChannels, triggerToNodes) {
  if (triggerToNodes == null) return false;
  for (const chan of updatedChannels) if (triggerToNodes[chan]) return true;
  return false;
}
function maxChannelMapVersion(channelVersions) {
  let maxVersion;
  for (const chan in channelVersions) {
    if (!Object.prototype.hasOwnProperty.call(channelVersions, chan)) continue;
    if (maxVersion == null) maxVersion = channelVersions[chan];
    else maxVersion = maxChannelVersion(maxVersion, channelVersions[chan]);
  }
  return maxVersion;
}
function shouldInterrupt(checkpoint, interruptNodes, tasks) {
  const nullVersion = getNullChannelVersion(checkpoint.channel_versions);
  const seen = checkpoint.versions_seen[INTERRUPT2] ?? {};
  let anyChannelUpdated = false;
  if ((checkpoint.channel_versions[START] ?? nullVersion) > (seen[START] ?? nullVersion)) anyChannelUpdated = true;
  else for (const chan in checkpoint.channel_versions) {
    if (!Object.prototype.hasOwnProperty.call(checkpoint.channel_versions, chan)) continue;
    if (checkpoint.channel_versions[chan] > (seen[chan] ?? nullVersion)) {
      anyChannelUpdated = true;
      break;
    }
  }
  const anyTriggeredNodeInInterruptNodes = tasks.some((task2) => interruptNodes === "*" ? !task2.config?.tags?.includes(TAG_HIDDEN) : interruptNodes.includes(task2.name));
  return anyChannelUpdated && anyTriggeredNodeInInterruptNodes;
}
function _localRead(checkpoint, channels, task2, select, fresh = false) {
  let updated = /* @__PURE__ */ new Set();
  if (!Array.isArray(select)) {
    for (const [c] of task2.writes) if (c === select) {
      updated = /* @__PURE__ */ new Set([c]);
      break;
    }
    updated = updated || /* @__PURE__ */ new Set();
  } else updated = new Set(select.filter((c) => task2.writes.some(([key, _]) => key === c)));
  let values;
  if (fresh && updated.size > 0) {
    const localChannels = Object.fromEntries(Object.entries(channels).filter(([k, _]) => updated.has(k)));
    const newCheckpoint = createCheckpoint(checkpoint, localChannels, -1);
    const newChannels = emptyChannels(localChannels, newCheckpoint);
    _applyWrites(copyCheckpoint(newCheckpoint), newChannels, [task2], void 0, void 0);
    values = readChannels({
      ...channels,
      ...newChannels
    }, select);
  } else values = readChannels(channels, select);
  return values;
}
function _localWrite(commit, processes, writes) {
  for (const [chan, value] of writes) if ([PUSH, TASKS2].includes(chan) && value != null) {
    if (!_isSend(value)) throw new InvalidUpdateError(`Invalid packet type, expected SendProtocol, got ${JSON.stringify(value)}`);
    if (!(value.node in processes)) throw new InvalidUpdateError(`Invalid node name "${value.node}" in Send packet`);
  }
  commit(writes);
}
var IGNORE = /* @__PURE__ */ new Set([
  NO_WRITES,
  PUSH,
  RESUME2,
  INTERRUPT2,
  RETURN,
  ERROR3
]);
function _applyWrites(checkpoint, channels, tasks, getNextVersion, triggerToNodes) {
  tasks.sort((a, b) => {
    const aPath = a.path?.slice(0, 3) || [];
    const bPath = b.path?.slice(0, 3) || [];
    for (let i = 0; i < Math.min(aPath.length, bPath.length); i += 1) {
      if (aPath[i] < bPath[i]) return -1;
      if (aPath[i] > bPath[i]) return 1;
    }
    return aPath.length - bPath.length;
  });
  const bumpStep = tasks.some((task2) => task2.triggers.length > 0);
  const onlyChannels = getOnlyChannels(channels);
  for (const task2 of tasks) {
    checkpoint.versions_seen[task2.name] ??= {};
    for (const chan of task2.triggers) if (chan in checkpoint.channel_versions) checkpoint.versions_seen[task2.name][chan] = checkpoint.channel_versions[chan];
  }
  let maxVersion = maxChannelMapVersion(checkpoint.channel_versions);
  const channelsToConsume = new Set(tasks.flatMap((task2) => task2.triggers).filter((chan) => !RESERVED.includes(chan)));
  let usedNewVersion = false;
  for (const chan of channelsToConsume) if (chan in onlyChannels && onlyChannels[chan].consume()) {
    if (getNextVersion !== void 0) {
      checkpoint.channel_versions[chan] = getNextVersion(maxVersion);
      usedNewVersion = true;
    }
  }
  const pendingWritesByChannel = {};
  for (const task2 of tasks) for (const [chan, val] of task2.writes) if (IGNORE.has(chan)) {
  } else if (chan in onlyChannels) {
    pendingWritesByChannel[chan] ??= [];
    pendingWritesByChannel[chan].push(val);
  }
  if (maxVersion != null && getNextVersion != null) maxVersion = usedNewVersion ? getNextVersion(maxVersion) : maxVersion;
  const updatedChannels = /* @__PURE__ */ new Set();
  for (const [chan, vals] of Object.entries(pendingWritesByChannel)) if (chan in onlyChannels) {
    const channel = onlyChannels[chan];
    let updated;
    try {
      updated = channel.update(vals);
    } catch (e) {
      if (e.name === InvalidUpdateError.unminifiable_name) {
        const wrappedError = new InvalidUpdateError(`Invalid update for channel "${chan}" with values ${JSON.stringify(vals)}: ${e.message}`);
        wrappedError.lc_error_code = e.lc_error_code;
        throw wrappedError;
      } else throw e;
    }
    if (updated && getNextVersion !== void 0) {
      checkpoint.channel_versions[chan] = getNextVersion(maxVersion);
      if (channel.isAvailable()) updatedChannels.add(chan);
    }
  }
  if (bumpStep) for (const chan in onlyChannels) {
    if (!Object.prototype.hasOwnProperty.call(onlyChannels, chan)) continue;
    const channel = onlyChannels[chan];
    if (channel.isAvailable() && !updatedChannels.has(chan)) {
      if (channel.update([]) && getNextVersion !== void 0) {
        checkpoint.channel_versions[chan] = getNextVersion(maxVersion);
        if (channel.isAvailable()) updatedChannels.add(chan);
      }
    }
  }
  if (bumpStep && !triggersNextStep(updatedChannels, triggerToNodes)) for (const chan in onlyChannels) {
    if (!Object.prototype.hasOwnProperty.call(onlyChannels, chan)) continue;
    const channel = onlyChannels[chan];
    if (channel.finish() && getNextVersion !== void 0) {
      checkpoint.channel_versions[chan] = getNextVersion(maxVersion);
      if (channel.isAvailable()) updatedChannels.add(chan);
    }
  }
  return updatedChannels;
}
function* candidateNodes(checkpoint, processes, extra) {
  if (extra.updatedChannels != null && extra.triggerToNodes != null) {
    const triggeredNodes = /* @__PURE__ */ new Set();
    for (const channel of extra.updatedChannels) {
      const nodeIds = extra.triggerToNodes[channel];
      for (const id of nodeIds ?? []) triggeredNodes.add(id);
    }
    yield* [...triggeredNodes].sort();
    return;
  }
  if ((() => {
    for (const chan in checkpoint.channel_versions) if (checkpoint.channel_versions[chan] !== null) return false;
    return true;
  })()) return;
  for (const name in processes) {
    if (!Object.prototype.hasOwnProperty.call(processes, name)) continue;
    yield name;
  }
}
function _prepareNextTasks(checkpoint, pendingWrites, processes, channels, config2, forExecution, extra) {
  const tasks = {};
  const tasksChannel = channels[TASKS2];
  if (tasksChannel?.isAvailable()) {
    const len = tasksChannel.get().length;
    for (let i = 0; i < len; i += 1) {
      const task2 = _prepareSingleTask([PUSH, i], checkpoint, pendingWrites, processes, channels, config2, forExecution, extra);
      if (task2 !== void 0) tasks[task2.id] = task2;
    }
  }
  for (const name of candidateNodes(checkpoint, processes, extra)) {
    const task2 = _prepareSingleTask([PULL, name], checkpoint, pendingWrites, processes, channels, config2, forExecution, extra);
    if (task2 !== void 0) tasks[task2.id] = task2;
  }
  return tasks;
}
function _prepareSingleTask(taskPath, checkpoint, pendingWrites, processes, channels, config2, forExecution, extra) {
  const { step, checkpointer, manager } = extra;
  const configurable = config2.configurable ?? {};
  const parentNamespace = configurable.checkpoint_ns ?? "";
  if (taskPath[0] === PUSH && isCall(taskPath[taskPath.length - 1])) {
    const call3 = taskPath[taskPath.length - 1];
    const proc = getRunnableForFunc(call3.name, call3.func);
    const triggers = [PUSH];
    const checkpointNamespace = parentNamespace === "" ? call3.name : `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${call3.name}`;
    const id = uuid5(JSON.stringify([
      checkpointNamespace,
      step.toString(),
      call3.name,
      PUSH,
      taskPath[1],
      taskPath[2]
    ]), checkpoint.id);
    const taskCheckpointNamespace = `${checkpointNamespace}${CHECKPOINT_NAMESPACE_END}${id}`;
    const outputTaskPath = [...taskPath.slice(0, 3), true];
    const metadata = {
      langgraph_step: step,
      langgraph_node: call3.name,
      langgraph_triggers: triggers,
      langgraph_path: outputTaskPath,
      langgraph_checkpoint_ns: taskCheckpointNamespace
    };
    if (forExecution) {
      const writes = [];
      return {
        name: call3.name,
        input: call3.input,
        proc,
        writes,
        config: patchConfig(mergeConfigs(config2, {
          metadata,
          store: extra.store ?? config2.store
        }), {
          runName: call3.name,
          callbacks: manager?.getChild(`graph:step:${step}`),
          configurable: {
            [CONFIG_KEY_TASK_ID]: id,
            [CONFIG_KEY_SEND]: (writes_) => _localWrite((items) => writes.push(...items), processes, writes_),
            [CONFIG_KEY_READ]: (select_, fresh_ = false) => _localRead(checkpoint, channels, {
              name: call3.name,
              writes,
              triggers,
              path: outputTaskPath
            }, select_, fresh_),
            [CONFIG_KEY_CHECKPOINTER]: checkpointer ?? configurable[CONFIG_KEY_CHECKPOINTER],
            [CONFIG_KEY_CHECKPOINT_MAP]: {
              ...configurable[CONFIG_KEY_CHECKPOINT_MAP],
              [parentNamespace]: checkpoint.id
            },
            [CONFIG_KEY_SCRATCHPAD]: _scratchpad({
              pendingWrites: pendingWrites ?? [],
              taskId: id,
              currentTaskInput: call3.input,
              resumeMap: config2.configurable?.[CONFIG_KEY_RESUME_MAP],
              namespaceHash: XXH3(taskCheckpointNamespace)
            }),
            [CONFIG_KEY_PREVIOUS_STATE]: checkpoint.channel_values[PREVIOUS],
            checkpoint_id: void 0,
            checkpoint_ns: taskCheckpointNamespace
          }
        }),
        triggers,
        retry_policy: call3.retry,
        cache_key: call3.cache ? {
          key: XXH3((call3.cache.keyFunc ?? JSON.stringify)([call3.input])),
          ns: [CACHE_NS_WRITES, call3.name ?? "__dynamic__"],
          ttl: call3.cache.ttl
        } : void 0,
        id,
        path: outputTaskPath,
        writers: []
      };
    } else return {
      id,
      name: call3.name,
      interrupts: [],
      path: outputTaskPath
    };
  } else if (taskPath[0] === PUSH) {
    const index2 = typeof taskPath[1] === "number" ? taskPath[1] : parseInt(taskPath[1], 10);
    if (!channels[TASKS2]?.isAvailable()) return;
    const sends = channels[TASKS2].get();
    if (index2 < 0 || index2 >= sends.length) return;
    const packet = _isSendInterface(sends[index2]) && !_isSend(sends[index2]) ? new Send(sends[index2].node, sends[index2].args) : sends[index2];
    if (!_isSendInterface(packet)) {
      console.warn(`Ignoring invalid packet ${JSON.stringify(packet)} in pending sends.`);
      return;
    }
    if (!(packet.node in processes)) {
      console.warn(`Ignoring unknown node name ${packet.node} in pending sends.`);
      return;
    }
    const triggers = [PUSH];
    const checkpointNamespace = parentNamespace === "" ? packet.node : `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${packet.node}`;
    const taskId = uuid5(JSON.stringify([
      checkpointNamespace,
      step.toString(),
      packet.node,
      PUSH,
      index2.toString()
    ]), checkpoint.id);
    const taskCheckpointNamespace = `${checkpointNamespace}${CHECKPOINT_NAMESPACE_END}${taskId}`;
    let metadata = {
      langgraph_step: step,
      langgraph_node: packet.node,
      langgraph_triggers: triggers,
      langgraph_path: taskPath.slice(0, 3),
      langgraph_checkpoint_ns: taskCheckpointNamespace
    };
    if (forExecution) {
      const proc = processes[packet.node];
      const node = proc.getNode();
      if (node !== void 0) {
        if (proc.metadata !== void 0) metadata = {
          ...metadata,
          ...proc.metadata
        };
        const writes = [];
        return {
          name: packet.node,
          input: packet.args,
          proc: node,
          subgraphs: proc.subgraphs,
          writes,
          config: patchConfig(mergeConfigs(config2, {
            metadata,
            tags: proc.tags,
            store: extra.store ?? config2.store
          }), {
            runName: packet.node,
            callbacks: manager?.getChild(`graph:step:${step}`),
            configurable: {
              [CONFIG_KEY_TASK_ID]: taskId,
              [CONFIG_KEY_SEND]: (writes_) => _localWrite((items) => writes.push(...items), processes, writes_),
              [CONFIG_KEY_READ]: (select_, fresh_ = false) => _localRead(checkpoint, channels, {
                name: packet.node,
                writes,
                triggers,
                path: taskPath
              }, select_, fresh_),
              [CONFIG_KEY_CHECKPOINTER]: checkpointer ?? configurable[CONFIG_KEY_CHECKPOINTER],
              [CONFIG_KEY_CHECKPOINT_MAP]: {
                ...configurable[CONFIG_KEY_CHECKPOINT_MAP],
                [parentNamespace]: checkpoint.id
              },
              [CONFIG_KEY_SCRATCHPAD]: _scratchpad({
                pendingWrites: pendingWrites ?? [],
                taskId,
                currentTaskInput: packet.args,
                resumeMap: config2.configurable?.[CONFIG_KEY_RESUME_MAP],
                namespaceHash: XXH3(taskCheckpointNamespace)
              }),
              [CONFIG_KEY_PREVIOUS_STATE]: checkpoint.channel_values[PREVIOUS],
              checkpoint_id: void 0,
              checkpoint_ns: taskCheckpointNamespace
            }
          }),
          triggers,
          retry_policy: proc.retryPolicy,
          cache_key: proc.cachePolicy ? {
            key: XXH3((proc.cachePolicy.keyFunc ?? JSON.stringify)([packet.args])),
            ns: [
              CACHE_NS_WRITES,
              proc.name ?? "__dynamic__",
              packet.node
            ],
            ttl: proc.cachePolicy.ttl
          } : void 0,
          id: taskId,
          path: taskPath,
          writers: proc.getWriters()
        };
      }
    } else return {
      id: taskId,
      name: packet.node,
      interrupts: [],
      path: taskPath
    };
  } else if (taskPath[0] === PULL) {
    const name = taskPath[1].toString();
    const proc = processes[name];
    if (proc === void 0) return;
    if (pendingWrites?.length) {
      const checkpointNamespace = parentNamespace === "" ? name : `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${name}`;
      const taskId = uuid5(JSON.stringify([
        checkpointNamespace,
        step.toString(),
        name,
        PULL,
        name
      ]), checkpoint.id);
      if (pendingWrites.some((w) => w[0] === taskId && w[1] !== ERROR3)) return;
    }
    const nullVersion = getNullChannelVersion(checkpoint.channel_versions);
    if (nullVersion === void 0) return;
    const seen = checkpoint.versions_seen[name] ?? {};
    const trigger = proc.triggers.find((chan) => {
      if (!channels[chan].isAvailable()) return false;
      return (checkpoint.channel_versions[chan] ?? nullVersion) > (seen[chan] ?? nullVersion);
    });
    if (trigger !== void 0) {
      const val = _procInput(proc, channels, forExecution);
      if (val === void 0) return;
      const checkpointNamespace = parentNamespace === "" ? name : `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${name}`;
      const taskId = uuid5(JSON.stringify([
        checkpointNamespace,
        step.toString(),
        name,
        PULL,
        [trigger]
      ]), checkpoint.id);
      const taskCheckpointNamespace = `${checkpointNamespace}${CHECKPOINT_NAMESPACE_END}${taskId}`;
      let metadata = {
        langgraph_step: step,
        langgraph_node: name,
        langgraph_triggers: [trigger],
        langgraph_path: taskPath,
        langgraph_checkpoint_ns: taskCheckpointNamespace
      };
      if (forExecution) {
        const node = proc.getNode();
        if (node !== void 0) {
          if (proc.metadata !== void 0) metadata = {
            ...metadata,
            ...proc.metadata
          };
          const writes = [];
          return {
            name,
            input: val,
            proc: node,
            subgraphs: proc.subgraphs,
            writes,
            config: patchConfig(mergeConfigs(config2, {
              metadata,
              tags: proc.tags,
              store: extra.store ?? config2.store
            }), {
              runName: name,
              callbacks: manager?.getChild(`graph:step:${step}`),
              configurable: {
                [CONFIG_KEY_TASK_ID]: taskId,
                [CONFIG_KEY_SEND]: (writes_) => _localWrite((items) => {
                  writes.push(...items);
                }, processes, writes_),
                [CONFIG_KEY_READ]: (select_, fresh_ = false) => _localRead(checkpoint, channels, {
                  name,
                  writes,
                  triggers: [trigger],
                  path: taskPath
                }, select_, fresh_),
                [CONFIG_KEY_CHECKPOINTER]: checkpointer ?? configurable[CONFIG_KEY_CHECKPOINTER],
                [CONFIG_KEY_CHECKPOINT_MAP]: {
                  ...configurable[CONFIG_KEY_CHECKPOINT_MAP],
                  [parentNamespace]: checkpoint.id
                },
                [CONFIG_KEY_SCRATCHPAD]: _scratchpad({
                  pendingWrites: pendingWrites ?? [],
                  taskId,
                  currentTaskInput: val,
                  resumeMap: config2.configurable?.[CONFIG_KEY_RESUME_MAP],
                  namespaceHash: XXH3(taskCheckpointNamespace)
                }),
                [CONFIG_KEY_PREVIOUS_STATE]: checkpoint.channel_values[PREVIOUS],
                checkpoint_id: void 0,
                checkpoint_ns: taskCheckpointNamespace
              }
            }),
            triggers: [trigger],
            retry_policy: proc.retryPolicy,
            cache_key: proc.cachePolicy ? {
              key: XXH3((proc.cachePolicy.keyFunc ?? JSON.stringify)([val])),
              ns: [
                CACHE_NS_WRITES,
                proc.name ?? "__dynamic__",
                name
              ],
              ttl: proc.cachePolicy.ttl
            } : void 0,
            id: taskId,
            path: taskPath,
            writers: proc.getWriters()
          };
        }
      } else return {
        id: taskId,
        name,
        interrupts: [],
        path: taskPath
      };
    }
  }
}
function _procInput(proc, channels, forExecution) {
  let val;
  if (typeof proc.channels === "object" && !Array.isArray(proc.channels)) {
    val = {};
    for (const [k, chan] of Object.entries(proc.channels)) if (proc.triggers.includes(chan)) try {
      val[k] = readChannel(channels, chan, false);
    } catch (e) {
      if (e.name === EmptyChannelError.unminifiable_name) return;
      else throw e;
    }
    else if (chan in channels) try {
      val[k] = readChannel(channels, chan, false);
    } catch (e) {
      if (e.name === EmptyChannelError.unminifiable_name) continue;
      else throw e;
    }
  } else if (Array.isArray(proc.channels)) {
    let successfulRead = false;
    for (const chan of proc.channels) try {
      val = readChannel(channels, chan, false);
      successfulRead = true;
      break;
    } catch (e) {
      if (e.name === EmptyChannelError.unminifiable_name) continue;
      else throw e;
    }
    if (!successfulRead) return;
  } else throw new Error(`Invalid channels type, expected list or dict, got ${proc.channels}`);
  if (forExecution && proc.mapper !== void 0) val = proc.mapper(val);
  return val;
}
function sanitizeUntrackedValuesInSend(packet, channels) {
  if (typeof packet.args !== "object" || packet.args === null) return packet;
  const sanitizedArg = {};
  for (const [key, value] of Object.entries(packet.args)) {
    const channel = channels[key];
    if (!channel || channel.lc_graph_name !== "UntrackedValue") sanitizedArg[key] = value;
  }
  return new Send(packet.node, sanitizedArg);
}
function _scratchpad({ pendingWrites, taskId, currentTaskInput, resumeMap, namespaceHash }) {
  const nullResume = pendingWrites.find(([writeTaskId, chan]) => writeTaskId === NULL_TASK_ID && chan === RESUME2)?.[2];
  const scratchpad = {
    callCounter: 0,
    interruptCounter: -1,
    resume: (() => {
      const result = pendingWrites.filter(([writeTaskId, chan]) => writeTaskId === taskId && chan === RESUME2).flatMap(([_writeTaskId, _chan, resume]) => resume);
      if (resumeMap != null && namespaceHash in resumeMap) {
        const mappedResume = resumeMap[namespaceHash];
        result.push(mappedResume);
      }
      return result;
    })(),
    nullResume,
    subgraphCounter: 0,
    currentTaskInput,
    consumeNullResume: () => {
      if (scratchpad.nullResume) {
        delete scratchpad.nullResume;
        pendingWrites.splice(pendingWrites.findIndex(([writeTaskId, chan]) => writeTaskId === NULL_TASK_ID && chan === RESUME2), 1);
        return nullResume;
      }
    }
  };
  return scratchpad;
}

// node_modules/@langchain/langgraph/dist/pregel/debug.js
var COLORS_MAP = {
  blue: {
    start: "\x1B[34m",
    end: "\x1B[0m"
  },
  green: {
    start: "\x1B[32m",
    end: "\x1B[0m"
  },
  yellow: {
    start: "\x1B[33;1m",
    end: "\x1B[0m"
  }
};
var wrap = (color, text) => `${color.start}${text}${color.end}`;
function* mapDebugTasks(tasks) {
  for (const { id, name, input, config: config2, triggers, writes } of tasks) {
    if (config2?.tags?.includes(TAG_HIDDEN)) continue;
    yield {
      id,
      name,
      input,
      triggers,
      interrupts: writes.filter(([writeId, n2]) => {
        return writeId === id && n2 === INTERRUPT2;
      }).map(([, v]) => {
        return v;
      })
    };
  }
}
function isMultipleChannelWrite(value) {
  if (typeof value !== "object" || value === null) return false;
  return "$writes" in value && Array.isArray(value.$writes);
}
function mapTaskResultWrites(writes) {
  const result = {};
  for (const [channel, value] of writes) {
    const strChannel = String(channel);
    if (strChannel in result) {
      const channelWrites = isMultipleChannelWrite(result[strChannel]) ? result[strChannel].$writes : [result[strChannel]];
      channelWrites.push(value);
      result[strChannel] = { $writes: channelWrites };
    } else result[strChannel] = value;
  }
  return result;
}
function* mapDebugTaskResults(tasks, streamChannels) {
  for (const [{ id, name, config: config2 }, writes] of tasks) {
    if (config2?.tags?.includes(TAG_HIDDEN)) continue;
    yield {
      id,
      name,
      result: mapTaskResultWrites(writes.filter(([channel]) => {
        return Array.isArray(streamChannels) ? streamChannels.includes(channel) : channel === streamChannels;
      })),
      interrupts: writes.filter((w) => w[0] === INTERRUPT2).map((w) => w[1])
    };
  }
}
function* mapDebugCheckpoint(config2, channels, streamChannels, metadata, tasks, pendingWrites, parentConfig, outputKeys) {
  function formatConfig(config3) {
    const pyConfig = {};
    if (config3.callbacks != null) pyConfig.callbacks = config3.callbacks;
    if (config3.configurable != null) pyConfig.configurable = config3.configurable;
    if (config3.maxConcurrency != null) pyConfig.max_concurrency = config3.maxConcurrency;
    if (config3.metadata != null) pyConfig.metadata = config3.metadata;
    if (config3.recursionLimit != null) pyConfig.recursion_limit = config3.recursionLimit;
    if (config3.runId != null) pyConfig.run_id = config3.runId;
    if (config3.runName != null) pyConfig.run_name = config3.runName;
    if (config3.tags != null) pyConfig.tags = config3.tags;
    return pyConfig;
  }
  const parentNs = config2.configurable?.checkpoint_ns;
  const taskStates = {};
  for (const task2 of tasks) {
    if (!(task2.subgraphs?.length ? task2.subgraphs : [task2.proc]).find(findSubgraphPregel)) continue;
    let taskNs = `${task2.name}:${task2.id}`;
    if (parentNs) taskNs = `${parentNs}|${taskNs}`;
    taskStates[task2.id] = { configurable: {
      thread_id: config2.configurable?.thread_id,
      checkpoint_ns: taskNs
    } };
  }
  yield {
    config: formatConfig(config2),
    values: readChannels(channels, streamChannels),
    metadata,
    next: tasks.map((task2) => task2.name),
    tasks: tasksWithWrites(tasks, pendingWrites, taskStates, outputKeys),
    parentConfig: parentConfig ? formatConfig(parentConfig) : void 0
  };
}
function tasksWithWrites(tasks, pendingWrites, states, outputKeys) {
  return tasks.map((task2) => {
    const error = pendingWrites.find(([id, n2]) => id === task2.id && n2 === ERROR3)?.[2];
    const interrupts = pendingWrites.filter(([id, n2]) => id === task2.id && n2 === INTERRUPT2).map(([, , v]) => v);
    const result = (() => {
      if (error || interrupts.length || !pendingWrites.length) return void 0;
      const idx = pendingWrites.findIndex(([tid, n2]) => tid === task2.id && n2 === RETURN);
      if (idx >= 0) return pendingWrites[idx][2];
      if (typeof outputKeys === "string") return pendingWrites.find(([tid, n2]) => tid === task2.id && n2 === outputKeys)?.[2];
      if (Array.isArray(outputKeys)) {
        const results = pendingWrites.filter(([tid, n2]) => tid === task2.id && outputKeys.includes(n2)).map(([, n2, v]) => [n2, v]);
        if (!results.length) return void 0;
        return mapTaskResultWrites(results);
      }
    })();
    if (error) return {
      id: task2.id,
      name: task2.name,
      path: task2.path,
      error,
      interrupts,
      result
    };
    const taskState = states?.[task2.id];
    return {
      id: task2.id,
      name: task2.name,
      path: task2.path,
      interrupts,
      ...taskState !== void 0 ? { state: taskState } : {},
      result
    };
  });
}
function printStepCheckpoint(step, channels, whitelist) {
  console.log([
    `${wrap(COLORS_MAP.blue, `[${step}:checkpoint]`)}`,
    `\x1B[1m State at the end of step ${step}:\x1B[0m
`,
    JSON.stringify(readChannels(channels, whitelist), null, 2)
  ].join(""));
}
function printStepTasks(step, nextTasks) {
  const nTasks = nextTasks.length;
  console.log([
    `${wrap(COLORS_MAP.blue, `[${step}:tasks]`)}`,
    `\x1B[1m Starting step ${step} with ${nTasks} task${nTasks === 1 ? "" : "s"}:\x1B[0m
`,
    nextTasks.map((task2) => `- ${wrap(COLORS_MAP.green, String(task2.name))} -> ${JSON.stringify(task2.input, null, 2)}`).join("\n")
  ].join(""));
}
function printStepWrites(step, writes, whitelist) {
  const byChannel = {};
  for (const [channel, value] of writes) if (whitelist.includes(channel)) {
    if (!byChannel[channel]) byChannel[channel] = [];
    byChannel[channel].push(value);
  }
  console.log([
    `${wrap(COLORS_MAP.blue, `[${step}:writes]`)}`,
    `\x1B[1m Finished step ${step} with writes to ${Object.keys(byChannel).length} channel${Object.keys(byChannel).length !== 1 ? "s" : ""}:\x1B[0m
`,
    Object.entries(byChannel).map(([name, vals]) => `- ${wrap(COLORS_MAP.yellow, name)} -> ${vals.map((v) => JSON.stringify(v)).join(", ")}`).join("\n")
  ].join(""));
}

// node_modules/@langchain/langgraph/dist/pregel/stream.js
var IterableReadableStreamWithAbortSignal = class extends IterableReadableStream {
  _abortController;
  _innerReader;
  /**
  * @param readableStream - The stream to wrap.
  * @param abortController - The abort controller to use. Optional. One will be created if not provided.
  */
  constructor(readableStream, abortController) {
    const reader = readableStream.getReader();
    const ac = abortController ?? new AbortController();
    super({ start(controller) {
      return pump();
      function pump() {
        return reader.read().then(({ done, value }) => {
          if (done) {
            controller.close();
            return;
          }
          controller.enqueue(value);
          return pump();
        });
      }
    } });
    this._abortController = ac;
    this._innerReader = reader;
  }
  /**
  * Aborts the stream, abandoning any pending operations in progress. Calling this triggers an
  * {@link AbortSignal} that is propagated to the tasks that are producing the data for this stream.
  * @param reason - The reason for aborting the stream. Optional.
  */
  async cancel(reason) {
    this._abortController.abort(reason);
    this._innerReader.releaseLock();
  }
  /**
  * The {@link AbortSignal} for the stream. Aborted when {@link cancel} is called.
  */
  get signal() {
    return this._abortController.signal;
  }
};
var IterableReadableWritableStream = class extends IterableReadableStream {
  modes;
  controller;
  passthroughFn;
  _closed = false;
  get closed() {
    return this._closed;
  }
  constructor(params) {
    let streamControllerPromiseResolver;
    const streamControllerPromise = new Promise((resolve) => {
      streamControllerPromiseResolver = resolve;
    });
    super({ start: (controller) => {
      streamControllerPromiseResolver(controller);
    } });
    streamControllerPromise.then((controller) => {
      this.controller = controller;
    });
    this.passthroughFn = params.passthroughFn;
    this.modes = params.modes;
  }
  push(chunk) {
    this.passthroughFn?.(chunk);
    this.controller.enqueue(chunk);
  }
  close() {
    try {
      this.controller.close();
    } catch (e) {
    } finally {
      this._closed = true;
    }
  }
  error(e) {
    this.controller.error(e);
  }
};
function _stringifyAsDict(obj) {
  return JSON.stringify(obj, function(key, value) {
    const rawValue2 = this[key];
    if (rawValue2 != null && typeof rawValue2 === "object" && "toDict" in rawValue2 && typeof rawValue2.toDict === "function") {
      const { type, data } = rawValue2.toDict();
      return {
        ...data,
        type
      };
    }
    return value;
  });
}
function _serializeError(error) {
  if (error instanceof Error) return {
    error: error.name,
    message: error.message
  };
  return {
    error: "Error",
    message: JSON.stringify(error)
  };
}
function _isRunnableConfig(config2) {
  if (typeof config2 !== "object" || config2 == null) return false;
  return "configurable" in config2 && typeof config2.configurable === "object" && config2.configurable != null;
}
function _extractCheckpointFromConfig(config2) {
  if (!_isRunnableConfig(config2) || !config2.configurable.thread_id) return null;
  return {
    thread_id: config2.configurable.thread_id,
    checkpoint_ns: config2.configurable.checkpoint_ns || "",
    checkpoint_id: config2.configurable.checkpoint_id || null,
    checkpoint_map: config2.configurable.checkpoint_map || null
  };
}
function _serializeConfig(config2) {
  if (_isRunnableConfig(config2)) {
    const configurable = Object.fromEntries(Object.entries(config2.configurable).filter(([key]) => !key.startsWith("__")));
    const newConfig = {
      ...config2,
      configurable
    };
    delete newConfig.callbacks;
    return newConfig;
  }
  return config2;
}
function _serializeCheckpoint(payload) {
  const result = {
    ...payload,
    checkpoint: _extractCheckpointFromConfig(payload.config),
    parent_checkpoint: _extractCheckpointFromConfig(payload.parentConfig),
    config: _serializeConfig(payload.config),
    parent_config: _serializeConfig(payload.parentConfig),
    tasks: payload.tasks.map((task2) => {
      if (_isRunnableConfig(task2.state)) {
        const checkpoint = _extractCheckpointFromConfig(task2.state);
        if (checkpoint != null) {
          const cloneTask = {
            ...task2,
            checkpoint
          };
          delete cloneTask.state;
          return cloneTask;
        }
      }
      return task2;
    })
  };
  delete result.parentConfig;
  return result;
}
function toEventStream(stream) {
  const encoder = new TextEncoder();
  return new ReadableStream({ async start(controller) {
    const enqueueChunk = (sse) => {
      controller.enqueue(encoder.encode(`event: ${sse.event}
data: ${_stringifyAsDict(sse.data)}

`));
    };
    try {
      for await (const payload of stream) {
        const [ns, mode, chunk] = payload;
        let data = chunk;
        if (mode === "debug") {
          const debugChunk = chunk;
          if (debugChunk.type === "checkpoint") data = {
            ...debugChunk,
            payload: _serializeCheckpoint(debugChunk.payload)
          };
        }
        if (mode === "checkpoints") data = _serializeCheckpoint(chunk);
        enqueueChunk({
          event: ns?.length ? `${mode}|${ns.join("|")}` : mode,
          data
        });
      }
    } catch (error) {
      enqueueChunk({
        event: "error",
        data: _serializeError(error)
      });
    }
    controller.close();
  } });
}

// node_modules/@langchain/langgraph/dist/pregel/loop.js
var INPUT_DONE = /* @__PURE__ */ Symbol.for("INPUT_DONE");
var INPUT_RESUMING = /* @__PURE__ */ Symbol.for("INPUT_RESUMING");
var DEFAULT_LOOP_LIMIT = 25;
function createDuplexStream(...streams) {
  return new IterableReadableWritableStream({
    passthroughFn: (value) => {
      for (const stream of streams) if (stream.modes.has(value[1])) stream.push(value);
    },
    modes: new Set(streams.flatMap((s) => Array.from(s.modes)))
  });
}
var AsyncBatchedCache = class extends BaseCache2 {
  cache;
  queue = Promise.resolve();
  constructor(cache) {
    super();
    this.cache = cache;
  }
  async get(keys) {
    return this.enqueueOperation("get", keys);
  }
  async set(pairs) {
    return this.enqueueOperation("set", pairs);
  }
  async clear(namespaces) {
    return this.enqueueOperation("clear", namespaces);
  }
  async stop() {
    await this.queue;
  }
  enqueueOperation(type, ...args) {
    const newPromise = this.queue.then(() => {
      return this.cache[type](...args);
    });
    this.queue = newPromise.then(() => void 0, () => void 0);
    return newPromise;
  }
};
var PregelLoop = class PregelLoop2 {
  input;
  output;
  config;
  checkpointer;
  checkpointerGetNextVersion;
  channels;
  checkpoint;
  checkpointIdSaved;
  checkpointConfig;
  checkpointMetadata;
  checkpointNamespace;
  checkpointPendingWrites = [];
  checkpointPreviousVersions;
  step;
  stop;
  durability;
  outputKeys;
  streamKeys;
  nodes;
  skipDoneTasks;
  prevCheckpointConfig;
  updatedChannels;
  status = "pending";
  tasks = {};
  stream;
  checkpointerPromises = [];
  isNested;
  _checkpointerChainedPromise = Promise.resolve();
  store;
  cache;
  manager;
  interruptAfter;
  interruptBefore;
  toInterrupt = [];
  debug = false;
  triggerToNodes;
  get isResuming() {
    let hasChannelVersions = false;
    if (START in this.checkpoint.channel_versions) hasChannelVersions = true;
    else for (const chan in this.checkpoint.channel_versions) if (Object.prototype.hasOwnProperty.call(this.checkpoint.channel_versions, chan)) {
      hasChannelVersions = true;
      break;
    }
    const configIsResuming = this.config.configurable?.[CONFIG_KEY_RESUMING] !== void 0 && this.config.configurable?.[CONFIG_KEY_RESUMING];
    const inputIsNullOrUndefined = this.input === null || this.input === void 0;
    const inputIsCommandResuming = isCommand(this.input) && this.input.resume != null;
    const inputIsResuming = this.input === INPUT_RESUMING;
    const runIdMatchesPrevious = !this.isNested && this.config.metadata?.run_id !== void 0 && this.checkpointMetadata?.run_id !== void 0 && this.config.metadata.run_id === this.checkpointMetadata?.run_id;
    return hasChannelVersions && (configIsResuming || inputIsNullOrUndefined || inputIsCommandResuming || inputIsResuming || runIdMatchesPrevious);
  }
  constructor(params) {
    this.input = params.input;
    this.checkpointer = params.checkpointer;
    if (this.checkpointer !== void 0) this.checkpointerGetNextVersion = this.checkpointer.getNextVersion.bind(this.checkpointer);
    else this.checkpointerGetNextVersion = increment;
    this.checkpoint = params.checkpoint;
    this.checkpointMetadata = params.checkpointMetadata;
    this.checkpointPreviousVersions = params.checkpointPreviousVersions;
    this.channels = params.channels;
    this.checkpointPendingWrites = params.checkpointPendingWrites;
    this.step = params.step;
    this.stop = params.stop;
    this.config = params.config;
    this.checkpointConfig = params.checkpointConfig;
    this.isNested = params.isNested;
    this.manager = params.manager;
    this.outputKeys = params.outputKeys;
    this.streamKeys = params.streamKeys;
    this.nodes = params.nodes;
    this.skipDoneTasks = params.skipDoneTasks;
    this.store = params.store;
    this.cache = params.cache ? new AsyncBatchedCache(params.cache) : void 0;
    this.stream = params.stream;
    this.checkpointNamespace = params.checkpointNamespace;
    this.prevCheckpointConfig = params.prevCheckpointConfig;
    this.interruptAfter = params.interruptAfter;
    this.interruptBefore = params.interruptBefore;
    this.durability = params.durability;
    this.debug = params.debug;
    this.triggerToNodes = params.triggerToNodes;
  }
  static async initialize(params) {
    let { config: config2, stream } = params;
    if (stream !== void 0 && config2.configurable?.[CONFIG_KEY_STREAM] !== void 0) stream = createDuplexStream(stream, config2.configurable[CONFIG_KEY_STREAM]);
    const skipDoneTasks = config2.configurable ? !("checkpoint_id" in config2.configurable) : true;
    const scratchpad = config2.configurable?.[CONFIG_KEY_SCRATCHPAD];
    if (config2.configurable && scratchpad) {
      if (scratchpad.subgraphCounter > 0) config2 = patchConfigurable2(config2, { [CONFIG_KEY_CHECKPOINT_NS]: [config2.configurable[CONFIG_KEY_CHECKPOINT_NS], scratchpad.subgraphCounter.toString()].join(CHECKPOINT_NAMESPACE_SEPARATOR) });
      scratchpad.subgraphCounter += 1;
    }
    const isNested = CONFIG_KEY_READ in (config2.configurable ?? {});
    if (!isNested && config2.configurable?.checkpoint_ns !== void 0 && config2.configurable?.checkpoint_ns !== "") config2 = patchConfigurable2(config2, {
      checkpoint_ns: "",
      checkpoint_id: void 0
    });
    let checkpointConfig = config2;
    if (config2.configurable?.[CONFIG_KEY_CHECKPOINT_MAP] !== void 0 && config2.configurable?.[CONFIG_KEY_CHECKPOINT_MAP]?.[config2.configurable?.checkpoint_ns]) checkpointConfig = patchConfigurable2(config2, { checkpoint_id: config2.configurable[CONFIG_KEY_CHECKPOINT_MAP][config2.configurable?.checkpoint_ns] });
    const checkpointNamespace = config2.configurable?.checkpoint_ns?.split(CHECKPOINT_NAMESPACE_SEPARATOR) ?? [];
    const saved = await params.checkpointer?.getTuple(checkpointConfig) ?? {
      config: config2,
      checkpoint: emptyCheckpoint(),
      metadata: {
        source: "input",
        step: -2,
        parents: {}
      },
      pendingWrites: []
    };
    checkpointConfig = {
      ...config2,
      ...saved.config,
      configurable: {
        checkpoint_ns: "",
        ...config2.configurable,
        ...saved.config.configurable
      }
    };
    const prevCheckpointConfig = saved.parentConfig;
    const checkpoint = copyCheckpoint(saved.checkpoint);
    const checkpointMetadata = { ...saved.metadata };
    const checkpointPendingWrites = saved.pendingWrites ?? [];
    const channels = emptyChannels(params.channelSpecs, checkpoint);
    const step = (checkpointMetadata.step ?? 0) + 1;
    const stop = step + (config2.recursionLimit ?? DEFAULT_LOOP_LIMIT) + 1;
    const checkpointPreviousVersions = { ...checkpoint.channel_versions };
    const store = params.store ? new AsyncBatchedStore(params.store) : void 0;
    if (store) await store.start();
    return new PregelLoop2({
      input: params.input,
      config: config2,
      checkpointer: params.checkpointer,
      checkpoint,
      checkpointMetadata,
      checkpointConfig,
      prevCheckpointConfig,
      checkpointNamespace,
      channels,
      isNested,
      manager: params.manager,
      skipDoneTasks,
      step,
      stop,
      checkpointPreviousVersions,
      checkpointPendingWrites,
      outputKeys: params.outputKeys ?? [],
      streamKeys: params.streamKeys ?? [],
      nodes: params.nodes,
      stream,
      store,
      cache: params.cache,
      interruptAfter: params.interruptAfter,
      interruptBefore: params.interruptBefore,
      durability: params.durability,
      debug: params.debug,
      triggerToNodes: params.triggerToNodes
    });
  }
  _checkpointerPutAfterPrevious(input) {
    this._checkpointerChainedPromise = this._checkpointerChainedPromise.then(() => {
      return this.checkpointer?.put(input.config, input.checkpoint, input.metadata, input.newVersions);
    });
    this.checkpointerPromises.push(this._checkpointerChainedPromise);
  }
  /**
  * Put writes for a task, to be read by the next tick.
  * @param taskId
  * @param writes
  */
  putWrites(taskId, writes) {
    let writesCopy = writes;
    if (writesCopy.length === 0) return;
    if (writesCopy.every(([key]) => key in WRITES_IDX_MAP)) writesCopy = Array.from(new Map(writesCopy.map((w) => [w[0], w])).values());
    let hasUntrackedChannels = false;
    for (const key in this.channels) if (Object.prototype.hasOwnProperty.call(this.channels, key)) {
      if (this.channels[key].lc_graph_name === "UntrackedValue") {
        hasUntrackedChannels = true;
        break;
      }
    }
    let writesToSave = writesCopy;
    if (hasUntrackedChannels) writesToSave = writesCopy.filter(([c]) => {
      const channel = this.channels[c];
      return !channel || channel.lc_graph_name !== "UntrackedValue";
    }).map(([c, v]) => {
      if (c === TASKS2 && _isSend(v)) return [c, sanitizeUntrackedValuesInSend(v, this.channels)];
      return [c, v];
    });
    this.checkpointPendingWrites = this.checkpointPendingWrites.filter((w) => w[0] !== taskId);
    for (const [c, v] of writesToSave) this.checkpointPendingWrites.push([
      taskId,
      c,
      v
    ]);
    const config2 = patchConfigurable2(this.checkpointConfig, {
      [CONFIG_KEY_CHECKPOINT_NS]: this.config.configurable?.checkpoint_ns ?? "",
      [CONFIG_KEY_CHECKPOINT_ID]: this.checkpoint.id
    });
    if (this.durability !== "exit" && this.checkpointer != null) this.checkpointerPromises.push(this.checkpointer.putWrites(config2, writesToSave, taskId));
    if (this.tasks) this._outputWrites(taskId, writesCopy);
    if (!writes.length || !this.cache || !this.tasks) return;
    const task2 = this.tasks[taskId];
    if (task2 == null || task2.cache_key == null) return;
    if (writes[0][0] === ERROR3 || writes[0][0] === INTERRUPT2) return;
    this.cache.set([{
      key: [task2.cache_key.ns, task2.cache_key.key],
      value: task2.writes,
      ttl: task2.cache_key.ttl
    }]);
  }
  _outputWrites(taskId, writes, cached = false) {
    const task2 = this.tasks[taskId];
    if (task2 !== void 0) {
      if (task2.config !== void 0 && (task2.config.tags ?? []).includes(TAG_HIDDEN)) return;
      if (writes.length > 0) {
        if (writes[0][0] === INTERRUPT2) {
          if (task2.path?.[0] === PUSH && task2.path?.[task2.path.length - 1] === true) return;
          const interruptWrites = writes.filter((w) => w[0] === INTERRUPT2).flatMap((w) => w[1]);
          this._emit([["updates", { [INTERRUPT2]: interruptWrites }], ["values", { [INTERRUPT2]: interruptWrites }]]);
        } else if (writes[0][0] !== ERROR3) this._emit(gatherIteratorSync(prefixGenerator(mapOutputUpdates(this.outputKeys, [[task2, writes]], cached), "updates")));
      }
      if (!cached) this._emit(gatherIteratorSync(prefixGenerator(mapDebugTaskResults([[task2, writes]], this.streamKeys), "tasks")));
    }
  }
  async _matchCachedWrites() {
    if (!this.cache) return [];
    const matched = [];
    const serializeKey = ([ns, key]) => {
      return `ns:${ns.join(",")}|key:${key}`;
    };
    const keys = [];
    const keyMap = {};
    for (const task2 of Object.values(this.tasks)) if (task2.cache_key != null && !task2.writes.length) {
      keys.push([task2.cache_key.ns, task2.cache_key.key]);
      keyMap[serializeKey([task2.cache_key.ns, task2.cache_key.key])] = task2;
    }
    if (keys.length === 0) return [];
    const cache = await this.cache.get(keys);
    for (const { key, value } of cache) {
      const task2 = keyMap[serializeKey(key)];
      if (task2 != null) {
        task2.writes.push(...value);
        matched.push({
          task: task2,
          result: value
        });
      }
    }
    return matched;
  }
  /**
  * Execute a single iteration of the Pregel loop.
  * Returns true if more iterations are needed.
  * @param params
  */
  async tick(params) {
    if (this.store && !this.store.isRunning) await this.store?.start();
    const { inputKeys = [] } = params;
    if (this.status !== "pending") throw new Error(`Cannot tick when status is no longer "pending". Current status: "${this.status}"`);
    if (![INPUT_DONE, INPUT_RESUMING].includes(this.input)) await this._first(inputKeys);
    else if (this.toInterrupt.length > 0) {
      this.status = "interrupt_before";
      throw new GraphInterrupt();
    } else if (Object.values(this.tasks).every((task2) => task2.writes.length > 0)) {
      const writes = Object.values(this.tasks).flatMap((t) => t.writes);
      this.updatedChannels = _applyWrites(this.checkpoint, this.channels, Object.values(this.tasks), this.checkpointerGetNextVersion, this.triggerToNodes);
      const valuesOutput = await gatherIterator(prefixGenerator(mapOutputValues(this.outputKeys, writes, this.channels), "values"));
      this._emit(valuesOutput);
      this.checkpointPendingWrites = [];
      await this._putCheckpoint({ source: "loop" });
      if (shouldInterrupt(this.checkpoint, this.interruptAfter, Object.values(this.tasks))) {
        this.status = "interrupt_after";
        throw new GraphInterrupt();
      }
      if (this.config.configurable?.[CONFIG_KEY_RESUMING] !== void 0) delete this.config.configurable?.[CONFIG_KEY_RESUMING];
    } else return false;
    if (this.step > this.stop) {
      this.status = "out_of_steps";
      return false;
    }
    this.tasks = _prepareNextTasks(this.checkpoint, this.checkpointPendingWrites, this.nodes, this.channels, this.config, true, {
      step: this.step,
      checkpointer: this.checkpointer,
      isResuming: this.isResuming,
      manager: this.manager,
      store: this.store,
      stream: this.stream,
      triggerToNodes: this.triggerToNodes,
      updatedChannels: this.updatedChannels
    });
    if (this.checkpointer) this._emit(await gatherIterator(prefixGenerator(mapDebugCheckpoint(this.checkpointConfig, this.channels, this.streamKeys, this.checkpointMetadata, Object.values(this.tasks), this.checkpointPendingWrites, this.prevCheckpointConfig, this.outputKeys), "checkpoints")));
    if (Object.values(this.tasks).length === 0) {
      this.status = "done";
      return false;
    }
    if (this.skipDoneTasks && this.checkpointPendingWrites.length > 0) {
      for (const [tid, k, v] of this.checkpointPendingWrites) {
        if (k === ERROR3 || k === INTERRUPT2 || k === RESUME2) continue;
        const task2 = Object.values(this.tasks).find((t) => t.id === tid);
        if (task2) task2.writes.push([k, v]);
      }
      for (const task2 of Object.values(this.tasks)) if (task2.writes.length > 0) this._outputWrites(task2.id, task2.writes, true);
    }
    if (Object.values(this.tasks).every((task2) => task2.writes.length > 0)) return this.tick({ inputKeys });
    if (shouldInterrupt(this.checkpoint, this.interruptBefore, Object.values(this.tasks))) {
      this.status = "interrupt_before";
      throw new GraphInterrupt();
    }
    const debugOutput = await gatherIterator(prefixGenerator(mapDebugTasks(Object.values(this.tasks)), "tasks"));
    this._emit(debugOutput);
    return true;
  }
  async finishAndHandleError(error) {
    if (this.durability === "exit" && (!this.isNested || typeof error !== "undefined" || this.checkpointNamespace.every((part) => !part.includes(CHECKPOINT_NAMESPACE_END)))) {
      this._putCheckpoint(this.checkpointMetadata);
      this._flushPendingWrites();
    }
    const suppress = this._suppressInterrupt(error);
    if (suppress || error === void 0) this.output = readChannels(this.channels, this.outputKeys);
    if (suppress) {
      if (this.tasks !== void 0 && this.checkpointPendingWrites.length > 0 && Object.values(this.tasks).some((task2) => task2.writes.length > 0)) {
        this.updatedChannels = _applyWrites(this.checkpoint, this.channels, Object.values(this.tasks), this.checkpointerGetNextVersion, this.triggerToNodes);
        this._emit(gatherIteratorSync(prefixGenerator(mapOutputValues(this.outputKeys, Object.values(this.tasks).flatMap((t) => t.writes), this.channels), "values")));
      }
      if (isGraphInterrupt(error) && !error.interrupts.length) this._emit([["updates", { [INTERRUPT2]: [] }], ["values", { [INTERRUPT2]: [] }]]);
    }
    return suppress;
  }
  async acceptPush(task2, writeIdx, call3) {
    if (this.interruptAfter?.length > 0 && shouldInterrupt(this.checkpoint, this.interruptAfter, [task2])) {
      this.toInterrupt.push(task2);
      return;
    }
    const pushed = _prepareSingleTask([
      PUSH,
      task2.path ?? [],
      writeIdx,
      task2.id,
      call3
    ], this.checkpoint, this.checkpointPendingWrites, this.nodes, this.channels, task2.config ?? {}, true, {
      step: this.step,
      checkpointer: this.checkpointer,
      manager: this.manager,
      store: this.store,
      stream: this.stream
    });
    if (!pushed) return;
    if (this.interruptBefore?.length > 0 && shouldInterrupt(this.checkpoint, this.interruptBefore, [pushed])) {
      this.toInterrupt.push(pushed);
      return;
    }
    this._emit(gatherIteratorSync(prefixGenerator(mapDebugTasks([pushed]), "tasks")));
    if (this.debug) printStepTasks(this.step, [pushed]);
    this.tasks[pushed.id] = pushed;
    if (this.skipDoneTasks) this._matchWrites({ [pushed.id]: pushed });
    const tasks = await this._matchCachedWrites();
    for (const { task: task3 } of tasks) this._outputWrites(task3.id, task3.writes, true);
    return pushed;
  }
  _suppressInterrupt(e) {
    return isGraphInterrupt(e) && !this.isNested;
  }
  async _first(inputKeys) {
    const { configurable } = this.config;
    const scratchpad = configurable?.[CONFIG_KEY_SCRATCHPAD];
    if (scratchpad && scratchpad.nullResume !== void 0) this.putWrites(NULL_TASK_ID, [[RESUME2, scratchpad.nullResume]]);
    if (isCommand(this.input)) {
      const hasResume = this.input.resume != null;
      if (this.input.resume != null && typeof this.input.resume === "object" && Object.keys(this.input.resume).every(isXXH3)) {
        this.config.configurable ??= {};
        this.config.configurable[CONFIG_KEY_RESUME_MAP] = this.input.resume;
      }
      if (hasResume && this.checkpointer == null) throw new Error("Cannot use Command(resume=...) without checkpointer");
      const writes = {};
      for (const [tid, key, value] of mapCommand(this.input, this.checkpointPendingWrites)) {
        writes[tid] ??= [];
        writes[tid].push([key, value]);
      }
      if (Object.keys(writes).length === 0) throw new EmptyInputError("Received empty Command input");
      for (const [tid, ws] of Object.entries(writes)) this.putWrites(tid, ws);
    }
    const nullWrites = (this.checkpointPendingWrites ?? []).filter((w) => w[0] === NULL_TASK_ID).map((w) => w.slice(1));
    if (nullWrites.length > 0) _applyWrites(this.checkpoint, this.channels, [{
      name: INPUT,
      writes: nullWrites,
      triggers: []
    }], this.checkpointerGetNextVersion, this.triggerToNodes);
    const isCommandUpdateOrGoto = isCommand(this.input) && nullWrites.length > 0;
    if (this.isResuming || isCommandUpdateOrGoto) {
      for (const channelName in this.channels) {
        if (!Object.prototype.hasOwnProperty.call(this.channels, channelName)) continue;
        if (this.checkpoint.channel_versions[channelName] !== void 0) {
          const version = this.checkpoint.channel_versions[channelName];
          this.checkpoint.versions_seen[INTERRUPT2] = {
            ...this.checkpoint.versions_seen[INTERRUPT2],
            [channelName]: version
          };
        }
      }
      const valuesOutput = await gatherIterator(prefixGenerator(mapOutputValues(this.outputKeys, true, this.channels), "values"));
      this._emit(valuesOutput);
    }
    if (this.isResuming) this.input = INPUT_RESUMING;
    else if (isCommandUpdateOrGoto) {
      await this._putCheckpoint({ source: "input" });
      this.input = INPUT_DONE;
    } else {
      const inputWrites = await gatherIterator(mapInput(inputKeys, this.input));
      if (inputWrites.length > 0) {
        const discardTasks = _prepareNextTasks(this.checkpoint, this.checkpointPendingWrites, this.nodes, this.channels, this.config, true, { step: this.step });
        this.updatedChannels = _applyWrites(this.checkpoint, this.channels, Object.values(discardTasks).concat([{
          name: INPUT,
          writes: inputWrites,
          triggers: []
        }]), this.checkpointerGetNextVersion, this.triggerToNodes);
        await this._putCheckpoint({ source: "input" });
        this.input = INPUT_DONE;
      } else if (!(CONFIG_KEY_RESUMING in (this.config.configurable ?? {}))) throw new EmptyInputError(`Received no input writes for ${JSON.stringify(inputKeys, null, 2)}`);
      else this.input = INPUT_DONE;
    }
    if (!this.isNested) this.config = patchConfigurable2(this.config, { [CONFIG_KEY_RESUMING]: this.isResuming });
  }
  _emit(values) {
    for (const [mode, payload] of values) {
      if (this.stream.modes.has(mode)) this.stream.push([
        this.checkpointNamespace,
        mode,
        payload
      ]);
      if ((mode === "checkpoints" || mode === "tasks") && this.stream.modes.has("debug")) {
        const step = mode === "checkpoints" ? this.step - 1 : this.step;
        const timestamp = (/* @__PURE__ */ new Date()).toISOString();
        const type = (() => {
          if (mode === "checkpoints") return "checkpoint";
          else if (typeof payload === "object" && payload != null && "result" in payload) return "task_result";
          else return "task";
        })();
        this.stream.push([
          this.checkpointNamespace,
          "debug",
          {
            step,
            type,
            timestamp,
            payload
          }
        ]);
      }
    }
  }
  _putCheckpoint(inputMetadata) {
    const exiting = this.checkpointMetadata === inputMetadata;
    const doCheckpoint = this.checkpointer != null && (this.durability !== "exit" || exiting);
    const storeCheckpoint = (checkpoint) => {
      this.prevCheckpointConfig = this.checkpointConfig?.configurable?.checkpoint_id ? this.checkpointConfig : void 0;
      this.checkpointConfig = patchConfigurable2(this.checkpointConfig, { [CONFIG_KEY_CHECKPOINT_NS]: this.config.configurable?.checkpoint_ns ?? "" });
      const channelVersions = { ...this.checkpoint.channel_versions };
      const newVersions = getNewChannelVersions(this.checkpointPreviousVersions, channelVersions);
      this.checkpointPreviousVersions = channelVersions;
      this._checkpointerPutAfterPrevious({
        config: { ...this.checkpointConfig },
        checkpoint: copyCheckpoint(checkpoint),
        metadata: { ...this.checkpointMetadata },
        newVersions
      });
      this.checkpointConfig = {
        ...this.checkpointConfig,
        configurable: {
          ...this.checkpointConfig.configurable,
          checkpoint_id: this.checkpoint.id
        }
      };
    };
    if (!exiting) this.checkpointMetadata = {
      ...inputMetadata,
      step: this.step,
      parents: this.config.configurable?.[CONFIG_KEY_CHECKPOINT_MAP] ?? {}
    };
    this.checkpoint = createCheckpoint(this.checkpoint, doCheckpoint ? this.channels : void 0, this.step, exiting ? { id: this.checkpoint.id } : void 0);
    if (doCheckpoint) storeCheckpoint(this.checkpoint);
    if (!exiting) this.step += 1;
  }
  _flushPendingWrites() {
    if (this.checkpointer == null) return;
    if (this.checkpointPendingWrites.length === 0) return;
    const config2 = patchConfigurable2(this.checkpointConfig, {
      [CONFIG_KEY_CHECKPOINT_NS]: this.config.configurable?.checkpoint_ns ?? "",
      [CONFIG_KEY_CHECKPOINT_ID]: this.checkpoint.id
    });
    const byTask = {};
    for (const [tid, key, value] of this.checkpointPendingWrites) {
      byTask[tid] ??= [];
      byTask[tid].push([key, value]);
    }
    for (const [tid, ws] of Object.entries(byTask)) this.checkpointerPromises.push(this.checkpointer.putWrites(config2, ws, tid));
  }
  _matchWrites(tasks) {
    for (const [tid, k, v] of this.checkpointPendingWrites) {
      if (k === ERROR3 || k === INTERRUPT2 || k === RESUME2) continue;
      const task2 = Object.values(tasks).find((t) => t.id === tid);
      if (task2) task2.writes.push([k, v]);
    }
    for (const task2 of Object.values(tasks)) if (task2.writes.length > 0) this._outputWrites(task2.id, task2.writes, true);
  }
};

// node_modules/@langchain/langgraph/dist/pregel/messages.js
function isChatGenerationChunk(x) {
  return isBaseMessage(x?.message);
}
var StreamMessagesHandler = class extends BaseCallbackHandler {
  name = "StreamMessagesHandler";
  streamFn;
  metadatas = {};
  seen = {};
  emittedChatModelRunIds = {};
  stableMessageIdMap = {};
  lc_prefer_streaming = true;
  constructor(streamFn) {
    super();
    this.streamFn = streamFn;
  }
  _emit(meta3, message, runId, dedupe = false) {
    if (dedupe && message.id !== void 0 && this.seen[message.id] !== void 0) return;
    let messageId = message.id;
    if (runId != null) if (isToolMessage(message)) messageId ??= `run-${runId}-tool-${message.tool_call_id}`;
    else {
      if (messageId == null || messageId === `run-${runId}`) messageId = this.stableMessageIdMap[runId] ?? messageId ?? `run-${runId}`;
      this.stableMessageIdMap[runId] ??= messageId;
    }
    if (messageId !== message.id) {
      message.id = messageId;
      message.lc_kwargs.id = messageId;
    }
    if (message.id != null) this.seen[message.id] = message;
    this.streamFn([
      meta3[0],
      "messages",
      [message, meta3[1]]
    ]);
  }
  handleChatModelStart(_llm, _messages, runId, _parentRunId, _extraParams, tags, metadata, name) {
    if (metadata && (!tags || !tags.includes(TAG_NOSTREAM) && !tags.includes("nostream"))) this.metadatas[runId] = [metadata.langgraph_checkpoint_ns.split("|"), {
      tags,
      name,
      ...metadata
    }];
  }
  handleLLMNewToken(token, _idx, runId, _parentRunId, _tags, fields) {
    const chunk = fields?.chunk;
    this.emittedChatModelRunIds[runId] = true;
    if (this.metadatas[runId] !== void 0) if (isChatGenerationChunk(chunk)) this._emit(this.metadatas[runId], chunk.message, runId);
    else this._emit(this.metadatas[runId], new AIMessageChunk({ content: token }), runId);
  }
  handleLLMEnd(output, runId) {
    if (this.metadatas[runId] === void 0) return;
    if (!this.emittedChatModelRunIds[runId]) {
      const chatGeneration = output.generations?.[0]?.[0];
      if (isBaseMessage(chatGeneration?.message)) this._emit(this.metadatas[runId], chatGeneration?.message, runId, true);
      delete this.emittedChatModelRunIds[runId];
    }
    delete this.metadatas[runId];
    delete this.stableMessageIdMap[runId];
  }
  handleLLMError(_err, runId) {
    delete this.metadatas[runId];
  }
  handleChainStart(_chain, inputs, runId, _parentRunId, tags, metadata, _runType, name) {
    if (metadata !== void 0 && name === metadata.langgraph_node && (tags === void 0 || !tags.includes(TAG_HIDDEN))) {
      this.metadatas[runId] = [metadata.langgraph_checkpoint_ns.split("|"), {
        tags,
        name,
        ...metadata
      }];
      if (typeof inputs === "object") {
        for (const value of Object.values(inputs)) if ((isBaseMessage(value) || isBaseMessageChunk(value)) && value.id !== void 0) this.seen[value.id] = value;
        else if (Array.isArray(value)) {
          for (const item of value) if ((isBaseMessage(item) || isBaseMessageChunk(item)) && item.id !== void 0) this.seen[item.id] = item;
        }
      }
    }
  }
  handleChainEnd(outputs, runId) {
    const metadata = this.metadatas[runId];
    delete this.metadatas[runId];
    if (metadata !== void 0) {
      if (isBaseMessage(outputs)) this._emit(metadata, outputs, runId, true);
      else if (Array.isArray(outputs)) {
        for (const value of outputs) if (isBaseMessage(value)) this._emit(metadata, value, runId, true);
      } else if (outputs != null && typeof outputs === "object") {
        for (const value of Object.values(outputs)) if (isBaseMessage(value)) this._emit(metadata, value, runId, true);
        else if (Array.isArray(value)) {
          for (const item of value) if (isBaseMessage(item)) this._emit(metadata, item, runId, true);
        }
      }
    }
  }
  handleChainError(_err, runId) {
    delete this.metadatas[runId];
  }
};

// node_modules/@langchain/langgraph/dist/pregel/retry.js
var DEFAULT_INITIAL_INTERVAL = 500;
var DEFAULT_BACKOFF_FACTOR = 2;
var DEFAULT_MAX_INTERVAL = 128e3;
var DEFAULT_MAX_RETRIES = 3;
var DEFAULT_STATUS_NO_RETRY = [
  400,
  401,
  402,
  403,
  404,
  405,
  406,
  407,
  409
];
var DEFAULT_RETRY_ON_HANDLER = (error) => {
  if (error.message.startsWith("Cancel") || error.message.startsWith("AbortError") || error.name === "AbortError") return false;
  if (error.name === "GraphValueError") return false;
  if (error?.code === "ECONNABORTED") return false;
  const status = error?.response?.status ?? error?.status;
  if (status && DEFAULT_STATUS_NO_RETRY.includes(+status)) return false;
  if (error?.error?.code === "insufficient_quota") return false;
  return true;
};
async function _runWithRetry(pregelTask, retryPolicy, configurable, signal) {
  const resolvedRetryPolicy = pregelTask.retry_policy ?? retryPolicy;
  let interval = resolvedRetryPolicy !== void 0 ? resolvedRetryPolicy.initialInterval ?? DEFAULT_INITIAL_INTERVAL : 0;
  let attempts = 0;
  let error;
  let result;
  let { config: config2 } = pregelTask;
  if (configurable) config2 = patchConfigurable2(config2, configurable);
  config2 = {
    ...config2,
    signal
  };
  while (true) {
    if (signal?.aborted) break;
    pregelTask.writes.splice(0, pregelTask.writes.length);
    error = void 0;
    try {
      result = await pregelTask.proc.invoke(pregelTask.input, config2);
      break;
    } catch (e) {
      error = e;
      error.pregelTaskId = pregelTask.id;
      if (isParentCommand(error)) {
        const ns = config2?.configurable?.checkpoint_ns;
        const cmd = error.command;
        if (cmd.graph === ns) {
          for (const writer2 of pregelTask.writers) await writer2.invoke(cmd, config2);
          error = void 0;
          break;
        } else if (cmd.graph === Command.PARENT) {
          const parentNs = getParentCheckpointNamespace(ns);
          error.command = new Command({
            ...error.command,
            graph: parentNs
          });
        }
      }
      if (isGraphBubbleUp(error)) break;
      if (resolvedRetryPolicy === void 0) break;
      attempts += 1;
      if (attempts >= (resolvedRetryPolicy.maxAttempts ?? DEFAULT_MAX_RETRIES)) break;
      if (!(resolvedRetryPolicy.retryOn ?? DEFAULT_RETRY_ON_HANDLER)(error)) break;
      interval = Math.min(resolvedRetryPolicy.maxInterval ?? DEFAULT_MAX_INTERVAL, interval * (resolvedRetryPolicy.backoffFactor ?? DEFAULT_BACKOFF_FACTOR));
      const intervalWithJitter = resolvedRetryPolicy.jitter ? Math.floor(interval + Math.random() * 1e3) : interval;
      await new Promise((resolve) => setTimeout(resolve, intervalWithJitter));
      const errorName = error.name ?? error.constructor.unminifiable_name ?? error.constructor.name;
      if (resolvedRetryPolicy?.logWarning ?? true) console.log(`Retrying task "${String(pregelTask.name)}" after ${interval.toFixed(2)}ms (attempt ${attempts}) after ${errorName}: ${error}`);
      config2 = patchConfigurable2(config2, { [CONFIG_KEY_RESUMING]: true });
    }
  }
  return {
    task: pregelTask,
    result,
    error,
    signalAborted: signal?.aborted
  };
}

// node_modules/@langchain/langgraph/dist/pregel/runner.js
var PROMISE_ADDED_SYMBOL = /* @__PURE__ */ Symbol.for("promiseAdded");
function createPromiseBarrier() {
  const barrier = {
    next: () => void 0,
    wait: Promise.resolve(PROMISE_ADDED_SYMBOL)
  };
  function waitHandler(resolve) {
    barrier.next = () => {
      barrier.wait = new Promise(waitHandler);
      resolve(PROMISE_ADDED_SYMBOL);
    };
  }
  barrier.wait = new Promise(waitHandler);
  return barrier;
}
var PregelRunner = class {
  nodeFinished;
  loop;
  /**
  * Construct a new PregelRunner, which executes tasks from the provided PregelLoop.
  * @param loop - The PregelLoop that produces tasks for this runner to execute.
  */
  constructor({ loop, nodeFinished }) {
    this.loop = loop;
    this.nodeFinished = nodeFinished;
  }
  /**
  * Execute tasks from the current step of the PregelLoop.
  *
  * Note: this method does NOT call {@link PregelLoop}#tick. That must be handled externally.
  * @param options - Options for the execution.
  */
  async tick(options = {}) {
    const { timeout, retryPolicy, onStepWrite, maxConcurrency } = options;
    const nodeErrors = /* @__PURE__ */ new Set();
    let graphBubbleUp;
    const exceptionSignalController = new AbortController();
    const exceptionSignal = exceptionSignalController.signal;
    const stepTimeoutSignal = timeout ? AbortSignal.timeout(timeout) : void 0;
    const pendingTasks = Object.values(this.loop.tasks).filter((t) => t.writes.length === 0);
    const { signals, disposeCombinedSignal } = this._initializeAbortSignals({
      exceptionSignal,
      stepTimeoutSignal,
      signal: options.signal
    });
    const taskStream = this._executeTasksWithRetry(pendingTasks, {
      signals,
      retryPolicy,
      maxConcurrency
    });
    for await (const { task: task2, error, signalAborted } of taskStream) {
      this._commit(task2, error);
      if (isGraphInterrupt(error)) graphBubbleUp = error;
      else if (isGraphBubbleUp(error) && !isGraphInterrupt(graphBubbleUp)) graphBubbleUp = error;
      else if (error && (nodeErrors.size === 0 || !signalAborted)) {
        exceptionSignalController.abort();
        nodeErrors.add(error);
      }
    }
    disposeCombinedSignal?.();
    onStepWrite?.(this.loop.step, Object.values(this.loop.tasks).map((task2) => task2.writes).flat());
    if (nodeErrors.size === 1) throw Array.from(nodeErrors)[0];
    else if (nodeErrors.size > 1) throw new AggregateError(Array.from(nodeErrors), `Multiple errors occurred during superstep ${this.loop.step}. See the "errors" field of this exception for more details.`);
    if (isGraphInterrupt(graphBubbleUp)) throw graphBubbleUp;
    if (isGraphBubbleUp(graphBubbleUp) && this.loop.isNested) throw graphBubbleUp;
  }
  /**
  * Initializes the current AbortSignals for the PregelRunner, handling the various ways that
  * AbortSignals must be chained together so that the PregelLoop can be interrupted if necessary
  * while still allowing nodes to gracefully exit.
  *
  * This method must only be called once per PregelRunner#tick. It has the side effect of updating
  * the PregelLoop#config with the new AbortSignals so they may be propagated correctly to future
  * ticks and subgraph calls.
  *
  * @param options - Options for the initialization.
  * @returns The current abort signals.
  * @internal
  */
  _initializeAbortSignals({ exceptionSignal, stepTimeoutSignal, signal }) {
    const previousSignals = this.loop.config.configurable?.[CONFIG_KEY_ABORT_SIGNALS] ?? {};
    const externalAbortSignal = previousSignals.externalAbortSignal ?? signal;
    const timeoutAbortSignal = stepTimeoutSignal ?? previousSignals.timeoutAbortSignal;
    const { signal: composedAbortSignal, dispose: disposeCombinedSignal } = combineAbortSignals(externalAbortSignal, timeoutAbortSignal, exceptionSignal);
    const signals = {
      externalAbortSignal,
      timeoutAbortSignal,
      composedAbortSignal
    };
    this.loop.config = patchConfigurable2(this.loop.config, { [CONFIG_KEY_ABORT_SIGNALS]: signals });
    return {
      signals,
      disposeCombinedSignal
    };
  }
  /**
  * Concurrently executes tasks with the requested retry policy, yielding a {@link SettledPregelTask} for each task as it completes.
  * @param tasks - The tasks to execute.
  * @param options - Options for the execution.
  */
  async *_executeTasksWithRetry(tasks, options) {
    const { retryPolicy, maxConcurrency, signals } = options ?? {};
    const barrier = createPromiseBarrier();
    const executingTasksMap = {};
    const thisCall = {
      executingTasksMap,
      barrier,
      retryPolicy,
      scheduleTask: async (task2, writeIdx, call3) => this.loop.acceptPush(task2, writeIdx, call3)
    };
    if (signals?.composedAbortSignal?.aborted) throw new Error("Abort");
    let startedTasksCount = 0;
    let listener;
    const timeoutOrCancelSignal = combineAbortSignals(signals?.externalAbortSignal, signals?.timeoutAbortSignal);
    const abortPromise = timeoutOrCancelSignal.signal ? new Promise((_resolve, reject) => {
      listener = () => reject(new Error("Abort"));
      timeoutOrCancelSignal.signal?.addEventListener("abort", listener, { once: true });
    }) : void 0;
    while ((startedTasksCount === 0 || Object.keys(executingTasksMap).length > 0) && tasks.length) {
      for (; Object.values(executingTasksMap).length < (maxConcurrency ?? tasks.length) && startedTasksCount < tasks.length; startedTasksCount += 1) {
        const task2 = tasks[startedTasksCount];
        executingTasksMap[task2.id] = _runWithRetry(task2, retryPolicy, { [CONFIG_KEY_CALL]: call?.bind(thisCall, this, task2) }, signals?.composedAbortSignal).catch((error) => {
          return {
            task: task2,
            error,
            signalAborted: signals?.composedAbortSignal?.aborted
          };
        });
      }
      const settledTask = await Promise.race([
        ...Object.values(executingTasksMap),
        ...abortPromise ? [abortPromise] : [],
        barrier.wait
      ]);
      if (settledTask === PROMISE_ADDED_SYMBOL) continue;
      yield settledTask;
      if (listener != null) {
        timeoutOrCancelSignal.signal?.removeEventListener("abort", listener);
        timeoutOrCancelSignal.dispose?.();
      }
      delete executingTasksMap[settledTask.task.id];
    }
  }
  /**
  * Determines what writes to apply based on whether the task completed successfully, and what type of error occurred.
  *
  * Throws an error if the error is a {@link GraphBubbleUp} error and {@link PregelLoop}#isNested is true.
  *
  * @param task - The task to commit.
  * @param error - The error that occurred, if any.
  */
  _commit(task2, error) {
    if (error !== void 0) if (isGraphInterrupt(error)) {
      if (error.interrupts.length) {
        const interrupts = error.interrupts.map((interrupt2) => [INTERRUPT2, interrupt2]);
        const resumes = task2.writes.filter((w) => w[0] === RESUME2);
        if (resumes.length) interrupts.push(...resumes);
        this.loop.putWrites(task2.id, interrupts);
      }
    } else if (isGraphBubbleUp(error) && task2.writes.length) this.loop.putWrites(task2.id, task2.writes);
    else this.loop.putWrites(task2.id, [[ERROR3, {
      message: error.message,
      name: error.name
    }]]);
    else {
      if (this.nodeFinished && (task2.config?.tags == null || !task2.config.tags.includes(TAG_HIDDEN))) this.nodeFinished(String(task2.name));
      if (task2.writes.length === 0) task2.writes.push([NO_WRITES, null]);
      this.loop.putWrites(task2.id, task2.writes);
    }
  }
};
async function call(runner, task2, func, name, input, options = {}) {
  const scratchpad = task2.config?.configurable?.[CONFIG_KEY_SCRATCHPAD];
  if (!scratchpad) throw new Error(`BUG: No scratchpad found on task ${task2.name}__${task2.id}`);
  const cnt = scratchpad.callCounter;
  scratchpad.callCounter += 1;
  const wcall = new Call({
    func,
    name,
    input,
    cache: options.cache,
    retry: options.retry,
    callbacks: options.callbacks
  });
  const nextTask = await this.scheduleTask(task2, cnt, wcall);
  if (!nextTask) return void 0;
  const existingPromise = this.executingTasksMap[nextTask.id];
  if (existingPromise !== void 0) return existingPromise;
  if (nextTask.writes.length > 0) {
    const returns = nextTask.writes.filter(([c]) => c === RETURN);
    const errors = nextTask.writes.filter(([c]) => c === ERROR3);
    if (returns.length > 0) {
      if (returns.length === 1) return Promise.resolve(returns[0][1]);
      throw new Error(`BUG: multiple returns found for task ${nextTask.name}__${nextTask.id}`);
    }
    if (errors.length > 0) {
      if (errors.length === 1) {
        const errorValue = errors[0][1];
        const error = errorValue instanceof Error ? errorValue : new Error(String(errorValue));
        return Promise.reject(error);
      }
      throw new Error(`BUG: multiple errors found for task ${nextTask.name}__${nextTask.id}`);
    }
    return;
  } else {
    const prom = _runWithRetry(nextTask, options.retry, { [CONFIG_KEY_CALL]: call.bind(this, runner, nextTask) });
    this.executingTasksMap[nextTask.id] = prom;
    this.barrier.next();
    return prom.then(({ result, error }) => {
      if (error) return Promise.reject(error);
      return result;
    });
  }
}

// node_modules/@langchain/langgraph/dist/pregel/validate.js
var GraphValidationError = class extends Error {
  constructor(message) {
    super(message);
    this.name = "GraphValidationError";
  }
};
function validateGraph({ nodes, channels, inputChannels, outputChannels, streamChannels, interruptAfterNodes, interruptBeforeNodes }) {
  if (!channels) throw new GraphValidationError("Channels not provided");
  const subscribedChannels = /* @__PURE__ */ new Set();
  const allOutputChannels = /* @__PURE__ */ new Set();
  for (const [name, node] of Object.entries(nodes)) {
    if (name === INTERRUPT2) throw new GraphValidationError(`"Node name ${INTERRUPT2} is reserved"`);
    if (node.constructor === PregelNode) node.triggers.forEach((trigger) => subscribedChannels.add(trigger));
    else throw new GraphValidationError(`Invalid node type ${typeof node}, expected PregelNode`);
  }
  for (const chan of subscribedChannels) if (!(chan in channels)) throw new GraphValidationError(`Subscribed channel '${String(chan)}' not in channels`);
  if (!Array.isArray(inputChannels)) {
    if (!subscribedChannels.has(inputChannels)) throw new GraphValidationError(`Input channel ${String(inputChannels)} is not subscribed to by any node`);
  } else if (inputChannels.every((channel) => !subscribedChannels.has(channel))) throw new GraphValidationError(`None of the input channels ${inputChannels} are subscribed to by any node`);
  if (!Array.isArray(outputChannels)) allOutputChannels.add(outputChannels);
  else outputChannels.forEach((chan) => allOutputChannels.add(chan));
  if (streamChannels && !Array.isArray(streamChannels)) allOutputChannels.add(streamChannels);
  else if (Array.isArray(streamChannels)) streamChannels.forEach((chan) => allOutputChannels.add(chan));
  for (const chan of allOutputChannels) if (!(chan in channels)) throw new GraphValidationError(`Output channel '${String(chan)}' not in channels`);
  if (interruptAfterNodes && interruptAfterNodes !== "*") {
    for (const node of interruptAfterNodes) if (!(node in nodes)) throw new GraphValidationError(`Node ${String(node)} not in nodes`);
  }
  if (interruptBeforeNodes && interruptBeforeNodes !== "*") {
    for (const node of interruptBeforeNodes) if (!(node in nodes)) throw new GraphValidationError(`Node ${String(node)} not in nodes`);
  }
}
function validateKeys(keys, channels) {
  if (Array.isArray(keys)) {
    for (const key of keys) if (!(key in channels)) throw new Error(`Key ${String(key)} not found in channels`);
  } else if (!(keys in channels)) throw new Error(`Key ${String(keys)} not found in channels`);
}

// node_modules/@langchain/langgraph/dist/channels/topic.js
var Topic = class Topic2 extends BaseChannel {
  lc_graph_name = "Topic";
  unique = false;
  accumulate = false;
  seen;
  values;
  constructor(fields) {
    super();
    this.unique = fields?.unique ?? this.unique;
    this.accumulate = fields?.accumulate ?? this.accumulate;
    this.seen = /* @__PURE__ */ new Set();
    this.values = [];
  }
  fromCheckpoint(checkpoint) {
    const empty = new Topic2({
      unique: this.unique,
      accumulate: this.accumulate
    });
    if (typeof checkpoint !== "undefined") {
      empty.seen = new Set(checkpoint[0]);
      empty.values = checkpoint[1];
    }
    return empty;
  }
  update(values) {
    let updated = false;
    if (!this.accumulate) {
      updated = this.values.length > 0;
      this.values = [];
    }
    const flatValues = values.flat();
    if (flatValues.length > 0) if (this.unique) {
      for (const value of flatValues) if (!this.seen.has(value)) {
        updated = true;
        this.seen.add(value);
        this.values.push(value);
      }
    } else {
      updated = true;
      this.values.push(...flatValues);
    }
    return updated;
  }
  get() {
    if (this.values.length === 0) throw new EmptyChannelError();
    return this.values;
  }
  checkpoint() {
    return [[...this.seen], this.values];
  }
  isAvailable() {
    return this.values.length !== 0;
  }
};

// node_modules/@langchain/langgraph/dist/pregel/index.js
var Channel = class {
  static subscribeTo(channels, options) {
    const { key, tags } = {
      key: void 0,
      tags: void 0,
      ...options ?? {}
    };
    if (Array.isArray(channels) && key !== void 0) throw new Error("Can't specify a key when subscribing to multiple channels");
    let channelMappingOrArray;
    if (typeof channels === "string") if (key) channelMappingOrArray = { [key]: channels };
    else channelMappingOrArray = [channels];
    else channelMappingOrArray = Object.fromEntries(channels.map((chan) => [chan, chan]));
    return new PregelNode({
      channels: channelMappingOrArray,
      triggers: Array.isArray(channels) ? channels : [channels],
      tags
    });
  }
  /**
  * Creates a ChannelWrite that specifies how to write values to channels.
  * This is used to define how nodes send output to channels.
  *
  * @example
  * ```typescript
  * // Write to multiple channels
  * const write = Channel.writeTo(["output", "state"]);
  *
  * // Write with specific values
  * const write = Channel.writeTo(["output"], {
  *   state: "completed",
  *   result: calculateResult()
  * });
  *
  * // Write with a transformation function
  * const write = Channel.writeTo(["output"], {
  *   result: (x) => processResult(x)
  * });
  * ```
  *
  * @param channels - Array of channel names to write to
  * @param writes - Optional map of channel names to values or transformations
  * @returns A ChannelWrite object that can be used to write to the specified channels
  */
  static writeTo(channels, writes) {
    const channelWriteEntries = [];
    for (const channel of channels) channelWriteEntries.push({
      channel,
      value: PASSTHROUGH,
      skipNone: false
    });
    for (const [key, value] of Object.entries(writes ?? {})) if (Runnable.isRunnable(value) || typeof value === "function") channelWriteEntries.push({
      channel: key,
      value: PASSTHROUGH,
      skipNone: true,
      mapper: _coerceToRunnable(value)
    });
    else channelWriteEntries.push({
      channel: key,
      value,
      skipNone: false
    });
    return new ChannelWrite(channelWriteEntries);
  }
};
var PartialRunnable = class extends Runnable {
  lc_namespace = ["langgraph", "pregel"];
  invoke(_input, _options) {
    throw new Error("Not implemented");
  }
  withConfig(_config) {
    return super.withConfig(_config);
  }
  stream(input, options) {
    return super.stream(input, options);
  }
};
var Pregel = class extends PartialRunnable {
  /**
  * Name of the class when serialized
  * @internal
  */
  static lc_name() {
    return "LangGraph";
  }
  /** @internal LangChain namespace for serialization necessary because Pregel extends Runnable */
  lc_namespace = ["langgraph", "pregel"];
  /** @internal Flag indicating this is a Pregel instance - necessary for serialization */
  lg_is_pregel = true;
  /** The nodes in the graph, mapping node names to their PregelNode instances */
  nodes;
  /** The channels in the graph, mapping channel names to their BaseChannel or ManagedValueSpec instances */
  channels;
  /**
  * The input channels for the graph. These channels receive the initial input when the graph is invoked.
  * Can be a single channel key or an array of channel keys.
  */
  inputChannels;
  /**
  * The output channels for the graph. These channels contain the final output when the graph completes.
  * Can be a single channel key or an array of channel keys.
  */
  outputChannels;
  /** Whether to automatically validate the graph structure when it is compiled. Defaults to true. */
  autoValidate = true;
  /**
  * The streaming modes enabled for this graph. Defaults to ["values"].
  * Supported modes:
  * - "values": Streams the full state after each step
  * - "updates": Streams state updates after each step
  * - "messages": Streams messages from within nodes
  * - "custom": Streams custom events from within nodes
  * - "debug": Streams events related to the execution of the graph - useful for tracing & debugging graph execution
  */
  streamMode = ["values"];
  /**
  * Optional channels to stream. If not specified, all channels will be streamed.
  * Can be a single channel key or an array of channel keys.
  */
  streamChannels;
  /**
  * Optional array of node names or "all" to interrupt after executing these nodes.
  * Used for implementing human-in-the-loop workflows.
  */
  interruptAfter;
  /**
  * Optional array of node names or "all" to interrupt before executing these nodes.
  * Used for implementing human-in-the-loop workflows.
  */
  interruptBefore;
  /** Optional timeout in milliseconds for the execution of each superstep */
  stepTimeout;
  /** Whether to enable debug logging. Defaults to false. */
  debug = false;
  /**
  * Optional checkpointer for persisting graph state.
  * When provided, saves a checkpoint of the graph state at every superstep.
  * When false or undefined, checkpointing is disabled, and the graph will not be able to save or restore state.
  */
  checkpointer;
  /** Optional retry policy for handling failures in node execution */
  retryPolicy;
  /** The default configuration for graph execution, can be overridden on a per-invocation basis */
  config;
  /**
  * Optional long-term memory store for the graph, allows for persistence & retrieval of data across threads
  */
  store;
  /**
  * Optional cache for the graph, useful for caching tasks.
  */
  cache;
  /**
  * Optional interrupt helper function.
  * @internal
  */
  userInterrupt;
  /**
  * The trigger to node mapping for the graph run.
  * @internal
  */
  triggerToNodes = {};
  /**
  * Constructor for Pregel - meant for internal use only.
  *
  * @internal
  */
  constructor(fields) {
    super(fields);
    let { streamMode } = fields;
    if (streamMode != null && !Array.isArray(streamMode)) streamMode = [streamMode];
    this.nodes = fields.nodes;
    this.channels = fields.channels;
    if (TASKS2 in this.channels && "lc_graph_name" in this.channels[TASKS2] && this.channels[TASKS2].lc_graph_name !== "Topic") throw new Error(`Channel '${TASKS2}' is reserved and cannot be used in the graph.`);
    else this.channels[TASKS2] = new Topic({ accumulate: false });
    this.autoValidate = fields.autoValidate ?? this.autoValidate;
    this.streamMode = streamMode ?? this.streamMode;
    this.inputChannels = fields.inputChannels;
    this.outputChannels = fields.outputChannels;
    this.streamChannels = fields.streamChannels ?? this.streamChannels;
    this.interruptAfter = fields.interruptAfter;
    this.interruptBefore = fields.interruptBefore;
    this.stepTimeout = fields.stepTimeout ?? this.stepTimeout;
    this.debug = fields.debug ?? this.debug;
    this.checkpointer = fields.checkpointer;
    this.retryPolicy = fields.retryPolicy;
    this.config = fields.config;
    this.store = fields.store;
    this.cache = fields.cache;
    this.name = fields.name;
    this.triggerToNodes = fields.triggerToNodes ?? this.triggerToNodes;
    this.userInterrupt = fields.userInterrupt;
    if (this.autoValidate) this.validate();
  }
  /**
  * Creates a new instance of the Pregel graph with updated configuration.
  * This method follows the immutable pattern - instead of modifying the current instance,
  * it returns a new instance with the merged configuration.
  *
  * @example
  * ```typescript
  * // Create a new instance with debug enabled
  * const debugGraph = graph.withConfig({ debug: true });
  *
  * // Create a new instance with a specific thread ID
  * const threadGraph = graph.withConfig({
  *   configurable: { thread_id: "123" }
  * });
  * ```
  *
  * @param config - The configuration to merge with the current configuration
  * @returns A new Pregel instance with the merged configuration
  */
  withConfig(config2) {
    const mergedConfig = mergeConfigs(this.config, config2);
    return new this.constructor({
      ...this,
      config: mergedConfig
    });
  }
  /**
  * Validates the graph structure to ensure it is well-formed.
  * Checks for:
  * - No orphaned nodes
  * - Valid input/output channel configurations
  * - Valid interrupt configurations
  *
  * @returns this - The Pregel instance for method chaining
  * @throws {GraphValidationError} If the graph structure is invalid
  */
  validate() {
    validateGraph({
      nodes: this.nodes,
      channels: this.channels,
      outputChannels: this.outputChannels,
      inputChannels: this.inputChannels,
      streamChannels: this.streamChannels,
      interruptAfterNodes: this.interruptAfter,
      interruptBeforeNodes: this.interruptBefore
    });
    for (const [name, node] of Object.entries(this.nodes)) for (const trigger of node.triggers) {
      this.triggerToNodes[trigger] ??= [];
      this.triggerToNodes[trigger].push(name);
    }
    return this;
  }
  /**
  * Gets a list of all channels that should be streamed.
  * If streamChannels is specified, returns those channels.
  * Otherwise, returns all channels in the graph.
  *
  * @returns Array of channel keys to stream
  */
  get streamChannelsList() {
    if (Array.isArray(this.streamChannels)) return this.streamChannels;
    else if (this.streamChannels) return [this.streamChannels];
    else return Object.keys(this.channels);
  }
  /**
  * Gets the channels to stream in their original format.
  * If streamChannels is specified, returns it as-is (either single key or array).
  * Otherwise, returns all channels in the graph as an array.
  *
  * @returns Channel keys to stream, either as a single key or array
  */
  get streamChannelsAsIs() {
    if (this.streamChannels) return this.streamChannels;
    else return Object.keys(this.channels);
  }
  /**
  * Gets a drawable representation of the graph structure.
  * This is an async version of getGraph() and is the preferred method to use.
  *
  * @param config - Configuration for generating the graph visualization
  * @returns A representation of the graph that can be visualized
  */
  async getGraphAsync(config2) {
    return this.getGraph(config2);
  }
  /**
  * Gets all subgraphs within this graph.
  * A subgraph is a Pregel instance that is nested within a node of this graph.
  *
  * @deprecated Use getSubgraphsAsync instead. The async method will become the default in the next minor release.
  * @param namespace - Optional namespace to filter subgraphs
  * @param recurse - Whether to recursively get subgraphs of subgraphs
  * @returns Generator yielding tuples of [name, subgraph]
  */
  *getSubgraphs(namespace, recurse) {
    for (const [name, node] of Object.entries(this.nodes)) {
      if (namespace !== void 0) {
        if (!namespace.startsWith(name)) continue;
      }
      const candidates = node.subgraphs?.length ? node.subgraphs : [node.bound];
      for (const candidate of candidates) {
        const graph = findSubgraphPregel(candidate);
        if (graph !== void 0) {
          if (name === namespace) {
            yield [name, graph];
            return;
          }
          if (namespace === void 0) yield [name, graph];
          if (recurse) {
            let newNamespace = namespace;
            if (namespace !== void 0) newNamespace = namespace.slice(name.length + 1);
            for (const [subgraphName, subgraph] of graph.getSubgraphs(newNamespace, recurse)) yield [`${name}${CHECKPOINT_NAMESPACE_SEPARATOR}${subgraphName}`, subgraph];
          }
        }
      }
    }
  }
  /**
  * Gets all subgraphs within this graph asynchronously.
  * A subgraph is a Pregel instance that is nested within a node of this graph.
  *
  * @param namespace - Optional namespace to filter subgraphs
  * @param recurse - Whether to recursively get subgraphs of subgraphs
  * @returns AsyncGenerator yielding tuples of [name, subgraph]
  */
  async *getSubgraphsAsync(namespace, recurse) {
    yield* this.getSubgraphs(namespace, recurse);
  }
  /**
  * Prepares a state snapshot from saved checkpoint data.
  * This is an internal method used by getState and getStateHistory.
  *
  * @param config - Configuration for preparing the snapshot
  * @param saved - Optional saved checkpoint data
  * @param subgraphCheckpointer - Optional checkpointer for subgraphs
  * @param applyPendingWrites - Whether to apply pending writes to tasks and then to channels
  * @returns A snapshot of the graph state
  * @internal
  */
  async _prepareStateSnapshot({ config: config2, saved, subgraphCheckpointer, applyPendingWrites = false }) {
    if (saved === void 0) return {
      values: {},
      next: [],
      config: config2,
      tasks: []
    };
    const channels = emptyChannels(this.channels, saved.checkpoint);
    if (saved.pendingWrites?.length) {
      const nullWrites = saved.pendingWrites.filter(([taskId, _]) => taskId === NULL_TASK_ID).map(([_, channel, value]) => [String(channel), value]);
      if (nullWrites.length > 0) _applyWrites(saved.checkpoint, channels, [{
        name: INPUT,
        writes: nullWrites,
        triggers: []
      }], void 0, this.triggerToNodes);
    }
    const nextTasks = Object.values(_prepareNextTasks(saved.checkpoint, saved.pendingWrites, this.nodes, channels, saved.config, true, {
      step: (saved.metadata?.step ?? -1) + 1,
      store: this.store
    }));
    const subgraphs = await gatherIterator(this.getSubgraphsAsync());
    const parentNamespace = saved.config.configurable?.checkpoint_ns ?? "";
    const taskStates = {};
    for (const task2 of nextTasks) {
      const matchingSubgraph = subgraphs.find(([name]) => name === task2.name);
      if (!matchingSubgraph) continue;
      let taskNs = `${String(task2.name)}${CHECKPOINT_NAMESPACE_END}${task2.id}`;
      if (parentNamespace) taskNs = `${parentNamespace}${CHECKPOINT_NAMESPACE_SEPARATOR}${taskNs}`;
      if (subgraphCheckpointer === void 0) {
        const config3 = { configurable: {
          thread_id: saved.config.configurable?.thread_id,
          checkpoint_ns: taskNs
        } };
        taskStates[task2.id] = config3;
      } else {
        const subgraphConfig = { configurable: {
          [CONFIG_KEY_CHECKPOINTER]: subgraphCheckpointer,
          thread_id: saved.config.configurable?.thread_id,
          checkpoint_ns: taskNs
        } };
        const pregel = matchingSubgraph[1];
        taskStates[task2.id] = await pregel.getState(subgraphConfig, { subgraphs: true });
      }
    }
    if (applyPendingWrites && saved.pendingWrites?.length) {
      const nextTaskById = Object.fromEntries(nextTasks.map((task2) => [task2.id, task2]));
      for (const [taskId, channel, value] of saved.pendingWrites) {
        if ([
          ERROR3,
          INTERRUPT2,
          SCHEDULED
        ].includes(channel)) continue;
        if (!(taskId in nextTaskById)) continue;
        nextTaskById[taskId].writes.push([String(channel), value]);
      }
      const tasksWithWrites2 = nextTasks.filter((task2) => task2.writes.length > 0);
      if (tasksWithWrites2.length > 0) _applyWrites(saved.checkpoint, channels, tasksWithWrites2, void 0, this.triggerToNodes);
    }
    let metadata = saved?.metadata;
    if (metadata && saved?.config?.configurable?.thread_id) metadata = {
      ...metadata,
      thread_id: saved.config.configurable.thread_id
    };
    const nextList = nextTasks.filter((task2) => task2.writes.length === 0).map((task2) => task2.name);
    return {
      values: readChannels(channels, this.streamChannelsAsIs),
      next: nextList,
      tasks: tasksWithWrites(nextTasks, saved?.pendingWrites ?? [], taskStates, this.streamChannelsAsIs),
      metadata,
      config: patchCheckpointMap(saved.config, saved.metadata),
      createdAt: saved.checkpoint.ts,
      parentConfig: saved.parentConfig
    };
  }
  /**
  * Gets the current state of the graph.
  * Requires a checkpointer to be configured.
  *
  * @param config - Configuration for retrieving the state
  * @param options - Additional options
  * @returns A snapshot of the current graph state
  * @throws {GraphValueError} If no checkpointer is configured
  */
  async getState(config2, options) {
    const checkpointer = config2.configurable?.[CONFIG_KEY_CHECKPOINTER] ?? this.checkpointer;
    if (!checkpointer) throw new GraphValueError("No checkpointer set", { lc_error_code: "MISSING_CHECKPOINTER" });
    const checkpointNamespace = config2.configurable?.checkpoint_ns ?? "";
    if (checkpointNamespace !== "" && config2.configurable?.[CONFIG_KEY_CHECKPOINTER] === void 0) {
      const recastNamespace = recastCheckpointNamespace(checkpointNamespace);
      for await (const [name, subgraph] of this.getSubgraphsAsync(recastNamespace, true)) if (name === recastNamespace) return await subgraph.getState(patchConfigurable(config2, { [CONFIG_KEY_CHECKPOINTER]: checkpointer }), { subgraphs: options?.subgraphs });
      throw new Error(`Subgraph with namespace "${recastNamespace}" not found.`);
    }
    const mergedConfig = mergeConfigs(this.config, config2);
    const saved = await checkpointer.getTuple(config2);
    return await this._prepareStateSnapshot({
      config: mergedConfig,
      saved,
      subgraphCheckpointer: options?.subgraphs ? checkpointer : void 0,
      applyPendingWrites: !config2.configurable?.checkpoint_id
    });
  }
  /**
  * Gets the history of graph states.
  * Requires a checkpointer to be configured.
  * Useful for:
  * - Debugging execution history
  * - Implementing time travel
  * - Analyzing graph behavior
  *
  * @param config - Configuration for retrieving the history
  * @param options - Options for filtering the history
  * @returns An async iterator of state snapshots
  * @throws {Error} If no checkpointer is configured
  */
  async *getStateHistory(config2, options) {
    const checkpointer = config2.configurable?.[CONFIG_KEY_CHECKPOINTER] ?? this.checkpointer;
    if (!checkpointer) throw new GraphValueError("No checkpointer set", { lc_error_code: "MISSING_CHECKPOINTER" });
    const checkpointNamespace = config2.configurable?.checkpoint_ns ?? "";
    if (checkpointNamespace !== "" && config2.configurable?.[CONFIG_KEY_CHECKPOINTER] === void 0) {
      const recastNamespace = recastCheckpointNamespace(checkpointNamespace);
      for await (const [name, pregel] of this.getSubgraphsAsync(recastNamespace, true)) if (name === recastNamespace) {
        yield* pregel.getStateHistory(patchConfigurable(config2, { [CONFIG_KEY_CHECKPOINTER]: checkpointer }), options);
        return;
      }
      throw new Error(`Subgraph with namespace "${recastNamespace}" not found.`);
    }
    const mergedConfig = mergeConfigs(this.config, config2, { configurable: { checkpoint_ns: checkpointNamespace } });
    for await (const checkpointTuple of checkpointer.list(mergedConfig, options)) yield this._prepareStateSnapshot({
      config: checkpointTuple.config,
      saved: checkpointTuple
    });
  }
  /**
  * Apply updates to the graph state in bulk.
  * Requires a checkpointer to be configured.
  *
  * This method is useful for recreating a thread
  * from a list of updates, especially if a checkpoint
  * is created as a result of multiple tasks.
  *
  * @internal The API might change in the future.
  *
  * @param startConfig - Configuration for the update
  * @param updates - The list of updates to apply to graph state
  * @returns Updated configuration
  * @throws {GraphValueError} If no checkpointer is configured
  * @throws {InvalidUpdateError} If the update cannot be attributed to a node or an update can be only applied in sequence.
  */
  async bulkUpdateState(startConfig, supersteps) {
    const checkpointer = startConfig.configurable?.[CONFIG_KEY_CHECKPOINTER] ?? this.checkpointer;
    if (!checkpointer) throw new GraphValueError("No checkpointer set", { lc_error_code: "MISSING_CHECKPOINTER" });
    if (supersteps.length === 0) throw new Error("No supersteps provided");
    if (supersteps.some((s) => s.updates.length === 0)) throw new Error("No updates provided");
    const checkpointNamespace = startConfig.configurable?.checkpoint_ns ?? "";
    if (checkpointNamespace !== "" && startConfig.configurable?.[CONFIG_KEY_CHECKPOINTER] === void 0) {
      const recastNamespace = recastCheckpointNamespace(checkpointNamespace);
      for await (const [, pregel] of this.getSubgraphsAsync(recastNamespace, true)) return await pregel.bulkUpdateState(patchConfigurable(startConfig, { [CONFIG_KEY_CHECKPOINTER]: checkpointer }), supersteps);
      throw new Error(`Subgraph "${recastNamespace}" not found`);
    }
    const updateSuperStep = async (inputConfig, updates) => {
      const config2 = this.config ? mergeConfigs(this.config, inputConfig) : inputConfig;
      const saved = await checkpointer.getTuple(config2);
      const checkpoint = saved !== void 0 ? copyCheckpoint(saved.checkpoint) : emptyCheckpoint();
      const checkpointPreviousVersions = { ...saved?.checkpoint.channel_versions };
      const step = saved?.metadata?.step ?? -1;
      let checkpointConfig = patchConfigurable(config2, { checkpoint_ns: config2.configurable?.checkpoint_ns ?? "" });
      let checkpointMetadata = config2.metadata ?? {};
      if (saved?.config.configurable) {
        checkpointConfig = patchConfigurable(config2, saved.config.configurable);
        checkpointMetadata = {
          ...saved.metadata,
          ...checkpointMetadata
        };
      }
      const { values, asNode } = updates[0];
      if (values == null && asNode === void 0) {
        if (updates.length > 1) throw new InvalidUpdateError(`Cannot create empty checkpoint with multiple updates`);
        return patchCheckpointMap(await checkpointer.put(checkpointConfig, createCheckpoint(checkpoint, void 0, step), {
          source: "update",
          step: step + 1,
          parents: saved?.metadata?.parents ?? {}
        }, {}), saved ? saved.metadata : void 0);
      }
      const channels = emptyChannels(this.channels, checkpoint);
      if (values === null && asNode === END) {
        if (updates.length > 1) throw new InvalidUpdateError(`Cannot apply multiple updates when clearing state`);
        if (saved) {
          const nextTasks = _prepareNextTasks(checkpoint, saved.pendingWrites || [], this.nodes, channels, saved.config, true, {
            step: (saved.metadata?.step ?? -1) + 1,
            checkpointer,
            store: this.store
          });
          const nullWrites = (saved.pendingWrites || []).filter((w) => w[0] === NULL_TASK_ID).map((w) => w.slice(1));
          if (nullWrites.length > 0) _applyWrites(checkpoint, channels, [{
            name: INPUT,
            writes: nullWrites,
            triggers: []
          }], checkpointer.getNextVersion.bind(checkpointer), this.triggerToNodes);
          for (const [taskId, k, v] of saved.pendingWrites || []) {
            if ([
              ERROR3,
              INTERRUPT2,
              SCHEDULED
            ].includes(k)) continue;
            if (!(taskId in nextTasks)) continue;
            nextTasks[taskId].writes.push([k, v]);
          }
          _applyWrites(checkpoint, channels, Object.values(nextTasks), checkpointer.getNextVersion.bind(checkpointer), this.triggerToNodes);
        }
        return patchCheckpointMap(await checkpointer.put(checkpointConfig, createCheckpoint(checkpoint, channels, step), {
          ...checkpointMetadata,
          source: "update",
          step: step + 1,
          parents: saved?.metadata?.parents ?? {}
        }, getNewChannelVersions(checkpointPreviousVersions, checkpoint.channel_versions)), saved ? saved.metadata : void 0);
      }
      if (asNode === COPY) {
        if (updates.length > 1) throw new InvalidUpdateError(`Cannot copy checkpoint with multiple updates`);
        if (saved == null) throw new InvalidUpdateError(`Cannot copy a non-existent checkpoint`);
        const isCopyWithUpdates = (values2) => {
          if (!Array.isArray(values2)) return false;
          if (values2.length === 0) return false;
          return values2.every((v) => Array.isArray(v) && v.length === 2);
        };
        const nextCheckpoint = createCheckpoint(checkpoint, void 0, step);
        const nextConfig2 = await checkpointer.put(saved.parentConfig ?? patchConfigurable(saved.config, { checkpoint_id: void 0 }), nextCheckpoint, {
          source: "fork",
          step: step + 1,
          parents: saved.metadata?.parents ?? {}
        }, {});
        if (isCopyWithUpdates(values)) {
          const nextTasks = _prepareNextTasks(nextCheckpoint, saved.pendingWrites, this.nodes, channels, nextConfig2, false, { step: step + 2 });
          const tasksGroupBy = Object.values(nextTasks).reduce((acc, { name, id }) => {
            acc[name] ??= [];
            acc[name].push({ id });
            return acc;
          }, {});
          const userGroupBy = values.reduce((acc, item) => {
            const [values2, asNode2] = item;
            acc[asNode2] ??= [];
            const targetIdx = acc[asNode2].length;
            const taskId = tasksGroupBy[asNode2]?.[targetIdx]?.id;
            acc[asNode2].push({
              values: values2,
              asNode: asNode2,
              taskId
            });
            return acc;
          }, {});
          return updateSuperStep(patchCheckpointMap(nextConfig2, saved.metadata), Object.values(userGroupBy).flat());
        }
        return patchCheckpointMap(nextConfig2, saved.metadata);
      }
      if (asNode === INPUT) {
        if (updates.length > 1) throw new InvalidUpdateError(`Cannot apply multiple updates when updating as input`);
        const inputWrites = await gatherIterator(mapInput(this.inputChannels, values));
        if (inputWrites.length === 0) throw new InvalidUpdateError(`Received no input writes for ${JSON.stringify(this.inputChannels, null, 2)}`);
        _applyWrites(checkpoint, channels, [{
          name: INPUT,
          writes: inputWrites,
          triggers: []
        }], checkpointer.getNextVersion.bind(this.checkpointer), this.triggerToNodes);
        const nextStep = saved?.metadata?.step != null ? saved.metadata.step + 1 : -1;
        const nextConfig2 = await checkpointer.put(checkpointConfig, createCheckpoint(checkpoint, channels, nextStep), {
          source: "input",
          step: nextStep,
          parents: saved?.metadata?.parents ?? {}
        }, getNewChannelVersions(checkpointPreviousVersions, checkpoint.channel_versions));
        await checkpointer.putWrites(nextConfig2, inputWrites, uuid5(INPUT, checkpoint.id));
        return patchCheckpointMap(nextConfig2, saved ? saved.metadata : void 0);
      }
      if (config2.configurable?.checkpoint_id === void 0 && saved?.pendingWrites !== void 0 && saved.pendingWrites.length > 0) {
        const nextTasks = _prepareNextTasks(checkpoint, saved.pendingWrites, this.nodes, channels, saved.config, true, {
          store: this.store,
          checkpointer: this.checkpointer,
          step: (saved.metadata?.step ?? -1) + 1
        });
        const nullWrites = (saved.pendingWrites ?? []).filter((w) => w[0] === NULL_TASK_ID).map((w) => w.slice(1));
        if (nullWrites.length > 0) _applyWrites(saved.checkpoint, channels, [{
          name: INPUT,
          writes: nullWrites,
          triggers: []
        }], void 0, this.triggerToNodes);
        for (const [tid, k, v] of saved.pendingWrites) {
          if ([
            ERROR3,
            INTERRUPT2,
            SCHEDULED
          ].includes(k) || nextTasks[tid] === void 0) continue;
          nextTasks[tid].writes.push([k, v]);
        }
        const tasks2 = Object.values(nextTasks).filter((task2) => {
          return task2.writes.length > 0;
        });
        if (tasks2.length > 0) _applyWrites(checkpoint, channels, tasks2, void 0, this.triggerToNodes);
      }
      const nonNullVersion = Object.values(checkpoint.versions_seen).map((seenVersions) => {
        return Object.values(seenVersions);
      }).flat().find((v) => !!v);
      const validUpdates = [];
      if (updates.length === 1) {
        let { values: values2, asNode: asNode2, taskId } = updates[0];
        if (asNode2 === void 0 && Object.keys(this.nodes).length === 1) [asNode2] = Object.keys(this.nodes);
        else if (asNode2 === void 0 && nonNullVersion === void 0) {
          if (typeof this.inputChannels === "string" && this.nodes[this.inputChannels] !== void 0) asNode2 = this.inputChannels;
        } else if (asNode2 === void 0) {
          const lastSeenByNode = Object.entries(checkpoint.versions_seen).map(([n2, seen]) => {
            return Object.values(seen).map((v) => {
              return [v, n2];
            });
          }).flat().filter(([_, v]) => v !== INTERRUPT2).sort(([aNumber], [bNumber]) => compareChannelVersions(aNumber, bNumber));
          if (lastSeenByNode) {
            if (lastSeenByNode.length === 1) asNode2 = lastSeenByNode[0][1];
            else if (lastSeenByNode[lastSeenByNode.length - 1][0] !== lastSeenByNode[lastSeenByNode.length - 2][0]) asNode2 = lastSeenByNode[lastSeenByNode.length - 1][1];
          }
        }
        if (asNode2 === void 0) throw new InvalidUpdateError(`Ambiguous update, specify "asNode"`);
        validUpdates.push({
          values: values2,
          asNode: asNode2,
          taskId
        });
      } else for (const { asNode: asNode2, values: values2, taskId } of updates) {
        if (asNode2 == null) throw new InvalidUpdateError(`"asNode" is required when applying multiple updates`);
        validUpdates.push({
          values: values2,
          asNode: asNode2,
          taskId
        });
      }
      const tasks = [];
      for (const { asNode: asNode2, values: values2, taskId } of validUpdates) {
        if (this.nodes[asNode2] === void 0) throw new InvalidUpdateError(`Node "${asNode2.toString()}" does not exist`);
        const writers = this.nodes[asNode2].getWriters();
        if (!writers.length) throw new InvalidUpdateError(`No writers found for node "${asNode2.toString()}"`);
        tasks.push({
          name: asNode2,
          input: values2,
          proc: writers.length > 1 ? RunnableSequence.from(writers, { omitSequenceTags: true }) : writers[0],
          writes: [],
          triggers: [INTERRUPT2],
          id: taskId ?? uuid5(INTERRUPT2, checkpoint.id),
          writers: []
        });
      }
      for (const task2 of tasks) await task2.proc.invoke(task2.input, patchConfig({
        ...config2,
        store: config2?.store ?? this.store
      }, {
        runName: config2.runName ?? `${this.getName()}UpdateState`,
        configurable: {
          [CONFIG_KEY_SEND]: (items) => task2.writes.push(...items),
          [CONFIG_KEY_READ]: (select_, fresh_ = false) => _localRead(checkpoint, channels, task2, select_, fresh_)
        }
      }));
      for (const task2 of tasks) {
        const channelWrites = task2.writes.filter((w) => w[0] !== PUSH);
        if (saved !== void 0 && channelWrites.length > 0) await checkpointer.putWrites(checkpointConfig, channelWrites, task2.id);
      }
      _applyWrites(checkpoint, channels, tasks, checkpointer.getNextVersion.bind(this.checkpointer), this.triggerToNodes);
      const newVersions = getNewChannelVersions(checkpointPreviousVersions, checkpoint.channel_versions);
      const nextConfig = await checkpointer.put(checkpointConfig, createCheckpoint(checkpoint, channels, step + 1), {
        source: "update",
        step: step + 1,
        parents: saved?.metadata?.parents ?? {}
      }, newVersions);
      for (const task2 of tasks) {
        const pushWrites = task2.writes.filter((w) => w[0] === PUSH);
        if (pushWrites.length > 0) await checkpointer.putWrites(nextConfig, pushWrites, task2.id);
      }
      return patchCheckpointMap(nextConfig, saved ? saved.metadata : void 0);
    };
    let currentConfig = startConfig;
    for (const { updates } of supersteps) currentConfig = await updateSuperStep(currentConfig, updates);
    return currentConfig;
  }
  /**
  * Updates the state of the graph with new values.
  * Requires a checkpointer to be configured.
  *
  * This method can be used for:
  * - Implementing human-in-the-loop workflows
  * - Modifying graph state during breakpoints
  * - Integrating external inputs into the graph
  *
  * @param inputConfig - Configuration for the update
  * @param values - The values to update the state with
  * @param asNode - Optional node name to attribute the update to
  * @returns Updated configuration
  * @throws {GraphValueError} If no checkpointer is configured
  * @throws {InvalidUpdateError} If the update cannot be attributed to a node
  */
  async updateState(inputConfig, values, asNode) {
    return this.bulkUpdateState(inputConfig, [{ updates: [{
      values,
      asNode
    }] }]);
  }
  /**
  * Gets the default values for various graph configuration options.
  * This is an internal method used to process and normalize configuration options.
  *
  * @param config - The input configuration options
  * @returns A tuple containing normalized values for:
  * - debug mode
  * - stream modes
  * - input keys
  * - output keys
  * - remaining config
  * - interrupt before nodes
  * - interrupt after nodes
  * - checkpointer
  * - store
  * - whether stream mode is single
  * - node cache
  * - whether checkpoint during is enabled
  * @internal
  */
  _defaults(config2) {
    const { debug, streamMode, inputKeys, outputKeys, interruptAfter, interruptBefore, ...rest } = config2;
    let streamModeSingle = true;
    const defaultDebug = debug !== void 0 ? debug : this.debug;
    let defaultOutputKeys = outputKeys;
    if (defaultOutputKeys === void 0) defaultOutputKeys = this.streamChannelsAsIs;
    else validateKeys(defaultOutputKeys, this.channels);
    let defaultInputKeys = inputKeys;
    if (defaultInputKeys === void 0) defaultInputKeys = this.inputChannels;
    else validateKeys(defaultInputKeys, this.channels);
    const defaultInterruptBefore = interruptBefore ?? this.interruptBefore ?? [];
    const defaultInterruptAfter = interruptAfter ?? this.interruptAfter ?? [];
    let defaultStreamMode;
    if (streamMode !== void 0) {
      defaultStreamMode = Array.isArray(streamMode) ? streamMode : [streamMode];
      streamModeSingle = typeof streamMode === "string";
    } else {
      if (config2.configurable?.[CONFIG_KEY_TASK_ID] !== void 0) defaultStreamMode = ["values"];
      else defaultStreamMode = this.streamMode;
      streamModeSingle = true;
    }
    let defaultCheckpointer;
    if (this.checkpointer === false) defaultCheckpointer = void 0;
    else if (config2 !== void 0 && config2.configurable?.[CONFIG_KEY_CHECKPOINTER] !== void 0) defaultCheckpointer = config2.configurable[CONFIG_KEY_CHECKPOINTER];
    else if (this.checkpointer === true) throw new Error("checkpointer: true cannot be used for root graphs.");
    else defaultCheckpointer = this.checkpointer;
    const defaultStore = config2.store ?? this.store;
    const defaultCache = config2.cache ?? this.cache;
    if (config2.durability != null && config2.checkpointDuring != null) throw new Error("Cannot use both `durability` and `checkpointDuring` at the same time.");
    const checkpointDuringDurability = (() => {
      if (config2.checkpointDuring == null) return void 0;
      if (config2.checkpointDuring === false) return "exit";
      return "async";
    })();
    const defaultDurability = config2.durability ?? checkpointDuringDurability ?? config2?.configurable?.[CONFIG_KEY_DURABILITY] ?? "async";
    return [
      defaultDebug,
      defaultStreamMode,
      defaultInputKeys,
      defaultOutputKeys,
      rest,
      defaultInterruptBefore,
      defaultInterruptAfter,
      defaultCheckpointer,
      defaultStore,
      streamModeSingle,
      defaultCache,
      defaultDurability
    ];
  }
  /**
  * Streams the execution of the graph, emitting state updates as they occur.
  * This is the primary method for observing graph execution in real-time.
  *
  * Stream modes:
  * - "values": Emits complete state after each step
  * - "updates": Emits only state changes after each step
  * - "debug": Emits detailed debug information
  * - "messages": Emits messages from within nodes
  * - "custom": Emits custom events from within nodes
  * - "checkpoints": Emits checkpoints from within nodes
  * - "tasks": Emits tasks from within nodes
  *
  * @param input - The input to start graph execution with
  * @param options - Configuration options for streaming
  * @returns An async iterable stream of graph state updates
  */
  async stream(input, options) {
    const abortController = new AbortController();
    const config2 = {
      recursionLimit: this.config?.recursionLimit,
      ...options,
      signal: combineAbortSignals(options?.signal, abortController.signal).signal
    };
    const stream = await super.stream(input, config2);
    return new IterableReadableStreamWithAbortSignal(options?.encoding === "text/event-stream" ? toEventStream(stream) : stream, abortController);
  }
  streamEvents(input, options, streamOptions) {
    const abortController = new AbortController();
    const config2 = {
      recursionLimit: this.config?.recursionLimit,
      ...options,
      callbacks: combineCallbacks(this.config?.callbacks, options?.callbacks),
      signal: combineAbortSignals(options?.signal, abortController.signal).signal
    };
    return new IterableReadableStreamWithAbortSignal(super.streamEvents(input, config2, streamOptions), abortController);
  }
  /**
  * Validates the input for the graph.
  * @param input - The input to validate
  * @returns The validated input
  * @internal
  */
  async _validateInput(input) {
    return input;
  }
  /**
  * Validates the context options for the graph.
  * @param context - The context options to validate
  * @returns The validated context options
  * @internal
  */
  async _validateContext(context2) {
    return context2;
  }
  /**
  * Internal iterator used by stream() to generate state updates.
  * This method handles the core logic of graph execution and streaming.
  *
  * @param input - The input to start graph execution with
  * @param options - Configuration options for streaming
  * @returns AsyncGenerator yielding state updates
  * @internal
  */
  async *_streamIterator(input, options) {
    const streamEncoding = "version" in (options ?? {}) ? void 0 : options?.encoding ?? void 0;
    const streamSubgraphs = options?.subgraphs;
    const inputConfig = ensureLangGraphConfig(this.config, options);
    if (inputConfig.recursionLimit === void 0 || inputConfig.recursionLimit < 1) throw new Error(`Passed "recursionLimit" must be at least 1.`);
    if (this.checkpointer !== void 0 && this.checkpointer !== false && inputConfig.configurable === void 0) throw new Error(`Checkpointer requires one or more of the following "configurable" keys: "thread_id", "checkpoint_ns", "checkpoint_id"`);
    const validInput = await this._validateInput(input);
    const { runId, ...restConfig } = inputConfig;
    const [debug, streamMode, , outputKeys, config2, interruptBefore, interruptAfter, checkpointer, store, streamModeSingle, cache, durability] = this._defaults(restConfig);
    if (typeof config2.context !== "undefined") config2.context = await this._validateContext(config2.context);
    else config2.configurable = await this._validateContext(config2.configurable);
    const stream = new IterableReadableWritableStream({ modes: new Set(streamMode) });
    if (this.checkpointer === true) {
      config2.configurable ??= {};
      const ns = config2.configurable[CONFIG_KEY_CHECKPOINT_NS] ?? "";
      config2.configurable[CONFIG_KEY_CHECKPOINT_NS] = ns.split(CHECKPOINT_NAMESPACE_SEPARATOR).map((part) => part.split(CHECKPOINT_NAMESPACE_END)[0]).join(CHECKPOINT_NAMESPACE_SEPARATOR);
    }
    if (streamMode.includes("messages")) {
      const messageStreamer = new StreamMessagesHandler((chunk) => stream.push(chunk));
      const { callbacks } = config2;
      if (callbacks === void 0) config2.callbacks = [messageStreamer];
      else if (Array.isArray(callbacks)) config2.callbacks = callbacks.concat(messageStreamer);
      else {
        const copiedCallbacks = callbacks.copy();
        copiedCallbacks.addHandler(messageStreamer, true);
        config2.callbacks = copiedCallbacks;
      }
    }
    config2.writer ??= (chunk) => {
      if (!streamMode.includes("custom")) return;
      const ns = getConfig()?.configurable?.[CONFIG_KEY_CHECKPOINT_NS]?.split(CHECKPOINT_NAMESPACE_SEPARATOR).slice(0, -1);
      stream.push([
        ns ?? [],
        "custom",
        chunk
      ]);
    };
    config2.interrupt ??= this.userInterrupt ?? interrupt;
    const runManager = await (await getCallbackManagerForConfig(config2))?.handleChainStart(this.toJSON(), _coerceToDict2(input, "input"), runId, void 0, void 0, void 0, config2?.runName ?? this.getName());
    const channelSpecs = getOnlyChannels(this.channels);
    let loop;
    let loopError;
    const createAndRunLoop = async () => {
      try {
        loop = await PregelLoop.initialize({
          input: validInput,
          config: config2,
          checkpointer,
          nodes: this.nodes,
          channelSpecs,
          outputKeys,
          streamKeys: this.streamChannelsAsIs,
          store,
          cache,
          stream,
          interruptAfter,
          interruptBefore,
          manager: runManager,
          debug: this.debug,
          triggerToNodes: this.triggerToNodes,
          durability
        });
        const runner = new PregelRunner({
          loop,
          nodeFinished: config2.configurable?.[CONFIG_KEY_NODE_FINISHED]
        });
        if (options?.subgraphs) loop.config.configurable = {
          ...loop.config.configurable,
          [CONFIG_KEY_STREAM]: loop.stream
        };
        await this._runLoop({
          loop,
          runner,
          debug,
          config: config2
        });
        if (durability === "sync") await Promise.all(loop?.checkpointerPromises ?? []);
      } catch (e) {
        loopError = e;
      } finally {
        try {
          if (loop) {
            await loop.store?.stop();
            await loop.cache?.stop();
          }
          await Promise.all(loop?.checkpointerPromises ?? []);
        } catch (e) {
          loopError = loopError ?? e;
        }
        if (loopError) stream.error(loopError);
        else stream.close();
      }
    };
    const runLoopPromise = createAndRunLoop();
    try {
      for await (const chunk of stream) {
        if (chunk === void 0) throw new Error("Data structure error.");
        const [namespace, mode, payload] = chunk;
        if (streamMode.includes(mode)) {
          if (streamEncoding === "text/event-stream") {
            if (streamSubgraphs) yield [
              namespace,
              mode,
              payload
            ];
            else yield [
              null,
              mode,
              payload
            ];
            continue;
          }
          if (streamSubgraphs && !streamModeSingle) yield [
            namespace,
            mode,
            payload
          ];
          else if (!streamModeSingle) yield [mode, payload];
          else if (streamSubgraphs) yield [namespace, payload];
          else yield payload;
        }
      }
    } catch (e) {
      await runManager?.handleChainError(loopError);
      throw e;
    } finally {
      await runLoopPromise;
    }
    await runManager?.handleChainEnd(loop?.output ?? {}, runId, void 0, void 0, void 0);
  }
  /**
  * Run the graph with a single input and config.
  * @param input The input to the graph.
  * @param options The configuration to use for the run.
  */
  async invoke(input, options) {
    const streamMode = options?.streamMode ?? "values";
    const config2 = {
      ...options,
      outputKeys: options?.outputKeys ?? this.outputChannels,
      streamMode,
      encoding: void 0
    };
    const chunks = [];
    const stream = await this.stream(input, config2);
    const interruptChunks = [];
    let latest;
    for await (const chunk of stream) if (streamMode === "values") if (isInterrupted(chunk)) interruptChunks.push(chunk[INTERRUPT2]);
    else latest = chunk;
    else chunks.push(chunk);
    if (streamMode === "values") {
      if (interruptChunks.length > 0) {
        const interrupts = interruptChunks.flat(1);
        if (latest == null) return { [INTERRUPT2]: interrupts };
        if (typeof latest === "object") return {
          ...latest,
          [INTERRUPT2]: interrupts
        };
      }
      return latest;
    }
    return chunks;
  }
  async _runLoop(params) {
    const { loop, runner, debug, config: config2 } = params;
    let tickError;
    try {
      while (await loop.tick({ inputKeys: this.inputChannels })) {
        for (const { task: task2 } of await loop._matchCachedWrites()) loop._outputWrites(task2.id, task2.writes, true);
        if (debug) printStepCheckpoint(loop.checkpointMetadata.step, loop.channels, this.streamChannelsList);
        if (debug) printStepTasks(loop.step, Object.values(loop.tasks));
        await runner.tick({
          timeout: this.stepTimeout,
          retryPolicy: this.retryPolicy,
          onStepWrite: (step, writes) => {
            if (debug) printStepWrites(step, writes, this.streamChannelsList);
          },
          maxConcurrency: config2.maxConcurrency,
          signal: config2.signal
        });
      }
      if (loop.status === "out_of_steps") throw new GraphRecursionError([
        `Recursion limit of ${config2.recursionLimit} reached`,
        "without hitting a stop condition. You can increase the",
        `limit by setting the "recursionLimit" config key.`
      ].join(" "), { lc_error_code: "GRAPH_RECURSION_LIMIT" });
    } catch (e) {
      tickError = e;
      if (!await loop.finishAndHandleError(tickError)) throw e;
    } finally {
      if (tickError === void 0) await loop.finishAndHandleError();
    }
  }
  async clearCache() {
    await this.cache?.clear([]);
  }
};

// node_modules/@langchain/langgraph/dist/channels/ephemeral_value.js
var EphemeralValue = class EphemeralValue2 extends BaseChannel {
  lc_graph_name = "EphemeralValue";
  guard;
  value = [];
  constructor(guard = true) {
    super();
    this.guard = guard;
  }
  fromCheckpoint(checkpoint) {
    const empty = new EphemeralValue2(this.guard);
    if (typeof checkpoint !== "undefined") empty.value = [checkpoint];
    return empty;
  }
  update(values) {
    if (values.length === 0) {
      const updated = this.value.length > 0;
      this.value = [];
      return updated;
    }
    if (values.length !== 1 && this.guard) throw new InvalidUpdateError("EphemeralValue can only receive one value per step.");
    this.value = [values[values.length - 1]];
    return true;
  }
  get() {
    if (this.value.length === 0) throw new EmptyChannelError();
    return this.value[0];
  }
  checkpoint() {
    if (this.value.length === 0) throw new EmptyChannelError();
    return this.value[0];
  }
  isAvailable() {
    return this.value.length !== 0;
  }
};

// node_modules/@langchain/langgraph/dist/graph/graph.js
var Branch = class {
  path;
  ends;
  constructor(options) {
    if (Runnable.isRunnable(options.path)) this.path = options.path;
    else this.path = _coerceToRunnable(options.path).withConfig({ runName: `Branch` });
    this.ends = Array.isArray(options.pathMap) ? options.pathMap.reduce((acc, n2) => {
      acc[n2] = n2;
      return acc;
    }, {}) : options.pathMap;
  }
  run(writer2, reader) {
    return ChannelWrite.registerWriter(new RunnableCallable({
      name: "<branch_run>",
      trace: false,
      func: async (input, config2) => {
        try {
          return await this._route(input, config2, writer2, reader);
        } catch (e) {
          if (e.name === NodeInterrupt.unminifiable_name) console.warn("[WARN]: 'NodeInterrupt' thrown in conditional edge. This is likely a bug in your graph implementation.\nNodeInterrupt should only be thrown inside a node, not in edge conditions.");
          throw e;
        }
      }
    }));
  }
  async _route(input, config2, writer2, reader) {
    let result = await this.path.invoke(reader ? reader(config2) : input, config2);
    if (!Array.isArray(result)) result = [result];
    let destinations;
    if (this.ends) destinations = result.map((r) => _isSend(r) ? r : this.ends[r]);
    else destinations = result;
    if (destinations.some((dest) => !dest)) throw new Error("Branch condition returned unknown or null destination");
    if (destinations.filter(_isSend).some((packet) => packet.node === END)) throw new InvalidUpdateError("Cannot send a packet to the END node");
    return await writer2(destinations, config2) ?? input;
  }
};
var Graph$1 = class {
  nodes;
  edges;
  branches;
  entryPoint;
  compiled = false;
  constructor() {
    this.nodes = {};
    this.edges = /* @__PURE__ */ new Set();
    this.branches = {};
  }
  warnIfCompiled(message) {
    if (this.compiled) console.warn(message);
  }
  get allEdges() {
    return this.edges;
  }
  addNode(...args) {
    function isMutlipleNodes(args2) {
      return args2.length >= 1 && typeof args2[0] !== "string";
    }
    const nodes = isMutlipleNodes(args) ? Array.isArray(args[0]) ? args[0] : Object.entries(args[0]) : [[
      args[0],
      args[1],
      args[2]
    ]];
    if (nodes.length === 0) throw new Error("No nodes provided in `addNode`");
    for (const [key, action, options] of nodes) {
      for (const reservedChar of [CHECKPOINT_NAMESPACE_SEPARATOR, CHECKPOINT_NAMESPACE_END]) if (key.includes(reservedChar)) throw new Error(`"${reservedChar}" is a reserved character and is not allowed in node names.`);
      this.warnIfCompiled(`Adding a node to a graph that has already been compiled. This will not be reflected in the compiled graph.`);
      if (key in this.nodes) throw new Error(`Node \`${key}\` already present.`);
      if (key === END) throw new Error(`Node \`${key}\` is reserved.`);
      const runnable = _coerceToRunnable(action);
      this.nodes[key] = {
        runnable,
        metadata: options?.metadata,
        subgraphs: isPregelLike(runnable) ? [runnable] : options?.subgraphs,
        ends: options?.ends
      };
    }
    return this;
  }
  addEdge(startKey, endKey) {
    this.warnIfCompiled(`Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.`);
    if (startKey === END) throw new Error("END cannot be a start node");
    if (endKey === START) throw new Error("START cannot be an end node");
    if (Array.from(this.edges).some(([start]) => start === startKey) && !("channels" in this)) throw new Error(`Already found path for ${startKey}. For multiple edges, use StateGraph.`);
    this.edges.add([startKey, endKey]);
    return this;
  }
  addConditionalEdges(source, path, pathMap) {
    const options = typeof source === "object" ? source : {
      source,
      path,
      pathMap
    };
    this.warnIfCompiled("Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.");
    if (!Runnable.isRunnable(options.path)) {
      const pathDisplayValues = Array.isArray(options.pathMap) ? options.pathMap.join(",") : Object.keys(options.pathMap ?? {}).join(",");
      options.path = _coerceToRunnable(options.path).withConfig({ runName: `Branch<${options.source}${pathDisplayValues !== "" ? `,${pathDisplayValues}` : ""}>`.slice(0, 63) });
    }
    const name = options.path.getName() === "RunnableLambda" ? "condition" : options.path.getName();
    if (this.branches[options.source] && this.branches[options.source][name]) throw new Error(`Condition \`${name}\` already present for node \`${source}\``);
    this.branches[options.source] ??= {};
    this.branches[options.source][name] = new Branch(options);
    return this;
  }
  /**
  * @deprecated use `addEdge(START, key)` instead
  */
  setEntryPoint(key) {
    this.warnIfCompiled("Setting the entry point of a graph that has already been compiled. This will not be reflected in the compiled graph.");
    return this.addEdge(START, key);
  }
  /**
  * @deprecated use `addEdge(key, END)` instead
  */
  setFinishPoint(key) {
    this.warnIfCompiled("Setting a finish point of a graph that has already been compiled. This will not be reflected in the compiled graph.");
    return this.addEdge(key, END);
  }
  compile({ checkpointer, interruptBefore, interruptAfter, name } = {}) {
    this.validate([...Array.isArray(interruptBefore) ? interruptBefore : [], ...Array.isArray(interruptAfter) ? interruptAfter : []]);
    const compiled = new CompiledGraph({
      builder: this,
      checkpointer,
      interruptAfter,
      interruptBefore,
      autoValidate: false,
      nodes: {},
      channels: {
        [START]: new EphemeralValue(),
        [END]: new EphemeralValue()
      },
      inputChannels: START,
      outputChannels: END,
      streamChannels: [],
      streamMode: "values",
      name
    });
    for (const [key, node] of Object.entries(this.nodes)) compiled.attachNode(key, node);
    for (const [start, end] of this.edges) compiled.attachEdge(start, end);
    for (const [start, branches] of Object.entries(this.branches)) for (const [name2, branch] of Object.entries(branches)) compiled.attachBranch(start, name2, branch);
    return compiled.validate();
  }
  validate(interrupt2) {
    const allSources = new Set([...this.allEdges].map(([src, _]) => src));
    for (const [start] of Object.entries(this.branches)) allSources.add(start);
    for (const source of allSources) if (source !== START && !(source in this.nodes)) throw new Error(`Found edge starting at unknown node \`${source}\``);
    const allTargets = new Set([...this.allEdges].map(([_, target]) => target));
    for (const [start, branches] of Object.entries(this.branches)) for (const branch of Object.values(branches)) if (branch.ends != null) for (const end of Object.values(branch.ends)) allTargets.add(end);
    else {
      allTargets.add(END);
      for (const node of Object.keys(this.nodes)) if (node !== start) allTargets.add(node);
    }
    for (const node of Object.values(this.nodes)) for (const target of node.ends ?? []) allTargets.add(target);
    for (const node of Object.keys(this.nodes)) if (!allTargets.has(node)) throw new UnreachableNodeError([
      `Node \`${node}\` is not reachable.`,
      "",
      "If you are returning Command objects from your node,",
      'make sure you are passing names of potential destination nodes as an "ends" array',
      'into ".addNode(..., { ends: ["node1", "node2"] })".'
    ].join("\n"), { lc_error_code: "UNREACHABLE_NODE" });
    for (const target of allTargets) if (target !== END && !(target in this.nodes)) throw new Error(`Found edge ending at unknown node \`${target}\``);
    if (interrupt2) {
      for (const node of interrupt2) if (!(node in this.nodes)) throw new Error(`Interrupt node \`${node}\` is not present`);
    }
    this.compiled = true;
  }
};
var CompiledGraph = class extends Pregel {
  builder;
  constructor({ builder, ...rest }) {
    super(rest);
    this.builder = builder;
  }
  attachNode(key, node) {
    this.channels[key] = new EphemeralValue();
    this.nodes[key] = new PregelNode({
      channels: [],
      triggers: [],
      metadata: node.metadata,
      subgraphs: node.subgraphs,
      ends: node.ends
    }).pipe(node.runnable).pipe(new ChannelWrite([{
      channel: key,
      value: PASSTHROUGH
    }], [TAG_HIDDEN]));
    this.streamChannels.push(key);
  }
  attachEdge(start, end) {
    if (end === END) {
      if (start === START) throw new Error("Cannot have an edge from START to END");
      this.nodes[start].writers.push(new ChannelWrite([{
        channel: END,
        value: PASSTHROUGH
      }], [TAG_HIDDEN]));
    } else {
      this.nodes[end].triggers.push(start);
      this.nodes[end].channels.push(start);
    }
  }
  attachBranch(start, name, branch) {
    if (start === START && !this.nodes[START]) this.nodes[START] = Channel.subscribeTo(START, { tags: [TAG_HIDDEN] });
    this.nodes[start].pipe(branch.run((dests) => {
      return new ChannelWrite(dests.map((dest) => {
        if (_isSend(dest)) return dest;
        return {
          channel: dest === END ? END : `branch:${start}:${name}:${dest}`,
          value: PASSTHROUGH
        };
      }), [TAG_HIDDEN]);
    }));
    const ends = branch.ends ? Object.values(branch.ends) : Object.keys(this.nodes);
    for (const end of ends) if (end !== END) {
      const channelName = `branch:${start}:${name}:${end}`;
      this.channels[channelName] = new EphemeralValue();
      this.nodes[end].triggers.push(channelName);
      this.nodes[end].channels.push(channelName);
    }
  }
  /**
  * Returns a drawable representation of the computation graph.
  */
  async getGraphAsync(config2) {
    const xray = config2?.xray;
    const graph = new Graph();
    const startNodes = { [START]: graph.addNode({ schema: external_exports2.any() }, START) };
    const endNodes = {};
    let subgraphs = {};
    if (xray) subgraphs = Object.fromEntries((await gatherIterator(this.getSubgraphsAsync())).filter((x) => isCompiledGraph(x[1])));
    function addEdge(start, end, label, conditional = false) {
      if (end === END && endNodes[END] === void 0) endNodes[END] = graph.addNode({ schema: external_exports2.any() }, END);
      if (startNodes[start] === void 0) return;
      if (endNodes[end] === void 0) throw new Error(`End node ${end} not found!`);
      return graph.addEdge(startNodes[start], endNodes[end], label !== end ? label : void 0, conditional);
    }
    for (const [key, nodeSpec] of Object.entries(this.builder.nodes)) {
      const displayKey = _escapeMermaidKeywords(key);
      const node = nodeSpec.runnable;
      const metadata = nodeSpec.metadata ?? {};
      if (this.interruptBefore?.includes(key) && this.interruptAfter?.includes(key)) metadata.__interrupt = "before,after";
      else if (this.interruptBefore?.includes(key)) metadata.__interrupt = "before";
      else if (this.interruptAfter?.includes(key)) metadata.__interrupt = "after";
      if (xray) {
        const newXrayValue = typeof xray === "number" ? xray - 1 : xray;
        const drawableSubgraph = subgraphs[key] !== void 0 ? await subgraphs[key].getGraphAsync({
          ...config2,
          xray: newXrayValue
        }) : node.getGraph(config2);
        drawableSubgraph.trimFirstNode();
        drawableSubgraph.trimLastNode();
        if (Object.keys(drawableSubgraph.nodes).length > 1) {
          let _isRunnableInterface = function(thing) {
            return thing ? thing.lc_runnable : false;
          }, _nodeDataStr = function(id, data) {
            if (id !== void 0 && !validate_default(id)) return id;
            else if (_isRunnableInterface(data)) try {
              let dataStr = data.getName();
              dataStr = dataStr.startsWith("Runnable") ? dataStr.slice(8) : dataStr;
              return dataStr;
            } catch (error) {
              return data.getName();
            }
            else return data.name ?? "UnknownSchema";
          };
          const [e, s] = graph.extend(drawableSubgraph, displayKey);
          if (e === void 0) throw new Error(`Could not extend subgraph "${key}" due to missing entrypoint.`);
          if (s !== void 0) startNodes[displayKey] = {
            name: _nodeDataStr(s.id, s.data),
            ...s
          };
          endNodes[displayKey] = {
            name: _nodeDataStr(e.id, e.data),
            ...e
          };
        } else {
          const newNode = graph.addNode(node, displayKey, metadata);
          startNodes[displayKey] = newNode;
          endNodes[displayKey] = newNode;
        }
      } else {
        const newNode = graph.addNode(node, displayKey, metadata);
        startNodes[displayKey] = newNode;
        endNodes[displayKey] = newNode;
      }
    }
    const sortedEdges = [...this.builder.allEdges].sort(([a], [b]) => {
      if (a < b) return -1;
      else if (b > a) return 1;
      else return 0;
    });
    for (const [start, end] of sortedEdges) addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end));
    for (const [start, branches] of Object.entries(this.builder.branches)) {
      const defaultEnds = {
        ...Object.fromEntries(Object.keys(this.builder.nodes).filter((k) => k !== start).map((k) => [_escapeMermaidKeywords(k), _escapeMermaidKeywords(k)])),
        [END]: END
      };
      for (const branch of Object.values(branches)) {
        let ends;
        if (branch.ends !== void 0) ends = branch.ends;
        else ends = defaultEnds;
        for (const [label, end] of Object.entries(ends)) addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end), label, true);
      }
    }
    for (const [key, node] of Object.entries(this.builder.nodes)) if (node.ends !== void 0) for (const end of node.ends) addEdge(_escapeMermaidKeywords(key), _escapeMermaidKeywords(end), void 0, true);
    return graph;
  }
  /**
  * Returns a drawable representation of the computation graph.
  *
  * @deprecated Use getGraphAsync instead. The async method will be the default in the next minor core release.
  */
  getGraph(config2) {
    const xray = config2?.xray;
    const graph = new Graph();
    const startNodes = { [START]: graph.addNode({ schema: external_exports2.any() }, START) };
    const endNodes = {};
    let subgraphs = {};
    if (xray) subgraphs = Object.fromEntries(gatherIteratorSync(this.getSubgraphs()).filter((x) => isCompiledGraph(x[1])));
    function addEdge(start, end, label, conditional = false) {
      if (end === END && endNodes[END] === void 0) endNodes[END] = graph.addNode({ schema: external_exports2.any() }, END);
      return graph.addEdge(startNodes[start], endNodes[end], label !== end ? label : void 0, conditional);
    }
    for (const [key, nodeSpec] of Object.entries(this.builder.nodes)) {
      const displayKey = _escapeMermaidKeywords(key);
      const node = nodeSpec.runnable;
      const metadata = nodeSpec.metadata ?? {};
      if (this.interruptBefore?.includes(key) && this.interruptAfter?.includes(key)) metadata.__interrupt = "before,after";
      else if (this.interruptBefore?.includes(key)) metadata.__interrupt = "before";
      else if (this.interruptAfter?.includes(key)) metadata.__interrupt = "after";
      if (xray) {
        const newXrayValue = typeof xray === "number" ? xray - 1 : xray;
        const drawableSubgraph = subgraphs[key] !== void 0 ? subgraphs[key].getGraph({
          ...config2,
          xray: newXrayValue
        }) : node.getGraph(config2);
        drawableSubgraph.trimFirstNode();
        drawableSubgraph.trimLastNode();
        if (Object.keys(drawableSubgraph.nodes).length > 1) {
          let _isRunnableInterface = function(thing) {
            return thing ? thing.lc_runnable : false;
          }, _nodeDataStr = function(id, data) {
            if (id !== void 0 && !validate_default(id)) return id;
            else if (_isRunnableInterface(data)) try {
              let dataStr = data.getName();
              dataStr = dataStr.startsWith("Runnable") ? dataStr.slice(8) : dataStr;
              return dataStr;
            } catch (error) {
              return data.getName();
            }
            else return data.name ?? "UnknownSchema";
          };
          const [e, s] = graph.extend(drawableSubgraph, displayKey);
          if (e === void 0) throw new Error(`Could not extend subgraph "${key}" due to missing entrypoint.`);
          if (s !== void 0) startNodes[displayKey] = {
            name: _nodeDataStr(s.id, s.data),
            ...s
          };
          endNodes[displayKey] = {
            name: _nodeDataStr(e.id, e.data),
            ...e
          };
        } else {
          const newNode = graph.addNode(node, displayKey, metadata);
          startNodes[displayKey] = newNode;
          endNodes[displayKey] = newNode;
        }
      } else {
        const newNode = graph.addNode(node, displayKey, metadata);
        startNodes[displayKey] = newNode;
        endNodes[displayKey] = newNode;
      }
    }
    const sortedEdges = [...this.builder.allEdges].sort(([a], [b]) => {
      if (a < b) return -1;
      else if (b > a) return 1;
      else return 0;
    });
    for (const [start, end] of sortedEdges) addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end));
    for (const [start, branches] of Object.entries(this.builder.branches)) {
      const defaultEnds = {
        ...Object.fromEntries(Object.keys(this.builder.nodes).filter((k) => k !== start).map((k) => [_escapeMermaidKeywords(k), _escapeMermaidKeywords(k)])),
        [END]: END
      };
      for (const branch of Object.values(branches)) {
        let ends;
        if (branch.ends !== void 0) ends = branch.ends;
        else ends = defaultEnds;
        for (const [label, end] of Object.entries(ends)) addEdge(_escapeMermaidKeywords(start), _escapeMermaidKeywords(end), label, true);
      }
    }
    return graph;
  }
};
function isCompiledGraph(x) {
  return typeof x.attachNode === "function" && typeof x.attachEdge === "function";
}
function _escapeMermaidKeywords(key) {
  if (key === "subgraph") return `"${key}"`;
  return key;
}

// node_modules/@langchain/langgraph/dist/state/types.js
function isStandardSchema(schema) {
  return typeof schema === "object" && schema !== null && "~standard" in schema && typeof schema["~standard"] === "object" && schema["~standard"] !== null && "validate" in schema["~standard"];
}
function isStandardJSONSchema(schema) {
  return typeof schema === "object" && schema !== null && "~standard" in schema && typeof schema["~standard"] === "object" && schema["~standard"] !== null && "jsonSchema" in schema["~standard"];
}

// node_modules/@langchain/langgraph/dist/state/adapter.js
function getJsonSchemaFromSchema(schema) {
  if (isStandardJSONSchema(schema)) try {
    return schema["~standard"].jsonSchema.input({ target: "draft-07" });
  } catch {
    return;
  }
}
function getSchemaDefaultGetter(schema) {
  if (schema == null) return;
  if (!isStandardSchema(schema)) return;
  try {
    const result = schema["~standard"].validate(void 0);
    if (result && typeof result === "object" && !("then" in result && typeof result.then === "function")) {
      const syncResult = result;
      if (!syncResult.issues) {
        const defaultValue = syncResult.value;
        return () => defaultValue;
      }
    }
  } catch {
  }
}

// node_modules/@langchain/langgraph/dist/channels/untracked_value.js
var MISSING = /* @__PURE__ */ Symbol.for("langgraph.channel.missing");
var UntrackedValueChannel = class UntrackedValueChannel2 extends BaseChannel {
  lc_graph_name = "UntrackedValue";
  /**
  * If true, throws an error when multiple values are received in a single step.
  * If false, stores the last value received.
  */
  guard;
  /**
  * The current value. MISSING sentinel indicates no value has been set.
  */
  _value = MISSING;
  /**
  * Optional factory function for the initial value.
  */
  initialValueFactory;
  constructor(options) {
    super();
    this.guard = options?.guard ?? true;
    this.initialValueFactory = options?.initialValueFactory;
    if (this.initialValueFactory) this._value = this.initialValueFactory();
  }
  /**
  * Return a new channel, ignoring the checkpoint since we don't persist.
  * The initial value (if any) is restored.
  */
  fromCheckpoint(_checkpoint) {
    return new UntrackedValueChannel2({
      guard: this.guard,
      initialValueFactory: this.initialValueFactory
    });
  }
  /**
  * Update the channel with the given values.
  * If guard is true, throws if more than one value is received.
  */
  update(values) {
    if (values.length === 0) return false;
    if (values.length !== 1 && this.guard) throw new InvalidUpdateError("UntrackedValue(guard=true) can receive only one value per step. Use guard=false if you want to store any one of multiple values.", { lc_error_code: "INVALID_CONCURRENT_GRAPH_UPDATE" });
    this._value = values[values.length - 1];
    return true;
  }
  /**
  * Get the current value.
  * @throws EmptyChannelError if no value has been set.
  */
  get() {
    if (this._value === MISSING) throw new EmptyChannelError();
    return this._value;
  }
  /**
  * Always returns undefined - untracked values are never checkpointed.
  */
  checkpoint() {
  }
  /**
  * Return true if a value has been set.
  */
  isAvailable() {
    return this._value !== MISSING;
  }
};

// node_modules/@langchain/langgraph/dist/state/values/reduced.js
var REDUCED_VALUE_SYMBOL = /* @__PURE__ */ Symbol.for("langgraph.state.reduced_value");
var ReducedValue = class {
  /**
  * Instance marker for runtime identification.
  * @internal
  */
  [REDUCED_VALUE_SYMBOL] = true;
  /**
  * The schema that describes the type of value stored in state (i.e., after reduction).
  * Note: We use `unknown` for the input type to allow schemas with `.default()` wrappers,
  * where the input type includes `undefined`.
  */
  valueSchema;
  /**
  * The schema used to validate reducer inputs.
  * If not specified explicitly, this defaults to `valueSchema`.
  */
  inputSchema;
  /**
  * The reducer function that combines a current output value and an incoming input.
  */
  reducer;
  /**
  * Optional extra fields to merge into the generated JSON Schema (e.g., for documentation or constraints).
  */
  jsonSchemaExtra;
  constructor(valueSchema, init) {
    this.reducer = init.reducer;
    this.jsonSchemaExtra = init.jsonSchemaExtra;
    this.valueSchema = valueSchema;
    this.inputSchema = "inputSchema" in init ? init.inputSchema : valueSchema;
    this.jsonSchemaExtra = init.jsonSchemaExtra;
  }
  static isInstance(value) {
    return typeof value === "object" && value !== null && REDUCED_VALUE_SYMBOL in value && value[REDUCED_VALUE_SYMBOL] === true;
  }
};

// node_modules/@langchain/langgraph/dist/state/values/untracked.js
var UNTRACKED_VALUE_SYMBOL = /* @__PURE__ */ Symbol.for("langgraph.state.untracked_value");
var UntrackedValue = class {
  /**
  * Instance marker for runtime identification.
  * @internal
  */
  [UNTRACKED_VALUE_SYMBOL] = true;
  /**
  * Optional schema describing the type and shape of the value stored in this field.
  *
  * If provided, this can be used for runtime validation or code generation.
  */
  schema;
  /**
  * Whether to guard against multiple updates to this untracked value in a single step.
  *
  * - If `true` (default), throws an error if multiple updates are received in one step.
  * - If `false`, only the last value from that step is kept, others are ignored.
  *
  * This helps prevent accidental state replacement within a step.
  */
  guard;
  /**
  * Create a new untracked value state field.
  *
  * @param schema - Optional type schema describing the value (e.g. a Zod schema).
  * @param init - Optional options for tracking updates or enabling multiple-writes-per-step.
  */
  constructor(schema, init) {
    this.schema = schema;
    this.guard = init?.guard ?? true;
  }
  static isInstance(value) {
    return typeof value === "object" && value !== null && UNTRACKED_VALUE_SYMBOL in value;
  }
};

// node_modules/@langchain/langgraph/dist/channels/named_barrier_value.js
var areSetsEqual = (a, b) => a.size === b.size && [...a].every((value) => b.has(value));
var NamedBarrierValue = class NamedBarrierValue2 extends BaseChannel {
  lc_graph_name = "NamedBarrierValue";
  names;
  seen;
  constructor(names) {
    super();
    this.names = names;
    this.seen = /* @__PURE__ */ new Set();
  }
  fromCheckpoint(checkpoint) {
    const empty = new NamedBarrierValue2(this.names);
    if (typeof checkpoint !== "undefined") empty.seen = new Set(checkpoint);
    return empty;
  }
  update(values) {
    let updated = false;
    for (const nodeName of values) if (this.names.has(nodeName)) {
      if (!this.seen.has(nodeName)) {
        this.seen.add(nodeName);
        updated = true;
      }
    } else throw new InvalidUpdateError(`Value ${JSON.stringify(nodeName)} not in names ${JSON.stringify(this.names)}`);
    return updated;
  }
  get() {
    if (!areSetsEqual(this.names, this.seen)) throw new EmptyChannelError();
  }
  checkpoint() {
    return [...this.seen];
  }
  consume() {
    if (this.seen && this.names && areSetsEqual(this.seen, this.names)) {
      this.seen = /* @__PURE__ */ new Set();
      return true;
    }
    return false;
  }
  isAvailable() {
    return !!this.names && areSetsEqual(this.names, this.seen);
  }
};
var NamedBarrierValueAfterFinish = class NamedBarrierValueAfterFinish2 extends BaseChannel {
  lc_graph_name = "NamedBarrierValueAfterFinish";
  names;
  seen;
  finished;
  constructor(names) {
    super();
    this.names = names;
    this.seen = /* @__PURE__ */ new Set();
    this.finished = false;
  }
  fromCheckpoint(checkpoint) {
    const empty = new NamedBarrierValueAfterFinish2(this.names);
    if (typeof checkpoint !== "undefined") {
      const [seen, finished] = checkpoint;
      empty.seen = new Set(seen);
      empty.finished = finished;
    }
    return empty;
  }
  update(values) {
    let updated = false;
    for (const nodeName of values) if (this.names.has(nodeName) && !this.seen.has(nodeName)) {
      this.seen.add(nodeName);
      updated = true;
    } else if (!this.names.has(nodeName)) throw new InvalidUpdateError(`Value ${JSON.stringify(nodeName)} not in names ${JSON.stringify(this.names)}`);
    return updated;
  }
  get() {
    if (!this.finished || !areSetsEqual(this.names, this.seen)) throw new EmptyChannelError();
  }
  checkpoint() {
    return [[...this.seen], this.finished];
  }
  consume() {
    if (this.finished && this.seen && this.names && areSetsEqual(this.seen, this.names)) {
      this.seen = /* @__PURE__ */ new Set();
      this.finished = false;
      return true;
    }
    return false;
  }
  finish() {
    if (!this.finished && !!this.names && areSetsEqual(this.names, this.seen)) {
      this.finished = true;
      return true;
    }
    return false;
  }
  isAvailable() {
    return this.finished && !!this.names && areSetsEqual(this.names, this.seen);
  }
};

// node_modules/@langchain/langgraph/dist/state/schema.js
var STATE_SCHEMA_SYMBOL = /* @__PURE__ */ Symbol.for("langgraph.state.state_schema");
var StateSchema = class {
  /**
  * Symbol for runtime identification.
  * @internal Used by isInstance for runtime type checking
  */
  [STATE_SCHEMA_SYMBOL] = true;
  constructor(fields) {
    this.fields = fields;
  }
  /**
  * Get the channel definitions for use with StateGraph.
  * This converts the StateSchema fields into BaseChannel instances.
  */
  getChannels() {
    const channels = {};
    for (const [key, value] of Object.entries(this.fields)) if (ReducedValue.isInstance(value)) {
      const defaultGetter = getSchemaDefaultGetter(value.valueSchema);
      channels[key] = new BinaryOperatorAggregate(value.reducer, defaultGetter);
    } else if (UntrackedValue.isInstance(value)) {
      const defaultGetter = value.schema ? getSchemaDefaultGetter(value.schema) : void 0;
      channels[key] = new UntrackedValueChannel({
        guard: value.guard,
        initialValueFactory: defaultGetter
      });
    } else if (isStandardSchema(value)) channels[key] = new LastValue(getSchemaDefaultGetter(value));
    else throw new Error(`Invalid state field "${key}": must be a schema, ReducedValue, UntrackedValue, or ManagedValue`);
    return channels;
  }
  /**
  * Get the JSON schema for the full state type.
  * Used by Studio and API for schema introspection.
  */
  getJsonSchema() {
    const properties = {};
    const required = [];
    for (const [key, value] of Object.entries(this.fields)) {
      let fieldSchema;
      if (ReducedValue.isInstance(value)) {
        fieldSchema = getJsonSchemaFromSchema(value.valueSchema);
        if (fieldSchema && value.jsonSchemaExtra) fieldSchema = {
          ...fieldSchema,
          ...value.jsonSchemaExtra
        };
      } else if (UntrackedValue.isInstance(value)) fieldSchema = value.schema ? getJsonSchemaFromSchema(value.schema) : void 0;
      else if (isStandardSchema(value)) fieldSchema = getJsonSchemaFromSchema(value);
      if (fieldSchema) {
        properties[key] = fieldSchema;
        let hasDefault = false;
        if (ReducedValue.isInstance(value)) hasDefault = getSchemaDefaultGetter(value.valueSchema) !== void 0;
        else if (UntrackedValue.isInstance(value)) hasDefault = value.schema ? getSchemaDefaultGetter(value.schema) !== void 0 : false;
        else hasDefault = getSchemaDefaultGetter(value) !== void 0;
        if (!hasDefault) required.push(key);
      }
    }
    return {
      type: "object",
      properties,
      required: required.length > 0 ? required : void 0
    };
  }
  /**
  * Get the JSON schema for the update/input type.
  * All fields are optional in updates.
  */
  getInputJsonSchema() {
    const properties = {};
    for (const [key, value] of Object.entries(this.fields)) {
      let fieldSchema;
      if (ReducedValue.isInstance(value)) fieldSchema = getJsonSchemaFromSchema(value.inputSchema);
      else if (UntrackedValue.isInstance(value)) fieldSchema = value.schema ? getJsonSchemaFromSchema(value.schema) : void 0;
      else if (isStandardSchema(value)) fieldSchema = getJsonSchemaFromSchema(value);
      if (fieldSchema) properties[key] = fieldSchema;
    }
    return {
      type: "object",
      properties
    };
  }
  /**
  * Get the list of channel keys (excluding managed values).
  */
  getChannelKeys() {
    return Object.entries(this.fields).map(([key]) => key);
  }
  /**
  * Get all keys (channels + managed values).
  */
  getAllKeys() {
    return Object.keys(this.fields);
  }
  /**
  * Validate input data against the schema.
  * This validates each field using its corresponding schema.
  *
  * @param data - The input data to validate
  * @returns The validated data with coerced types
  */
  async validateInput(data) {
    if (data == null || typeof data !== "object") return data;
    const result = {};
    for (const [key, value] of Object.entries(data)) {
      const fieldDef = this.fields[key];
      if (fieldDef === void 0) {
        result[key] = value;
        continue;
      }
      let schema;
      if (ReducedValue.isInstance(fieldDef)) schema = fieldDef.inputSchema;
      else if (UntrackedValue.isInstance(fieldDef)) schema = fieldDef.schema;
      else if (isStandardSchema(fieldDef)) schema = fieldDef;
      if (schema) {
        const validationResult = await schema["~standard"].validate(value);
        if (validationResult.issues) throw new Error(`Validation failed for field "${key}": ${JSON.stringify(validationResult.issues)}`);
        result[key] = validationResult.value;
      } else result[key] = value;
    }
    return result;
  }
  static isInstance(value) {
    return typeof value === "object" && value !== null && STATE_SCHEMA_SYMBOL in value && value[STATE_SCHEMA_SYMBOL] === true;
  }
};

// node_modules/@langchain/langgraph/dist/graph/messages_reducer.js
var REMOVE_ALL_MESSAGES = "__remove_all__";
function messagesStateReducer(left, right) {
  const leftArray = Array.isArray(left) ? left : [left];
  const rightArray = Array.isArray(right) ? right : [right];
  const leftMessages = leftArray.map(coerceMessageLikeToMessage);
  const rightMessages = rightArray.map(coerceMessageLikeToMessage);
  for (const m of leftMessages) if (m.id === null || m.id === void 0) {
    m.id = v4_default();
    m.lc_kwargs.id = m.id;
  }
  let removeAllIdx;
  for (let i = 0; i < rightMessages.length; i += 1) {
    const m = rightMessages[i];
    if (m.id === null || m.id === void 0) {
      m.id = v4_default();
      m.lc_kwargs.id = m.id;
    }
    if (RemoveMessage.isInstance(m) && m.id === REMOVE_ALL_MESSAGES) removeAllIdx = i;
  }
  if (removeAllIdx != null) return rightMessages.slice(removeAllIdx + 1);
  const merged = [...leftMessages];
  const mergedById = new Map(merged.map((m, i) => [m.id, i]));
  const idsToRemove = /* @__PURE__ */ new Set();
  for (const m of rightMessages) {
    const existingIdx = mergedById.get(m.id);
    if (existingIdx !== void 0) if (RemoveMessage.isInstance(m)) idsToRemove.add(m.id);
    else {
      idsToRemove.delete(m.id);
      merged[existingIdx] = m;
    }
    else {
      if (RemoveMessage.isInstance(m)) throw new Error(`Attempting to delete a message with an ID that doesn't exist ('${m.id}')`);
      mergedById.set(m.id, merged.length);
      merged.push(m);
    }
  }
  return merged.filter((m) => !idsToRemove.has(m.id));
}

// node_modules/@langchain/langgraph/dist/state/prebuilt/messages.js
var messagesValueSchema = external_exports2.custom().default(() => []);
var messagesInputSchema = external_exports2.custom();
var MessagesValue = new ReducedValue(messagesValueSchema, {
  inputSchema: messagesInputSchema,
  reducer: messagesStateReducer,
  jsonSchemaExtra: {
    langgraph_type: "messages",
    description: "A list of chat messages"
  }
});

// node_modules/@langchain/langgraph/dist/graph/zod/meta.js
var META_EXTRAS_DESCRIPTION_PREFIX = "lg:";
var SchemaMetaRegistry = class {
  /**
  * Internal map storing schema metadata.
  * @internal
  */
  _map = /* @__PURE__ */ new WeakMap();
  /**
  * Cache for extended schfemas.
  * @internal
  */
  _extensionCache = /* @__PURE__ */ new Map();
  /**
  * Retrieves the metadata associated with a given schema.
  * @template TValue The value type of the schema.
  * @template TUpdate The update type of the schema (defaults to TValue).
  * @param schema The schema to retrieve metadata for.
  * @returns The associated SchemaMeta, or undefined if not present.
  */
  get(schema) {
    return this._map.get(schema);
  }
  /**
  * Extends or sets the metadata for a given schema.
  * @template TValue The value type of the schema.
  * @template TUpdate The update type of the schema (defaults to TValue).
  * @param schema The schema to extend metadata for.
  * @param predicate A function that receives the existing metadata (or undefined) and returns the new metadata.
  */
  extend(schema, predicate) {
    const existingMeta = this.get(schema);
    this._map.set(schema, predicate(existingMeta));
  }
  /**
  * Removes the metadata associated with a given schema.
  * @param schema The schema to remove metadata for.
  * @returns The SchemaMetaRegistry instance (for chaining).
  */
  remove(schema) {
    this._map.delete(schema);
    return this;
  }
  /**
  * Checks if metadata exists for a given schema.
  * @param schema The schema to check.
  * @returns True if metadata exists, false otherwise.
  */
  has(schema) {
    return this._map.has(schema);
  }
  /**
  * Returns a mapping of channel instances for each property in the schema
  * using the associated metadata in the registry.
  *
  * This is used to create the `channels` object that's passed to the `Graph` constructor.
  *
  * @template T The shape of the schema.
  * @param schema The schema to extract channels from.
  * @returns A mapping from property names to channel instances.
  */
  getChannelsForSchema(schema) {
    const channels = {};
    const shape = getInteropZodObjectShape(schema);
    for (const [key, channelSchema] of Object.entries(shape)) {
      const meta3 = this.get(channelSchema);
      if (meta3?.reducer) channels[key] = new BinaryOperatorAggregate(meta3.reducer.fn, meta3.default);
      else channels[key] = new LastValue(meta3?.default);
    }
    return channels;
  }
  /**
  * Returns a modified schema that introspectively looks at all keys of the provided
  * object schema, and applies the augmentations based on meta provided with those keys
  * in the registry and the selectors provided in the `effects` parameter.
  *
  * This assumes that the passed in schema is the "root" schema object for a graph where
  * the keys of the schema are the channels of the graph. Because we need to represent
  * the input of a graph in a couple of different ways, the `effects` parameter allows
  * us to apply those augmentations based on pre determined conditions.
  *
  * @param schema The root schema object to extend.
  * @param effects The effects that are being applied.
  * @returns The extended schema.
  */
  getExtendedChannelSchemas(schema, effects) {
    if (Object.keys(effects).length === 0) return schema;
    const cacheKey = Object.entries(effects).filter(([, v]) => v === true).sort(([a], [b]) => a.localeCompare(b)).map(([k, v]) => `${k}:${v}`).join("|");
    const cache = this._extensionCache.get(cacheKey) ?? /* @__PURE__ */ new WeakMap();
    if (cache.has(schema)) return cache.get(schema);
    let modifiedSchema = schema;
    if (effects.withReducerSchema || effects.withJsonSchemaExtrasAsDescription) {
      const newShapeEntries = Object.entries(getInteropZodObjectShape(schema)).map(([key, schema2]) => {
        const meta3 = this.get(schema2);
        let outputSchema = effects.withReducerSchema ? meta3?.reducer?.schema ?? schema2 : schema2;
        if (effects.withJsonSchemaExtrasAsDescription && meta3?.jsonSchemaExtra) {
          const description = getSchemaDescription(outputSchema) ?? getSchemaDescription(schema2);
          const strExtras = JSON.stringify({
            ...meta3.jsonSchemaExtra,
            description
          });
          outputSchema = outputSchema.describe(`${META_EXTRAS_DESCRIPTION_PREFIX}${strExtras}`);
        }
        return [key, outputSchema];
      });
      modifiedSchema = extendInteropZodObject(schema, Object.fromEntries(newShapeEntries));
      if (isZodSchemaV3(modifiedSchema)) modifiedSchema._def.unknownKeys = "strip";
    }
    if (effects.asPartial) modifiedSchema = interopZodObjectPartial(modifiedSchema);
    cache.set(schema, modifiedSchema);
    this._extensionCache.set(cacheKey, cache);
    return modifiedSchema;
  }
};
var schemaMetaRegistry = new SchemaMetaRegistry();
function withLangGraph(schema, meta3) {
  if (meta3.reducer && !meta3.default) {
    const defaultValueGetter = getInteropZodDefaultGetter(schema);
    if (defaultValueGetter != null) meta3.default = defaultValueGetter;
  }
  if (meta3.reducer) {
    const schemaWithReducer = Object.assign(schema, { lg_reducer_schema: meta3.reducer?.schema ?? schema });
    schemaMetaRegistry.extend(schemaWithReducer, () => meta3);
    return schemaWithReducer;
  } else {
    schemaMetaRegistry.extend(schema, () => meta3);
    return schema;
  }
}

// node_modules/@langchain/langgraph/dist/graph/types.js
function isStateDefinitionInit(value) {
  if (value == null) return false;
  if (StateSchema.isInstance(value)) return true;
  if (isInteropZodObject(value)) return true;
  if (typeof value === "object" && "lc_graph_name" in value && value.lc_graph_name === "AnnotationRoot") return true;
  if (typeof value === "object" && !Array.isArray(value) && Object.keys(value).length > 0 && Object.values(value).every((v) => typeof v === "function" || isBaseChannel(v))) return true;
  return false;
}
function isStateGraphInit(value) {
  if (typeof value !== "object" || value == null) return false;
  const obj = value;
  const hasState = "state" in obj && isStateDefinitionInit(obj.state);
  const hasStateSchema = "stateSchema" in obj && isStateDefinitionInit(obj.stateSchema);
  const hasInput = "input" in obj && isStateDefinitionInit(obj.input);
  if (!hasState && !hasStateSchema && !hasInput) return false;
  if ("input" in obj && obj.input != null && !isStateDefinitionInit(obj.input)) return false;
  if ("output" in obj && obj.output != null && !isStateDefinitionInit(obj.output)) return false;
  return true;
}

// node_modules/@langchain/langgraph/dist/graph/state.js
var ROOT = "__root__";
var PartialStateSchema = /* @__PURE__ */ Symbol.for("langgraph.state.partial");
var StateGraph = class extends Graph$1 {
  channels = {};
  waitingEdges = /* @__PURE__ */ new Set();
  /** @internal */
  _schemaDefinition;
  /** @internal */
  _schemaRuntimeDefinition;
  /** @internal */
  _inputDefinition;
  /** @internal */
  _inputRuntimeDefinition;
  /** @internal */
  _outputDefinition;
  /** @internal */
  _outputRuntimeDefinition;
  /**
  * Map schemas to managed values
  * @internal
  */
  _schemaDefinitions = /* @__PURE__ */ new Map();
  /** @internal */
  _metaRegistry = schemaMetaRegistry;
  /** @internal Used only for typing. */
  _configSchema;
  /** @internal */
  _configRuntimeSchema;
  /** @internal */
  _interrupt;
  /** @internal */
  _writer;
  constructor(stateOrInit, options) {
    super();
    const init = this._normalizeToStateGraphInit(stateOrInit, options);
    const stateSchema4 = init.state ?? init.stateSchema ?? init.input;
    if (!stateSchema4) throw new StateGraphInputError();
    const stateChannelDef = this._getChannelsFromSchema(stateSchema4);
    this._schemaDefinition = stateChannelDef;
    if (StateSchema.isInstance(stateSchema4)) this._schemaRuntimeDefinition = stateSchema4;
    else if (isInteropZodObject(stateSchema4)) this._schemaRuntimeDefinition = stateSchema4;
    if (init.input) if (StateSchema.isInstance(init.input)) this._inputRuntimeDefinition = init.input;
    else if (isInteropZodObject(init.input)) this._inputRuntimeDefinition = init.input;
    else this._inputRuntimeDefinition = PartialStateSchema;
    else this._inputRuntimeDefinition = PartialStateSchema;
    if (init.output) if (StateSchema.isInstance(init.output)) this._outputRuntimeDefinition = init.output;
    else if (isInteropZodObject(init.output)) this._outputRuntimeDefinition = init.output;
    else this._outputRuntimeDefinition = this._schemaRuntimeDefinition;
    else this._outputRuntimeDefinition = this._schemaRuntimeDefinition;
    const inputChannelDef = init.input ? this._getChannelsFromSchema(init.input) : stateChannelDef;
    const outputChannelDef = init.output ? this._getChannelsFromSchema(init.output) : stateChannelDef;
    this._inputDefinition = inputChannelDef;
    this._outputDefinition = outputChannelDef;
    this._addSchema(this._schemaDefinition);
    this._addSchema(this._inputDefinition);
    this._addSchema(this._outputDefinition);
    if (init.context) {
      if (isInteropZodObject(init.context)) this._configRuntimeSchema = init.context;
    }
    this._interrupt = init.interrupt;
    this._writer = init.writer;
  }
  /**
  * Normalize all constructor input patterns to a unified StateGraphInit object.
  * @internal
  */
  _normalizeToStateGraphInit(stateOrInit, options) {
    if (isStateGraphInit(stateOrInit)) {
      if (isInteropZodObject(options) || AnnotationRoot.isInstance(options)) return {
        ...stateOrInit,
        context: options
      };
      const opts = options;
      return {
        ...stateOrInit,
        input: stateOrInit.input ?? opts?.input,
        output: stateOrInit.output ?? opts?.output,
        context: stateOrInit.context ?? opts?.context,
        interrupt: stateOrInit.interrupt ?? opts?.interrupt,
        writer: stateOrInit.writer ?? opts?.writer,
        nodes: stateOrInit.nodes ?? opts?.nodes
      };
    }
    if (isStateDefinitionInit(stateOrInit)) {
      if (isInteropZodObject(options) || AnnotationRoot.isInstance(options)) return {
        state: stateOrInit,
        context: options
      };
      const opts = options;
      return {
        state: stateOrInit,
        input: opts?.input,
        output: opts?.output,
        context: opts?.context,
        interrupt: opts?.interrupt,
        writer: opts?.writer,
        nodes: opts?.nodes
      };
    }
    if (isStateGraphArgs(stateOrInit)) return { state: _getChannels(stateOrInit.channels) };
    throw new StateGraphInputError();
  }
  /**
  * Convert any supported schema type to a StateDefinition (channel map).
  * @internal
  */
  _getChannelsFromSchema(schema) {
    if (StateSchema.isInstance(schema)) return schema.getChannels();
    if (isInteropZodObject(schema)) return this._metaRegistry.getChannelsForSchema(schema);
    if (typeof schema === "object" && "lc_graph_name" in schema && schema.lc_graph_name === "AnnotationRoot") return schema.spec;
    if (typeof schema === "object" && !Array.isArray(schema) && Object.keys(schema).length > 0) return schema;
    throw new StateGraphInputError("Invalid schema type. Expected StateSchema, Zod object, AnnotationRoot, or StateDefinition.");
  }
  get allEdges() {
    return /* @__PURE__ */ new Set([...this.edges, ...Array.from(this.waitingEdges).flatMap(([starts, end]) => starts.map((start) => [start, end]))]);
  }
  _addSchema(stateDefinition) {
    if (this._schemaDefinitions.has(stateDefinition)) return;
    this._schemaDefinitions.set(stateDefinition, stateDefinition);
    for (const [key, val] of Object.entries(stateDefinition)) {
      let channel;
      if (typeof val === "function") channel = val();
      else channel = val;
      if (this.channels[key] !== void 0) {
        if (!this.channels[key].equals(channel)) {
          if (channel.lc_graph_name !== "LastValue") throw new Error(`Channel "${key}" already exists with a different type.`);
        }
      } else this.channels[key] = channel;
    }
  }
  addNode(...args) {
    function isMultipleNodes(args2) {
      return args2.length >= 1 && typeof args2[0] !== "string";
    }
    const nodes = isMultipleNodes(args) ? Array.isArray(args[0]) ? args[0] : Object.entries(args[0]).map(([key, action]) => [key, action]) : [[
      args[0],
      args[1],
      args[2]
    ]];
    if (nodes.length === 0) throw new Error("No nodes provided in `addNode`");
    for (const [key, action, options] of nodes) {
      if (key in this.channels) throw new Error(`${key} is already being used as a state attribute (a.k.a. a channel), cannot also be used as a node name.`);
      for (const reservedChar of [CHECKPOINT_NAMESPACE_SEPARATOR, CHECKPOINT_NAMESPACE_END]) if (key.includes(reservedChar)) throw new Error(`"${reservedChar}" is a reserved character and is not allowed in node names.`);
      this.warnIfCompiled(`Adding a node to a graph that has already been compiled. This will not be reflected in the compiled graph.`);
      if (key in this.nodes) throw new Error(`Node \`${key}\` already present.`);
      if (key === END || key === START) throw new Error(`Node \`${key}\` is reserved.`);
      let inputSpec = this._schemaDefinition;
      if (options?.input !== void 0) inputSpec = this._getChannelsFromSchema(options.input);
      this._addSchema(inputSpec);
      let runnable;
      if (Runnable.isRunnable(action)) runnable = action;
      else if (typeof action === "function") runnable = new RunnableCallable({
        func: action,
        name: key,
        trace: false
      });
      else runnable = _coerceToRunnable(action);
      let cachePolicy = options?.cachePolicy;
      if (typeof cachePolicy === "boolean") cachePolicy = cachePolicy ? {} : void 0;
      const nodeSpec = {
        runnable,
        retryPolicy: options?.retryPolicy,
        cachePolicy,
        metadata: options?.metadata,
        input: inputSpec ?? this._schemaDefinition,
        subgraphs: isPregelLike(runnable) ? [runnable] : options?.subgraphs,
        ends: options?.ends,
        defer: options?.defer
      };
      this.nodes[key] = nodeSpec;
    }
    return this;
  }
  addEdge(startKey, endKey) {
    if (typeof startKey === "string") return super.addEdge(startKey, endKey);
    if (this.compiled) console.warn("Adding an edge to a graph that has already been compiled. This will not be reflected in the compiled graph.");
    for (const start of startKey) {
      if (start === END) throw new Error("END cannot be a start node");
      if (!Object.keys(this.nodes).some((node) => node === start)) throw new Error(`Need to add a node named "${start}" first`);
    }
    if (endKey === END) throw new Error("END cannot be an end node");
    if (!Object.keys(this.nodes).some((node) => node === endKey)) throw new Error(`Need to add a node named "${endKey}" first`);
    this.waitingEdges.add([startKey, endKey]);
    return this;
  }
  addSequence(nodes) {
    const parsedNodes = Array.isArray(nodes) ? nodes : Object.entries(nodes);
    if (parsedNodes.length === 0) throw new Error("Sequence requires at least one node.");
    let previousNode;
    for (const [key, action, options] of parsedNodes) {
      if (key in this.nodes) throw new Error(`Node names must be unique: node with the name "${key}" already exists.`);
      const validKey = key;
      this.addNode(validKey, action, options);
      if (previousNode != null) this.addEdge(previousNode, validKey);
      previousNode = validKey;
    }
    return this;
  }
  compile({ checkpointer, store, cache, interruptBefore, interruptAfter, name, description } = {}) {
    this.validate([...Array.isArray(interruptBefore) ? interruptBefore : [], ...Array.isArray(interruptAfter) ? interruptAfter : []]);
    const outputKeys = Object.keys(this._schemaDefinitions.get(this._outputDefinition));
    const outputChannels = outputKeys.length === 1 && outputKeys[0] === ROOT ? ROOT : outputKeys;
    const streamKeys = Object.keys(this.channels);
    const streamChannels = streamKeys.length === 1 && streamKeys[0] === ROOT ? ROOT : streamKeys;
    const userInterrupt = this._interrupt;
    const compiled = new CompiledStateGraph({
      builder: this,
      checkpointer,
      interruptAfter,
      interruptBefore,
      autoValidate: false,
      nodes: {},
      channels: {
        ...this.channels,
        [START]: new EphemeralValue()
      },
      inputChannels: START,
      outputChannels,
      streamChannels,
      streamMode: "updates",
      store,
      cache,
      name,
      description,
      userInterrupt
    });
    compiled.attachNode(START);
    for (const [key, node] of Object.entries(this.nodes)) compiled.attachNode(key, node);
    compiled.attachBranch(START, SELF, _getControlBranch(), { withReader: false });
    for (const [key] of Object.entries(this.nodes)) compiled.attachBranch(key, SELF, _getControlBranch(), { withReader: false });
    for (const [start, end] of this.edges) compiled.attachEdge(start, end);
    for (const [starts, end] of this.waitingEdges) compiled.attachEdge(starts, end);
    for (const [start, branches] of Object.entries(this.branches)) for (const [name2, branch] of Object.entries(branches)) compiled.attachBranch(start, name2, branch);
    return compiled.validate();
  }
};
function _getChannels(schema) {
  const channels = {};
  for (const [name, val] of Object.entries(schema)) if (name === ROOT) channels[name] = getChannel(val);
  else channels[name] = getChannel(val);
  return channels;
}
var CompiledStateGraph = class extends CompiledGraph {
  /**
  * The description of the compiled graph.
  * This is used by the supervisor agent to describe the handoff to the agent.
  */
  description;
  /** @internal */
  _metaRegistry = schemaMetaRegistry;
  constructor({ description, ...rest }) {
    super(rest);
    this.description = description;
  }
  attachNode(key, node) {
    let outputKeys;
    if (key === START) outputKeys = Object.entries(this.builder._schemaDefinitions.get(this.builder._inputDefinition)).map(([k]) => k);
    else outputKeys = Object.keys(this.builder.channels);
    function _getRoot(input) {
      if (isCommand(input)) {
        if (input.graph === Command.PARENT) return null;
        return input._updateAsTuples();
      } else if (Array.isArray(input) && input.length > 0 && input.some((i) => isCommand(i))) {
        const updates = [];
        for (const i of input) if (isCommand(i)) {
          if (i.graph === Command.PARENT) continue;
          updates.push(...i._updateAsTuples());
        } else updates.push([ROOT, i]);
        return updates;
      } else if (input != null) return [[ROOT, input]];
      return null;
    }
    const nodeKey = key;
    function _getUpdates(input) {
      if (!input) return null;
      else if (isCommand(input)) {
        if (input.graph === Command.PARENT) return null;
        return input._updateAsTuples().filter(([k]) => outputKeys.includes(k));
      } else if (Array.isArray(input) && input.length > 0 && input.some(isCommand)) {
        const updates = [];
        for (const item of input) if (isCommand(item)) {
          if (item.graph === Command.PARENT) continue;
          updates.push(...item._updateAsTuples().filter(([k]) => outputKeys.includes(k)));
        } else {
          const itemUpdates = _getUpdates(item);
          if (itemUpdates) updates.push(...itemUpdates ?? []);
        }
        return updates;
      } else if (typeof input === "object" && !Array.isArray(input)) return Object.entries(input).filter(([k]) => outputKeys.includes(k));
      else {
        const typeofInput = Array.isArray(input) ? "array" : typeof input;
        throw new InvalidUpdateError(`Expected node "${nodeKey.toString()}" to return an object or an array containing at least one Command object, received ${typeofInput}`, { lc_error_code: "INVALID_GRAPH_NODE_RETURN_VALUE" });
      }
    }
    const stateWriteEntries = [{
      value: PASSTHROUGH,
      mapper: new RunnableCallable({
        func: outputKeys.length && outputKeys[0] === ROOT ? _getRoot : _getUpdates,
        trace: false,
        recurse: false
      })
    }];
    if (key === START) this.nodes[key] = new PregelNode({
      tags: [TAG_HIDDEN],
      triggers: [START],
      channels: [START],
      writers: [new ChannelWrite(stateWriteEntries, [TAG_HIDDEN])]
    });
    else {
      const inputDefinition = node?.input ?? this.builder._schemaDefinition;
      const inputValues = Object.fromEntries(Object.keys(this.builder._schemaDefinitions.get(inputDefinition)).map((k) => [k, k]));
      const isSingleInput = Object.keys(inputValues).length === 1 && ROOT in inputValues;
      const branchChannel = `branch:to:${key}`;
      this.channels[branchChannel] = node?.defer ? new LastValueAfterFinish() : new EphemeralValue(false);
      this.nodes[key] = new PregelNode({
        triggers: [branchChannel],
        channels: isSingleInput ? Object.keys(inputValues) : inputValues,
        writers: [new ChannelWrite(stateWriteEntries, [TAG_HIDDEN])],
        mapper: isSingleInput ? void 0 : (input) => {
          return Object.fromEntries(Object.entries(input).filter(([k]) => k in inputValues));
        },
        bound: node?.runnable,
        metadata: node?.metadata,
        retryPolicy: node?.retryPolicy,
        cachePolicy: node?.cachePolicy,
        subgraphs: node?.subgraphs,
        ends: node?.ends
      });
    }
  }
  attachEdge(starts, end) {
    if (end === END) return;
    if (typeof starts === "string") this.nodes[starts].writers.push(new ChannelWrite([{
      channel: `branch:to:${end}`,
      value: null
    }], [TAG_HIDDEN]));
    else if (Array.isArray(starts)) {
      const channelName = `join:${starts.join("+")}:${end}`;
      this.channels[channelName] = this.builder.nodes[end].defer ? new NamedBarrierValueAfterFinish(new Set(starts)) : new NamedBarrierValue(new Set(starts));
      this.nodes[end].triggers.push(channelName);
      for (const start of starts) this.nodes[start].writers.push(new ChannelWrite([{
        channel: channelName,
        value: start
      }], [TAG_HIDDEN]));
    }
  }
  attachBranch(start, _, branch, options = { withReader: true }) {
    const branchWriter = async (packets, config2) => {
      const filteredPackets = packets.filter((p) => p !== END);
      if (!filteredPackets.length) return;
      const writes = filteredPackets.map((p) => {
        if (_isSend(p)) return p;
        return {
          channel: p === END ? p : `branch:to:${p}`,
          value: start
        };
      });
      await ChannelWrite.doWrite({
        ...config2,
        tags: (config2.tags ?? []).concat([TAG_HIDDEN])
      }, writes);
    };
    this.nodes[start].writers.push(branch.run(branchWriter, options.withReader ? (config2) => ChannelRead.doRead(config2, this.streamChannels ?? this.outputChannels, true) : void 0));
  }
  async _validateInput(input) {
    if (input == null) return input;
    const inputDef = this.builder._inputRuntimeDefinition;
    const schemaDef = this.builder._schemaRuntimeDefinition;
    if (StateSchema.isInstance(inputDef)) {
      if (isCommand(input)) {
        const parsedInput = input;
        if (input.update) parsedInput.update = await inputDef.validateInput(Array.isArray(input.update) ? Object.fromEntries(input.update) : input.update);
        return parsedInput;
      }
      return await inputDef.validateInput(input);
    }
    if (inputDef === PartialStateSchema && StateSchema.isInstance(schemaDef)) {
      if (isCommand(input)) {
        const parsedInput = input;
        if (input.update) parsedInput.update = await schemaDef.validateInput(Array.isArray(input.update) ? Object.fromEntries(input.update) : input.update);
        return parsedInput;
      }
      return await schemaDef.validateInput(input);
    }
    const schema = (() => {
      const apply = (schema2) => {
        if (schema2 == null) return void 0;
        return this._metaRegistry.getExtendedChannelSchemas(schema2, { withReducerSchema: true });
      };
      if (isInteropZodObject(inputDef)) return apply(inputDef);
      if (inputDef === PartialStateSchema) {
        if (isInteropZodObject(schemaDef)) return interopZodObjectPartial(apply(schemaDef));
        return;
      }
    })();
    if (isCommand(input)) {
      const parsedInput = input;
      if (input.update && schema != null) parsedInput.update = interopParse(schema, input.update);
      return parsedInput;
    }
    if (schema != null) return interopParse(schema, input);
    return input;
  }
  isInterrupted(input) {
    return isInterrupted(input);
  }
  async _validateContext(config2) {
    const configSchema = this.builder._configRuntimeSchema;
    if (isInteropZodObject(configSchema)) interopParse(configSchema, config2);
    return config2;
  }
};
function isStateGraphArgs(obj) {
  return typeof obj === "object" && obj !== null && obj.channels !== void 0;
}
function _controlBranch(value) {
  if (_isSend(value)) return [value];
  const commands = [];
  if (isCommand(value)) commands.push(value);
  else if (Array.isArray(value)) commands.push(...value.filter(isCommand));
  const destinations = [];
  for (const command of commands) {
    if (command.graph === Command.PARENT) throw new ParentCommand(command);
    if (_isSend(command.goto)) destinations.push(command.goto);
    else if (typeof command.goto === "string") destinations.push(command.goto);
    else if (Array.isArray(command.goto)) destinations.push(...command.goto);
  }
  return destinations;
}
function _getControlBranch() {
  return new Branch({ path: new RunnableCallable({
    func: _controlBranch,
    tags: [TAG_HIDDEN],
    trace: false,
    recurse: false,
    name: "<control_branch>"
  }) });
}

// node_modules/@langchain/langgraph/dist/func/index.js
var entrypoint = function entrypoint2(optionsOrName, func) {
  const { name, checkpointer, store, cache } = typeof optionsOrName === "string" ? {
    name: optionsOrName,
    checkpointer: void 0,
    store: void 0
  } : optionsOrName;
  if (isAsyncGeneratorFunction(func) || isGeneratorFunction(func)) throw new Error("Generators are disallowed as entrypoints. For streaming responses, use config.write.");
  const streamMode = "updates";
  const bound = getRunnableForEntrypoint(name, func);
  function isEntrypointFinal(value) {
    return typeof value === "object" && value !== null && "__lg_type" in value && value.__lg_type === "__pregel_final";
  }
  const pluckReturnValue = new RunnableCallable({
    name: "pluckReturnValue",
    func: (value) => {
      return isEntrypointFinal(value) ? value.value : value;
    }
  });
  const pluckSaveValue = new RunnableCallable({
    name: "pluckSaveValue",
    func: (value) => {
      return isEntrypointFinal(value) ? value.save : value;
    }
  });
  const entrypointNode = new PregelNode({
    bound,
    triggers: [START],
    channels: [START],
    writers: [new ChannelWrite([{
      channel: END,
      value: PASSTHROUGH,
      mapper: pluckReturnValue
    }, {
      channel: PREVIOUS,
      value: PASSTHROUGH,
      mapper: pluckSaveValue
    }], [TAG_HIDDEN])]
  });
  return new Pregel({
    name,
    checkpointer,
    nodes: { [name]: entrypointNode },
    channels: {
      [START]: new EphemeralValue(),
      [END]: new LastValue(),
      [PREVIOUS]: new LastValue()
    },
    inputChannels: START,
    outputChannels: END,
    streamChannels: END,
    streamMode,
    store,
    cache
  });
};
entrypoint.final = function final({ value, save }) {
  return {
    value,
    save,
    __lg_type: "__pregel_final"
  };
};

// node_modules/@langchain/langgraph/dist/graph/messages_annotation.js
var MessagesAnnotation = Annotation.Root({ messages: Annotation({
  reducer: messagesStateReducer,
  default: () => []
}) });
var MessagesZodMeta = {
  reducer: { fn: messagesStateReducer },
  jsonSchemaExtra: { langgraph_type: "messages" },
  default: () => []
};
var MessagesZodState = external_exports.object({ messages: withLangGraph(external_exports.custom(), MessagesZodMeta) });

// node_modules/@langchain/langgraph/dist/index.js
initializeAsyncLocalStorageSingleton();

// node_modules/langchain/dist/agents/errors.js
var MultipleToolsBoundError = class extends Error {
  constructor() {
    super("The provided LLM already has bound tools. Please provide an LLM without bound tools to createAgent. The agent will bind the tools provided in the 'tools' parameter.");
  }
};
var MultipleStructuredOutputsError = class extends Error {
  toolNames;
  constructor(toolNames) {
    super(`The model has called multiple tools: ${toolNames.join(", ")} to return a structured output. This is not supported. Please provide a single structured output.`);
    this.toolNames = toolNames;
  }
};
var StructuredOutputParsingError = class extends Error {
  toolName;
  errors;
  constructor(toolName, errors) {
    super(`Failed to parse structured output for tool '${toolName}':${errors.map((e) => `
  - ${e}`).join("")}.`);
    this.toolName = toolName;
    this.errors = errors;
  }
};
var ToolInvocationError = class extends Error {
  toolCall;
  toolError;
  constructor(toolError, toolCall) {
    const error = toolError instanceof Error ? toolError : new Error(String(toolError));
    const toolArgs = JSON.stringify(toolCall.args);
    super(`Error invoking tool '${toolCall.name}' with kwargs ${toolArgs} with error: ${error.stack}
 Please fix the error and try again.`);
    this.toolCall = toolCall;
    this.toolError = error;
  }
};
var MiddlewareError = class MiddlewareError2 extends Error {
  static "~brand" = "MiddlewareError";
  constructor(error, middlewareName) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    super(errorMessage);
    this.name = error instanceof Error ? error.name : `${middlewareName[0].toUpperCase() + middlewareName.slice(1)}Error`;
    if (error instanceof Error) this.cause = error;
  }
  /**
  * Wrap an error in a MiddlewareError, unless it's a GraphBubbleUp error
  * (like GraphInterrupt) which should propagate unchanged.
  *
  * @param error - The error to wrap
  * @param middlewareName - The name of the middleware that threw the error
  * @returns The original error if it's a GraphBubbleUp, otherwise a new MiddlewareError
  */
  static wrap(error, middlewareName) {
    if (isGraphBubbleUp(error)) return error;
    return new MiddlewareError2(error, middlewareName);
  }
  /**
  * Check if the error is a MiddlewareError.
  * @param error - The error to check
  * @returns Whether the error is a MiddlewareError
  */
  static isInstance(error) {
    return error instanceof Error && "~brand" in error && error["~brand"] === "MiddlewareError";
  }
};

// node_modules/langchain/dist/agents/model.js
function isBaseChatModel(model) {
  return "invoke" in model && typeof model.invoke === "function" && "_streamResponseChunks" in model;
}
function isConfigurableModel(model) {
  return typeof model === "object" && model != null && "_queuedMethodOperations" in model && "_getModelInstance" in model && typeof model._getModelInstance === "function";
}

// node_modules/langchain/dist/agents/responses.js
var PROVIDER_STRATEGY_DEFAULT_STRICT = true;
var bindingIdentifier = 0;
var ToolStrategy = class ToolStrategy2 {
  constructor(schema, tool2, options) {
    this.schema = schema;
    this.tool = tool2;
    this.options = options;
  }
  get name() {
    return this.tool.function.name;
  }
  static fromSchema(schema, outputOptions) {
    function getFunctionName(name) {
      return name ?? `extract-${++bindingIdentifier}`;
    }
    if (isInteropZodSchema(schema)) {
      const asJsonSchema$1 = toJsonSchema(schema);
      const tool$1 = {
        type: "function",
        function: {
          name: getFunctionName(asJsonSchema$1.title),
          strict: false,
          description: asJsonSchema$1.description ?? "Tool for extracting structured output from the model's response.",
          parameters: asJsonSchema$1
        }
      };
      return new ToolStrategy2(asJsonSchema$1, tool$1, outputOptions);
    }
    let functionDefinition;
    if (typeof schema.name === "string" && typeof schema.parameters === "object" && schema.parameters != null) functionDefinition = schema;
    else functionDefinition = {
      name: getFunctionName(schema.title),
      description: schema.description ?? "",
      parameters: schema.schema || schema
    };
    const asJsonSchema = toJsonSchema(schema);
    const tool2 = {
      type: "function",
      function: functionDefinition
    };
    return new ToolStrategy2(asJsonSchema, tool2, outputOptions);
  }
  /**
  * Parse tool arguments according to the schema.
  *
  * @throws {StructuredOutputParsingError} if the response is not valid
  * @param toolArgs - The arguments from the tool call
  * @returns The parsed response according to the schema type
  */
  parse(toolArgs) {
    const validator = new Validator(this.schema);
    const result = validator.validate(toolArgs);
    if (!result.valid) throw new StructuredOutputParsingError(this.name, result.errors.map((e) => e.error));
    return toolArgs;
  }
};
var ProviderStrategy = class ProviderStrategy2 {
  _schemaType;
  /**
  * The schema to use for the provider strategy
  */
  schema;
  /**
  * Whether to use strict mode for the provider strategy
  */
  strict;
  constructor(schemaOrOptions, strict) {
    if ("schema" in schemaOrOptions && typeof schemaOrOptions.schema === "object" && schemaOrOptions.schema !== null && !("type" in schemaOrOptions)) {
      const options = schemaOrOptions;
      this.schema = options.schema;
      this.strict = options.strict ?? PROVIDER_STRATEGY_DEFAULT_STRICT;
    } else {
      this.schema = schemaOrOptions;
      this.strict = strict ?? PROVIDER_STRATEGY_DEFAULT_STRICT;
    }
  }
  static fromSchema(schema, strict) {
    const asJsonSchema = toJsonSchema(schema);
    return new ProviderStrategy2(asJsonSchema, strict);
  }
  /**
  * Parse tool arguments according to the schema. If the response is not valid, return undefined.
  *
  * @param response - The AI message response to parse
  * @returns The parsed response according to the schema type
  */
  parse(response) {
    let textContent;
    if (typeof response.content === "string") textContent = response.content;
    else if (Array.isArray(response.content)) {
      for (const block of response.content) if (typeof block === "object" && block !== null && "type" in block && block.type === "text" && "text" in block && typeof block.text === "string") {
        textContent = block.text;
        break;
      }
    }
    if (!textContent || textContent === "") return;
    try {
      const content = JSON.parse(textContent);
      const validator = new Validator(this.schema);
      const result = validator.validate(content);
      if (!result.valid) return;
      return content;
    } catch {
    }
  }
};
function transformResponseFormat(responseFormat, options, model) {
  if (!responseFormat) return [];
  if (typeof responseFormat === "object" && responseFormat !== null && "__responseFormatUndefined" in responseFormat) return [];
  if (Array.isArray(responseFormat)) {
    if (responseFormat.every((item) => item instanceof ToolStrategy || item instanceof ProviderStrategy)) return responseFormat;
    if (responseFormat.every((item) => isInteropZodObject(item))) return responseFormat.map((item) => ToolStrategy.fromSchema(item, options));
    if (responseFormat.every((item) => typeof item === "object" && item !== null && !isInteropZodObject(item))) return responseFormat.map((item) => ToolStrategy.fromSchema(item, options));
    throw new Error("Invalid response format: list contains mixed types.\nAll items must be either InteropZodObject or plain JSON schema objects.");
  }
  if (responseFormat instanceof ToolStrategy || responseFormat instanceof ProviderStrategy) return [responseFormat];
  const useProviderStrategy = hasSupportForJsonSchemaOutput(model);
  if (isInteropZodObject(responseFormat)) return useProviderStrategy ? [ProviderStrategy.fromSchema(responseFormat)] : [ToolStrategy.fromSchema(responseFormat, options)];
  if (typeof responseFormat === "object" && responseFormat !== null && "properties" in responseFormat) return useProviderStrategy ? [ProviderStrategy.fromSchema(responseFormat)] : [ToolStrategy.fromSchema(responseFormat, options)];
  throw new Error(`Invalid response format: ${String(responseFormat)}`);
}
function toolStrategy(responseFormat, options) {
  return transformResponseFormat(responseFormat, options);
}
function providerStrategy(responseFormat) {
  if (typeof responseFormat === "object" && responseFormat !== null && "schema" in responseFormat && !isInteropZodSchema(responseFormat) && !("type" in responseFormat)) {
    const { schema, strict: strictFlag } = responseFormat;
    return ProviderStrategy.fromSchema(schema, strictFlag);
  }
  return ProviderStrategy.fromSchema(responseFormat);
}
var CHAT_MODELS_THAT_SUPPORT_JSON_SCHEMA_OUTPUT = ["ChatOpenAI", "ChatXAI"];
var MODEL_NAMES_THAT_SUPPORT_JSON_SCHEMA_OUTPUT = [
  "grok",
  "gpt-5",
  "gpt-4.1",
  "gpt-4o",
  "gpt-oss",
  "o3-pro",
  "o3-mini"
];
function hasSupportForJsonSchemaOutput(model) {
  if (!model) return false;
  if (typeof model === "string") {
    const modelName = model.split(":").pop();
    return MODEL_NAMES_THAT_SUPPORT_JSON_SCHEMA_OUTPUT.some((modelNameSnippet) => modelName.includes(modelNameSnippet));
  }
  if (isConfigurableModel(model)) {
    const configurableModel = model;
    return hasSupportForJsonSchemaOutput(configurableModel._defaultConfig.model);
  }
  if (!isBaseChatModel(model)) return false;
  const chatModelClass = model.getName();
  if (chatModelClass === "FakeToolCallingChatModel") return true;
  if (CHAT_MODELS_THAT_SUPPORT_JSON_SCHEMA_OUTPUT.includes(chatModelClass) && ("model" in model && MODEL_NAMES_THAT_SUPPORT_JSON_SCHEMA_OUTPUT.some((modelNameSnippet) => typeof model.model === "string" && model.model.includes(modelNameSnippet)) || chatModelClass === "FakeToolCallingModel" && "structuredResponse" in model)) return true;
  return false;
}

// node_modules/langchain/dist/agents/middleware/utils.js
function countTokensApproximately(messages) {
  let totalChars = 0;
  for (const msg of messages) {
    let textContent;
    if (typeof msg.content === "string") textContent = msg.content;
    else if (Array.isArray(msg.content)) textContent = msg.content.map((item) => {
      if (typeof item === "string") return item;
      if (item.type === "text" && "text" in item) return item.text;
      return "";
    }).join("");
    else textContent = "";
    if (AIMessage.isInstance(msg) && Array.isArray(msg.tool_calls) && msg.tool_calls.length > 0) textContent += JSON.stringify(msg.tool_calls);
    if (ToolMessage.isInstance(msg)) textContent += msg.tool_call_id ?? "";
    totalChars += textContent.length;
  }
  return Math.ceil(totalChars / 4);
}
function getHookConstraint(hook) {
  if (!hook || typeof hook === "function") return void 0;
  return hook.canJumpTo;
}
function getHookFunction(arg) {
  if (typeof arg === "function") return arg;
  return arg.hook;
}
function sleep(ms) {
  return new Promise((resolve) => setTimeout(resolve, ms));
}
function calculateRetryDelay(config2, retryNumber) {
  const { backoffFactor, initialDelayMs, maxDelayMs, jitter } = config2;
  let delay;
  if (backoffFactor === 0) delay = initialDelayMs;
  else delay = initialDelayMs * backoffFactor ** retryNumber;
  delay = Math.min(delay, maxDelayMs);
  if (jitter && delay > 0) {
    const jitterAmount = delay * 0.25;
    delay = delay + (Math.random() * 2 - 1) * jitterAmount;
    delay = Math.max(0, delay);
  }
  return delay;
}

// node_modules/langchain/dist/agents/middleware/types.js
var MIDDLEWARE_BRAND = /* @__PURE__ */ Symbol("AgentMiddleware");

// node_modules/langchain/dist/agents/middleware.js
function createMiddleware(config2) {
  const middleware = {
    [MIDDLEWARE_BRAND]: true,
    name: config2.name,
    stateSchema: config2.stateSchema,
    contextSchema: config2.contextSchema,
    wrapToolCall: config2.wrapToolCall,
    wrapModelCall: config2.wrapModelCall,
    beforeAgent: config2.beforeAgent,
    beforeModel: config2.beforeModel,
    afterModel: config2.afterModel,
    afterAgent: config2.afterAgent,
    tools: config2.tools
  };
  return middleware;
}

// node_modules/langchain/dist/agents/tests/utils.js
var FakeToolCallingModel = class FakeToolCallingModel2 extends BaseChatModel {
  toolCalls;
  toolStyle;
  indexRef;
  structuredResponse;
  tools = [];
  constructor({ toolCalls = [], toolStyle = "openai", index: index2 = 0, structuredResponse, indexRef, ...rest } = {}) {
    super(rest);
    this.toolCalls = toolCalls;
    this.toolStyle = toolStyle;
    this.indexRef = indexRef ?? { current: index2 };
    this.structuredResponse = structuredResponse;
  }
  get index() {
    return this.indexRef.current;
  }
  set index(value) {
    this.indexRef.current = value;
  }
  _llmType() {
    return "fake-tool-calling";
  }
  _combineLLMOutput() {
    return [];
  }
  bindTools(tools) {
    const newInstance = new FakeToolCallingModel2({
      toolCalls: this.toolCalls,
      toolStyle: this.toolStyle,
      structuredResponse: this.structuredResponse,
      indexRef: this.indexRef
    });
    newInstance.tools = [...this.tools, ...tools];
    return newInstance;
  }
  withStructuredOutput(_schema) {
    return new RunnableLambda({ func: async () => {
      return this.structuredResponse;
    } });
  }
  async _generate(messages, _options, _runManager) {
    const lastMessage = messages[messages.length - 1];
    let content = lastMessage.content;
    if (messages.length > 1) {
      const parts = messages.map((m) => m.content).filter(Boolean);
      content = parts.map((part) => {
        if (typeof part === "string") return part;
        else if (typeof part === "object" && "text" in part) return part.text;
        else if (Array.isArray(part)) return part.map((p) => {
          if (typeof p === "string") return p;
          else if (typeof p === "object" && "text" in p) return p.text;
          return "";
        }).join("-");
        else return JSON.stringify(part);
      }).join("-");
    }
    const isStartOfConversation = messages.length === 1 || messages.length === 2 && messages.every(HumanMessage.isInstance);
    if (isStartOfConversation && this.index !== 0) this.index = 0;
    const currentToolCalls = this.toolCalls[this.index] || [];
    const messageId = this.index.toString();
    this.index = (this.index + 1) % Math.max(1, this.toolCalls.length);
    const message = new AIMessage({
      content,
      id: messageId,
      tool_calls: currentToolCalls.length > 0 ? currentToolCalls.map((tc) => ({
        ...tc,
        type: "tool_call"
      })) : void 0
    });
    return {
      generations: [{
        text: content,
        message
      }],
      llmOutput: {}
    };
  }
};

// node_modules/@langchain/langgraph/dist/graph/zod/plugin.js
var metaSymbol = /* @__PURE__ */ Symbol.for("langgraph-zod");
if (!(metaSymbol in globalThis)) globalThis[metaSymbol] = /* @__PURE__ */ new WeakSet();
function applyPluginPrototype(prototype) {
  const cache = globalThis[metaSymbol];
  if (cache.has(prototype)) return;
  Object.defineProperty(prototype, "langgraph", { get() {
    const zodThis = this;
    return {
      metadata(jsonSchemaExtra) {
        return withLangGraph(zodThis, { jsonSchemaExtra });
      },
      reducer(fn, schema) {
        return withLangGraph(zodThis, {
          default: getInteropZodDefaultGetter(zodThis),
          reducer: {
            schema,
            fn
          }
        });
      }
    };
  } });
  cache.add(prototype);
}
try {
  applyPluginPrototype(external_exports.ZodType.prototype);
  applyPluginPrototype(external_exports2.ZodType.prototype);
} catch (error) {
  throw new Error("Failed to extend Zod with LangGraph-related methods. This is most likely a bug, consider opening an issue and/or using `withLangGraph` to augment your Zod schema.", { cause: error });
}

// node_modules/@langchain/langgraph/dist/graph/zod/zod-registry.js
var LanggraphZodMetaRegistry = class extends $ZodRegistry {
  /**
  * Creates a new LanggraphZodMetaRegistry instance.
  *
  * @param parent - The base SchemaMetaRegistry to use for metadata storage.
  */
  constructor(parent) {
    super();
    this.parent = parent;
    this._map = this.parent._map;
  }
  add(schema, ..._meta) {
    const firstMeta = _meta[0];
    if (firstMeta && !firstMeta?.default) {
      const defaultValueGetter = getInteropZodDefaultGetter(schema);
      if (defaultValueGetter != null) firstMeta.default = defaultValueGetter;
    }
    return super.add(schema, ..._meta);
  }
};
var registry2 = new LanggraphZodMetaRegistry(schemaMetaRegistry);

// node_modules/langchain/dist/agents/annotation.js
function createAgentState(hasStructuredResponse = true, stateSchema4, middlewareList = []) {
  const stateFields = { jumpTo: new UntrackedValue() };
  const inputFields = {};
  const outputFields = {};
  const applySchema = (schema) => {
    if (StateSchema.isInstance(schema)) {
      for (const [key, field] of Object.entries(schema.fields)) {
        if (key.startsWith("_")) continue;
        if (!(key in stateFields)) {
          stateFields[key] = field;
          if (ReducedValue.isInstance(field)) {
            inputFields[key] = field.inputSchema || field.valueSchema;
            outputFields[key] = field.valueSchema;
          } else {
            inputFields[key] = field;
            outputFields[key] = field;
          }
        }
      }
      return;
    }
    const shape = getInteropZodObjectShape(schema);
    for (const [key, fieldSchema] of Object.entries(shape)) {
      if (key.startsWith("_")) continue;
      if (!(key in stateFields)) {
        if (isZodSchemaV4(fieldSchema)) {
          const meta3 = schemaMetaRegistry.get(fieldSchema);
          if (meta3?.reducer) {
            if (meta3.reducer.schema) {
              stateFields[key] = new ReducedValue(fieldSchema, {
                inputSchema: meta3.reducer.schema,
                reducer: meta3.reducer.fn
              });
              inputFields[key] = meta3.reducer.schema;
              outputFields[key] = fieldSchema;
            } else {
              stateFields[key] = new ReducedValue(fieldSchema, { reducer: meta3.reducer.fn });
              inputFields[key] = fieldSchema;
              outputFields[key] = fieldSchema;
            }
            continue;
          }
        }
        stateFields[key] = fieldSchema;
        inputFields[key] = fieldSchema;
        outputFields[key] = fieldSchema;
      }
    }
  };
  if (stateSchema4 && (StateSchema.isInstance(stateSchema4) || isInteropZodObject(stateSchema4))) applySchema(stateSchema4);
  for (const middleware of middlewareList) if (middleware.stateSchema && (StateSchema.isInstance(middleware.stateSchema) || isInteropZodObject(middleware.stateSchema))) applySchema(middleware.stateSchema);
  if (hasStructuredResponse) outputFields.structuredResponse = new UntrackedValue();
  return {
    state: new StateSchema({
      messages: MessagesValue,
      ...stateFields
    }),
    input: new StateSchema({
      messages: MessagesValue,
      ...inputFields
    }),
    output: new StateSchema({
      messages: MessagesValue,
      ...outputFields
    })
  };
}

// node_modules/langchain/dist/agents/utils.js
var NAME_PATTERN = /<name>(.*?)<\/name>/s;
var CONTENT_PATTERN = /<content>(.*?)<\/content>/s;
function parseMiddlewareState(stateSchema4, state) {
  if (StateSchema.isInstance(stateSchema4)) {
    const result = {};
    for (const key of Object.keys(stateSchema4.fields)) if (key in state) result[key] = state[key];
    return result;
  }
  if (isInteropZodSchema(stateSchema4)) return interopParse(stateSchema4, state);
  throw new Error(`Invalid state schema type: ${typeof stateSchema4}`);
}
function _addInlineAgentName(message) {
  if (!AIMessage.isInstance(message) || AIMessageChunk.isInstance(message)) return message;
  if (!message.name) return message;
  const { name } = message;
  if (typeof message.content === "string") return new AIMessage({
    ...message.lc_kwargs,
    content: `<name>${name}</name><content>${message.content}</content>`,
    name: void 0
  });
  const updatedContent = [];
  let textBlockCount = 0;
  for (const contentBlock of message.content) if (typeof contentBlock === "string") {
    textBlockCount += 1;
    updatedContent.push(`<name>${name}</name><content>${contentBlock}</content>`);
  } else if (typeof contentBlock === "object" && "type" in contentBlock && contentBlock.type === "text") {
    textBlockCount += 1;
    updatedContent.push({
      ...contentBlock,
      text: `<name>${name}</name><content>${contentBlock.text}</content>`
    });
  } else updatedContent.push(contentBlock);
  if (!textBlockCount) updatedContent.unshift({
    type: "text",
    text: `<name>${name}</name><content></content>`
  });
  return new AIMessage({
    ...message.lc_kwargs,
    content: updatedContent,
    name: void 0
  });
}
function _removeInlineAgentName(message) {
  if (!AIMessage.isInstance(message) || !message.content) return message;
  let updatedContent = [];
  let updatedName;
  if (Array.isArray(message.content)) updatedContent = message.content.filter((block) => {
    if (block.type === "text" && typeof block.text === "string") {
      const nameMatch = block.text.match(NAME_PATTERN);
      const contentMatch = block.text.match(CONTENT_PATTERN);
      if (nameMatch && (!contentMatch || contentMatch[1] === "")) {
        updatedName = nameMatch[1];
        return false;
      }
      return true;
    }
    return true;
  }).map((block) => {
    if (block.type === "text" && typeof block.text === "string") {
      const nameMatch = block.text.match(NAME_PATTERN);
      const contentMatch = block.text.match(CONTENT_PATTERN);
      if (!nameMatch || !contentMatch) return block;
      updatedName = nameMatch[1];
      return {
        ...block,
        text: contentMatch[1]
      };
    }
    return block;
  });
  else {
    const content = message.content;
    const nameMatch = content.match(NAME_PATTERN);
    const contentMatch = content.match(CONTENT_PATTERN);
    if (!nameMatch || !contentMatch) return message;
    updatedName = nameMatch[1];
    updatedContent = contentMatch[1];
  }
  return new AIMessage({
    ...Object.keys(message.lc_kwargs ?? {}).length > 0 ? message.lc_kwargs : message,
    content: updatedContent,
    name: updatedName
  });
}
function isClientTool(tool2) {
  return Runnable.isRunnable(tool2);
}
function _isChatModelWithBindTools(llm) {
  if (!isBaseChatModel(llm)) return false;
  return "bindTools" in llm && typeof llm.bindTools === "function";
}
var _simpleBindTools = (llm, toolClasses, options = {}) => {
  if (_isChatModelWithBindTools(llm)) return llm.bindTools(toolClasses, options);
  if (RunnableBinding.isRunnableBinding(llm) && _isChatModelWithBindTools(llm.bound)) {
    const newBound = llm.bound.bindTools(toolClasses, options);
    if (RunnableBinding.isRunnableBinding(newBound)) return new RunnableBinding({
      bound: newBound.bound,
      config: {
        ...llm.config,
        ...newBound.config
      },
      kwargs: {
        ...llm.kwargs,
        ...newBound.kwargs
      },
      configFactories: newBound.configFactories ?? llm.configFactories
    });
    return new RunnableBinding({
      bound: newBound,
      config: llm.config,
      kwargs: llm.kwargs,
      configFactories: llm.configFactories
    });
  }
  return null;
};
function validateLLMHasNoBoundTools(llm) {
  if (typeof llm === "function") return;
  let model = llm;
  if (RunnableSequence.isRunnableSequence(model)) model = model.steps.find((step) => RunnableBinding.isRunnableBinding(step)) || model;
  if (isConfigurableModel(model))
    return;
  if (RunnableBinding.isRunnableBinding(model)) {
    const hasToolsInKwargs = model.kwargs != null && typeof model.kwargs === "object" && "tools" in model.kwargs && Array.isArray(model.kwargs.tools) && model.kwargs.tools.length > 0;
    const hasToolsInConfig = model.config != null && typeof model.config === "object" && "tools" in model.config && Array.isArray(model.config.tools) && model.config.tools.length > 0;
    if (hasToolsInKwargs || hasToolsInConfig) throw new MultipleToolsBoundError();
  }
  if ("tools" in model && model.tools !== void 0 && Array.isArray(model.tools) && model.tools.length > 0) throw new MultipleToolsBoundError();
}
function hasToolCalls(message) {
  return Boolean(AIMessage.isInstance(message) && message.tool_calls && message.tool_calls.length > 0);
}
function normalizeSystemPrompt(systemPrompt) {
  if (systemPrompt == null) return new SystemMessage("");
  if (SystemMessage.isInstance(systemPrompt)) return systemPrompt;
  if (typeof systemPrompt === "string") return new SystemMessage({ content: [{
    type: "text",
    text: systemPrompt
  }] });
  throw new Error(`Invalid systemPrompt type: expected string or SystemMessage, got ${typeof systemPrompt}`);
}
async function bindTools(llm, toolClasses, options = {}) {
  const model = _simpleBindTools(llm, toolClasses, options);
  if (model) return model;
  if (isConfigurableModel(llm)) {
    const model$1 = _simpleBindTools(await llm._getModelInstance(), toolClasses, options);
    if (model$1) return model$1;
  }
  if (RunnableSequence.isRunnableSequence(llm)) {
    const modelStep = llm.steps.findIndex((step) => RunnableBinding.isRunnableBinding(step) || isBaseChatModel(step) || isConfigurableModel(step));
    if (modelStep >= 0) {
      const model$1 = _simpleBindTools(llm.steps[modelStep], toolClasses, options);
      if (model$1) {
        const nextSteps = llm.steps.slice();
        nextSteps.splice(modelStep, 1, model$1);
        return RunnableSequence.from(nextSteps);
      }
    }
  }
  throw new Error(`llm ${llm} must define bindTools method.`);
}
function chainToolCallHandlers(handlers) {
  if (handlers.length === 0) return void 0;
  if (handlers.length === 1) return handlers[0];
  function composeTwo(outer, inner) {
    return async (request, handler) => {
      const innerHandler = async (passedRequest) => {
        return inner(passedRequest, handler);
      };
      return outer(request, innerHandler);
    };
  }
  let result = handlers[handlers.length - 1];
  for (let i = handlers.length - 2; i >= 0; i--) result = composeTwo(handlers[i], result);
  return result;
}
function wrapToolCall(middleware) {
  const middlewareWithWrapToolCall = middleware.filter((m) => m.wrapToolCall);
  if (middlewareWithWrapToolCall.length === 0) return;
  return chainToolCallHandlers(middlewareWithWrapToolCall.map((m) => {
    const originalHandler = m.wrapToolCall;
    const wrappedHandler = async (request, handler) => {
      const originalState = request.state;
      const wrappedInnerHandler = async (passedRequest) => {
        const mergedState = {
          ...originalState,
          ...passedRequest.state
        };
        return handler({
          ...passedRequest,
          state: mergedState
        });
      };
      try {
        const result = await originalHandler({
          ...request,
          state: {
            messages: originalState.messages,
            ...m.stateSchema ? parseMiddlewareState(m.stateSchema, { ...originalState }) : {}
          }
        }, wrappedInnerHandler);
        if (!ToolMessage.isInstance(result) && !isCommand(result)) throw new Error(`Invalid response from "wrapToolCall" in middleware "${m.name}": expected ToolMessage or Command, got ${typeof result}`);
        return result;
      } catch (error) {
        throw MiddlewareError.wrap(error, m.name);
      }
    };
    return wrappedHandler;
  }));
}

// node_modules/langchain/dist/agents/nodes/utils.js
async function initializeMiddlewareStates(middlewareList, state) {
  const middlewareStates = {};
  for (const middleware of middlewareList) {
    if (!middleware.stateSchema) continue;
    let zodSchema = middleware.stateSchema;
    if (StateSchema.isInstance(middleware.stateSchema)) {
      const zodShape = {};
      for (const [key, field] of Object.entries(middleware.stateSchema.fields)) if (ReducedValue.isInstance(field)) zodShape[key] = field.inputSchema || field.valueSchema;
      else zodShape[key] = field;
      zodSchema = external_exports2.object(zodShape);
    }
    const modifiedSchema = interopZodObjectMakeFieldsOptional(zodSchema, (key) => key.startsWith("_"));
    const parseResult = await interopSafeParseAsync(modifiedSchema, state);
    if (parseResult.success) {
      Object.assign(middlewareStates, parseResult.data);
      continue;
    }
    const requiredFields = parseResult.error.issues.filter((issue) => issue.code === "invalid_type").map((issue) => `  - ${issue.path.join(".")}: Required`).join("\n");
    throw new Error(`Middleware "${middleware.name}" has required state fields that must be initialized:
${requiredFields}

To fix this, either:
1. Provide default values in your middleware's state schema using .default():
   stateSchema: z.object({
     myField: z.string().default("default value")
   })

2. Or make the fields optional using .optional():
   stateSchema: z.object({
     myField: z.string().optional()
   })

3. Or ensure you pass these values when invoking the agent:
   agent.invoke({
     messages: [...],
     ${parseResult.error.issues[0]?.path.join(".")}: "value"
   })`);
  }
  return middlewareStates;
}
function derivePrivateState(stateSchema4) {
  const builtInStateSchema = {
    messages: external_exports2.custom(() => []),
    structuredResponse: external_exports2.any().optional()
  };
  if (!stateSchema4) return external_exports2.object(builtInStateSchema);
  let shape;
  if (StateSchema.isInstance(stateSchema4)) {
    shape = {};
    for (const [key, field] of Object.entries(stateSchema4.fields)) if (ReducedValue.isInstance(field)) shape[key] = field.inputSchema || field.valueSchema;
    else shape[key] = field;
  } else shape = stateSchema4.shape;
  const privateShape = { ...builtInStateSchema };
  for (const [key, value] of Object.entries(shape)) if (key.startsWith("_")) privateShape[key] = value.optional();
  else privateShape[key] = value;
  return external_exports2.object(privateShape);
}
function toPartialZodObject(schema) {
  if (isInteropZodObject(schema)) return interopZodObjectPartial(schema);
  if (StateSchema.isInstance(schema)) {
    const partialShape = {};
    for (const [key, field] of Object.entries(schema.fields)) {
      let fieldSchema;
      if (ReducedValue.isInstance(field)) fieldSchema = field.inputSchema || field.valueSchema;
      else fieldSchema = field;
      partialShape[key] = isZodSchemaV4(fieldSchema) ? fieldSchema.optional() : external_exports2.any().optional();
    }
    return external_exports2.object(partialShape);
  }
  return external_exports2.object({});
}
function parseJumpToTarget(target) {
  if (!target) return void 0;
  if ([
    "model_request",
    "tools",
    END
  ].includes(target)) return target;
  if (target === "model") return "model_request";
  if (target === "tools") return "tools";
  if (target === "end") return END;
  throw new Error(`Invalid jump target: ${target}, must be "model", "tools" or "end".`);
}
function mergeAbortSignals(...signals) {
  return AbortSignal.any(signals.filter((maybeSignal) => maybeSignal !== null && maybeSignal !== void 0 && typeof maybeSignal === "object" && "aborted" in maybeSignal && typeof maybeSignal.aborted === "boolean"));
}

// node_modules/langchain/dist/agents/RunnableCallable.js
var RunnableCallable2 = class extends Runnable {
  lc_namespace = ["langgraph"];
  func;
  tags;
  config;
  trace = true;
  recurse = true;
  #state;
  constructor(fields) {
    super();
    this.name = fields.name ?? fields.func.name;
    this.func = fields.func;
    this.config = fields.tags ? { tags: fields.tags } : void 0;
    this.recurse = fields.recurse ?? this.recurse;
  }
  getState() {
    return this.#state;
  }
  /**
  * This allows us to set the state of the runnable, e.g. for model and middleware nodes.
  * @internal
  */
  setState(state) {
    this.#state = {
      ...this.#state,
      ...state
    };
  }
  async invoke(input, options) {
    const mergedConfig = mergeConfigs(this.config, options);
    const returnValue = await AsyncLocalStorageProviderSingleton.runWithConfig(mergedConfig, async () => this.func(input, mergedConfig));
    if (Runnable.isRunnable(returnValue) && this.recurse) return await AsyncLocalStorageProviderSingleton.runWithConfig(mergedConfig, async () => returnValue.invoke(input, mergedConfig));
    this.#state = returnValue;
    return returnValue;
  }
};

// node_modules/langchain/dist/agents/withAgentName.js
function withAgentName(model, agentNameMode) {
  let processInputMessage;
  let processOutputMessage;
  if (agentNameMode === "inline") {
    processInputMessage = _addInlineAgentName;
    processOutputMessage = _removeInlineAgentName;
  } else throw new Error(`Invalid agent name mode: ${agentNameMode}. Needs to be one of: "inline"`);
  function processInputMessages(messages) {
    return messages.map(processInputMessage);
  }
  return RunnableSequence.from([
    RunnableLambda.from(processInputMessages),
    model,
    RunnableLambda.from(processOutputMessage)
  ]);
}

// node_modules/langchain/dist/agents/nodes/AgentNode.js
function isInternalModelResponse(response) {
  return AIMessage.isInstance(response) || typeof response === "object" && response !== null && "structuredResponse" in response && "messages" in response;
}
var AGENT_NODE_NAME = "model_request";
var AgentNode = class extends RunnableCallable2 {
  #options;
  #systemMessage;
  #currentSystemMessage;
  constructor(options) {
    super({
      name: options.name ?? "model",
      func: (input, config2) => this.#run(input, config2)
    });
    this.#options = options;
    this.#systemMessage = options.systemMessage;
  }
  /**
  * Returns response format primtivies based on given model and response format provided by the user.
  *
  * If the user selects a tool output:
  * - return a record of tools to extract structured output from the model's response
  *
  * if the the user selects a native schema output or if the model supports JSON schema output:
  * - return a provider strategy to extract structured output from the model's response
  *
  * @param model - The model to get the response format for.
  * @returns The response format.
  */
  #getResponseFormat(model) {
    if (!this.#options.responseFormat) return void 0;
    const strategies = transformResponseFormat(this.#options.responseFormat, void 0, model);
    const isProviderStrategy = strategies.every((format) => format instanceof ProviderStrategy);
    if (!isProviderStrategy) return {
      type: "tool",
      tools: strategies.filter((format) => format instanceof ToolStrategy).reduce((acc, format) => {
        acc[format.name] = format;
        return acc;
      }, {})
    };
    return {
      type: "native",
      strategy: strategies[0]
    };
  }
  async #run(state, config2) {
    const lastMessage = state.messages.at(-1);
    if (lastMessage && ToolMessage.isInstance(lastMessage) && lastMessage.name && this.#options.shouldReturnDirect.has(lastMessage.name))
      return { messages: [] };
    const response = await this.#invokeModel(state, config2);
    if ("structuredResponse" in response) return {
      messages: [...state.messages, ...response.messages || []],
      structuredResponse: response.structuredResponse
    };
    if (response instanceof Command) return response;
    response.name = this.name;
    response.lc_kwargs.name = this.name;
    if (this.#areMoreStepsNeeded(state, response)) return { messages: [new AIMessage({
      content: "Sorry, need more steps to process this request.",
      name: this.name,
      id: response.id
    })] };
    return { messages: [response] };
  }
  /**
  * Derive the model from the options.
  * @param state - The state of the agent.
  * @param config - The config of the agent.
  * @returns The model.
  */
  #deriveModel() {
    if (typeof this.#options.model === "string") return initChatModel(this.#options.model);
    if (this.#options.model) return this.#options.model;
    throw new Error("No model option was provided, either via `model` option.");
  }
  async #invokeModel(state, config2, options = {}) {
    const model = await this.#deriveModel();
    const lgConfig = config2;
    const baseHandler = async (request) => {
      validateLLMHasNoBoundTools(request.model);
      const structuredResponseFormat = this.#getResponseFormat(request.model);
      const modelWithTools = await this.#bindTools(request.model, request, structuredResponseFormat);
      const messages = [...this.#currentSystemMessage.text === "" ? [] : [this.#currentSystemMessage], ...request.messages];
      const signal = mergeAbortSignals(this.#options.signal, config2.signal);
      const response = await raceWithSignal(modelWithTools.invoke(messages, {
        ...config2,
        signal
      }), signal);
      if (structuredResponseFormat?.type === "native") {
        const structuredResponse = structuredResponseFormat.strategy.parse(response);
        if (structuredResponse) return {
          structuredResponse,
          messages: [response]
        };
        return response;
      }
      if (!structuredResponseFormat || !response.tool_calls) return response;
      const toolCalls = response.tool_calls.filter((call3) => call3.name in structuredResponseFormat.tools);
      if (toolCalls.length === 0) return response;
      if (toolCalls.length > 1) return this.#handleMultipleStructuredOutputs(response, toolCalls, structuredResponseFormat);
      const toolStrategy2 = structuredResponseFormat.tools[toolCalls[0].name];
      const toolMessageContent = toolStrategy2?.options?.toolMessageContent;
      return this.#handleSingleStructuredOutput(response, toolCalls[0], structuredResponseFormat, toolMessageContent ?? options.lastMessage);
    };
    const wrapperMiddleware = this.#options.wrapModelCallHookMiddleware ?? [];
    let wrappedHandler = baseHandler;
    for (let i = wrapperMiddleware.length - 1; i >= 0; i--) {
      const [middleware, getMiddlewareState] = wrapperMiddleware[i];
      if (middleware.wrapModelCall) {
        const innerHandler = wrappedHandler;
        const currentMiddleware = middleware;
        const currentGetState = getMiddlewareState;
        wrappedHandler = async (request) => {
          const context2 = currentMiddleware.contextSchema ? interopParse(currentMiddleware.contextSchema, lgConfig?.context || {}) : lgConfig?.context;
          const runtime = Object.freeze({
            context: context2,
            writer: lgConfig.writer,
            interrupt: lgConfig.interrupt,
            signal: lgConfig.signal
          });
          const requestWithStateAndRuntime = {
            ...request,
            state: {
              ...middleware.stateSchema ? interopParse(toPartialZodObject(middleware.stateSchema), state) : {},
              ...currentGetState(),
              messages: state.messages
            },
            runtime
          };
          const handlerWithValidation = async (req) => {
            const modifiedTools = req.tools ?? [];
            const newTools = modifiedTools.filter((tool2) => isClientTool(tool2) && !this.#options.toolClasses.some((t) => t.name === tool2.name));
            if (newTools.length > 0) throw new Error(`You have added a new tool in "wrapModelCall" hook of middleware "${currentMiddleware.name}": ${newTools.map((tool2) => tool2.name).join(", ")}. This is not supported.`);
            const invalidTools = modifiedTools.filter((tool2) => isClientTool(tool2) && this.#options.toolClasses.every((t) => t !== tool2));
            if (invalidTools.length > 0) throw new Error(`You have modified a tool in "wrapModelCall" hook of middleware "${currentMiddleware.name}": ${invalidTools.map((tool2) => tool2.name).join(", ")}. This is not supported.`);
            let normalizedReq = req;
            const hasSystemPromptChanged = req.systemPrompt !== this.#currentSystemMessage.text;
            const hasSystemMessageChanged = req.systemMessage !== this.#currentSystemMessage;
            if (hasSystemPromptChanged && hasSystemMessageChanged) throw new Error("Cannot change both systemPrompt and systemMessage in the same request.");
            if (hasSystemPromptChanged) {
              this.#currentSystemMessage = new SystemMessage({ content: [{
                type: "text",
                text: req.systemPrompt
              }] });
              normalizedReq = {
                ...req,
                systemPrompt: this.#currentSystemMessage.text,
                systemMessage: this.#currentSystemMessage
              };
            }
            if (hasSystemMessageChanged) {
              this.#currentSystemMessage = new SystemMessage({ ...req.systemMessage });
              normalizedReq = {
                ...req,
                systemPrompt: this.#currentSystemMessage.text,
                systemMessage: this.#currentSystemMessage
              };
            }
            return innerHandler(normalizedReq);
          };
          if (!currentMiddleware.wrapModelCall) return handlerWithValidation(requestWithStateAndRuntime);
          try {
            const middlewareResponse = await currentMiddleware.wrapModelCall(requestWithStateAndRuntime, handlerWithValidation);
            if (!isInternalModelResponse(middlewareResponse)) throw new Error(`Invalid response from "wrapModelCall" in middleware "${currentMiddleware.name}": expected AIMessage, got ${typeof middlewareResponse}`);
            return middlewareResponse;
          } catch (error) {
            throw MiddlewareError.wrap(error, currentMiddleware.name);
          }
        };
      }
    }
    this.#currentSystemMessage = this.#systemMessage;
    const initialRequest = {
      model,
      systemPrompt: this.#currentSystemMessage?.text,
      systemMessage: this.#currentSystemMessage,
      messages: state.messages,
      tools: this.#options.toolClasses,
      state,
      runtime: Object.freeze({
        context: lgConfig?.context,
        writer: lgConfig.writer,
        interrupt: lgConfig.interrupt,
        signal: lgConfig.signal
      })
    };
    return wrappedHandler(initialRequest);
  }
  /**
  * If the model returns multiple structured outputs, we need to handle it.
  * @param response - The response from the model
  * @param toolCalls - The tool calls that were made
  * @returns The response from the model
  */
  #handleMultipleStructuredOutputs(response, toolCalls, responseFormat) {
    const multipleStructuredOutputsError = new MultipleStructuredOutputsError(toolCalls.map((call3) => call3.name));
    return this.#handleToolStrategyError(multipleStructuredOutputsError, response, toolCalls[0], responseFormat);
  }
  /**
  * If the model returns a single structured output, we need to handle it.
  * @param toolCall - The tool call that was made
  * @returns The structured response and a message to the LLM if needed
  */
  #handleSingleStructuredOutput(response, toolCall, responseFormat, lastMessage) {
    const tool2 = responseFormat.tools[toolCall.name];
    try {
      const structuredResponse = tool2.parse(toolCall.args);
      return {
        structuredResponse,
        messages: [
          response,
          new ToolMessage({
            tool_call_id: toolCall.id ?? "",
            content: JSON.stringify(structuredResponse),
            name: toolCall.name
          }),
          new AIMessage(lastMessage ?? `Returning structured response: ${JSON.stringify(structuredResponse)}`)
        ]
      };
    } catch (error) {
      return this.#handleToolStrategyError(error, response, toolCall, responseFormat);
    }
  }
  async #handleToolStrategyError(error, response, toolCall, responseFormat) {
    const errorHandler = Object.values(responseFormat.tools).at(0)?.options?.handleError;
    const toolCallId = toolCall.id;
    if (!toolCallId) throw new Error("Tool call ID is required to handle tool output errors. Please provide a tool call ID.");
    if (errorHandler === false) throw error;
    if (errorHandler === void 0 || typeof errorHandler === "boolean" && errorHandler || Array.isArray(errorHandler) && errorHandler.some((h) => h instanceof MultipleStructuredOutputsError)) return new Command({
      update: { messages: [response, new ToolMessage({
        content: error.message,
        tool_call_id: toolCallId
      })] },
      goto: AGENT_NODE_NAME
    });
    if (typeof errorHandler === "string") return new Command({
      update: { messages: [response, new ToolMessage({
        content: errorHandler,
        tool_call_id: toolCallId
      })] },
      goto: AGENT_NODE_NAME
    });
    if (typeof errorHandler === "function") {
      const content = await errorHandler(error);
      if (typeof content !== "string") throw new Error("Error handler must return a string.");
      return new Command({
        update: { messages: [response, new ToolMessage({
          content,
          tool_call_id: toolCallId
        })] },
        goto: AGENT_NODE_NAME
      });
    }
    return new Command({
      update: { messages: [response, new ToolMessage({
        content: error.message,
        tool_call_id: toolCallId
      })] },
      goto: AGENT_NODE_NAME
    });
  }
  #areMoreStepsNeeded(state, response) {
    const allToolsReturnDirect = AIMessage.isInstance(response) && response.tool_calls?.every((call3) => this.#options.shouldReturnDirect.has(call3.name));
    const remainingSteps = "remainingSteps" in state ? state.remainingSteps : void 0;
    return Boolean(remainingSteps && (remainingSteps < 1 && allToolsReturnDirect || remainingSteps < 2 && hasToolCalls(state.messages.at(-1))));
  }
  async #bindTools(model, preparedOptions, structuredResponseFormat) {
    const options = {};
    const structuredTools = Object.values(structuredResponseFormat && "tools" in structuredResponseFormat ? structuredResponseFormat.tools : {});
    const allTools = [...preparedOptions?.tools ?? this.#options.toolClasses, ...structuredTools.map((toolStrategy2) => toolStrategy2.tool)];
    const toolChoice = preparedOptions?.toolChoice || (structuredTools.length > 0 ? "any" : void 0);
    if (structuredResponseFormat?.type === "native") {
      const resolvedStrict = preparedOptions?.modelSettings?.strict ?? structuredResponseFormat?.strategy?.strict ?? true;
      const jsonSchemaParams = {
        name: structuredResponseFormat.strategy.schema?.name ?? "extract",
        description: getSchemaDescription(structuredResponseFormat.strategy.schema),
        schema: structuredResponseFormat.strategy.schema,
        strict: resolvedStrict
      };
      Object.assign(options, {
        response_format: {
          type: "json_schema",
          json_schema: jsonSchemaParams
        },
        output_format: {
          type: "json_schema",
          schema: structuredResponseFormat.strategy.schema
        },
        headers: { "anthropic-beta": "structured-outputs-2025-11-13" },
        ls_structured_output_format: {
          kwargs: { method: "json_schema" },
          schema: structuredResponseFormat.strategy.schema
        },
        strict: resolvedStrict
      });
    }
    const modelWithTools = await bindTools(model, allTools, {
      ...options,
      ...preparedOptions?.modelSettings,
      tool_choice: toolChoice
    });
    const modelRunnable = this.#options.includeAgentName === "inline" ? withAgentName(modelWithTools, this.#options.includeAgentName) : modelWithTools;
    return modelRunnable;
  }
  getState() {
    const state = super.getState();
    const origState = state && !(state instanceof Command) ? state : {};
    return {
      messages: [],
      ...origState
    };
  }
};

// node_modules/langchain/dist/agents/nodes/ToolNode.js
var getInvalidToolError = (toolName, availableTools) => `Error: ${toolName} is not a valid tool, try one of [${availableTools.join(", ")}].`;
var TOOLS_NODE_NAME = "tools";
var isBaseMessageArray = (input) => Array.isArray(input) && input.every(BaseMessage.isInstance);
var isMessagesState = (input) => typeof input === "object" && input != null && "messages" in input && isBaseMessageArray(input.messages);
var isSendInput = (input) => typeof input === "object" && input != null && "lg_tool_call" in input;
function defaultHandleToolErrors(error, toolCall) {
  if (error instanceof ToolInvocationError) return new ToolMessage({
    content: error.message,
    tool_call_id: toolCall.id,
    name: toolCall.name
  });
  return new ToolMessage({
    content: `${error}
 Please fix your mistakes.`,
    tool_call_id: toolCall.id,
    name: toolCall.name
  });
}
var ToolNode = class extends RunnableCallable2 {
  tools;
  trace = false;
  signal;
  handleToolErrors = defaultHandleToolErrors;
  wrapToolCall;
  constructor(tools, options) {
    const { name, tags, handleToolErrors, signal, wrapToolCall: wrapToolCall2 } = options ?? {};
    super({
      name,
      tags,
      func: (state, config2) => this.run(state, config2)
    });
    this.options = options;
    this.tools = tools;
    this.handleToolErrors = handleToolErrors ?? this.handleToolErrors;
    this.signal = signal;
    this.wrapToolCall = wrapToolCall2;
  }
  /**
  * Handle errors from tool execution or middleware.
  * @param error - The error to handle
  * @param call - The tool call that caused the error
  * @param isMiddlewareError - Whether the error came from wrapToolCall middleware
  * @returns ToolMessage if error is handled, otherwise re-throws
  */
  #handleError(error, call3, isMiddlewareError) {
    if (isGraphInterrupt(error)) throw error;
    if (this.signal?.aborted) throw error;
    if (isMiddlewareError && this.handleToolErrors !== true) throw error;
    if (!this.handleToolErrors) throw error;
    if (typeof this.handleToolErrors === "function") {
      const result = this.handleToolErrors(error, call3);
      if (result && ToolMessage.isInstance(result)) return result;
      throw error;
    } else if (this.handleToolErrors) return new ToolMessage({
      name: call3.name,
      content: `${error}
 Please fix your mistakes.`,
      tool_call_id: call3.id
    });
    throw error;
  }
  async runTool(call3, config2, state) {
    const lgConfig = config2;
    const runtime = {
      context: lgConfig?.context,
      writer: lgConfig?.writer,
      interrupt: lgConfig?.interrupt,
      signal: lgConfig?.signal
    };
    const registeredTool = this.tools.find((t) => t.name === call3.name);
    const baseHandler = async (request$1) => {
      const { toolCall, tool: requestTool } = request$1;
      const tool$1 = requestTool ?? this.tools.find((t) => t.name === toolCall.name);
      if (tool$1 === void 0) {
        const availableTools = this.tools.map((t) => t.name);
        return new ToolMessage({
          content: getInvalidToolError(toolCall.name, availableTools),
          tool_call_id: toolCall.id,
          name: toolCall.name,
          status: "error"
        });
      }
      const invokableTool = tool$1;
      try {
        const output = await invokableTool.invoke({
          ...toolCall,
          type: "tool_call"
        }, {
          ...config2,
          config: config2,
          toolCallId: toolCall.id,
          state: config2.configurable?.__pregel_scratchpad?.currentTaskInput,
          signal: mergeAbortSignals(this.signal, config2.signal)
        });
        if (ToolMessage.isInstance(output) || isCommand(output)) return output;
        return new ToolMessage({
          name: invokableTool.name,
          content: typeof output === "string" ? output : JSON.stringify(output),
          tool_call_id: toolCall.id
        });
      } catch (e) {
        if (e instanceof ToolInputParsingException) throw new ToolInvocationError(e, toolCall);
        throw e;
      }
    };
    const request = {
      toolCall: call3,
      tool: registeredTool,
      state,
      runtime
    };
    if (this.wrapToolCall) try {
      return await this.wrapToolCall(request, baseHandler);
    } catch (e) {
      return this.#handleError(e, call3, true);
    }
    if (!registeredTool) {
      const availableTools = this.tools.map((t) => t.name);
      return new ToolMessage({
        content: getInvalidToolError(call3.name, availableTools),
        tool_call_id: call3.id,
        name: call3.name,
        status: "error"
      });
    }
    try {
      return await baseHandler(request);
    } catch (e) {
      return this.#handleError(e, call3, false);
    }
  }
  async run(state, config2) {
    let outputs;
    if (isSendInput(state)) {
      const { lg_tool_call: _, jumpTo: __, ...newState } = state;
      outputs = [await this.runTool(state.lg_tool_call, config2, newState)];
    } else {
      let messages;
      if (isBaseMessageArray(state)) messages = state;
      else if (isMessagesState(state)) messages = state.messages;
      else throw new Error("ToolNode only accepts BaseMessage[] or { messages: BaseMessage[] } as input.");
      const toolMessageIds = new Set(messages.filter((msg) => msg.getType() === "tool").map((msg) => msg.tool_call_id));
      let aiMessage;
      for (let i = messages.length - 1; i >= 0; i -= 1) {
        const message = messages[i];
        if (AIMessage.isInstance(message)) {
          aiMessage = message;
          break;
        }
      }
      if (!AIMessage.isInstance(aiMessage)) throw new Error("ToolNode only accepts AIMessages as input.");
      outputs = await Promise.all(aiMessage.tool_calls?.filter((call3) => call3.id == null || !toolMessageIds.has(call3.id)).map((call3) => this.runTool(call3, config2, state)) ?? []);
    }
    if (!outputs.some(isCommand)) return Array.isArray(state) ? outputs : { messages: outputs };
    const combinedOutputs = [];
    let parentCommand = null;
    for (const output of outputs) if (isCommand(output)) if (output.graph === Command.PARENT && Array.isArray(output.goto) && output.goto.every((send) => isSend(send))) if (parentCommand) parentCommand.goto.push(...output.goto);
    else parentCommand = new Command({
      graph: Command.PARENT,
      goto: output.goto
    });
    else combinedOutputs.push(output);
    else combinedOutputs.push(Array.isArray(state) ? [output] : { messages: [output] });
    if (parentCommand) combinedOutputs.push(parentCommand);
    return combinedOutputs;
  }
};
function isSend(x) {
  return x instanceof Send;
}

// node_modules/langchain/dist/agents/nodes/middleware.js
var AgentContext = class {
};
var AgentRuntime = class {
};
var MiddlewareNode = class extends RunnableCallable2 {
  #options;
  constructor(fields, options) {
    super(fields);
    this.#options = options;
  }
  async invokeMiddleware(invokeState, config2) {
    let filteredContext = {};
    if (this.middleware.contextSchema) {
      const schemaShape = this.middleware.contextSchema?.shape;
      if (schemaShape) {
        const relevantContext = {};
        const invokeContext = config2?.context || {};
        for (const key of Object.keys(schemaShape)) if (key in invokeContext) relevantContext[key] = invokeContext[key];
        filteredContext = interopParse(this.middleware.contextSchema, relevantContext);
      }
    }
    const state = {
      ...this.#options.getState(),
      ...invokeState,
      messages: invokeState.messages
    };
    const runtime = {
      context: filteredContext,
      writer: config2?.writer,
      interrupt: config2?.interrupt,
      signal: config2?.signal
    };
    const result = await this.runHook(
      state,
      /**
      * assign runtime and context values into empty named class
      * instances to create a better error message.
      */
      Object.freeze(Object.assign(new AgentRuntime(), {
        ...runtime,
        context: Object.freeze(Object.assign(new AgentContext(), filteredContext))
      }))
    );
    if (!result) return {
      ...state,
      jumpTo: void 0
    };
    let jumpToConstraint;
    let constraint;
    if (this.name?.startsWith("BeforeAgentNode_")) {
      jumpToConstraint = getHookConstraint(this.middleware.beforeAgent);
      constraint = "beforeAgent.canJumpTo";
    } else if (this.name?.startsWith("BeforeModelNode_")) {
      jumpToConstraint = getHookConstraint(this.middleware.beforeModel);
      constraint = "beforeModel.canJumpTo";
    } else if (this.name?.startsWith("AfterAgentNode_")) {
      jumpToConstraint = getHookConstraint(this.middleware.afterAgent);
      constraint = "afterAgent.canJumpTo";
    } else if (this.name?.startsWith("AfterModelNode_")) {
      jumpToConstraint = getHookConstraint(this.middleware.afterModel);
      constraint = "afterModel.canJumpTo";
    }
    if (typeof result.jumpTo === "string" && !jumpToConstraint?.includes(result.jumpTo)) {
      const suggestion = jumpToConstraint && jumpToConstraint.length > 0 ? `must be one of: ${jumpToConstraint?.join(", ")}.` : constraint ? `no ${constraint} defined in middleware ${this.middleware.name}` : "";
      throw new Error(`Invalid jump target: ${result.jumpTo}, ${suggestion}.`);
    }
    if (typeof result === "object" && "type" in result) {
      if (result.type === "terminate") {
        if (result.error) throw result.error;
        return {
          ...state,
          ...result.result || {},
          jumpTo: result.jumpTo
        };
      }
      throw new Error(`Invalid control action: ${JSON.stringify(result)}`);
    }
    return {
      ...state,
      ...result,
      jumpTo: result.jumpTo
    };
  }
  get nodeOptions() {
    return { input: derivePrivateState(this.middleware.stateSchema) };
  }
};

// node_modules/langchain/dist/agents/nodes/BeforeAgentNode.js
var BeforeAgentNode = class extends MiddlewareNode {
  lc_namespace = [
    "langchain",
    "agents",
    "beforeAgentNodes"
  ];
  constructor(middleware, options) {
    super({
      name: `BeforeAgentNode_${middleware.name}`,
      func: async (state, config2) => this.invokeMiddleware(state, config2)
    }, options);
    this.middleware = middleware;
  }
  runHook(state, runtime) {
    const fn = getHookFunction(this.middleware.beforeAgent);
    return fn(state, runtime);
  }
};

// node_modules/langchain/dist/agents/nodes/BeforeModelNode.js
var BeforeModelNode = class extends MiddlewareNode {
  lc_namespace = [
    "langchain",
    "agents",
    "beforeModelNodes"
  ];
  constructor(middleware, options) {
    super({
      name: `BeforeModelNode_${middleware.name}`,
      func: async (state, config2) => this.invokeMiddleware(state, config2)
    }, options);
    this.middleware = middleware;
  }
  runHook(state, runtime) {
    const fn = getHookFunction(this.middleware.beforeModel);
    return fn(state, runtime);
  }
};

// node_modules/langchain/dist/agents/nodes/AfterModelNode.js
var AfterModelNode = class extends MiddlewareNode {
  lc_namespace = [
    "langchain",
    "agents",
    "afterModelNodes"
  ];
  constructor(middleware, options) {
    super({
      name: `AfterModelNode_${middleware.name}`,
      func: async (state, config2) => this.invokeMiddleware(state, config2)
    }, options);
    this.middleware = middleware;
  }
  runHook(state, runtime) {
    const fn = getHookFunction(this.middleware.afterModel);
    return fn(state, runtime);
  }
};

// node_modules/langchain/dist/agents/nodes/AfterAgentNode.js
var AfterAgentNode = class extends MiddlewareNode {
  lc_namespace = [
    "langchain",
    "agents",
    "afterAgentNodes"
  ];
  constructor(middleware, options) {
    super({
      name: `AfterAgentNode_${middleware.name}`,
      func: async (state, config2) => this.invokeMiddleware(state, config2)
    }, options);
    this.middleware = middleware;
  }
  runHook(state, runtime) {
    const fn = getHookFunction(this.middleware.afterAgent);
    return fn(state, runtime);
  }
};

// node_modules/langchain/dist/agents/state.js
var StateManager = class {
  #nodes = /* @__PURE__ */ new Map();
  /**
  * Add node to middleware group.
  * @param name - The name of the middleware group.
  * @param node - The node to add.
  */
  addNode(middleware, node) {
    this.#nodes.set(middleware.name, [...this.#nodes.get(middleware.name) ?? [], node]);
  }
  /**
  * Get the state of a middleware group.
  * @param name - The name of the middleware group.
  * @returns The state of the middleware group.
  */
  getState(name) {
    const middlewareNodes = this.#nodes.get(name) ?? [];
    const state = middlewareNodes.reduce((prev, node) => {
      return {
        ...prev,
        ...node.getState() ?? {}
      };
    }, {});
    delete state.jumpTo;
    return state;
  }
};

// node_modules/langchain/dist/agents/ReactAgent.js
var ReactAgent = class {
  #graph;
  #toolBehaviorVersion = "v2";
  #agentNode;
  #stateManager = new StateManager();
  constructor(options) {
    this.options = options;
    this.#toolBehaviorVersion = options.version ?? this.#toolBehaviorVersion;
    if (!options.model) throw new Error("`model` option is required to create an agent.");
    if (typeof options.model !== "string") validateLLMHasNoBoundTools(options.model);
    const middlewareTools = this.options.middleware?.filter((m) => m.tools).flatMap((m) => m.tools) ?? [];
    const toolClasses = [...options.tools ?? [], ...middlewareTools];
    const shouldReturnDirect = new Set(toolClasses.filter(isClientTool).filter((tool2) => "returnDirect" in tool2 && tool2.returnDirect).map((tool2) => tool2.name));
    const { state, input, output } = createAgentState(this.options.responseFormat !== void 0, this.options.stateSchema, this.options.middleware);
    const workflow = new StateGraph(state, {
      input,
      output,
      context: this.options.contextSchema
    });
    const allNodeWorkflows = workflow;
    const beforeAgentNodes = [];
    const beforeModelNodes = [];
    const afterModelNodes = [];
    const afterAgentNodes = [];
    const wrapModelCallHookMiddleware = [];
    this.#agentNode = new AgentNode({
      model: this.options.model,
      systemMessage: normalizeSystemPrompt(this.options.systemPrompt),
      includeAgentName: this.options.includeAgentName,
      name: this.options.name,
      responseFormat: this.options.responseFormat,
      middleware: this.options.middleware,
      toolClasses,
      shouldReturnDirect,
      signal: this.options.signal,
      wrapModelCallHookMiddleware
    });
    const middlewareNames = /* @__PURE__ */ new Set();
    const middleware = this.options.middleware ?? [];
    for (let i = 0; i < middleware.length; i++) {
      let beforeAgentNode;
      let beforeModelNode;
      let afterModelNode;
      let afterAgentNode;
      const m = middleware[i];
      if (middlewareNames.has(m.name)) throw new Error(`Middleware ${m.name} is defined multiple times`);
      middlewareNames.add(m.name);
      if (m.beforeAgent) {
        beforeAgentNode = new BeforeAgentNode(m, { getState: () => this.#stateManager.getState(m.name) });
        this.#stateManager.addNode(m, beforeAgentNode);
        const name = `${m.name}.before_agent`;
        beforeAgentNodes.push({
          index: i,
          name,
          allowed: getHookConstraint(m.beforeAgent)
        });
        allNodeWorkflows.addNode(name, beforeAgentNode, beforeAgentNode.nodeOptions);
      }
      if (m.beforeModel) {
        beforeModelNode = new BeforeModelNode(m, { getState: () => this.#stateManager.getState(m.name) });
        this.#stateManager.addNode(m, beforeModelNode);
        const name = `${m.name}.before_model`;
        beforeModelNodes.push({
          index: i,
          name,
          allowed: getHookConstraint(m.beforeModel)
        });
        allNodeWorkflows.addNode(name, beforeModelNode, beforeModelNode.nodeOptions);
      }
      if (m.afterModel) {
        afterModelNode = new AfterModelNode(m, { getState: () => this.#stateManager.getState(m.name) });
        this.#stateManager.addNode(m, afterModelNode);
        const name = `${m.name}.after_model`;
        afterModelNodes.push({
          index: i,
          name,
          allowed: getHookConstraint(m.afterModel)
        });
        allNodeWorkflows.addNode(name, afterModelNode, afterModelNode.nodeOptions);
      }
      if (m.afterAgent) {
        afterAgentNode = new AfterAgentNode(m, { getState: () => this.#stateManager.getState(m.name) });
        this.#stateManager.addNode(m, afterAgentNode);
        const name = `${m.name}.after_agent`;
        afterAgentNodes.push({
          index: i,
          name,
          allowed: getHookConstraint(m.afterAgent)
        });
        allNodeWorkflows.addNode(name, afterAgentNode, afterAgentNode.nodeOptions);
      }
      if (m.wrapModelCall) wrapModelCallHookMiddleware.push([m, () => this.#stateManager.getState(m.name)]);
    }
    allNodeWorkflows.addNode(AGENT_NODE_NAME, this.#agentNode);
    const hasWrapToolCallMiddleware = middleware.some((m) => m.wrapToolCall);
    const clientTools = toolClasses.filter(isClientTool);
    if (clientTools.length > 0 || hasWrapToolCallMiddleware) {
      const toolNode = new ToolNode(clientTools, {
        signal: this.options.signal,
        wrapToolCall: wrapToolCall(middleware)
      });
      allNodeWorkflows.addNode(TOOLS_NODE_NAME, toolNode);
    }
    let entryNode;
    if (beforeAgentNodes.length > 0) entryNode = beforeAgentNodes[0].name;
    else if (beforeModelNodes.length > 0) entryNode = beforeModelNodes[0].name;
    else entryNode = AGENT_NODE_NAME;
    const loopEntryNode = beforeModelNodes.length > 0 ? beforeModelNodes[0].name : AGENT_NODE_NAME;
    const exitNode = afterAgentNodes.length > 0 ? afterAgentNodes[afterAgentNodes.length - 1].name : END;
    allNodeWorkflows.addEdge(START, entryNode);
    const hasToolsAvailable = clientTools.length > 0 || hasWrapToolCallMiddleware;
    for (let i = 0; i < beforeAgentNodes.length; i++) {
      const node = beforeAgentNodes[i];
      const current = node.name;
      const isLast = i === beforeAgentNodes.length - 1;
      const nextDefault = isLast ? loopEntryNode : beforeAgentNodes[i + 1].name;
      if (node.allowed && node.allowed.length > 0) {
        const allowedMapped = node.allowed.map((t) => parseJumpToTarget(t)).filter((dest) => dest !== TOOLS_NODE_NAME || hasToolsAvailable);
        const destinations = Array.from(/* @__PURE__ */ new Set([nextDefault, ...allowedMapped.map((dest) => dest === END ? exitNode : dest)]));
        allNodeWorkflows.addConditionalEdges(current, this.#createBeforeAgentRouter(clientTools, nextDefault, exitNode, hasToolsAvailable), destinations);
      } else allNodeWorkflows.addEdge(current, nextDefault);
    }
    for (let i = 0; i < beforeModelNodes.length; i++) {
      const node = beforeModelNodes[i];
      const current = node.name;
      const isLast = i === beforeModelNodes.length - 1;
      const nextDefault = isLast ? AGENT_NODE_NAME : beforeModelNodes[i + 1].name;
      if (node.allowed && node.allowed.length > 0) {
        const allowedMapped = node.allowed.map((t) => parseJumpToTarget(t)).filter((dest) => dest !== TOOLS_NODE_NAME || hasToolsAvailable);
        const destinations = Array.from(/* @__PURE__ */ new Set([nextDefault, ...allowedMapped]));
        allNodeWorkflows.addConditionalEdges(current, this.#createBeforeModelRouter(clientTools, nextDefault, hasToolsAvailable), destinations);
      } else allNodeWorkflows.addEdge(current, nextDefault);
    }
    const lastAfterModelNode = afterModelNodes.at(-1);
    if (afterModelNodes.length > 0 && lastAfterModelNode) allNodeWorkflows.addEdge(AGENT_NODE_NAME, lastAfterModelNode.name);
    else {
      const modelPaths = this.#getModelPaths(clientTools, false, hasToolsAvailable);
      const destinations = modelPaths.map((p) => p === END ? exitNode : p);
      if (destinations.length === 1) allNodeWorkflows.addEdge(AGENT_NODE_NAME, destinations[0]);
      else allNodeWorkflows.addConditionalEdges(AGENT_NODE_NAME, this.#createModelRouter(exitNode), destinations);
    }
    for (let i = afterModelNodes.length - 1; i > 0; i--) {
      const node = afterModelNodes[i];
      const current = node.name;
      const nextDefault = afterModelNodes[i - 1].name;
      if (node.allowed && node.allowed.length > 0) {
        const allowedMapped = node.allowed.map((t) => parseJumpToTarget(t)).filter((dest) => dest !== TOOLS_NODE_NAME || hasToolsAvailable);
        const destinations = Array.from(/* @__PURE__ */ new Set([nextDefault, ...allowedMapped]));
        allNodeWorkflows.addConditionalEdges(current, this.#createAfterModelSequenceRouter(clientTools, node.allowed, nextDefault, hasToolsAvailable), destinations);
      } else allNodeWorkflows.addEdge(current, nextDefault);
    }
    if (afterModelNodes.length > 0) {
      const firstAfterModel = afterModelNodes[0];
      const firstAfterModelNode = firstAfterModel.name;
      const modelPaths = this.#getModelPaths(clientTools, true, hasToolsAvailable).filter((p) => p !== TOOLS_NODE_NAME || hasToolsAvailable);
      const allowJump = Boolean(firstAfterModel.allowed && firstAfterModel.allowed.length > 0);
      const destinations = modelPaths.map((p) => p === END ? exitNode : p);
      allNodeWorkflows.addConditionalEdges(firstAfterModelNode, this.#createAfterModelRouter(clientTools, allowJump, exitNode, hasToolsAvailable), destinations);
    }
    for (let i = afterAgentNodes.length - 1; i > 0; i--) {
      const node = afterAgentNodes[i];
      const current = node.name;
      const nextDefault = afterAgentNodes[i - 1].name;
      if (node.allowed && node.allowed.length > 0) {
        const allowedMapped = node.allowed.map((t) => parseJumpToTarget(t)).filter((dest) => dest !== TOOLS_NODE_NAME || hasToolsAvailable);
        const destinations = Array.from(/* @__PURE__ */ new Set([nextDefault, ...allowedMapped]));
        allNodeWorkflows.addConditionalEdges(current, this.#createAfterModelSequenceRouter(clientTools, node.allowed, nextDefault, hasToolsAvailable), destinations);
      } else allNodeWorkflows.addEdge(current, nextDefault);
    }
    if (afterAgentNodes.length > 0) {
      const firstAfterAgent = afterAgentNodes[0];
      const firstAfterAgentNode = firstAfterAgent.name;
      if (firstAfterAgent.allowed && firstAfterAgent.allowed.length > 0) {
        const allowedMapped = firstAfterAgent.allowed.map((t) => parseJumpToTarget(t)).filter((dest) => dest !== TOOLS_NODE_NAME || hasToolsAvailable);
        const destinations = Array.from(/* @__PURE__ */ new Set([END, ...allowedMapped]));
        allNodeWorkflows.addConditionalEdges(firstAfterAgentNode, this.#createAfterModelSequenceRouter(clientTools, firstAfterAgent.allowed, END, hasToolsAvailable), destinations);
      } else allNodeWorkflows.addEdge(firstAfterAgentNode, END);
    }
    if (hasToolsAvailable) {
      const toolReturnTarget = loopEntryNode;
      if (shouldReturnDirect.size > 0) allNodeWorkflows.addConditionalEdges(TOOLS_NODE_NAME, this.#createToolsRouter(shouldReturnDirect, exitNode), [toolReturnTarget, exitNode]);
      else allNodeWorkflows.addEdge(TOOLS_NODE_NAME, toolReturnTarget);
    }
    this.#graph = allNodeWorkflows.compile({
      checkpointer: this.options.checkpointer,
      store: this.options.store,
      name: this.options.name,
      description: this.options.description
    });
  }
  /**
  * Get the compiled {@link https://docs.langchain.com/oss/javascript/langgraph/use-graph-api | StateGraph}.
  */
  get graph() {
    return this.#graph;
  }
  /**
  * Get possible edge destinations from model node.
  * @param toolClasses names of tools to call
  * @param includeModelRequest whether to include "model_request" as a valid path (for jumpTo routing)
  * @param hasToolsAvailable whether tools are available (includes dynamic tools via middleware)
  * @returns list of possible edge destinations
  */
  #getModelPaths(toolClasses, includeModelRequest = false, hasToolsAvailable = toolClasses.length > 0) {
    const paths = [];
    if (hasToolsAvailable) paths.push(TOOLS_NODE_NAME);
    if (includeModelRequest) paths.push(AGENT_NODE_NAME);
    paths.push(END);
    return paths;
  }
  /**
  * Create routing function for tools node conditional edges.
  */
  #createToolsRouter(shouldReturnDirect, exitNode) {
    return (state) => {
      const builtInState = state;
      const messages = builtInState.messages;
      const lastMessage = messages[messages.length - 1];
      if (ToolMessage.isInstance(lastMessage) && lastMessage.name && shouldReturnDirect.has(lastMessage.name)) return this.options.responseFormat ? AGENT_NODE_NAME : exitNode;
      return AGENT_NODE_NAME;
    };
  }
  /**
  * Create routing function for model node conditional edges.
  * @param exitNode - The exit node to route to (could be after_agent or END)
  */
  #createModelRouter(exitNode = END) {
    return (state) => {
      const builtInState = state;
      const messages = builtInState.messages;
      const lastMessage = messages.at(-1);
      if (!AIMessage.isInstance(lastMessage) || !lastMessage.tool_calls || lastMessage.tool_calls.length === 0) return exitNode;
      const hasOnlyStructuredResponseCalls = lastMessage.tool_calls.every((toolCall) => toolCall.name.startsWith("extract-"));
      if (hasOnlyStructuredResponseCalls) return exitNode;
      if (this.#toolBehaviorVersion === "v1") return TOOLS_NODE_NAME;
      const regularToolCalls = lastMessage.tool_calls.filter((toolCall) => !toolCall.name.startsWith("extract-"));
      if (regularToolCalls.length === 0) return exitNode;
      return regularToolCalls.map((toolCall) => new Send(TOOLS_NODE_NAME, {
        ...state,
        lg_tool_call: toolCall
      }));
    };
  }
  /**
  * Create routing function for jumpTo functionality after afterModel hooks.
  *
  * This router checks if the `jumpTo` property is set in the state after afterModel middleware
  * execution. If set, it routes to the specified target ("model_request" or "tools").
  * If not set, it falls back to the normal model routing logic for afterModel context.
  *
  * The jumpTo property is automatically cleared after use to prevent infinite loops.
  *
  * @param toolClasses - Available tool classes for validation
  * @param allowJump - Whether jumping is allowed
  * @param exitNode - The exit node to route to (could be after_agent or END)
  * @param hasToolsAvailable - Whether tools are available (includes dynamic tools via middleware)
  * @returns Router function that handles jumpTo logic and normal routing
  */
  #createAfterModelRouter(toolClasses, allowJump, exitNode, hasToolsAvailable = toolClasses.length > 0) {
    const hasStructuredResponse = Boolean(this.options.responseFormat);
    return (state) => {
      const builtInState = state;
      const messages = builtInState.messages;
      const lastMessage = messages.at(-1);
      if (AIMessage.isInstance(lastMessage) && (!lastMessage.tool_calls || lastMessage.tool_calls.length === 0)) return exitNode;
      if (allowJump && builtInState.jumpTo) {
        const destination = parseJumpToTarget(builtInState.jumpTo);
        if (destination === END) return exitNode;
        if (destination === TOOLS_NODE_NAME) {
          if (!hasToolsAvailable) return exitNode;
          return new Send(TOOLS_NODE_NAME, {
            ...state,
            jumpTo: void 0
          });
        }
        return new Send(AGENT_NODE_NAME, {
          ...state,
          jumpTo: void 0
        });
      }
      const toolMessages = messages.filter(ToolMessage.isInstance);
      const lastAiMessage = messages.filter(AIMessage.isInstance).at(-1);
      const pendingToolCalls = lastAiMessage?.tool_calls?.filter((call3) => !toolMessages.some((m) => m.tool_call_id === call3.id));
      if (pendingToolCalls && pendingToolCalls.length > 0) return pendingToolCalls.map((toolCall) => new Send(TOOLS_NODE_NAME, {
        ...state,
        lg_tool_call: toolCall
      }));
      const hasStructuredResponseCalls = lastAiMessage?.tool_calls?.some((toolCall) => toolCall.name.startsWith("extract-"));
      if (pendingToolCalls && pendingToolCalls.length === 0 && !hasStructuredResponseCalls && hasStructuredResponse) return AGENT_NODE_NAME;
      if (!AIMessage.isInstance(lastMessage) || !lastMessage.tool_calls || lastMessage.tool_calls.length === 0) return exitNode;
      const hasOnlyStructuredResponseCalls = lastMessage.tool_calls.every((toolCall) => toolCall.name.startsWith("extract-"));
      const hasRegularToolCalls = lastMessage.tool_calls.some((toolCall) => !toolCall.name.startsWith("extract-"));
      if (hasOnlyStructuredResponseCalls || !hasRegularToolCalls) return exitNode;
      return TOOLS_NODE_NAME;
    };
  }
  /**
  * Router for afterModel sequence nodes (connecting later middlewares to earlier ones),
  * honoring allowed jump targets and defaulting to the next node.
  * @param toolClasses - Available tool classes for validation
  * @param allowed - List of allowed jump targets
  * @param nextDefault - Default node to route to
  * @param hasToolsAvailable - Whether tools are available (includes dynamic tools via middleware)
  */
  #createAfterModelSequenceRouter(toolClasses, allowed, nextDefault, hasToolsAvailable = toolClasses.length > 0) {
    const allowedSet = new Set(allowed.map((t) => parseJumpToTarget(t)));
    return (state) => {
      const builtInState = state;
      if (builtInState.jumpTo) {
        const dest = parseJumpToTarget(builtInState.jumpTo);
        if (dest === END && allowedSet.has(END)) return END;
        if (dest === TOOLS_NODE_NAME && allowedSet.has(TOOLS_NODE_NAME)) {
          if (!hasToolsAvailable) return END;
          return new Send(TOOLS_NODE_NAME, {
            ...state,
            jumpTo: void 0
          });
        }
        if (dest === AGENT_NODE_NAME && allowedSet.has(AGENT_NODE_NAME)) return new Send(AGENT_NODE_NAME, {
          ...state,
          jumpTo: void 0
        });
      }
      return nextDefault;
    };
  }
  /**
  * Create routing function for jumpTo functionality after beforeAgent hooks.
  * Falls back to the default next node if no jumpTo is present.
  * When jumping to END, routes to exitNode (which could be an afterAgent node).
  * @param toolClasses - Available tool classes for validation
  * @param nextDefault - Default node to route to
  * @param exitNode - Exit node to route to (could be after_agent or END)
  * @param hasToolsAvailable - Whether tools are available (includes dynamic tools via middleware)
  */
  #createBeforeAgentRouter(toolClasses, nextDefault, exitNode, hasToolsAvailable = toolClasses.length > 0) {
    return (state) => {
      const builtInState = state;
      if (!builtInState.jumpTo) return nextDefault;
      const destination = parseJumpToTarget(builtInState.jumpTo);
      if (destination === END)
        return exitNode;
      if (destination === TOOLS_NODE_NAME) {
        if (!hasToolsAvailable) return exitNode;
        return new Send(TOOLS_NODE_NAME, {
          ...state,
          jumpTo: void 0
        });
      }
      return new Send(AGENT_NODE_NAME, {
        ...state,
        jumpTo: void 0
      });
    };
  }
  /**
  * Create routing function for jumpTo functionality after beforeModel hooks.
  * Falls back to the default next node if no jumpTo is present.
  * @param toolClasses - Available tool classes for validation
  * @param nextDefault - Default node to route to
  * @param hasToolsAvailable - Whether tools are available (includes dynamic tools via middleware)
  */
  #createBeforeModelRouter(toolClasses, nextDefault, hasToolsAvailable = toolClasses.length > 0) {
    return (state) => {
      const builtInState = state;
      if (!builtInState.jumpTo) return nextDefault;
      const destination = parseJumpToTarget(builtInState.jumpTo);
      if (destination === END) return END;
      if (destination === TOOLS_NODE_NAME) {
        if (!hasToolsAvailable) return END;
        return new Send(TOOLS_NODE_NAME, {
          ...state,
          jumpTo: void 0
        });
      }
      return new Send(AGENT_NODE_NAME, {
        ...state,
        jumpTo: void 0
      });
    };
  }
  /**
  * Initialize middleware states if not already present in the input state.
  */
  async #initializeMiddlewareStates(state, config2) {
    if (!this.options.middleware || this.options.middleware.length === 0 || state instanceof Command || !state) return state;
    const defaultStates = await initializeMiddlewareStates(this.options.middleware, state);
    const threadState = await this.#graph.getState(config2).catch(() => ({ values: {} }));
    const updatedState = {
      ...threadState.values,
      ...state
    };
    if (!updatedState) return updatedState;
    for (const [key, value] of Object.entries(defaultStates)) if (!(key in updatedState)) updatedState[key] = value;
    return updatedState;
  }
  /**
  * Executes the agent with the given state and returns the final state after all processing.
  *
  * This method runs the agent's entire workflow synchronously, including:
  * - Processing the input messages through any configured middleware
  * - Calling the language model to generate responses
  * - Executing any tool calls made by the model
  * - Running all middleware hooks (beforeModel, afterModel, etc.)
  *
  * @param state - The initial state for the agent execution. Can be:
  *   - An object containing `messages` array and any middleware-specific state properties
  *   - A Command object for more advanced control flow
  *
  * @param config - Optional runtime configuration including:
  * @param config.context - The context for the agent execution.
  * @param config.configurable - LangGraph configuration options like `thread_id`, `run_id`, etc.
  * @param config.store - The store for the agent execution for persisting state, see more in {@link https://docs.langchain.com/oss/javascript/langgraph/memory#memory-storage | Memory storage}.
  * @param config.signal - An optional {@link https://developer.mozilla.org/en-US/docs/Web/API/AbortSignal | `AbortSignal`} for the agent execution.
  * @param config.recursionLimit - The recursion limit for the agent execution.
  *
  * @returns A Promise that resolves to the final agent state after execution completes.
  *          The returned state includes:
  *          - a `messages` property containing an array with all messages (input, AI responses, tool calls/results)
  *          - a `structuredResponse` property containing the structured response (if configured)
  *          - all state values defined in the middleware
  *
  * @example
  * ```typescript
  * const agent = new ReactAgent({
  *   llm: myModel,
  *   tools: [calculator, webSearch],
  *   responseFormat: z.object({
  *     weather: z.string(),
  *   }),
  * });
  *
  * const result = await agent.invoke({
  *   messages: [{ role: "human", content: "What's the weather in Paris?" }]
  * });
  *
  * console.log(result.structuredResponse.weather); // outputs: "It's sunny and 75F."
  * ```
  */
  async invoke(state, config2) {
    const initializedState = await this.#initializeMiddlewareStates(state, config2);
    return this.#graph.invoke(initializedState, config2);
  }
  /**
  * Executes the agent with streaming, returning an async iterable of state updates as they occur.
  *
  * This method runs the agent's workflow similar to `invoke`, but instead of waiting for
  * completion, it streams high-level state updates in real-time. This allows you to:
  * - Display intermediate results to users as they're generated
  * - Monitor the agent's progress through each step
  * - React to state changes as nodes complete
  *
  * For more granular event-level streaming (like individual LLM tokens), use `streamEvents` instead.
  *
  * @param state - The initial state for the agent execution. Can be:
  *   - An object containing `messages` array and any middleware-specific state properties
  *   - A Command object for more advanced control flow
  *
  * @param config - Optional runtime configuration including:
  * @param config.context - The context for the agent execution.
  * @param config.configurable - LangGraph configuration options like `thread_id`, `run_id`, etc.
  * @param config.store - The store for the agent execution for persisting state, see more in {@link https://docs.langchain.com/oss/javascript/langgraph/memory#memory-storage | Memory storage}.
  * @param config.signal - An optional {@link https://developer.mozilla.org/en-US/docs/Web/API/AbortSignal | `AbortSignal`} for the agent execution.
  * @param config.streamMode - The streaming mode for the agent execution, see more in {@link https://docs.langchain.com/oss/javascript/langgraph/streaming#supported-stream-modes | Supported stream modes}.
  * @param config.recursionLimit - The recursion limit for the agent execution.
  *
  * @returns A Promise that resolves to an IterableReadableStream of state updates.
  *          Each update contains the current state after a node completes.
  *
  * @example
  * ```typescript
  * const agent = new ReactAgent({
  *   llm: myModel,
  *   tools: [calculator, webSearch]
  * });
  *
  * const stream = await agent.stream({
  *   messages: [{ role: "human", content: "What's 2+2 and the weather in NYC?" }]
  * });
  *
  * for await (const chunk of stream) {
  *   console.log(chunk); // State update from each node
  * }
  * ```
  */
  async stream(state, config2) {
    const initializedState = await this.#initializeMiddlewareStates(state, config2);
    return this.#graph.stream(initializedState, config2);
  }
  /**
  * Visualize the graph as a PNG image.
  * @param params - Parameters for the drawMermaidPng method.
  * @param params.withStyles - Whether to include styles in the graph.
  * @param params.curveStyle - The style of the graph's curves.
  * @param params.nodeColors - The colors of the graph's nodes.
  * @param params.wrapLabelNWords - The maximum number of words to wrap in a node's label.
  * @param params.backgroundColor - The background color of the graph.
  * @returns PNG image as a buffer
  */
  async drawMermaidPng(params) {
    const representation = await this.#graph.getGraphAsync();
    const image = await representation.drawMermaidPng(params);
    const arrayBuffer = await image.arrayBuffer();
    const buffer = new Uint8Array(arrayBuffer);
    return buffer;
  }
  /**
  * Draw the graph as a Mermaid string.
  * @param params - Parameters for the drawMermaid method.
  * @param params.withStyles - Whether to include styles in the graph.
  * @param params.curveStyle - The style of the graph's curves.
  * @param params.nodeColors - The colors of the graph's nodes.
  * @param params.wrapLabelNWords - The maximum number of words to wrap in a node's label.
  * @param params.backgroundColor - The background color of the graph.
  * @returns Mermaid string
  */
  async drawMermaid(params) {
    const representation = await this.#graph.getGraphAsync();
    return representation.drawMermaid(params);
  }
  /**
  * The following are internal methods to enable support for LangGraph Platform.
  * They are not part of the createAgent public API.
  *
  * Note: we intentionally return as `never` to avoid type errors due to type inference.
  */
  /**
  * @internal
  */
  streamEvents(state, config2, streamOptions) {
    return this.#graph.streamEvents(state, {
      ...config2,
      version: config2?.version ?? "v2"
    }, streamOptions);
  }
  /**
  * @internal
  */
  getGraphAsync(config2) {
    return this.#graph.getGraphAsync(config2);
  }
  /**
  * @internal
  */
  getState(config2, options) {
    return this.#graph.getState(config2, options);
  }
  /**
  * @internal
  */
  getStateHistory(config2, options) {
    return this.#graph.getStateHistory(config2, options);
  }
  /**
  * @internal
  */
  getSubgraphs(namespace, recurse) {
    return this.#graph.getSubgraphs(namespace, recurse);
  }
  /**
  * @internal
  */
  getSubgraphAsync(namespace, recurse) {
    return this.#graph.getSubgraphsAsync(namespace, recurse);
  }
  /**
  * @internal
  */
  updateState(inputConfig, values, asNode) {
    return this.#graph.updateState(inputConfig, values, asNode);
  }
  /**
  * @internal
  */
  get builder() {
    return this.#graph.builder;
  }
};

// node_modules/langchain/dist/agents/index.js
function createAgent(params) {
  return new ReactAgent(params);
}

// node_modules/langchain/dist/agents/middleware/hitl.js
var DescriptionFunctionSchema = external_exports.function().args(external_exports.custom(), external_exports.custom(), external_exports.custom()).returns(external_exports.union([external_exports.string(), external_exports.promise(external_exports.string())]));
var ALLOWED_DECISIONS = [
  "approve",
  "edit",
  "reject"
];
var DecisionType = external_exports.enum(ALLOWED_DECISIONS);
var InterruptOnConfigSchema = external_exports.object({
  allowedDecisions: external_exports.array(DecisionType),
  description: external_exports.union([external_exports.string(), DescriptionFunctionSchema]).optional(),
  argsSchema: external_exports.record(external_exports.any()).optional()
});
var contextSchema = external_exports.object({
  interruptOn: external_exports.record(external_exports.union([external_exports.boolean(), InterruptOnConfigSchema])).optional(),
  descriptionPrefix: external_exports.string().default("Tool execution requires approval")
});
function humanInTheLoopMiddleware(options) {
  const createActionAndConfig = async (toolCall, config2, state, runtime) => {
    const toolName = toolCall.name;
    const toolArgs = toolCall.args;
    const descriptionValue = config2.description;
    let description;
    if (typeof descriptionValue === "function") description = await descriptionValue(toolCall, state, runtime);
    else if (descriptionValue !== void 0) description = descriptionValue;
    else description = `${options.descriptionPrefix ?? "Tool execution requires approval"}

Tool: ${toolName}
Args: ${JSON.stringify(toolArgs, null, 2)}`;
    const actionRequest = {
      name: toolName,
      args: toolArgs,
      description
    };
    const reviewConfig = {
      actionName: toolName,
      allowedDecisions: config2.allowedDecisions
    };
    if (config2.argsSchema) reviewConfig.argsSchema = config2.argsSchema;
    return {
      actionRequest,
      reviewConfig
    };
  };
  const processDecision = (decision, toolCall, config2) => {
    const allowedDecisions = config2.allowedDecisions;
    if (decision.type === "approve" && allowedDecisions.includes("approve")) return {
      revisedToolCall: toolCall,
      toolMessage: null
    };
    if (decision.type === "edit" && allowedDecisions.includes("edit")) {
      const editedAction = decision.editedAction;
      if (!editedAction || typeof editedAction.name !== "string") throw new Error(`Invalid edited action for tool "${toolCall.name}": name must be a string`);
      if (!editedAction.args || typeof editedAction.args !== "object") throw new Error(`Invalid edited action for tool "${toolCall.name}": args must be an object`);
      return {
        revisedToolCall: {
          type: "tool_call",
          name: editedAction.name,
          args: editedAction.args,
          id: toolCall.id
        },
        toolMessage: null
      };
    }
    if (decision.type === "reject" && allowedDecisions.includes("reject")) {
      if (decision.message !== void 0 && typeof decision.message !== "string") throw new Error(`Tool call response for "${toolCall.name}" must be a string, got ${typeof decision.message}`);
      const content = decision.message ?? `User rejected the tool call for \`${toolCall.name}\` with id ${toolCall.id}`;
      const toolMessage = new ToolMessage({
        content,
        name: toolCall.name,
        tool_call_id: toolCall.id,
        status: "error"
      });
      return {
        revisedToolCall: toolCall,
        toolMessage
      };
    }
    const msg = `Unexpected human decision: ${JSON.stringify(decision)}. Decision type '${decision.type}' is not allowed for tool '${toolCall.name}'. Expected one of ${JSON.stringify(allowedDecisions)} based on the tool's configuration.`;
    throw new Error(msg);
  };
  return createMiddleware({
    name: "HumanInTheLoopMiddleware",
    contextSchema,
    afterModel: {
      canJumpTo: ["model"],
      hook: async (state, runtime) => {
        const config2 = interopParse(contextSchema, {
          ...options,
          ...runtime.context || {}
        });
        if (!config2) return;
        const { messages } = state;
        if (!messages.length) return;
        const lastMessage = [...messages].reverse().find((msg) => AIMessage.isInstance(msg));
        if (!lastMessage || !lastMessage.tool_calls?.length) return;
        if (!config2.interruptOn) return;
        const resolvedConfigs = {};
        for (const [toolName, toolConfig] of Object.entries(config2.interruptOn)) if (typeof toolConfig === "boolean") {
          if (toolConfig === true) resolvedConfigs[toolName] = { allowedDecisions: [...ALLOWED_DECISIONS] };
        } else if (toolConfig.allowedDecisions) resolvedConfigs[toolName] = toolConfig;
        const interruptToolCalls = [];
        const autoApprovedToolCalls = [];
        for (const toolCall of lastMessage.tool_calls) if (toolCall.name in resolvedConfigs) interruptToolCalls.push(toolCall);
        else autoApprovedToolCalls.push(toolCall);
        if (!interruptToolCalls.length) return;
        const actionRequests = [];
        const reviewConfigs = [];
        for (const toolCall of interruptToolCalls) {
          const interruptConfig = resolvedConfigs[toolCall.name];
          const { actionRequest, reviewConfig } = await createActionAndConfig(toolCall, interruptConfig, state, runtime);
          actionRequests.push(actionRequest);
          reviewConfigs.push(reviewConfig);
        }
        const hitlRequest = {
          actionRequests,
          reviewConfigs
        };
        const hitlResponse = await interrupt(hitlRequest);
        const decisions = hitlResponse.decisions;
        if (!decisions || !Array.isArray(decisions)) throw new Error("Invalid HITLResponse: decisions must be a non-empty array");
        if (decisions.length !== interruptToolCalls.length) throw new Error(`Number of human decisions (${decisions.length}) does not match number of hanging tool calls (${interruptToolCalls.length}).`);
        const revisedToolCalls = [...autoApprovedToolCalls];
        const artificialToolMessages = [];
        const hasRejectedToolCalls = decisions.some((decision) => decision.type === "reject");
        for (let i = 0; i < decisions.length; i++) {
          const decision = decisions[i];
          const toolCall = interruptToolCalls[i];
          const interruptConfig = resolvedConfigs[toolCall.name];
          const { revisedToolCall, toolMessage } = processDecision(decision, toolCall, interruptConfig);
          if (revisedToolCall && (!hasRejectedToolCalls || decision.type === "reject")) revisedToolCalls.push(revisedToolCall);
          if (toolMessage) artificialToolMessages.push(toolMessage);
        }
        if (AIMessage.isInstance(lastMessage)) lastMessage.tool_calls = revisedToolCalls;
        const jumpTo = hasRejectedToolCalls ? "model" : void 0;
        return {
          messages: [lastMessage, ...artificialToolMessages],
          jumpTo
        };
      }
    }
  });
}

// node_modules/langchain/dist/agents/middleware/summarization.js
var DEFAULT_SUMMARY_PROMPT = `<role>
Context Extraction Assistant
</role>

<primary_objective>
Your sole objective in this task is to extract the highest quality/most relevant context from the conversation history below.
</primary_objective>

<objective_information>
You're nearing the total number of input tokens you can accept, so you must extract the highest quality/most relevant pieces of information from your conversation history.
This context will then overwrite the conversation history presented below. Because of this, ensure the context you extract is only the most important information to your overall goal.
</objective_information>

<instructions>
The conversation history below will be replaced with the context you extract in this step. Because of this, you must do your very best to extract and record all of the most important context from the conversation history.
You want to ensure that you don't repeat any actions you've already completed, so the context you extract from the conversation history should be focused on the most important information to your overall goal.
</instructions>

The user will message you with the full message history you'll be extracting context from, to then replace. Carefully read over it all, and think deeply about what information is most important to your overall goal that should be saved:

With all of this in mind, please carefully read over the entire conversation history, and extract the most important and relevant context to replace it so that you can free up space in the conversation history.
Respond ONLY with the extracted context. Do not include any additional information, or text before or after the extracted context.

<messages>
Messages to summarize:
{messages}
</messages>`;
var DEFAULT_SUMMARY_PREFIX = "Here is a summary of the conversation to date:";
var DEFAULT_MESSAGES_TO_KEEP = 20;
var DEFAULT_TRIM_TOKEN_LIMIT = 4e3;
var DEFAULT_FALLBACK_MESSAGE_COUNT = 15;
var SEARCH_RANGE_FOR_TOOL_PAIRS = 5;
var tokenCounterSchema = external_exports.function().args(external_exports.array(external_exports.custom())).returns(external_exports.union([external_exports.number(), external_exports.promise(external_exports.number())]));
var contextSizeSchema = external_exports.object({
  fraction: external_exports.number().gt(0, "Fraction must be greater than 0").max(1, "Fraction must be less than or equal to 1").optional(),
  tokens: external_exports.number().positive("Tokens must be greater than 0").optional(),
  messages: external_exports.number().int("Messages must be an integer").positive("Messages must be greater than 0").optional()
}).refine((data) => {
  const count = [
    data.fraction,
    data.tokens,
    data.messages
  ].filter((v) => v !== void 0).length;
  return count >= 1;
}, { message: "At least one of fraction, tokens, or messages must be provided" });
var keepSchema = external_exports.object({
  fraction: external_exports.number().min(0, "Messages must be non-negative").max(1, "Fraction must be less than or equal to 1").optional(),
  tokens: external_exports.number().min(0, "Tokens must be greater than or equal to 0").optional(),
  messages: external_exports.number().int("Messages must be an integer").min(0, "Messages must be non-negative").optional()
}).refine((data) => {
  const count = [
    data.fraction,
    data.tokens,
    data.messages
  ].filter((v) => v !== void 0).length;
  return count === 1;
}, { message: "Exactly one of fraction, tokens, or messages must be provided" });
var contextSchema2 = external_exports.object({
  model: external_exports.custom(),
  trigger: external_exports.union([contextSizeSchema, external_exports.array(contextSizeSchema)]).optional(),
  keep: keepSchema.optional(),
  tokenCounter: tokenCounterSchema.optional(),
  summaryPrompt: external_exports.string().default(DEFAULT_SUMMARY_PROMPT),
  trimTokensToSummarize: external_exports.number().optional(),
  summaryPrefix: external_exports.string().optional(),
  maxTokensBeforeSummary: external_exports.number().optional(),
  messagesToKeep: external_exports.number().optional()
});
function getProfileLimits(input) {
  if ("profile" in input && typeof input.profile === "object" && input.profile && "maxInputTokens" in input.profile && (typeof input.profile.maxInputTokens === "number" || input.profile.maxInputTokens == null)) return input.profile.maxInputTokens ?? void 0;
  if ("model" in input && typeof input.model === "string") return getModelContextSize(input.model);
  if ("modelName" in input && typeof input.modelName === "string") return getModelContextSize(input.modelName);
  return void 0;
}
function summarizationMiddleware(options) {
  const { data: userOptions, error } = interopSafeParse(contextSchema2, options);
  if (error) throw new Error(`Invalid summarization middleware options: ${external_exports2.prettifyError(error)}`);
  return createMiddleware({
    name: "SummarizationMiddleware",
    contextSchema: contextSchema2.extend({ model: external_exports.custom().optional() }),
    beforeModel: async (state, runtime) => {
      let trigger = userOptions.trigger;
      let keep = userOptions.keep;
      if (userOptions.maxTokensBeforeSummary !== void 0) {
        console.warn("maxTokensBeforeSummary is deprecated. Use `trigger: { tokens: value }` instead.");
        if (trigger === void 0) trigger = { tokens: userOptions.maxTokensBeforeSummary };
      }
      if (userOptions.messagesToKeep !== void 0) {
        console.warn("messagesToKeep is deprecated. Use `keep: { messages: value }` instead.");
        if (!keep || keep && "messages" in keep && keep.messages === DEFAULT_MESSAGES_TO_KEEP) keep = { messages: userOptions.messagesToKeep };
      }
      const resolvedTrigger = runtime.context?.trigger !== void 0 ? runtime.context.trigger : trigger;
      const resolvedKeep = runtime.context?.keep !== void 0 ? runtime.context.keep : keep ?? { messages: DEFAULT_MESSAGES_TO_KEEP };
      const validatedKeep = keepSchema.parse(resolvedKeep);
      let triggerConditions = [];
      if (resolvedTrigger === void 0) triggerConditions = [];
      else if (Array.isArray(resolvedTrigger))
        triggerConditions = resolvedTrigger.map((t) => contextSizeSchema.parse(t));
      else
        triggerConditions = [contextSizeSchema.parse(resolvedTrigger)];
      const requiresProfile = triggerConditions.some((c) => "fraction" in c) || "fraction" in validatedKeep;
      const model = typeof userOptions.model === "string" ? await initChatModel(userOptions.model) : userOptions.model;
      if (requiresProfile && !getProfileLimits(model)) throw new Error("Model profile information is required to use fractional token limits. Use absolute token counts instead.");
      const summaryPrompt = runtime.context?.summaryPrompt === DEFAULT_SUMMARY_PROMPT ? userOptions.summaryPrompt ?? DEFAULT_SUMMARY_PROMPT : runtime.context?.summaryPrompt ?? userOptions.summaryPrompt ?? DEFAULT_SUMMARY_PROMPT;
      const summaryPrefix = runtime.context.summaryPrefix ?? userOptions.summaryPrefix ?? DEFAULT_SUMMARY_PREFIX;
      const trimTokensToSummarize = runtime.context?.trimTokensToSummarize !== void 0 ? runtime.context.trimTokensToSummarize : userOptions.trimTokensToSummarize ?? DEFAULT_TRIM_TOKEN_LIMIT;
      ensureMessageIds(state.messages);
      const tokenCounter = runtime.context?.tokenCounter !== void 0 ? runtime.context.tokenCounter : userOptions.tokenCounter ?? countTokensApproximately;
      const totalTokens = await tokenCounter(state.messages);
      const doSummarize = await shouldSummarize(state.messages, totalTokens, triggerConditions, model);
      if (!doSummarize) return;
      const { systemPrompt, conversationMessages } = splitSystemMessage(state.messages);
      const cutoffIndex = await determineCutoffIndex(conversationMessages, validatedKeep, tokenCounter, model);
      if (cutoffIndex <= 0) return;
      const { messagesToSummarize, preservedMessages } = partitionMessages(systemPrompt, conversationMessages, cutoffIndex);
      const summary = await createSummary(messagesToSummarize, model, summaryPrompt, tokenCounter, trimTokensToSummarize, runtime);
      const summaryMessage = new HumanMessage({
        content: `${summaryPrefix}

${summary}`,
        id: v4_default(),
        additional_kwargs: { lc_source: "summarization" }
      });
      return { messages: [
        new RemoveMessage({ id: REMOVE_ALL_MESSAGES }),
        summaryMessage,
        ...preservedMessages
      ] };
    }
  });
}
function ensureMessageIds(messages) {
  for (const msg of messages) if (!msg.id) msg.id = v4_default();
}
function splitSystemMessage(messages) {
  if (messages.length > 0 && SystemMessage.isInstance(messages[0])) return {
    systemPrompt: messages[0],
    conversationMessages: messages.slice(1)
  };
  return { conversationMessages: messages };
}
function partitionMessages(systemPrompt, conversationMessages, cutoffIndex) {
  const messagesToSummarize = conversationMessages.slice(0, cutoffIndex);
  const preservedMessages = conversationMessages.slice(cutoffIndex);
  if (systemPrompt) messagesToSummarize.unshift(systemPrompt);
  return {
    messagesToSummarize,
    preservedMessages
  };
}
async function shouldSummarize(messages, totalTokens, triggerConditions, model) {
  if (triggerConditions.length === 0) return false;
  for (const trigger of triggerConditions) {
    let conditionMet = true;
    let hasAnyProperty = false;
    if (trigger.messages !== void 0) {
      hasAnyProperty = true;
      if (messages.length < trigger.messages) conditionMet = false;
    }
    if (trigger.tokens !== void 0) {
      hasAnyProperty = true;
      if (totalTokens < trigger.tokens) conditionMet = false;
    }
    if (trigger.fraction !== void 0) {
      hasAnyProperty = true;
      const maxInputTokens = getProfileLimits(model);
      if (typeof maxInputTokens === "number") {
        const threshold = Math.floor(maxInputTokens * trigger.fraction);
        if (totalTokens < threshold) conditionMet = false;
      } else
        conditionMet = false;
    }
    if (hasAnyProperty && conditionMet) return true;
  }
  return false;
}
async function determineCutoffIndex(messages, keep, tokenCounter, model) {
  if ("tokens" in keep || "fraction" in keep) {
    const tokenBasedCutoff = await findTokenBasedCutoff(messages, keep, tokenCounter, model);
    if (typeof tokenBasedCutoff === "number") return tokenBasedCutoff;
    return findSafeCutoff(messages, DEFAULT_MESSAGES_TO_KEEP);
  }
  return findSafeCutoff(messages, keep.messages ?? DEFAULT_MESSAGES_TO_KEEP);
}
async function findTokenBasedCutoff(messages, keep, tokenCounter, model) {
  if (messages.length === 0) return 0;
  let targetTokenCount;
  if ("fraction" in keep && keep.fraction !== void 0) {
    const maxInputTokens = getProfileLimits(model);
    if (typeof maxInputTokens !== "number") return;
    targetTokenCount = Math.floor(maxInputTokens * keep.fraction);
  } else if ("tokens" in keep && keep.tokens !== void 0) targetTokenCount = Math.floor(keep.tokens);
  else return;
  if (targetTokenCount <= 0) targetTokenCount = 1;
  const totalTokens = await tokenCounter(messages);
  if (totalTokens <= targetTokenCount) return 0;
  let left = 0;
  let right = messages.length;
  let cutoffCandidate = messages.length;
  const maxIterations = Math.floor(Math.log2(messages.length)) + 1;
  for (let i = 0; i < maxIterations; i++) {
    if (left >= right) break;
    const mid = Math.floor((left + right) / 2);
    const suffixTokens = await tokenCounter(messages.slice(mid));
    if (suffixTokens <= targetTokenCount) {
      cutoffCandidate = mid;
      right = mid;
    } else left = mid + 1;
  }
  if (cutoffCandidate === messages.length) cutoffCandidate = left;
  if (cutoffCandidate >= messages.length) {
    if (messages.length === 1) return 0;
    cutoffCandidate = messages.length - 1;
  }
  const safeCutoff = findSafeCutoffPoint(messages, cutoffCandidate);
  if (safeCutoff <= cutoffCandidate) return safeCutoff;
  for (let i = cutoffCandidate; i >= 0; i--) if (isSafeCutoffPoint(messages, i)) return i;
  return 0;
}
function findSafeCutoff(messages, messagesToKeep) {
  if (messages.length <= messagesToKeep) return 0;
  const targetCutoff = messages.length - messagesToKeep;
  const safeCutoff = findSafeCutoffPoint(messages, targetCutoff);
  if (safeCutoff <= targetCutoff) return safeCutoff;
  for (let i = targetCutoff; i >= 0; i--) if (isSafeCutoffPoint(messages, i)) return i;
  return 0;
}
function isSafeCutoffPoint(messages, cutoffIndex) {
  if (cutoffIndex >= messages.length) return true;
  if (cutoffIndex < messages.length && AIMessage.isInstance(messages[cutoffIndex]) && hasToolCalls(messages[cutoffIndex])) return false;
  const searchStart = Math.max(0, cutoffIndex - SEARCH_RANGE_FOR_TOOL_PAIRS);
  const searchEnd = Math.min(messages.length, cutoffIndex + SEARCH_RANGE_FOR_TOOL_PAIRS);
  for (let i = searchStart; i < searchEnd; i++) {
    if (!hasToolCalls(messages[i])) continue;
    const toolCallIds = extractToolCallIds(messages[i]);
    if (cutoffSeparatesToolPair(messages, i, cutoffIndex, toolCallIds)) return false;
  }
  return true;
}
function extractToolCallIds(aiMessage) {
  const toolCallIds = /* @__PURE__ */ new Set();
  if (aiMessage.tool_calls) for (const toolCall of aiMessage.tool_calls) {
    const id = typeof toolCall === "object" && "id" in toolCall ? toolCall.id : null;
    if (id) toolCallIds.add(id);
  }
  return toolCallIds;
}
function findSafeCutoffPoint(messages, cutoffIndex) {
  if (cutoffIndex >= messages.length || !ToolMessage.isInstance(messages[cutoffIndex])) return cutoffIndex;
  const toolCallIds = /* @__PURE__ */ new Set();
  let idx = cutoffIndex;
  while (idx < messages.length && ToolMessage.isInstance(messages[idx])) {
    const toolMsg = messages[idx];
    if (toolMsg.tool_call_id) toolCallIds.add(toolMsg.tool_call_id);
    idx++;
  }
  for (let i = cutoffIndex - 1; i >= 0; i--) {
    const msg = messages[i];
    if (AIMessage.isInstance(msg) && hasToolCalls(msg)) {
      const aiToolCallIds = extractToolCallIds(msg);
      for (const id of toolCallIds) if (aiToolCallIds.has(id)) return i;
    }
  }
  return idx;
}
function cutoffSeparatesToolPair(messages, aiMessageIndex, cutoffIndex, toolCallIds) {
  for (let j = aiMessageIndex + 1; j < messages.length; j++) {
    const message = messages[j];
    if (ToolMessage.isInstance(message) && toolCallIds.has(message.tool_call_id)) {
      const aiBeforeCutoff = aiMessageIndex < cutoffIndex;
      const toolBeforeCutoff = j < cutoffIndex;
      if (aiBeforeCutoff !== toolBeforeCutoff) return true;
    }
  }
  return false;
}
async function createSummary(messagesToSummarize, model, summaryPrompt, tokenCounter, trimTokensToSummarize, runtime) {
  if (!messagesToSummarize.length) return "No previous conversation history.";
  const trimmedMessages = await trimMessagesForSummary(messagesToSummarize, tokenCounter, trimTokensToSummarize);
  if (!trimmedMessages.length) return "Previous conversation was too long to summarize.";
  const formattedMessages = getBufferString(trimmedMessages);
  try {
    const formattedPrompt = summaryPrompt.replace("{messages}", formattedMessages);
    const baseConfig = pickRunnableConfigKeys(runtime) ?? {};
    const config2 = mergeConfigs(baseConfig, { metadata: { lc_source: "summarization" } });
    const response = await model.invoke(formattedPrompt, config2);
    const content = response.content;
    if (typeof content === "string") return content.trim();
    else if (Array.isArray(content)) {
      const textContent = content.map((item) => {
        if (typeof item === "string") return item;
        if (typeof item === "object" && item !== null && "text" in item) return item.text;
        return "";
      }).join("");
      return textContent.trim();
    }
    return "Error generating summary: Invalid response format";
  } catch (e) {
    return `Error generating summary: ${e}`;
  }
}
async function trimMessagesForSummary(messages, tokenCounter, trimTokensToSummarize) {
  if (trimTokensToSummarize === void 0) return messages;
  try {
    return await trimMessages(messages, {
      maxTokens: trimTokensToSummarize,
      tokenCounter: async (msgs) => tokenCounter(msgs),
      strategy: "last",
      allowPartial: true,
      includeSystem: true
    });
  } catch {
    return messages.slice(-DEFAULT_FALLBACK_MESSAGE_COUNT);
  }
}

// node_modules/langchain/dist/agents/middleware/dynamicSystemPrompt.js
function dynamicSystemPromptMiddleware(fn) {
  return createMiddleware({
    name: "DynamicSystemPromptMiddleware",
    wrapModelCall: async (request, handler) => {
      const systemPrompt = await fn(request.state, request.runtime);
      const isExpectedType = typeof systemPrompt === "string" || SystemMessage.isInstance(systemPrompt);
      if (!isExpectedType) throw new Error("dynamicSystemPromptMiddleware function must return a string or SystemMessage");
      return handler({
        ...request,
        systemMessage: request.systemMessage.concat(systemPrompt)
      });
    }
  });
}

// node_modules/langchain/dist/agents/middleware/llmToolSelector.js
var DEFAULT_SYSTEM_PROMPT = "Your goal is to select the most relevant tools for answering the user's query.";
function createToolSelectionResponse(tools) {
  if (!tools || tools.length === 0) throw new Error("Invalid usage: tools must be non-empty");
  const toolLiterals = tools.map((tool2) => external_exports.literal(tool2.name));
  const toolEnum = external_exports.union(toolLiterals);
  return external_exports.object({ tools: external_exports.array(toolEnum).describe("Tools to use. Place the most relevant tools first.") });
}
var LLMToolSelectorOptionsSchema = external_exports.object({
  model: external_exports.string().or(external_exports.instanceof(BaseLanguageModel)).optional(),
  systemPrompt: external_exports.string().optional(),
  maxTools: external_exports.number().optional(),
  alwaysInclude: external_exports.array(external_exports.string()).optional()
});
function llmToolSelectorMiddleware(options) {
  return createMiddleware({
    name: "LLMToolSelector",
    contextSchema: LLMToolSelectorOptionsSchema,
    async wrapModelCall(request, handler) {
      const selectionRequest = await prepareSelectionRequest(request, options, request.runtime);
      if (!selectionRequest) return handler(request);
      const toolSelectionSchema = createToolSelectionResponse(selectionRequest.availableTools);
      const structuredModel = await selectionRequest.model.withStructuredOutput?.(toolSelectionSchema);
      const response = await structuredModel?.invoke([{
        role: "system",
        content: selectionRequest.systemMessage
      }, selectionRequest.lastUserMessage]);
      if (!response || typeof response !== "object" || !("tools" in response)) throw new Error(`Expected object response with tools array, got ${typeof response}`);
      return handler(processSelectionResponse(response, selectionRequest.availableTools, selectionRequest.validToolNames, request, options));
    }
  });
}
async function prepareSelectionRequest(request, options, runtime) {
  const model = runtime.context.model ?? options.model;
  const maxTools = runtime.context.maxTools ?? options.maxTools;
  const alwaysInclude = runtime.context.alwaysInclude ?? options.alwaysInclude ?? [];
  const systemPrompt = runtime.context.systemPrompt ?? options.systemPrompt ?? DEFAULT_SYSTEM_PROMPT;
  if (!request.tools || request.tools.length === 0) return void 0;
  const baseTools = request.tools.filter((tool2) => typeof tool2 === "object" && "name" in tool2 && "description" in tool2 && typeof tool2.name === "string");
  if (alwaysInclude.length > 0) {
    const availableToolNames = new Set(baseTools.map((tool2) => tool2.name));
    const missingTools = alwaysInclude.filter((name) => !availableToolNames.has(name));
    if (missingTools.length > 0) throw new Error(`Tools in alwaysInclude not found in request: ${missingTools.join(", ")}. Available tools: ${Array.from(availableToolNames).sort().join(", ")}`);
  }
  const availableTools = baseTools.filter((tool2) => !alwaysInclude.includes(tool2.name));
  if (availableTools.length === 0) return void 0;
  let systemMessage = systemPrompt;
  if (maxTools !== void 0) systemMessage += `
IMPORTANT: List the tool names in order of relevance, with the most relevant first. If you exceed the maximum number of tools, only the first ${maxTools} will be used.`;
  let lastUserMessage;
  for (const message of request.messages) if (HumanMessage.isInstance(message)) lastUserMessage = message;
  if (!lastUserMessage) throw new Error("No user message found in request messages");
  const modelInstance = !model ? request.model : typeof model === "string" ? await initChatModel(model) : model;
  const validToolNames = availableTools.map((tool2) => tool2.name);
  return {
    availableTools,
    systemMessage,
    lastUserMessage,
    model: modelInstance,
    validToolNames
  };
}
function processSelectionResponse(response, availableTools, validToolNames, request, options) {
  const maxTools = options.maxTools;
  const alwaysInclude = options.alwaysInclude ?? [];
  const selectedToolNames = [];
  const invalidToolSelections = [];
  for (const toolName of response.tools) {
    if (!validToolNames.includes(toolName)) {
      invalidToolSelections.push(toolName);
      continue;
    }
    if (!selectedToolNames.includes(toolName) && (maxTools === void 0 || selectedToolNames.length < maxTools)) selectedToolNames.push(toolName);
  }
  if (invalidToolSelections.length > 0) throw new Error(`Model selected invalid tools: ${invalidToolSelections.join(", ")}`);
  const selectedTools = availableTools.filter((tool2) => selectedToolNames.includes(tool2.name));
  const alwaysIncludedTools = (request.tools ?? []).filter((tool2) => typeof tool2 === "object" && "name" in tool2 && typeof tool2.name === "string" && alwaysInclude.includes(tool2.name));
  selectedTools.push(...alwaysIncludedTools);
  const providerTools = (request.tools ?? []).filter((tool2) => !(typeof tool2 === "object" && "name" in tool2 && "description" in tool2 && typeof tool2.name === "string"));
  return {
    ...request,
    tools: [...selectedTools, ...providerTools]
  };
}

// node_modules/langchain/dist/agents/middleware/pii.js
var PIIDetectionError = class extends Error {
  constructor(piiType, matches) {
    super(`PII detected: ${piiType} found ${matches.length} occurrence(s)`);
    this.piiType = piiType;
    this.matches = matches;
    this.name = "PIIDetectionError";
  }
};
var EMAIL_PATTERN = /\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}\b/g;
var CREDIT_CARD_PATTERN = /\b(?:\d{4}[-\s]?){3}\d{4}\b/g;
var IP_PATTERN = /\b(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\b/g;
var MAC_ADDRESS_PATTERN = /\b(?:[0-9A-Fa-f]{2}[:-]){5}(?:[0-9A-Fa-f]{2})\b/g;
var URL_PATTERN = /(?:https?:\/\/|www\.)[^\s<>"{}|\\^`[\]]+/gi;
function luhnCheck(cardNumber) {
  const digits = cardNumber.replace(/\D/g, "");
  let sum = 0;
  let isEven = false;
  for (let i = digits.length - 1; i >= 0; i--) {
    let digit = parseInt(digits[i], 10);
    if (isEven) {
      digit *= 2;
      if (digit > 9) digit -= 9;
    }
    sum += digit;
    isEven = !isEven;
  }
  return sum % 10 === 0;
}
function regexMatchToPIIMatch(match) {
  return {
    text: match[0],
    start: match.index ?? 0,
    end: (match.index ?? 0) + match[0].length
  };
}
function detectEmail(content) {
  const matches = [];
  const regex = new RegExp(EMAIL_PATTERN);
  let match;
  while ((match = regex.exec(content)) !== null) matches.push(regexMatchToPIIMatch(match));
  return matches;
}
function detectCreditCard(content) {
  const matches = [];
  const regex = new RegExp(CREDIT_CARD_PATTERN);
  let match;
  while ((match = regex.exec(content)) !== null) {
    const cardNumber = match[0].replace(/\D/g, "");
    if (cardNumber.length >= 13 && cardNumber.length <= 19 && luhnCheck(cardNumber)) matches.push(regexMatchToPIIMatch(match));
  }
  return matches;
}
function detectIP(content) {
  const matches = [];
  const regex = new RegExp(IP_PATTERN);
  let match;
  while ((match = regex.exec(content)) !== null) {
    const ip = match[0];
    const parts = ip.split(".");
    if (parts.length === 4 && parts.every((part) => {
      const num = parseInt(part, 10);
      return num >= 0 && num <= 255;
    })) matches.push(regexMatchToPIIMatch(match));
  }
  return matches;
}
function detectMacAddress(content) {
  const matches = [];
  const regex = new RegExp(MAC_ADDRESS_PATTERN);
  let match;
  while ((match = regex.exec(content)) !== null) matches.push(regexMatchToPIIMatch(match));
  return matches;
}
function detectUrl(content) {
  const matches = [];
  const regex = new RegExp(URL_PATTERN);
  let match;
  while ((match = regex.exec(content)) !== null) matches.push(regexMatchToPIIMatch(match));
  return matches;
}
var BUILT_IN_DETECTORS = {
  email: detectEmail,
  credit_card: detectCreditCard,
  ip: detectIP,
  mac_address: detectMacAddress,
  url: detectUrl
};
function resolveRedactionRule(config2) {
  let detector;
  if (config2.detector) if (typeof config2.detector === "string") {
    const regex = new RegExp(config2.detector, "g");
    detector = (content) => {
      const matches = [];
      let match;
      const regexCopy = new RegExp(regex);
      while ((match = regexCopy.exec(content)) !== null) matches.push(regexMatchToPIIMatch(match));
      return matches;
    };
  } else if (config2.detector instanceof RegExp) detector = (content) => {
    if (!(config2.detector instanceof RegExp)) throw new Error("Detector is required");
    const matches = [];
    let match;
    while ((match = config2.detector.exec(content)) !== null) matches.push(regexMatchToPIIMatch(match));
    return matches;
  };
  else detector = config2.detector;
  else {
    const builtInType = config2.piiType;
    if (!BUILT_IN_DETECTORS[builtInType]) throw new Error(`Unknown PII type: ${config2.piiType}. Must be one of: ${Object.keys(BUILT_IN_DETECTORS).join(", ")}, or provide a custom detector.`);
    detector = BUILT_IN_DETECTORS[builtInType];
  }
  return {
    piiType: config2.piiType,
    strategy: config2.strategy,
    detector
  };
}
function applyRedactStrategy(content, matches, piiType) {
  let result = content;
  for (let i = matches.length - 1; i >= 0; i--) {
    const match = matches[i];
    const replacement = `[REDACTED_${piiType.toUpperCase()}]`;
    result = result.slice(0, match.start) + replacement + result.slice(match.end);
  }
  return result;
}
function applyMaskStrategy(content, matches, piiType) {
  let result = content;
  for (let i = matches.length - 1; i >= 0; i--) {
    const match = matches[i];
    const text = match.text;
    let masked;
    if (piiType === "credit_card") {
      const digits = text.replace(/\D/g, "");
      const last4 = digits.slice(-4);
      masked = `****-****-****-${last4}`;
    } else if (piiType === "email") {
      const [local, domain] = text.split("@");
      if (local && domain) masked = `${local[0]}***@${domain}`;
      else masked = "***";
    } else {
      const visibleChars = Math.min(4, text.length);
      masked = `${"*".repeat(Math.max(0, text.length - visibleChars))}${text.slice(-visibleChars)}`;
    }
    result = result.slice(0, match.start) + masked + result.slice(match.end);
  }
  return result;
}
function applyHashStrategy(content, matches, piiType) {
  let result = content;
  for (let i = matches.length - 1; i >= 0; i--) {
    const match = matches[i];
    const hash2 = sha256(match.text).slice(0, 8);
    const replacement = `<${piiType}_hash:${hash2}>`;
    result = result.slice(0, match.start) + replacement + result.slice(match.end);
  }
  return result;
}
function applyStrategy(content, matches, strategy, piiType) {
  if (matches.length === 0) return content;
  switch (strategy) {
    case "block":
      throw new PIIDetectionError(piiType, matches);
    case "redact":
      return applyRedactStrategy(content, matches, piiType);
    case "mask":
      return applyMaskStrategy(content, matches, piiType);
    case "hash":
      return applyHashStrategy(content, matches, piiType);
    default:
      throw new Error(`Unknown strategy: ${strategy}`);
  }
}
var contextSchema3 = external_exports.object({
  applyToInput: external_exports.boolean().optional(),
  applyToOutput: external_exports.boolean().optional(),
  applyToToolResults: external_exports.boolean().optional()
});
function processContent(content, rule) {
  const matches = rule.detector(content);
  if (matches.length === 0) return {
    content,
    matches: []
  };
  const sanitized = applyStrategy(content, matches, rule.strategy, rule.piiType);
  return {
    content: sanitized,
    matches
  };
}
function piiMiddleware(piiType, options = {}) {
  const { strategy = "redact", detector } = options;
  const resolvedRule = resolveRedactionRule({
    piiType,
    strategy,
    detector
  });
  const middlewareName = `PIIMiddleware[${resolvedRule.piiType}]`;
  return createMiddleware({
    name: middlewareName,
    contextSchema: contextSchema3,
    beforeModel: async (state, runtime) => {
      const applyToInput = runtime.context.applyToInput ?? options.applyToInput ?? true;
      const applyToToolResults = runtime.context.applyToToolResults ?? options.applyToToolResults ?? false;
      if (!applyToInput && !applyToToolResults) return;
      const messages = state.messages;
      if (!messages || messages.length === 0) return;
      const newMessages = [...messages];
      let anyModified = false;
      if (applyToInput) {
        let lastUserIdx = null;
        for (let i = messages.length - 1; i >= 0; i--) if (HumanMessage.isInstance(messages[i])) {
          lastUserIdx = i;
          break;
        }
        if (lastUserIdx !== null) {
          const lastUserMsg = messages[lastUserIdx];
          if (lastUserMsg && lastUserMsg.content) {
            const content = String(lastUserMsg.content);
            const { content: newContent, matches } = processContent(content, resolvedRule);
            if (matches.length > 0) {
              newMessages[lastUserIdx] = new HumanMessage({
                content: newContent,
                id: lastUserMsg.id,
                name: lastUserMsg.name
              });
              anyModified = true;
            }
          }
        }
      }
      if (applyToToolResults) {
        let lastAiIdx = null;
        for (let i = messages.length - 1; i >= 0; i--) if (AIMessage.isInstance(messages[i])) {
          lastAiIdx = i;
          break;
        }
        if (lastAiIdx !== null) for (let i = lastAiIdx + 1; i < messages.length; i++) {
          const msg = messages[i];
          if (ToolMessage.isInstance(msg)) {
            if (!msg.content) continue;
            const content = String(msg.content);
            const { content: newContent, matches } = processContent(content, resolvedRule);
            if (matches.length > 0) {
              newMessages[i] = new ToolMessage({
                content: newContent,
                id: msg.id,
                name: msg.name,
                tool_call_id: msg.tool_call_id
              });
              anyModified = true;
            }
          }
        }
      }
      if (anyModified) return { messages: newMessages };
    },
    afterModel: async (state, runtime) => {
      const applyToOutput = runtime.context.applyToOutput ?? options.applyToOutput ?? false;
      if (!applyToOutput) return;
      const messages = state.messages;
      if (!messages || messages.length === 0) return;
      let lastAiIdx = null;
      let lastAiMsg = null;
      for (let i = messages.length - 1; i >= 0; i--) if (AIMessage.isInstance(messages[i])) {
        lastAiMsg = messages[i];
        lastAiIdx = i;
        break;
      }
      if (lastAiIdx === null || !lastAiMsg || !lastAiMsg.content) return;
      const content = String(lastAiMsg.content);
      const { content: newContent, matches } = processContent(content, resolvedRule);
      if (matches.length === 0) return;
      const updatedMessage = new AIMessage({
        content: newContent,
        id: lastAiMsg.id,
        name: lastAiMsg.name,
        tool_calls: lastAiMsg.tool_calls
      });
      const newMessages = [...messages];
      newMessages[lastAiIdx] = updatedMessage;
      return { messages: newMessages };
    }
  });
}

// node_modules/langchain/dist/agents/middleware/piiRedaction.js
var contextSchema4 = external_exports.object({ rules: external_exports.record(external_exports.string(), external_exports.instanceof(RegExp).describe("Regular expression pattern to match PII")).optional() });
function generateRedactionId() {
  return Math.random().toString(36).substring(2, 11);
}
function applyPIIRules(text, rules, redactionMap) {
  let processedText = text;
  for (const [name, pattern] of Object.entries(rules)) {
    const replacement = name.toUpperCase().replace(/[^a-zA-Z0-9_-]/g, "");
    processedText = processedText.replace(pattern, (match) => {
      const id = generateRedactionId();
      redactionMap[id] = match;
      return `[REDACTED_${replacement}_${id}]`;
    });
  }
  return processedText;
}
async function processMessage(message, config2) {
  if (HumanMessage.isInstance(message) || ToolMessage.isInstance(message) || SystemMessage.isInstance(message)) {
    const content = message.content;
    const processedContent = await applyPIIRules(content, config2.rules, config2.redactionMap);
    if (processedContent !== content) {
      const MessageConstructor = Object.getPrototypeOf(message).constructor;
      return new MessageConstructor({
        ...message,
        content: processedContent
      });
    }
    return message;
  }
  if (AIMessage.isInstance(message)) {
    const content = typeof message.content === "string" ? message.content : JSON.stringify(message.content);
    const toolCalls = JSON.stringify(message.tool_calls);
    const processedContent = await applyPIIRules(content, config2.rules, config2.redactionMap);
    const processedToolCalls = await applyPIIRules(toolCalls, config2.rules, config2.redactionMap);
    if (processedContent !== content || processedToolCalls !== toolCalls) return new AIMessage({
      ...message,
      content: typeof message.content === "string" ? processedContent : JSON.parse(processedContent),
      tool_calls: JSON.parse(processedToolCalls)
    });
    return message;
  }
  throw new Error(`Unsupported message type: ${message.type}`);
}
function restoreRedactedValues(text, redactionMap) {
  let restoredText = text;
  const redactionPattern = /\[REDACTED_[A-Z_]+_(\w+)\]/g;
  restoredText = restoredText.replace(redactionPattern, (match, id) => {
    if (redactionMap[id]) return redactionMap[id];
    return match;
  });
  return restoredText;
}
function restoreMessage(message, redactionMap) {
  if (HumanMessage.isInstance(message) || ToolMessage.isInstance(message) || SystemMessage.isInstance(message)) {
    const content = message.content;
    const restoredContent = restoreRedactedValues(content, redactionMap);
    if (restoredContent !== content) {
      const MessageConstructor = Object.getPrototypeOf(message).constructor;
      const newMessage2 = new MessageConstructor({
        ...message,
        content: restoredContent
      });
      return {
        message: newMessage2,
        changed: true
      };
    }
    return {
      message,
      changed: false
    };
  }
  if (AIMessage.isInstance(message)) {
    const content = typeof message.content === "string" ? message.content : JSON.stringify(message.content);
    const toolCalls = JSON.stringify(message.tool_calls);
    const processedContent = restoreRedactedValues(content, redactionMap);
    const processedToolCalls = restoreRedactedValues(toolCalls, redactionMap);
    if (processedContent !== content || processedToolCalls !== toolCalls) return {
      message: new AIMessage({
        ...message,
        content: typeof message.content === "string" ? processedContent : JSON.parse(processedContent),
        tool_calls: JSON.parse(processedToolCalls)
      }),
      changed: true
    };
    return {
      message,
      changed: false
    };
  }
  throw new Error(`Unsupported message type: ${message.type}`);
}
function piiRedactionMiddleware(options = {}) {
  const redactionMap = {};
  console.warn("DEPRECATED: piiRedactionMiddleware is deprecated. Please use piiMiddleware instead, go to https://docs.langchain.com/oss/javascript/langchain/middleware/built-in#pii-detection for more information.");
  return createMiddleware({
    name: "PIIRedactionMiddleware",
    contextSchema: contextSchema4,
    wrapModelCall: async (request, handler) => {
      const rules = request.runtime.context.rules ?? options.rules ?? {};
      if (Object.keys(rules).length === 0) return handler(request);
      const processedMessages = await Promise.all(request.state.messages.map((message) => processMessage(message, {
        rules,
        redactionMap
      })));
      return handler({
        ...request,
        messages: processedMessages
      });
    },
    afterModel: async (state) => {
      if (Object.keys(redactionMap).length === 0) return;
      const lastMessage = state.messages.at(-1);
      if (!AIMessage.isInstance(lastMessage)) return;
      const secondLastMessage = state.messages.at(-2);
      const { message: restoredLastMessage, changed } = restoreMessage(lastMessage, redactionMap);
      if (!changed) return;
      let structuredResponse;
      if (AIMessage.isInstance(lastMessage) && lastMessage?.tool_calls?.length === 0 && typeof lastMessage.content === "string" && lastMessage.content.startsWith("{") && lastMessage.content.endsWith("}")) try {
        structuredResponse = JSON.parse(restoreRedactedValues(lastMessage.content, redactionMap));
      } catch {
      }
      const isStructuredResponseToolCall = AIMessage.isInstance(secondLastMessage) && secondLastMessage?.tool_calls?.length !== 0 && secondLastMessage?.tool_calls?.some((call3) => call3.name.startsWith("extract-"));
      if (isStructuredResponseToolCall) {
        const { message: restoredSecondLastMessage, changed: changedSecondLastMessage } = restoreMessage(secondLastMessage, redactionMap);
        const structuredResponseRedacted = secondLastMessage.tool_calls?.find((call3) => call3.name.startsWith("extract-"))?.args;
        const structuredResponse$1 = structuredResponseRedacted ? JSON.parse(restoreRedactedValues(JSON.stringify(structuredResponseRedacted), redactionMap)) : void 0;
        if (changed || changedSecondLastMessage) return {
          ...state,
          ...structuredResponse$1 ? { structuredResponse: structuredResponse$1 } : {},
          messages: [
            new RemoveMessage({ id: secondLastMessage.id }),
            new RemoveMessage({ id: lastMessage.id }),
            restoredSecondLastMessage,
            restoredLastMessage
          ]
        };
      }
      return {
        ...state,
        ...structuredResponse ? { structuredResponse } : {},
        messages: [new RemoveMessage({ id: lastMessage.id }), restoredLastMessage]
      };
    }
  });
}

// node_modules/langchain/dist/agents/middleware/contextEditing.js
var DEFAULT_TOOL_PLACEHOLDER = "[cleared]";
var DEFAULT_TRIGGER_TOKENS = 1e5;
var DEFAULT_KEEP = 3;
var ClearToolUsesEdit = class {
  #triggerConditions;
  trigger;
  keep;
  clearToolInputs;
  excludeTools;
  placeholder;
  model;
  clearAtLeast;
  constructor(config2 = {}) {
    let trigger = config2.trigger;
    if (config2.triggerTokens !== void 0) {
      console.warn("triggerTokens is deprecated. Use `trigger: { tokens: value }` instead.");
      if (trigger === void 0) trigger = { tokens: config2.triggerTokens };
    }
    let keep = config2.keep;
    if (config2.keepMessages !== void 0) {
      console.warn("keepMessages is deprecated. Use `keep: { messages: value }` instead.");
      if (keep === void 0) keep = { messages: config2.keepMessages };
    }
    if (trigger === void 0) trigger = { tokens: DEFAULT_TRIGGER_TOKENS };
    if (keep === void 0) keep = { messages: DEFAULT_KEEP };
    if (Array.isArray(trigger)) {
      this.#triggerConditions = trigger.map((t) => contextSizeSchema.parse(t));
      this.trigger = this.#triggerConditions;
    } else {
      const validated = contextSizeSchema.parse(trigger);
      this.#triggerConditions = [validated];
      this.trigger = validated;
    }
    const validatedKeep = keepSchema.parse(keep);
    this.keep = validatedKeep;
    if (config2.clearAtLeast !== void 0) console.warn("clearAtLeast is deprecated and will be removed in a future version. It conflicts with the `keep` property. Use `keep: { tokens: value }` or `keep: { messages: value }` instead to control retention.");
    this.clearAtLeast = config2.clearAtLeast ?? 0;
    this.clearToolInputs = config2.clearToolInputs ?? false;
    this.excludeTools = new Set(config2.excludeTools ?? []);
    this.placeholder = config2.placeholder ?? DEFAULT_TOOL_PLACEHOLDER;
  }
  async apply(params) {
    const { messages, model, countTokens } = params;
    const tokens = await countTokens(messages);
    const orphanedIndices = [];
    for (let i = 0; i < messages.length; i++) {
      const msg = messages[i];
      if (ToolMessage.isInstance(msg)) {
        const aiMessage = this.#findAIMessageForToolCall(messages.slice(0, i), msg.tool_call_id);
        if (!aiMessage) orphanedIndices.push(i);
        else {
          const toolCall = aiMessage.tool_calls?.find((call3) => call3.id === msg.tool_call_id);
          if (!toolCall) orphanedIndices.push(i);
        }
      }
    }
    for (let i = orphanedIndices.length - 1; i >= 0; i--) messages.splice(orphanedIndices[i], 1);
    let currentTokens = tokens;
    if (orphanedIndices.length > 0) currentTokens = await countTokens(messages);
    if (!this.#shouldEdit(messages, currentTokens, model)) return;
    const candidates = [];
    for (let i = 0; i < messages.length; i++) {
      const msg = messages[i];
      if (ToolMessage.isInstance(msg)) candidates.push({
        idx: i,
        msg
      });
    }
    if (candidates.length === 0) return;
    const keepCount = await this.#determineKeepCount(candidates, countTokens, model);
    const candidatesToClear = keepCount >= candidates.length ? [] : keepCount > 0 ? candidates.slice(0, -keepCount) : candidates;
    let clearedTokens = 0;
    const initialCandidatesToClear = [...candidatesToClear];
    for (const { idx, msg: toolMessage } of initialCandidatesToClear) {
      const contextEditing = toolMessage.response_metadata?.context_editing;
      if (contextEditing?.cleared) continue;
      const aiMessage = this.#findAIMessageForToolCall(messages.slice(0, idx), toolMessage.tool_call_id);
      if (!aiMessage) continue;
      const toolCall = aiMessage.tool_calls?.find((call3) => call3.id === toolMessage.tool_call_id);
      if (!toolCall) continue;
      const toolName = toolMessage.name || toolCall.name;
      if (this.excludeTools.has(toolName)) continue;
      messages[idx] = new ToolMessage({
        tool_call_id: toolMessage.tool_call_id,
        content: this.placeholder,
        name: toolMessage.name,
        artifact: void 0,
        response_metadata: {
          ...toolMessage.response_metadata,
          context_editing: {
            cleared: true,
            strategy: "clear_tool_uses"
          }
        }
      });
      if (this.clearToolInputs) {
        const aiMsgIdx = messages.indexOf(aiMessage);
        if (aiMsgIdx >= 0) messages[aiMsgIdx] = this.#buildClearedToolInputMessage(aiMessage, toolMessage.tool_call_id);
      }
      const newTokenCount = await countTokens(messages);
      clearedTokens = Math.max(0, currentTokens - newTokenCount);
    }
    if (this.clearAtLeast > 0 && clearedTokens < this.clearAtLeast) {
      const remainingCandidates = keepCount > 0 && keepCount < candidates.length ? candidates.slice(-keepCount) : [];
      for (let i = remainingCandidates.length - 1; i >= 0; i--) {
        if (clearedTokens >= this.clearAtLeast) break;
        const { idx, msg: toolMessage } = remainingCandidates[i];
        const contextEditing = toolMessage.response_metadata?.context_editing;
        if (contextEditing?.cleared) continue;
        const aiMessage = this.#findAIMessageForToolCall(messages.slice(0, idx), toolMessage.tool_call_id);
        if (!aiMessage) continue;
        const toolCall = aiMessage.tool_calls?.find((call3) => call3.id === toolMessage.tool_call_id);
        if (!toolCall) continue;
        const toolName = toolMessage.name || toolCall.name;
        if (this.excludeTools.has(toolName)) continue;
        messages[idx] = new ToolMessage({
          tool_call_id: toolMessage.tool_call_id,
          content: this.placeholder,
          name: toolMessage.name,
          artifact: void 0,
          response_metadata: {
            ...toolMessage.response_metadata,
            context_editing: {
              cleared: true,
              strategy: "clear_tool_uses"
            }
          }
        });
        if (this.clearToolInputs) {
          const aiMsgIdx = messages.indexOf(aiMessage);
          if (aiMsgIdx >= 0) messages[aiMsgIdx] = this.#buildClearedToolInputMessage(aiMessage, toolMessage.tool_call_id);
        }
        const newTokenCount = await countTokens(messages);
        clearedTokens = Math.max(0, currentTokens - newTokenCount);
      }
    }
  }
  /**
  * Determine whether editing should run for the current token usage
  */
  #shouldEdit(messages, totalTokens, model) {
    for (const trigger of this.#triggerConditions) {
      let conditionMet = true;
      let hasAnyProperty = false;
      if (trigger.messages !== void 0) {
        hasAnyProperty = true;
        if (messages.length < trigger.messages) conditionMet = false;
      }
      if (trigger.tokens !== void 0) {
        hasAnyProperty = true;
        if (totalTokens < trigger.tokens) conditionMet = false;
      }
      if (trigger.fraction !== void 0) {
        hasAnyProperty = true;
        if (!model) continue;
        const maxInputTokens = getProfileLimits(model);
        if (typeof maxInputTokens === "number") {
          const threshold = Math.floor(maxInputTokens * trigger.fraction);
          if (threshold <= 0) continue;
          if (totalTokens < threshold) conditionMet = false;
        } else
          continue;
      }
      if (hasAnyProperty && conditionMet) return true;
    }
    return false;
  }
  /**
  * Determine how many tool results to keep based on keep policy
  */
  async #determineKeepCount(candidates, countTokens, model) {
    if ("messages" in this.keep && this.keep.messages !== void 0) return this.keep.messages;
    if ("tokens" in this.keep && this.keep.tokens !== void 0) {
      const targetTokens = this.keep.tokens;
      let tokenCount = 0;
      let keepCount = 0;
      for (let i = candidates.length - 1; i >= 0; i--) {
        const candidate = candidates[i];
        const msgTokens = await countTokens([candidate.msg]);
        if (tokenCount + msgTokens <= targetTokens) {
          tokenCount += msgTokens;
          keepCount++;
        } else break;
      }
      return keepCount;
    }
    if ("fraction" in this.keep && this.keep.fraction !== void 0) {
      if (!model) return DEFAULT_KEEP;
      const maxInputTokens = getProfileLimits(model);
      if (typeof maxInputTokens === "number") {
        const targetTokens = Math.floor(maxInputTokens * this.keep.fraction);
        if (targetTokens <= 0) return DEFAULT_KEEP;
        let tokenCount = 0;
        let keepCount = 0;
        for (let i = candidates.length - 1; i >= 0; i--) {
          const candidate = candidates[i];
          const msgTokens = await countTokens([candidate.msg]);
          if (tokenCount + msgTokens <= targetTokens) {
            tokenCount += msgTokens;
            keepCount++;
          } else break;
        }
        return keepCount;
      }
    }
    return DEFAULT_KEEP;
  }
  #findAIMessageForToolCall(previousMessages, toolCallId) {
    for (let i = previousMessages.length - 1; i >= 0; i--) {
      const msg = previousMessages[i];
      if (AIMessage.isInstance(msg)) {
        const hasToolCall = msg.tool_calls?.some((call3) => call3.id === toolCallId);
        if (hasToolCall) return msg;
      }
    }
    return null;
  }
  #buildClearedToolInputMessage(message, toolCallId) {
    const updatedToolCalls = message.tool_calls?.map((toolCall) => {
      if (toolCall.id === toolCallId) return {
        ...toolCall,
        args: {}
      };
      return toolCall;
    });
    const metadata = { ...message.response_metadata };
    const contextEntry = { ...metadata.context_editing };
    const clearedIds = new Set(contextEntry.cleared_tool_inputs);
    clearedIds.add(toolCallId);
    contextEntry.cleared_tool_inputs = Array.from(clearedIds).sort();
    metadata.context_editing = contextEntry;
    return new AIMessage({
      content: message.content,
      tool_calls: updatedToolCalls,
      response_metadata: metadata,
      id: message.id,
      name: message.name,
      additional_kwargs: message.additional_kwargs
    });
  }
};
function contextEditingMiddleware(config2 = {}) {
  const edits = config2.edits ?? [new ClearToolUsesEdit()];
  const tokenCountMethod = config2.tokenCountMethod ?? "approx";
  return createMiddleware({
    name: "ContextEditingMiddleware",
    wrapModelCall: async (request, handler) => {
      if (!request.messages || request.messages.length === 0) return handler(request);
      const systemMsg = request.systemPrompt ? [new SystemMessage(request.systemPrompt)] : [];
      const countTokens = tokenCountMethod === "approx" ? countTokensApproximately : async (messages) => {
        const allMessages = [...systemMsg, ...messages];
        if ("getNumTokensFromMessages" in request.model) return request.model.getNumTokensFromMessages(allMessages).then(({ totalCount }) => totalCount);
        throw new Error(`Model "${request.model.getName()}" does not support token counting`);
      };
      for (const edit of edits) await edit.apply({
        messages: request.messages,
        model: request.model,
        countTokens
      });
      return handler(request);
    }
  });
}

// node_modules/langchain/dist/agents/middleware/toolCallLimit.js
function buildToolMessageContent(toolName) {
  if (toolName) return `Tool call limit exceeded. Do not call '${toolName}' again.`;
  return "Tool call limit exceeded. Do not make additional tool calls.";
}
var VALID_EXIT_BEHAVIORS = [
  "continue",
  "error",
  "end"
];
var DEFAULT_EXIT_BEHAVIOR = "continue";
function buildFinalAIMessageContent(threadCount, runCount, threadLimit, runLimit, toolName) {
  const toolDesc = toolName ? `'${toolName}' tool` : "Tool";
  const exceededLimits = [];
  if (threadLimit !== void 0 && threadCount > threadLimit) exceededLimits.push(`thread limit exceeded (${threadCount}/${threadLimit} calls)`);
  if (runLimit !== void 0 && runCount > runLimit) exceededLimits.push(`run limit exceeded (${runCount}/${runLimit} calls)`);
  const limitsText = exceededLimits.join(" and ");
  return `${toolDesc} call limit reached: ${limitsText}.`;
}
var exitBehaviorSchema = external_exports.enum(VALID_EXIT_BEHAVIORS).default(DEFAULT_EXIT_BEHAVIOR);
var ToolCallLimitExceededError = class extends Error {
  /**
  * Current thread tool call count.
  */
  threadCount;
  /**
  * Current run tool call count.
  */
  runCount;
  /**
  * Thread tool call limit (if set).
  */
  threadLimit;
  /**
  * Run tool call limit (if set).
  */
  runLimit;
  /**
  * Tool name being limited (if specific tool), or undefined for all tools.
  */
  toolName;
  constructor(threadCount, runCount, threadLimit, runLimit, toolName = void 0) {
    const message = buildFinalAIMessageContent(threadCount, runCount, threadLimit, runLimit, toolName);
    super(message);
    this.name = "ToolCallLimitExceededError";
    this.threadCount = threadCount;
    this.runCount = runCount;
    this.threadLimit = threadLimit;
    this.runLimit = runLimit;
    this.toolName = toolName;
  }
};
var ToolCallLimitOptionsSchema = external_exports.object({
  toolName: external_exports.string().optional(),
  threadLimit: external_exports.number().optional(),
  runLimit: external_exports.number().optional(),
  exitBehavior: exitBehaviorSchema
});
var stateSchema = external_exports.object({
  threadToolCallCount: external_exports.record(external_exports.string(), external_exports.number()).default({}),
  runToolCallCount: external_exports.record(external_exports.string(), external_exports.number()).default({})
});
var DEFAULT_TOOL_COUNT_KEY = "__all__";
function toolCallLimitMiddleware(options) {
  if (options.threadLimit === void 0 && options.runLimit === void 0) throw new Error("At least one limit must be specified (threadLimit or runLimit)");
  const exitBehavior = options.exitBehavior ?? DEFAULT_EXIT_BEHAVIOR;
  const parseResult = exitBehaviorSchema.safeParse(exitBehavior);
  if (!parseResult.success) throw new Error(external_exports2.prettifyError(parseResult.error).slice(2));
  if (options.threadLimit !== void 0 && options.runLimit !== void 0 && options.runLimit > options.threadLimit) throw new Error(`runLimit (${options.runLimit}) cannot exceed threadLimit (${options.threadLimit}). The run limit should be less than or equal to the thread limit.`);
  const middlewareName = options.toolName ? `ToolCallLimitMiddleware[${options.toolName}]` : "ToolCallLimitMiddleware";
  return createMiddleware({
    name: middlewareName,
    stateSchema,
    afterModel: {
      canJumpTo: ["end"],
      hook: (state) => {
        const lastAIMessage = [...state.messages].reverse().find(AIMessage.isInstance);
        if (!lastAIMessage || !lastAIMessage.tool_calls) return void 0;
        const wouldExceedLimit = (threadCount, runCount) => {
          return options.threadLimit !== void 0 && threadCount + 1 > options.threadLimit || options.runLimit !== void 0 && runCount + 1 > options.runLimit;
        };
        const matchesToolFilter = (toolCall) => {
          return options.toolName === void 0 || toolCall.name === options.toolName;
        };
        const separateToolCalls = (toolCalls, threadCount, runCount) => {
          const allowed$1 = [];
          const blocked$1 = [];
          let tempThreadCount = threadCount;
          let tempRunCount = runCount;
          for (const toolCall of toolCalls) {
            if (!matchesToolFilter(toolCall)) continue;
            if (wouldExceedLimit(tempThreadCount, tempRunCount)) blocked$1.push(toolCall);
            else {
              allowed$1.push(toolCall);
              tempThreadCount += 1;
              tempRunCount += 1;
            }
          }
          return {
            allowed: allowed$1,
            blocked: blocked$1,
            finalThreadCount: tempThreadCount,
            finalRunCount: tempRunCount + blocked$1.length
          };
        };
        const countKey = options.toolName ?? DEFAULT_TOOL_COUNT_KEY;
        const threadCounts = { ...state.threadToolCallCount ?? {} };
        const runCounts = { ...state.runToolCallCount ?? {} };
        const currentThreadCount = threadCounts[countKey] ?? 0;
        const currentRunCount = runCounts[countKey] ?? 0;
        const { allowed, blocked, finalThreadCount, finalRunCount } = separateToolCalls(lastAIMessage.tool_calls, currentThreadCount, currentRunCount);
        threadCounts[countKey] = finalThreadCount;
        runCounts[countKey] = finalRunCount;
        if (blocked.length === 0) {
          if (allowed.length > 0) return {
            threadToolCallCount: threadCounts,
            runToolCallCount: runCounts
          };
          return void 0;
        }
        if (exitBehavior === "error") {
          const hypotheticalThreadCount = finalThreadCount + blocked.length;
          throw new ToolCallLimitExceededError(hypotheticalThreadCount, finalRunCount, options.threadLimit, options.runLimit, options.toolName);
        }
        const toolMsgContent = buildToolMessageContent(options.toolName);
        const artificialMessages = blocked.map((toolCall) => new ToolMessage({
          content: toolMsgContent,
          tool_call_id: toolCall.id,
          name: toolCall.name,
          status: "error"
        }));
        if (exitBehavior === "end") {
          let otherTools = [];
          if (options.toolName !== void 0)
            otherTools = lastAIMessage.tool_calls.filter((tc) => tc.name !== options.toolName);
          else {
            const uniqueToolNames = new Set(lastAIMessage.tool_calls.map((tc) => tc.name).filter(Boolean));
            if (uniqueToolNames.size > 1)
              otherTools = allowed.length > 0 ? allowed : lastAIMessage.tool_calls;
          }
          if (otherTools.length > 0) {
            const toolNames = Array.from(new Set(otherTools.map((tc) => tc.name).filter(Boolean))).join(", ");
            throw new Error(`Cannot end execution with other tool calls pending. Found calls to: ${toolNames}. Use 'continue' or 'error' behavior instead.`);
          }
          const hypotheticalThreadCount = finalThreadCount + blocked.length;
          const finalMsgContent = buildFinalAIMessageContent(hypotheticalThreadCount, finalRunCount, options.threadLimit, options.runLimit, options.toolName);
          artificialMessages.push(new AIMessage(finalMsgContent));
          return {
            threadToolCallCount: threadCounts,
            runToolCallCount: runCounts,
            jumpTo: "end",
            messages: artificialMessages
          };
        }
        return {
          threadToolCallCount: threadCounts,
          runToolCallCount: runCounts,
          messages: artificialMessages
        };
      }
    },
    afterAgent: () => ({ runToolCallCount: {} })
  });
}

// node_modules/langchain/dist/agents/middleware/todoListMiddleware.js
var WRITE_TODOS_DESCRIPTION = `Use this tool to create and manage a structured task list for your current work session. This helps you track progress, organize complex tasks, and demonstrate thoroughness to the user.
It also helps the user understand the progress of the task and overall progress of their requests.
Only use this tool if you think it will be helpful in staying organized. If the user's request is trivial and takes less than 3 steps, it is better to NOT use this tool and just do the taks directly.

## When to Use This Tool
Use this tool in these scenarios:

1. Complex multi-step tasks - When a task requires 3 or more distinct steps or actions
2. Non-trivial and complex tasks - Tasks that require careful planning or multiple operations
3. User explicitly requests todo list - When the user directly asks you to use the todo list
4. User provides multiple tasks - When users provide a list of things to be done (numbered or comma-separated)
5. The plan may need future revisions or updates based on results from the first few steps. Keeping track of this in a list is helpful.

## How to Use This Tool
1. When you start working on a task - Mark it as in_progress BEFORE beginning work.
2. After completing a task - Mark it as completed and add any new follow-up tasks discovered during implementation.
3. You can also update future tasks, such as deleting them if they are no longer necessary, or adding new tasks that are necessary. Don't change previously completed tasks.
4. You can make several updates to the todo list at once. For example, when you complete a task, you can mark the next task you need to start as in_progress.

## When NOT to Use This Tool
It is important to skip using this tool when:
1. There is only a single, straightforward task
2. The task is trivial and tracking it provides no benefit
3. The task can be completed in less than 3 trivial steps
4. The task is purely conversational or informational

## Examples of When to Use the Todo List

<example>
User: I want to add a dark mode toggle to the application settings. Make sure you run the tests and build when you're done!
Assistant: I'll help add a dark mode toggle to your application settings. Let me create a todo list to track this implementation.
*Creates todo list with the following items:*
1. Create dark mode toggle component in Settings page
2. Add dark mode state management (context/store)
3. Implement CSS-in-JS styles for dark theme
4. Update existing components to support theme switching
5. Run tests and build process, addressing any failures or errors that occur
*Begins working on the first task*

<reasoning>
The assistant used the todo list because:
1. Adding dark mode in it of itself is a multi-step feature requiring UI, state management, and styling changes
2. The assistant inferred that tests and build need to pass by adding "Ensure tests and build succeed" as the final task
3. Both of the user's requests are complex and require multiple steps to complete.
</reasoning>
</example>

<example>
User: Help me plan a comprehensive marketing campaign for our new product launch, including social media, email marketing, and press releases.
Assistant: I'll help you plan a comprehensive marketing campaign for your product launch. Let me create a todo list to organize all the components.
*Creates todo list with the following items:*
1. Define target audience and key messaging
2. Create social media content calendar and posting schedule
3. Design email marketing sequence and automation flows
4. Draft press release and identify media contacts
5. Set up tracking and analytics for campaign performance
6. Create visual assets and brand materials
7. Coordinate launch timeline and deliverables
*Begins working on the first task*

<reasoning>
The assistant used the todo list because:
1. Marketing campaign planning involves multiple distinct channels and activities
2. Each component requires careful coordination and planning
3. The systematic approach ensures all aspects of the launch are covered
</reasoning>
</example>

<example>
User: Help me rename the function getCwd to getCurrentWorkingDirectory across my project
Assistant: Let me first search through your codebase to find all occurrences of 'getCwd'.
*Uses search tools to locate all instances of getCwd in the codebase*
Assistant: I've found 15 instances of 'getCwd' across 8 different files. Let me create a todo list to track these changes.
*Creates todo list with specific items for each file that needs updating*

<reasoning>
The assistant used the todo list because:
1. The assistant searched to understand the scope of the task
2. Upon finding multiple occurrences across different files, it determined this was a complex task with multiple steps (>3)
3. The todo list helps ensure every instance is tracked and updated systematically
4. This approach prevents missing any occurrences and maintains consistency.
</reasoning>
</example>

<example>
User: I need help organizing my home office: decluttering the desk, setting up a filing system, organizing digital files, and creating a daily workflow.
Assistant: I'll help you organize your home office systematically. Let me create a todo list to track each area of organization.
*Creates todo list with items like: 1) Sort and declutter desk items, 2) Set up physical filing system for documents, 3) Organize digital files and folders, 4) Create daily workflow and productivity systems, 5) Establish maintenance routines*
Let's start with decluttering your desk space to create a clean foundation for the other organizational systems.

<reasoning>
The assistant used the todo list because:
1. The user provided multiple distinct organizational tasks
2. Each area requires different approaches and careful planning
3. Home organization benefits from systematic, step-by-step completion
4. Progress tracking ensures all areas are addressed thoroughly
</reasoning>
</example>

## Examples of When NOT to Use the Todo List

<example>
User: How do I print 'Hello World' in Python?
Assistant: In Python, you can print "Hello World" with this simple code:

\`\`\`python
print("Hello World")
\`\`\`

This will output the text "Hello World" to the console when executed.</assistant>

<reasoning>
The assistant did not use the todo list because this is a single, trivial task that can be completed in one step. There's no need to track multiple tasks or steps for such a straightforward request.
</reasoning>
</example>

<example>
User: What's the best way to water houseplants?
Assistant: The best way to water houseplants depends on the specific plant type, but here are some general guidelines:

- Check soil moisture by inserting your finger about 1-2 inches into the soil
- Water thoroughly when the top inch feels dry, allowing water to drain from the bottom
- Use room temperature water and water in the morning when possible
- Avoid overwatering, which is more harmful than underwatering for most plants

Different plants have different needs, so it's important to research your specific varieties for optimal care.

<reasoning>
The assistant did not use the todo list because this is an informational request with no actual tasks to complete. The user is simply asking for advice and explanation, not for the assistant to perform multiple steps or activities.
</reasoning>
</example>

<example>
User: Can you add a comment to the calculateTotal function to explain what it does?
Assistant: Sure, let me add a comment to the calculateTotal function to explain what it does.
* Uses the Edit tool to add a comment to the calculateTotal function *

<reasoning>
The assistant did not use the todo list because this is a single, straightforward task confined to one location. Adding a comment doesn't require tracking multiple steps or systematic organization.
</reasoning>
</example>

<example>
User: What time is it in Tokyo right now?
Assistant: I'll check the current time in Tokyo for you.

*Searches for current time in Tokyo*

The current time in Tokyo, Japan is [current time]. Tokyo is in the Japan Standard Time (JST) zone, which is UTC+9.

<reasoning>
The assistant did not use the todo list because this is a single information lookup with immediate results. There are no multiple steps to track or organize, making the todo list unnecessary for this straightforward request.
</reasoning>
</example>

<example>
User: I need to write a function that checks if a number is prime and then test it out.
Assistant: I'll help you write a function that checks if a number is prime and then test it out.
*Writes function that checks if a number is prime*
*Tests the function*

<reasoning>
Even though this is a multi-step task, it is very straightforward and can be completed in two trivial steps (which is less than 3 steps!). Using the todo list here is overkill and wastes time and tokens.
</reasoning>
</example>

<example>
User: I want you to order a pizza from Dominos, order a burger from McDonald's, and order a salad from Subway.
Assistant: I'll help you order a pizza from Dominos, order a burger from McDonald's, and order a salad from Subway.
*Orders a pizza from Dominos*
*Orders a burger from McDonald's*
*Orders a salad from Subway*

<reasoning>
Even though this is a multi-step task, assuming the assistant has the ability to order from these restaurants, it is very straightforward and can be completed in three trivial tool calls. 
Using the todo list here is overkill and wastes time and tokens. These three tool calls should be made in parallel, in fact.
</reasoning>
</example>


## Task States and Management

1. **Task States**: Use these states to track progress:
   - pending: Task not yet started
   - in_progress: Currently working on (you can have multiple tasks in_progress at a time if they are not related to each other and can be run in parallel)
   - completed: Task finished successfully

2. **Task Management**:
   - Update task status in real-time as you work
   - Mark tasks complete IMMEDIATELY after finishing (don't batch completions)
   - Complete current tasks before starting new ones
   - Remove tasks that are no longer relevant from the list entirely
   - IMPORTANT: When you write this todo list, you should mark your first task (or tasks) as in_progress immediately!.
   - IMPORTANT: Unless all tasks are completed, you should always have at least one task in_progress to show the user that you are working on something.

3. **Task Completion Requirements**:
   - ONLY mark a task as completed when you have FULLY accomplished it
   - If you encounter errors, blockers, or cannot finish, keep the task as in_progress
   - When blocked, create a new task describing what needs to be resolved
   - Never mark a task as completed if:
     - There are unresolved issues or errors
     - Work is partial or incomplete
     - You encountered blockers that prevent completion
     - You couldn't find necessary resources or dependencies
     - Quality standards haven't been met

4. **Task Breakdown**:
   - Create specific, actionable items
   - Break complex tasks into smaller, manageable steps
   - Use clear, descriptive task names

Being proactive with task management demonstrates attentiveness and ensures you complete all requirements successfully
Remember: If you only need to make a few tool calls to complete a task, and it is clear what you need to do, it is better to just do the task directly and NOT call this tool at all.`;
var TODO_LIST_MIDDLEWARE_SYSTEM_PROMPT = `## \`write_todos\`

You have access to the \`write_todos\` tool to help you manage and plan complex objectives. 
Use this tool for complex objectives to ensure that you are tracking each necessary step and giving the user visibility into your progress.
This tool is very helpful for planning complex objectives, and for breaking down these larger complex objectives into smaller steps.

It is critical that you mark todos as completed as soon as you are done with a step. Do not batch up multiple steps before marking them as completed.
For simple objectives that only require a few steps, it is better to just complete the objective directly and NOT use this tool.
Writing todos takes time and tokens, use it when it is helpful for managing complex many-step problems! But not for simple few-step requests.

## Important To-Do List Usage Notes to Remember
- The \`write_todos\` tool should never be called multiple times in parallel.
- Don't be afraid to revise the To-Do list as you go. New information may reveal new tasks that need to be done, or old tasks that are irrelevant.`;
var TodoStatus = external_exports.enum([
  "pending",
  "in_progress",
  "completed"
]).describe("Status of the todo");
var TodoSchema = external_exports.object({
  content: external_exports.string().describe("Content of the todo item"),
  status: TodoStatus
});
var stateSchema2 = external_exports.object({ todos: external_exports.array(TodoSchema).default([]) });
function todoListMiddleware(options) {
  const writeTodos = tool(({ todos }, config2) => {
    return new Command({ update: {
      todos,
      messages: [new ToolMessage({
        content: `Updated todo list to ${JSON.stringify(todos)}`,
        tool_call_id: config2.toolCall?.id
      })]
    } });
  }, {
    name: "write_todos",
    description: options?.toolDescription ?? WRITE_TODOS_DESCRIPTION,
    schema: external_exports.object({ todos: external_exports.array(TodoSchema).describe("List of todo items to update") })
  });
  return createMiddleware({
    name: "todoListMiddleware",
    stateSchema: stateSchema2,
    tools: [writeTodos],
    wrapModelCall: (request, handler) => handler({
      ...request,
      systemMessage: request.systemMessage.concat(`

${options?.systemPrompt ?? TODO_LIST_MIDDLEWARE_SYSTEM_PROMPT}`)
    }),
    afterModel: (state) => {
      const messages = state.messages;
      if (!messages || messages.length === 0) return void 0;
      const lastAiMsg = [...messages].reverse().find((msg) => AIMessage.isInstance(msg));
      if (!lastAiMsg || !lastAiMsg.tool_calls || lastAiMsg.tool_calls.length === 0) return void 0;
      const writeTodosCalls = lastAiMsg.tool_calls.filter((tc) => tc.name === writeTodos.name);
      if (writeTodosCalls.length > 1) {
        const errorMessages = writeTodosCalls.map((tc) => new ToolMessage({
          content: "Error: The `write_todos` tool should never be called multiple times in parallel. Please call it only once per model invocation to update the todo list.",
          tool_call_id: tc.id,
          status: "error"
        }));
        return { messages: errorMessages };
      }
      return void 0;
    }
  });
}

// node_modules/langchain/dist/agents/middleware/modelCallLimit.js
var DEFAULT_EXIT_BEHAVIOR2 = "end";
var contextSchema5 = external_exports.object({
  threadLimit: external_exports.number().optional(),
  runLimit: external_exports.number().optional(),
  exitBehavior: external_exports.enum(["error", "end"]).optional()
});
var stateSchema3 = external_exports.object({
  threadModelCallCount: external_exports.number().default(0),
  runModelCallCount: external_exports.number().default(0)
});
var ModelCallLimitMiddlewareError = class extends Error {
  constructor({ threadLimit, runLimit, threadCount, runCount }) {
    const exceededHint = [];
    if (typeof threadLimit === "number" && typeof threadCount === "number") exceededHint.push(`thread level call limit reached with ${threadCount} model calls`);
    if (typeof runLimit === "number" && typeof runCount === "number") exceededHint.push(`run level call limit reached with ${runCount} model calls`);
    super(`Model call limits exceeded${exceededHint.length > 0 ? `: ${exceededHint.join(", ")}` : ""}`);
    this.name = "ModelCallLimitMiddlewareError";
  }
};
function modelCallLimitMiddleware(middlewareOptions) {
  return createMiddleware({
    name: "ModelCallLimitMiddleware",
    contextSchema: contextSchema5,
    stateSchema: stateSchema3,
    beforeModel: {
      canJumpTo: ["end"],
      hook: (state, runtime) => {
        let exitBehavior = runtime.context.exitBehavior ?? middlewareOptions?.exitBehavior ?? DEFAULT_EXIT_BEHAVIOR2;
        if (exitBehavior === "throw") {
          console.warn("The 'throw' exit behavior is deprecated. Please use 'error' instead.");
          exitBehavior = "error";
        }
        const threadLimit = runtime.context.threadLimit ?? middlewareOptions?.threadLimit;
        const runLimit = runtime.context.runLimit ?? middlewareOptions?.runLimit;
        const threadCount = state.threadModelCallCount;
        const runCount = state.runModelCallCount;
        if (typeof threadLimit === "number" && threadLimit <= threadCount) {
          const error = new ModelCallLimitMiddlewareError({
            threadLimit,
            threadCount
          });
          if (exitBehavior === "end") return {
            jumpTo: "end",
            messages: [new AIMessage(error.message)]
          };
          throw error;
        }
        if (typeof runLimit === "number" && runLimit <= runCount) {
          const error = new ModelCallLimitMiddlewareError({
            runLimit,
            runCount
          });
          if (exitBehavior === "end") return {
            jumpTo: "end",
            messages: [new AIMessage(error.message)]
          };
          throw error;
        }
        return state;
      }
    },
    afterModel: (state) => ({
      runModelCallCount: state.runModelCallCount + 1,
      threadModelCallCount: state.threadModelCallCount + 1
    }),
    afterAgent: () => ({ runModelCallCount: 0 })
  });
}

// node_modules/langchain/dist/agents/middleware/modelFallback.js
function modelFallbackMiddleware(...fallbackModels) {
  return createMiddleware({
    name: "modelFallbackMiddleware",
    wrapModelCall: async (request, handler) => {
      try {
        return await handler(request);
      } catch (error) {
        for (let i = 0; i < fallbackModels.length; i++) try {
          const fallbackModel = fallbackModels[i];
          const model = typeof fallbackModel === "string" ? await initChatModel(fallbackModel) : fallbackModel;
          return await handler({
            ...request,
            model
          });
        } catch (fallbackError) {
          if (i === fallbackModels.length - 1) throw fallbackError;
        }
        throw error;
      }
    }
  });
}

// node_modules/langchain/dist/agents/middleware/constants.js
var RetrySchema = external_exports.object({
  maxRetries: external_exports.number().min(0).default(2),
  retryOn: external_exports.union([external_exports.function().args(external_exports.instanceof(Error)).returns(external_exports.boolean()), external_exports.array(external_exports.custom())]).default(() => () => true),
  backoffFactor: external_exports.number().min(0).default(2),
  initialDelayMs: external_exports.number().min(0).default(1e3),
  maxDelayMs: external_exports.number().min(0).default(6e4),
  jitter: external_exports.boolean().default(true)
});

// node_modules/langchain/dist/agents/middleware/error.js
var InvalidRetryConfigError = class extends Error {
  cause;
  constructor(error) {
    const message = external_exports2.prettifyError(error).slice(2);
    super(message);
    this.name = "InvalidRetryConfigError";
    this.cause = error;
  }
};

// node_modules/langchain/dist/agents/middleware/modelRetry.js
var ModelRetryMiddlewareOptionsSchema = external_exports.object({ onFailure: external_exports.union([
  external_exports.literal("error"),
  external_exports.literal("continue"),
  external_exports.function().args(external_exports.instanceof(Error)).returns(external_exports.string())
]).default("continue") }).merge(RetrySchema);
function modelRetryMiddleware(config2 = {}) {
  const { success: success2, error, data } = ModelRetryMiddlewareOptionsSchema.safeParse(config2);
  if (!success2) throw new InvalidRetryConfigError(error);
  const { maxRetries, retryOn, onFailure, backoffFactor, initialDelayMs, maxDelayMs, jitter } = data;
  const shouldRetryException = (error$1) => {
    if (typeof retryOn === "function") return retryOn(error$1);
    return retryOn.some((ErrorConstructor) => error$1.constructor === ErrorConstructor);
  };
  const delayConfig = {
    backoffFactor,
    initialDelayMs,
    maxDelayMs,
    jitter
  };
  const formatFailureMessage = (error$1, attemptsMade) => {
    const errorType = error$1.constructor.name;
    const attemptWord = attemptsMade === 1 ? "attempt" : "attempts";
    return `Model call failed after ${attemptsMade} ${attemptWord} with ${errorType}: ${error$1.message}`;
  };
  const handleFailure = (error$1, attemptsMade) => {
    if (onFailure === "error") throw error$1;
    let content;
    if (typeof onFailure === "function") content = onFailure(error$1);
    else content = formatFailureMessage(error$1, attemptsMade);
    return new AIMessage({ content });
  };
  return createMiddleware({
    name: "modelRetryMiddleware",
    contextSchema: ModelRetryMiddlewareOptionsSchema,
    wrapModelCall: async (request, handler) => {
      for (let attempt = 0; attempt <= maxRetries; attempt++) try {
        return await handler(request);
      } catch (error$1) {
        const attemptsMade = attempt + 1;
        const err = error$1 && typeof error$1 === "object" && "message" in error$1 ? error$1 : new Error(String(error$1));
        if (!shouldRetryException(err)) return handleFailure(err, attemptsMade);
        if (attempt < maxRetries) {
          const delay = calculateRetryDelay(delayConfig, attempt);
          if (delay > 0) await sleep(delay);
        } else return handleFailure(err, attemptsMade);
      }
      throw new Error("Unexpected: retry loop completed without returning");
    }
  });
}

// node_modules/langchain/dist/agents/middleware/toolRetry.js
var ToolRetryMiddlewareOptionsSchema = external_exports.object({
  tools: external_exports.array(external_exports.union([
    external_exports.custom(),
    external_exports.custom(),
    external_exports.string()
  ])).optional(),
  onFailure: external_exports.union([
    external_exports.literal("error"),
    external_exports.literal("continue"),
    external_exports.literal("raise"),
    external_exports.literal("return_message"),
    external_exports.function().args(external_exports.instanceof(Error)).returns(external_exports.string())
  ]).default("continue")
}).merge(RetrySchema);
function toolRetryMiddleware(config2 = {}) {
  const { success: success2, error, data } = ToolRetryMiddlewareOptionsSchema.safeParse(config2);
  if (!success2) throw new InvalidRetryConfigError(error);
  const { maxRetries, tools, retryOn, onFailure: onFailureConfig, backoffFactor, initialDelayMs, maxDelayMs, jitter } = data;
  let onFailure = onFailureConfig;
  if (onFailureConfig === "raise") {
    console.warn(" `onFailure: 'raise'` is deprecated. Use `onFailure: 'error'` instead.");
    onFailure = "error";
  } else if (onFailureConfig === "return_message") {
    console.warn(" `onFailure: 'return_message'` is deprecated. Use `onFailure: 'continue'` instead.");
    onFailure = "continue";
  }
  const toolFilter = [];
  for (const tool2 of tools ?? []) if (typeof tool2 === "string") toolFilter.push(tool2);
  else if ("name" in tool2 && typeof tool2.name === "string") toolFilter.push(tool2.name);
  else throw new TypeError("Expected a tool name string or tool instance to be passed to toolRetryMiddleware");
  const shouldRetryTool = (toolName) => {
    if (toolFilter.length === 0) return true;
    return toolFilter.includes(toolName);
  };
  const shouldRetryException = (error$1) => {
    if (typeof retryOn === "function") return retryOn(error$1);
    return retryOn.some((ErrorConstructor) => {
      return error$1 instanceof ErrorConstructor;
    });
  };
  const delayConfig = {
    backoffFactor,
    initialDelayMs,
    maxDelayMs,
    jitter
  };
  const formatFailureMessage = (toolName, error$1, attemptsMade) => {
    const errorType = error$1.constructor.name;
    const attemptWord = attemptsMade === 1 ? "attempt" : "attempts";
    return `Tool '${toolName}' failed after ${attemptsMade} ${attemptWord} with ${errorType}`;
  };
  const handleFailure = (toolName, toolCallId, error$1, attemptsMade) => {
    if (onFailure === "error") throw error$1;
    let content;
    if (typeof onFailure === "function") content = onFailure(error$1);
    else content = formatFailureMessage(toolName, error$1, attemptsMade);
    return new ToolMessage({
      content,
      tool_call_id: toolCallId,
      name: toolName,
      status: "error"
    });
  };
  return createMiddleware({
    name: "toolRetryMiddleware",
    contextSchema: ToolRetryMiddlewareOptionsSchema,
    wrapToolCall: async (request, handler) => {
      const toolName = request.tool?.name ?? request.toolCall.name;
      if (!shouldRetryTool(toolName)) return handler(request);
      const toolCallId = request.toolCall.id ?? "";
      for (let attempt = 0; attempt <= maxRetries; attempt++) try {
        return await handler(request);
      } catch (error$1) {
        const attemptsMade = attempt + 1;
        const err = error$1 && typeof error$1 === "object" && "message" in error$1 ? error$1 : new Error(String(error$1));
        if (!shouldRetryException(err)) return handleFailure(toolName, toolCallId, err, attemptsMade);
        if (attempt < maxRetries) {
          const delay = calculateRetryDelay(delayConfig, attempt);
          if (delay > 0) await sleep(delay);
        } else return handleFailure(toolName, toolCallId, err, attemptsMade);
      }
      throw new Error("Unexpected: retry loop completed without returning");
    }
  });
}

// node_modules/langchain/dist/agents/middleware/toolEmulator.js
function toolEmulatorMiddleware(options = {}) {
  let agentModel;
  const { tools, model } = options;
  const emulateAll = !tools || tools.length === 0;
  const toolsToEmulate = /* @__PURE__ */ new Set();
  if (!emulateAll && tools) for (const tool2 of tools) if (typeof tool2 === "string") toolsToEmulate.add(tool2);
  else {
    const toolName = typeof tool2.name === "string" ? tool2.name : String(tool2.name);
    toolsToEmulate.add(toolName);
  }
  let emulatorModel;
  const getEmulatorModel = async () => {
    if (typeof model === "object") return model;
    if (typeof model === "string") {
      emulatorModel = emulatorModel ?? await initChatModel(model, { temperature: 1 }).catch((err) => {
        console.error("Error initializing emulator model, using agent model:", err);
        return agentModel;
      });
      return emulatorModel;
    }
    return agentModel;
  };
  return createMiddleware({
    name: "ToolEmulatorMiddleware",
    wrapModelCall: async (request, handler) => {
      agentModel = request.model;
      return handler(request);
    },
    wrapToolCall: async (request, handler) => {
      const toolName = request.toolCall.name;
      const shouldEmulate = emulateAll || toolsToEmulate.has(toolName);
      if (!shouldEmulate) return handler(request);
      const toolArgs = request.toolCall.args;
      const toolDescription = request.tool?.description || "No description available";
      const toolArgsString = typeof toolArgs === "string" ? toolArgs : JSON.stringify(toolArgs);
      const prompt = `You are emulating a tool call for testing purposes.

Tool: ${toolName}
Description: ${toolDescription}
Arguments: ${toolArgsString}

Generate a realistic response that this tool would return given these arguments.
Return ONLY the tool's output, no explanation or preamble. Introduce variation into your responses.`;
      const emulator = await getEmulatorModel();
      const response = await emulator.invoke([new HumanMessage(prompt)]);
      const content = typeof response.content === "string" ? response.content : JSON.stringify(response.content);
      return new ToolMessage({
        content,
        tool_call_id: request.toolCall.id ?? "",
        name: toolName
      });
    }
  });
}

// node_modules/langchain/dist/agents/middleware/provider/openai/moderation.js
function isOpenAIModel(model) {
  if (!model || typeof model !== "object" || model === null || !("client" in model) || !("_getClientOptions" in model) || typeof model._getClientOptions !== "function") return false;
  model._getClientOptions();
  return typeof model.client === "object" && model.client !== null && "moderations" in model.client && typeof model.client.moderations === "object" && model.client.moderations !== null && "create" in model.client.moderations && typeof model.client.moderations.create === "function";
}
var DEFAULT_VIOLATION_TEMPLATE = "I'm sorry, but I can't comply with that request. It was flagged for {categories}.";
var OpenAIModerationError = class extends Error {
  content;
  stage;
  result;
  originalMessage;
  constructor({ content, stage, result, message }) {
    super(message);
    this.name = "OpenAIModerationError";
    this.content = content;
    this.stage = stage;
    this.result = result;
    this.originalMessage = message;
  }
};
function openAIModerationMiddleware(options) {
  const { model, moderationModel = "omni-moderation-latest", checkInput = true, checkOutput = true, checkToolResults = false, exitBehavior = "end", violationMessage } = options;
  let openaiModel;
  const initModerationModel = async () => {
    if (openaiModel) return openaiModel;
    const resolvedModel = typeof model === "string" ? await initChatModel(model) : model;
    if (!resolvedModel.getName().includes("ChatOpenAI")) throw new Error(`Model must be an OpenAI model to use moderation middleware. Got: ${resolvedModel.getName()}`);
    if (!isOpenAIModel(resolvedModel)) throw new Error("Model must support moderation to use moderation middleware.");
    openaiModel = resolvedModel;
    return openaiModel;
  };
  const extractText = (message) => {
    if (message.content == null) return null;
    const text = message.text;
    return text || null;
  };
  const findLastIndex = (messages, messageType) => {
    for (let idx = messages.length - 1; idx >= 0; idx--) if (messageType.isInstance(messages[idx])) return idx;
    return null;
  };
  const formatViolationMessage = (content, result) => {
    const categories = [];
    const categoriesObj = result.categories;
    for (const [name, flagged] of Object.entries(categoriesObj)) if (flagged) categories.push(name.replace(/_/g, " "));
    const categoryLabel = categories.length > 0 ? categories.join(", ") : "OpenAI's safety policies";
    const template = violationMessage || DEFAULT_VIOLATION_TEMPLATE;
    const scoresJson = JSON.stringify(result.category_scores, null, 2);
    try {
      return template.replace("{categories}", categoryLabel).replace("{category_scores}", scoresJson).replace("{original_content}", content);
    } catch {
      return template;
    }
  };
  function moderateContent(input, params) {
    const clientOptions = openaiModel?._getClientOptions?.();
    const moderationModel$1 = params?.model ?? "omni-moderation-latest";
    const moderationRequest = {
      input,
      model: moderationModel$1
    };
    return openaiModel.client.moderations.create(moderationRequest, clientOptions);
  }
  const applyViolation = (messages, index2, stage, content, result) => {
    const violationText = formatViolationMessage(content, result);
    if (exitBehavior === "error") throw new OpenAIModerationError({
      content,
      stage,
      result,
      message: violationText
    });
    if (exitBehavior === "end") return {
      jumpTo: "end",
      messages: [new AIMessage({ content: violationText })]
    };
    if (index2 == null) return void 0;
    const newMessages = [...messages];
    const original = newMessages[index2];
    const MessageConstructor = Object.getPrototypeOf(original).constructor;
    newMessages[index2] = new MessageConstructor({
      ...original,
      content: violationText
    });
    return { messages: newMessages };
  };
  const moderateUserMessage = async (messages) => {
    const idx = findLastIndex(messages, HumanMessage);
    if (idx == null) return null;
    const message = messages[idx];
    const text = extractText(message);
    if (!text) return null;
    await initModerationModel();
    const response = await moderateContent(text, { model: moderationModel });
    const flaggedResult = response.results.find((result) => result.flagged);
    if (!flaggedResult) return null;
    return applyViolation(messages, idx, "input", text, flaggedResult);
  };
  const moderateToolMessages = async (messages) => {
    const lastAiIdx = findLastIndex(messages, AIMessage);
    if (lastAiIdx == null) return null;
    const working = [...messages];
    let modified = false;
    for (let idx = lastAiIdx + 1; idx < working.length; idx++) {
      const msg = working[idx];
      if (!ToolMessage.isInstance(msg)) continue;
      const text = extractText(msg);
      if (!text) continue;
      await initModerationModel();
      const response = await moderateContent(text, { model: moderationModel });
      const flaggedResult = response.results.find((result) => result.flagged);
      if (!flaggedResult) continue;
      const action = applyViolation(working, idx, "tool", text, flaggedResult);
      if (action) {
        if ("jumpTo" in action) return action;
        if ("messages" in action) {
          working.splice(0, working.length, ...action.messages);
          modified = true;
        }
      }
    }
    if (modified) return { messages: working };
    return null;
  };
  const moderateOutput = async (messages) => {
    const lastAiIdx = findLastIndex(messages, AIMessage);
    if (lastAiIdx == null) return null;
    const aiMessage = messages[lastAiIdx];
    const text = extractText(aiMessage);
    if (!text) return null;
    await initModerationModel();
    const response = await moderateContent(text, { model: moderationModel });
    const flaggedResult = response.results.find((result) => result.flagged);
    if (!flaggedResult) return null;
    return applyViolation(messages, lastAiIdx, "output", text, flaggedResult);
  };
  const moderateInputs = async (messages) => {
    const working = [...messages];
    let modified = false;
    if (checkToolResults) {
      const action = await moderateToolMessages(working);
      if (action) {
        if ("jumpTo" in action) return action;
        if ("messages" in action) {
          working.splice(0, working.length, ...action.messages);
          modified = true;
        }
      }
    }
    if (checkInput) {
      const action = await moderateUserMessage(working);
      if (action) {
        if ("jumpTo" in action) return action;
        if ("messages" in action) {
          working.splice(0, working.length, ...action.messages);
          modified = true;
        }
      }
    }
    if (modified) return { messages: working };
    return null;
  };
  return createMiddleware({
    name: "OpenAIModerationMiddleware",
    beforeModel: {
      hook: async (state) => {
        if (!checkInput && !checkToolResults) return void 0;
        const messages = state.messages || [];
        if (messages.length === 0) return void 0;
        return await moderateInputs(messages) ?? void 0;
      },
      canJumpTo: ["end"]
    },
    afterModel: {
      hook: async (state) => {
        if (!checkOutput) return void 0;
        const messages = state.messages || [];
        if (messages.length === 0) return void 0;
        return await moderateOutput(messages) ?? void 0;
      },
      canJumpTo: ["end"]
    }
  });
}

// node_modules/langchain/dist/agents/middleware/provider/anthropic/promptCaching.js
var DEFAULT_ENABLE_CACHING = true;
var DEFAULT_TTL = "5m";
var DEFAULT_MIN_MESSAGES_TO_CACHE = 3;
var DEFAULT_UNSUPPORTED_MODEL_BEHAVIOR = "warn";
var contextSchema6 = external_exports.object({
  enableCaching: external_exports.boolean().optional(),
  ttl: external_exports.enum(["5m", "1h"]).optional(),
  minMessagesToCache: external_exports.number().optional(),
  unsupportedModelBehavior: external_exports.enum([
    "ignore",
    "warn",
    "raise"
  ]).optional()
});
var PromptCachingMiddlewareError = class extends Error {
  constructor(message) {
    super(message);
    this.name = "PromptCachingMiddlewareError";
  }
};
function anthropicPromptCachingMiddleware(middlewareOptions) {
  return createMiddleware({
    name: "PromptCachingMiddleware",
    contextSchema: contextSchema6,
    wrapModelCall: (request, handler) => {
      const enableCaching = request.runtime.context.enableCaching ?? middlewareOptions?.enableCaching ?? DEFAULT_ENABLE_CACHING;
      const ttl = request.runtime.context.ttl ?? middlewareOptions?.ttl ?? DEFAULT_TTL;
      const minMessagesToCache = request.runtime.context.minMessagesToCache ?? middlewareOptions?.minMessagesToCache ?? DEFAULT_MIN_MESSAGES_TO_CACHE;
      const unsupportedModelBehavior = request.runtime.context.unsupportedModelBehavior ?? middlewareOptions?.unsupportedModelBehavior ?? DEFAULT_UNSUPPORTED_MODEL_BEHAVIOR;
      if (!enableCaching || !request.model) return handler(request);
      const isAnthropicModel = request.model.getName() === "ChatAnthropic" || request.model.getName() === "ConfigurableModel" && request.model._defaultConfig?.modelProvider === "anthropic";
      if (!isAnthropicModel) {
        const modelName = request.model.getName();
        const modelInfo = request.model.getName() === "ConfigurableModel" ? `${modelName} (${request.model._defaultConfig?.modelProvider})` : modelName;
        const baseMessage = `Unsupported model '${modelInfo}'. Prompt caching requires an Anthropic model`;
        if (unsupportedModelBehavior === "raise") throw new PromptCachingMiddlewareError(`${baseMessage} (e.g., 'anthropic:claude-4-0-sonnet').`);
        else if (unsupportedModelBehavior === "warn") console.warn(`PromptCachingMiddleware: Skipping caching for ${modelName}. Consider switching to an Anthropic model for caching benefits.`);
        return handler(request);
      }
      const messagesCount = request.state.messages.length + (request.systemPrompt ? 1 : 0);
      if (messagesCount < minMessagesToCache) return handler(request);
      return handler({
        ...request,
        modelSettings: {
          ...request.modelSettings,
          cache_control: {
            type: "ephemeral",
            ttl
          }
        }
      });
    }
  });
}

// node_modules/langchain/dist/index.js
var src_exports2 = {};
__export3(src_exports2, {
  AIMessage: () => AIMessage,
  AIMessageChunk: () => AIMessageChunk,
  BaseMessage: () => BaseMessage,
  BaseMessageChunk: () => BaseMessageChunk,
  ClearToolUsesEdit: () => ClearToolUsesEdit,
  Document: () => Document,
  DynamicStructuredTool: () => DynamicStructuredTool,
  DynamicTool: () => DynamicTool,
  FakeToolCallingModel: () => FakeToolCallingModel,
  HumanMessage: () => HumanMessage,
  HumanMessageChunk: () => HumanMessageChunk,
  InMemoryStore: () => InMemoryStore,
  MIDDLEWARE_BRAND: () => MIDDLEWARE_BRAND,
  MiddlewareError: () => MiddlewareError,
  MultipleStructuredOutputsError: () => MultipleStructuredOutputsError,
  MultipleToolsBoundError: () => MultipleToolsBoundError,
  PIIDetectionError: () => PIIDetectionError,
  ProviderStrategy: () => ProviderStrategy,
  StructuredOutputParsingError: () => StructuredOutputParsingError,
  StructuredTool: () => StructuredTool,
  SystemMessage: () => SystemMessage,
  SystemMessageChunk: () => SystemMessageChunk,
  TODO_LIST_MIDDLEWARE_SYSTEM_PROMPT: () => TODO_LIST_MIDDLEWARE_SYSTEM_PROMPT,
  Tool: () => Tool,
  ToolCallLimitExceededError: () => ToolCallLimitExceededError,
  ToolInvocationError: () => ToolInvocationError,
  ToolMessage: () => ToolMessage,
  ToolMessageChunk: () => ToolMessageChunk,
  ToolStrategy: () => ToolStrategy,
  anthropicPromptCachingMiddleware: () => anthropicPromptCachingMiddleware,
  applyStrategy: () => applyStrategy,
  context: () => context,
  contextEditingMiddleware: () => contextEditingMiddleware,
  countTokensApproximately: () => countTokensApproximately,
  createAgent: () => createAgent,
  createMiddleware: () => createMiddleware,
  detectCreditCard: () => detectCreditCard,
  detectEmail: () => detectEmail,
  detectIP: () => detectIP,
  detectMacAddress: () => detectMacAddress,
  detectUrl: () => detectUrl,
  dynamicSystemPromptMiddleware: () => dynamicSystemPromptMiddleware,
  filterMessages: () => filterMessages,
  humanInTheLoopMiddleware: () => humanInTheLoopMiddleware,
  initChatModel: () => initChatModel,
  llmToolSelectorMiddleware: () => llmToolSelectorMiddleware,
  modelCallLimitMiddleware: () => modelCallLimitMiddleware,
  modelFallbackMiddleware: () => modelFallbackMiddleware,
  modelRetryMiddleware: () => modelRetryMiddleware,
  openAIModerationMiddleware: () => openAIModerationMiddleware,
  piiMiddleware: () => piiMiddleware,
  piiRedactionMiddleware: () => piiRedactionMiddleware,
  providerStrategy: () => providerStrategy,
  resolveRedactionRule: () => resolveRedactionRule,
  summarizationMiddleware: () => summarizationMiddleware,
  todoListMiddleware: () => todoListMiddleware,
  tool: () => tool,
  toolCallLimitMiddleware: () => toolCallLimitMiddleware,
  toolEmulatorMiddleware: () => toolEmulatorMiddleware,
  toolRetryMiddleware: () => toolRetryMiddleware,
  toolStrategy: () => toolStrategy,
  trimMessages: () => trimMessages
});
export {
  AIMessage,
  AIMessageChunk,
  BaseMessage,
  BaseMessageChunk,
  ClearToolUsesEdit,
  Document,
  DynamicStructuredTool,
  DynamicTool,
  FakeToolCallingModel,
  HumanMessage,
  HumanMessageChunk,
  InMemoryStore,
  MIDDLEWARE_BRAND,
  MiddlewareError,
  MultipleStructuredOutputsError,
  MultipleToolsBoundError,
  PIIDetectionError,
  ProviderStrategy,
  StructuredOutputParsingError,
  StructuredTool,
  SystemMessage,
  SystemMessageChunk,
  TODO_LIST_MIDDLEWARE_SYSTEM_PROMPT,
  Tool,
  ToolCallLimitExceededError,
  ToolInvocationError,
  ToolMessage,
  ToolMessageChunk,
  ToolStrategy,
  anthropicPromptCachingMiddleware,
  applyStrategy,
  context,
  contextEditingMiddleware,
  countTokensApproximately,
  createAgent,
  createMiddleware,
  detectCreditCard,
  detectEmail,
  detectIP,
  detectMacAddress,
  detectUrl,
  dynamicSystemPromptMiddleware,
  filterMessages,
  humanInTheLoopMiddleware,
  initChatModel,
  llmToolSelectorMiddleware,
  modelCallLimitMiddleware,
  modelFallbackMiddleware,
  modelRetryMiddleware,
  openAIModerationMiddleware,
  piiMiddleware,
  piiRedactionMiddleware,
  providerStrategy,
  resolveRedactionRule,
  src_exports2 as src_exports,
  summarizationMiddleware,
  todoListMiddleware,
  tool,
  toolCallLimitMiddleware,
  toolEmulatorMiddleware,
  toolRetryMiddleware,
  toolStrategy,
  trimMessages
};
//# sourceMappingURL=langchain.js.map
